<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 29 Nov 2019 11:04:16 +0000</pubDate>
    <lastBuildDate>Fri, 29 Nov 2019 11:04:16 +0000</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>How We Implemented Domain-Driven Development in Golang</title>
        <description>&lt;p&gt;Partnerships have always been core to Grab’s super app strategy. We believe in collaborating with partners who are the best in what they do - combining their expertise with what we’re good at so that we can bring high-quality new services to our customers, at the same time create new opportunities for the merchant and driver-partners in our ecosystem.&lt;/p&gt;

&lt;p&gt;That’s why we launched GrabPlatform last year. To make it easier for partners to either integrate Grab into their services, or integrate their services into Grab.&lt;/p&gt;

&lt;p&gt;In view of that, part of the GrabPlatform’s team mission is to make it easy for partners to integrate with Grab services. These partners are external companies that would like to offer Grab’s services such as ride-booking through their own websites or applications. To do that, we decided to build a website that will serve as a one-stop-shop that would allow them to self-service these integrations.&lt;/p&gt;

&lt;h3 id=&quot;the-challenges-we-faced-with-the-conventional-approach&quot;&gt;The challenges we faced with the conventional approach&lt;/h3&gt;

&lt;p&gt;In the process of building this website, our team noticed that the majority of the functions and responsibilities were added to files without proper segregation. A single file would contain more than 500 lines of code. Each of these files were  imported from different collections of source codes, resulting in an unstructured codebase. Any changes to the existing functions risked breaking existing functionality; we realized then that we needed to proactively plan for the future. Hence, we decided to use the principles of &lt;a href=&quot;https://airbrake.io/blog/software-design/domain-driven-design&quot;&gt;Domain-Driven Design (DDD)&lt;/a&gt; and &lt;a href=&quot;https://golang.org/doc/effective_go.html&quot;&gt;idiomatic Go&lt;/a&gt;. This blog aims to demonstrate the process of how we leveraged those concepts to design a modern application.&lt;/p&gt;

&lt;h3 id=&quot;how-we-implemented-dddin-our-codebase&quot;&gt;How we implemented DDD in our codebase&lt;/h3&gt;

&lt;p&gt;Here’s how we went about solving our unstructured codebase using DDD principles.&lt;/p&gt;

&lt;h4 id=&quot;step-1-gather-domain-business-knowledge&quot;&gt;Step 1: Gather domain (business) knowledge&lt;/h4&gt;
&lt;p&gt;We collaborated closely with our domain experts (in our case, this was our product team) to identify functionality and flow. From them, we discovered the following key points:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;After creating a project, developers are added to the project.&lt;/li&gt;
  &lt;li&gt;The domain experts wanted an ability to add other products (e.g. Pricing service, ETA service, GrabPay service) to their projects.&lt;/li&gt;
  &lt;li&gt;They wanted the ability to create multiple authentication clients to access the above products.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-2-break-down-domain-knowledge-into-bounded-context&quot;&gt;Step 2: Break down domain knowledge into bounded context&lt;/h4&gt;
&lt;p&gt;Now that we had gathered the required domain knowledge (i.e. what our code needed to reflect to our partners), it was time to use the DDD strategic tool &lt;em&gt;Bounded Context&lt;/em&gt; to break down problems into subcontexts. Here is a graphical representation of how we converted the problem into smaller units.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Bounded Context&quot; src=&quot;/img/domain-driven-development-in-golang/image2.jpg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We identified several dependencies on each of the units involved in the project. Take some of these examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The project domain overlapped with the product and developer domains.&lt;/li&gt;
  &lt;li&gt;Our RideBooking project can only exist if it has some products like Ridebooking APIs and not the other way around.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What this means is a product can exist independent of the project, but a project will have no significance without any product. In the same way, a project is dependent on the developers, but developers can exist whether or not they belong to a project.&lt;/p&gt;

&lt;h4 id=&quot;step-3-identify-value-objects-or-entity-lowest-layer&quot;&gt;Step 3: Identify value objects or entity (lowest layer)&lt;/h4&gt;
&lt;p&gt;Looking at the above bounded contexts, we figured out the building blocks (i.e. value objects or entity) to break down the above functionality and flow.&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;// ProjectDAO ...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UUID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectStatus&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CreatedAt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// DeveloperDAO ...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UUID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PhoneHash&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CreatedAt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// ProductDAO ...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UUID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductStatus&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CreatedAt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// DeveloperProjectDAO to map developer's to a project&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProjectDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProjectStatus&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// ProductProjectDAO to map product's to a project&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductProjectDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;     &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Status&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectProductStatus&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All the objects shown above have &lt;code class=&quot;highlighter-rouge&quot;&gt;ID&lt;/code&gt; as a field and can be identifiable, hence they are identified as &lt;strong&gt;entities&lt;/strong&gt; and not as &lt;strong&gt;value objects&lt;/strong&gt;. But if we apply domain knowledge, &lt;code class=&quot;highlighter-rouge&quot;&gt;DeveloperProjectDAO&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ProductProjectDAO&lt;/code&gt; are actually not independent entities. Project object is the aggregate root since it must exist before the child fields, &lt;code class=&quot;highlighter-rouge&quot;&gt;DevProjectDAO&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ProdcutProjectDAO&lt;/code&gt;, can exist.&lt;/p&gt;

&lt;h4 id=&quot;step-4-create-the-repositories&quot;&gt;Step 4: Create the repositories&lt;/h4&gt;
&lt;p&gt;As stated above, we created an interface to abstract the working logic of a particular domain (i.e. Repository). Here is an example of how we designed the repositories:&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;// ProductRepositoryImpl responsible for product functionality&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;productDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProductDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductRepository&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProductsByIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ids&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProduct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// DeveloperRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IDeveloperDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperRepository&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FindActiveAllowedByDeveloperIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerIDs&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Developer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetDeveloperDetailByProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerProfile&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IDeveloper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is a look at how we designed our repository for aggregate root project:&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;// Unexported Struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;productProjectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;productProjectDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProjectProductDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProductProjectRepository&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetAllProjectProductByProjectID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectProduct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// Unexported Struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerProjectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerProjectDAO&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IDeveloperProjectDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProjectRepository&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetDevelopersByProjectIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectIDs&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UpdateMappingWithRole&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developer&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IDeveloper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperProject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// Unexported Struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProjectDao&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectRepository&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProjectsByIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectIDs&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetActiveProjectByUUID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProjectByUUID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectAggregatorImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerProjectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;productProjectRepositoryImpl&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// private field&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectAggregator&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProjects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddDeveloper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddDeveloperRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddDeveloperResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProjectWithProducts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IProject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;step-5-identify-domain-events&quot;&gt;Step 5: Identify Domain Events&lt;/h4&gt;

&lt;p&gt;The functions described in &lt;em&gt;Step 4&lt;/em&gt; only returns the ID of the developer and product, which conveys no information to the users. In order to provide developer and product information, we use the domain-event technique to return the actual product and developer attributes.&lt;/p&gt;

&lt;p&gt;A domain event is something that happened in a bounded context that you want another context of a domain to be aware of. For example, if there are new updates to the developer domain, it’s important to convey these updates to the project domain. This propagation technique is termed as &lt;em&gt;domain event&lt;/em&gt;. Domain events enable independence between different classes.&lt;/p&gt;

&lt;p&gt;One way to implement it is seen here:&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;// file: project\_aggregator.go&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProjectAggregatorImpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetProjects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developers&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EventHandler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DomainEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FindDeveloperByDeveloperIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeveloperIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// file: event\_type.go&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FindDeveloperByDeveloperIDs&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerID&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// file: event\_handler.go&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EventHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FindDeveloperByDeveloperIDs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerRepository&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FindDeveloperByDeveloperIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developerIDs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;developers&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Domain Event&quot; src=&quot;/img/domain-driven-development-in-golang/image1.jpg&quot; style=&quot;width:50%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;some-common-mistakes-to-avoid-when-implementing-ddd-in-your-codebase&quot;&gt;Some common mistakes to avoid when implementing DDD in your codebase:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Not engaging with domain experts. Not interacting with domain experts is a common mistake when using DDD. Talking to domain experts to get an understanding of the problem domain from their perspective is at the core of DDD. Starting with schemas or data modelling instead of talking to domain experts may create code based on a relational model instead of it built around a domain model.&lt;/li&gt;
  &lt;li&gt;Ignoring the language of the domain experts. Creating a ubiquitous language shared with domain experts is also a core DDD practice. This common language must be used in all discussions as well as in the code, e.g. in class and method names.&lt;/li&gt;
  &lt;li&gt;Not identifying bounded contexts. A common approach to solving a complex problem is breaking it down into smaller parts. Creating &lt;a href=&quot;http://martinfowler.com/bliki/BoundedContext.html&quot;&gt;bounded contexts&lt;/a&gt; is breaking down a large domain into smaller ones, each handling one cohesive part of the domain.&lt;/li&gt;
  &lt;li&gt;Using an anaemic domain model. This is a common sign that a team is not doing DDD and often a symptom of a failure in the modelling process. At first, an &lt;a href=&quot;http://www.martinfowler.com/bliki/AnemicDomainModel.html&quot;&gt;anaemic domain model&lt;/a&gt; often looks like a real domain model with correct names, but the classes lack functionalities. They contain only the &lt;code class=&quot;highlighter-rouge&quot;&gt;Get&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Set&lt;/code&gt; methods.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-the-ddd-model-improved-our-software-development&quot;&gt;How the DDD model improved our software development&lt;/h2&gt;

&lt;p&gt;Thanks to this brand new clean up, we achieved the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Core functionalities are evenly distributed to the overall codebase and not limited to just a few files.&lt;/li&gt;
  &lt;li&gt;The developers are aware of what each folder is responsible for by simply looking at the file naming and folder structure.&lt;/li&gt;
  &lt;li&gt;The risk of breaking major functionalities by merely making small changes is greatly reduced. Changing a feature is now more efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The team now finds the code well structured and we require less hand-holding for onboarders, thanks to the simplicity of the structure.&lt;/p&gt;

&lt;p&gt;Finally, the most important thing, we now have a system oriented towards our business necessities. Everyone ends up using the same language and terms. Developers communicate better with the business team. The work is more efficient when it comes to establishing solutions for the models that reflect how the business operates, instead of how the software operates.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learnt&quot;&gt;Lessons Learnt&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use DDD to collaborate among all project disciplines (product, business, partner, and so on) and clearly understand the business requirements.&lt;/li&gt;
  &lt;li&gt;Establish a ubiquitous language to discuss domain-related concepts.&lt;/li&gt;
  &lt;li&gt;Use bounded contexts to break down complex domains into manageable parts.&lt;/li&gt;
  &lt;li&gt;Implement a layered architecture (i.e. DDD building blocks) to focus on particular aspects of the application.&lt;/li&gt;
  &lt;li&gt;To simplify your dependency, use domain event to communicate with sub-bounded context.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 21 Nov 2019 11:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/domain-driven-development-in-golang</link>
        <guid isPermaLink="true">https://engineering.grab.com/domain-driven-development-in-golang</guid>
        
        <category>Backend</category>
        
        <category>Go</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Driving Southeast Asia Forward Through People-Focused Design</title>
        <description>&lt;p&gt;Southeast Asia is home to around 650 million people from diverse and comparatively different economic, political and social backgrounds. Many people in the region today rely on super apps like Grab to earn a daily living or get from A to B more efficiently and safely. This means that decisions made have real impact on people’s lives – so how do you know when your decisions are right or wrong?&lt;/p&gt;

&lt;p&gt;In this post, I’ll share key customer insights that have guided my decisions and informed my design thinking over the last year whilst working as a product designer for Grab in Singapore. I’ve broken my learnings down into 3 transient areas for thinking about product development and how each one addressed our customers’ needs.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Relevance&lt;/strong&gt; – does the design solve the customer problem? For example, loss of connectivity which is common in Southeast Asia should not completely prevent a customer from accessing the content on our app.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inclusivity&lt;/strong&gt; – does the design consider the full range of customer diversity? For example, a driver waiting in the hot sun for his passenger can still use the product. Inclusive design covers people with a range of perspectives, disabilities and environments.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Engagement&lt;/strong&gt; – does the design invoke a feeling of satisfaction? For example, building a compelling narrative around your product that solicits a higher engagement.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Under each of these areas, I’ll elaborate on how we’ve built empathy from customer insights and applied these to our design thinking.&lt;/p&gt;

&lt;p&gt;But before jumping in, think about the lens which frames any customer experience – the mobile device. In Southeast Asia, the commonly used devices are inexpensive low-end devices made by OPPO, Xiaomi, and Samsung. Knowing which devices customers use helps us understand potential performance constraints, different screen resolutions, and custom Android UIs.&lt;/p&gt;

&lt;h2 id=&quot;designing-for-relevance-&quot;&gt;Designing for relevance  &lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image5.png&quot; alt=&quot;Shopping mall in Medan, Indonesia&quot; style=&quot;width:60%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Shopping mall in Medan, Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;connectivity&quot;&gt;Connectivity&lt;/h3&gt;

&lt;p&gt;In Southeast Asia, it’s not too hard to find public WiFi. However, the main challenge is finding a reliable network. Take this shopping mall in Medan, Indonesia. The WiFi connectivity didn’t live up to the modern infrastructure of the building. The locals knew this and used mobile data over spotty and congested connectivity. Mobile data is the norm for most people and 4G reach is high, but the power of the connections is relatively low.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;To genuinely design for customers’ needs, designers at Grab regularly get out the office to understand what people are doing in the real world. But how do we integrate empathy and compassion into the design process? Throughout this article, I’ll explain how the insights we gathered from around Southeast Asia can inform your decision making process.  &lt;/p&gt;

&lt;p&gt;For simulating a loss of connectivity, switch to airplane mode to observe current UI states and limitations. If you have the resources, create a 2G network to compare how bandwidth constraints page loading speeds.&lt;a href=&quot;https://nshipster.com/network-link-conditioner&quot;&gt;Network Link Conditioner&lt;/a&gt; for Mac and iOS or &lt;a href=&quot;https://developers.google.com/web/tools/lighthouse&quot;&gt;Lighthouse&lt;/a&gt; by Chrome DevTools can replicate a slower network.&lt;/p&gt;

&lt;h4 id=&quot;design-implications&quot;&gt;Design implications&lt;/h4&gt;

&lt;p&gt;This diagram is from Scott Hurff’s book, &lt;a href=&quot;https://smile.amazon.com/Designing-Products-People-Love-Successful/dp/1491923679/ref%3Dsmi_www_rco2_go_smi_g5171374337?_encoding%3DUTF8%26%252AVersion%252A%3D1%26%252Aentries%252A%3D0%26ie%3DUTF8&quot;&gt;Designing Products People Love&lt;/a&gt;. The book is amazing, but if you don’t have the time to read it, &lt;a href=&quot;http://scotthurff.com/posts/why-your-user-interface-is-awkward-youre-ignoring-the-ui-stack&quot;&gt;this article&lt;/a&gt; offers a quick overview.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image6.png&quot; alt=&quot;Scott Hurff’s UI Stack&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Scott Hurff’s UI Stack&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;An ideal state (the fully loaded experience) is primarily what a lot of designers think about when problem-solving. However, when connectivity is a common customer pain-point, designers at Grab have to design for the less desirable: Blank, Loading, Partial, and Error states in tandem with all the happy paths. Latency can make or break the user experience, so buffer wait times with visual progress to cushion each millisecond. Loading skeletons when you open Grab, act as momentary placeholders for content and reduce the perceived latency to load the full experience.&lt;/p&gt;

&lt;p&gt;A loss of connectivity shouldn’t mean the end of your product’s experience. Prepare connectivity issues by keeping screens alive through intuitive visual cues, messaging, and cached content.&lt;/p&gt;

&lt;h3 id=&quot;device-type-and-condition&quot;&gt;Device type and condition&lt;/h3&gt;

&lt;p&gt;In Southeast Asia, people tend to opt for low-end or hand-me-down devices that can sometimes have cracked screens or depleting batteries. These devices are usually in circulation much longer than in developed markets, and the device’s OS might not be the latest version because of the perceived effort or risk to update.  &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image1.png&quot; alt=&quot;A driver’s device taken during research in Indonesia&quot; style=&quot;width:50%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A driver’s device taken during research in Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;building-empathy-1&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;At Grab, we often use a range of popular, in-market devices to understand compatibility during the design process. Installing mainstream apps to a device with a small screen size, 512MB internal memory, low resolution and depleting battery life will provide insights into performance.  If these apps have lite versions or &lt;a href=&quot;https://developers.google.com/web/progressive-web-apps&quot;&gt;Progressive Web Apps (PWA)&lt;/a&gt;, try to understand the trade-offs in user experience compared to the parent app.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image4.png&quot; alt=&quot;Grab’s passenger app on the left versus the driver app&quot; style=&quot;width:100%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Grab’s passenger app on the left versus the driver app&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;design-implications-1&quot;&gt;Design implications&lt;/h4&gt;

&lt;p&gt;Design for small screens first to reduce the chances of design debt later in the development lifecycle. For interactive elements, it’s important to think about all types of customers that will use the product and in what circumstances. For Grab’s driver-partners who may have their devices mounted to the dashboard, tap targets need to be larger and more explicit.  &lt;/p&gt;

&lt;p&gt;Similarly, color contrast will vary depending on screen resolution and time of the day. Practical tests involve dimming the screen and standing near a window in bright sunshine (our HQ is in Singapore which helps!). To further improve accessibility, use a tool like Sketch’s &lt;a href=&quot;https://www.getstark.co&quot;&gt;Stark plugin&lt;/a&gt; to understand if contrast ratios are accessible to visually impaired customers. A general rule is to aim for higher contrast between essential UI components, text and interactive affordances.&lt;/p&gt;

&lt;p&gt;Fancy transitions can look great on high-end devices but can appear choppy or delayed on older and less performant phones. Aim for simple animations to offer a more seamless experience.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image3.gif&quot; alt=&quot;Passenger verification to improve safety&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Passenger verification to improve safety&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;day-to-day-budgeting&quot;&gt;Day-to-day budgeting&lt;/h3&gt;

&lt;p&gt;Many people in Southeast Asia earn a daily income, so it’s no surprise that prepaid mobile is more common over a monthly contract. This mindset to ration on a day-to-day basis also extends itself to other essentials like washing powder and nappies. Data can be an expensive necessity, and customers are selective over the types of content that will consume a daily or weekly budget. Some customers might turn off data after getting a ride, and not turn it back on until another Grab service is required.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy-2&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;Rationing data consumption daily can be achieved through not connecting to WiFi, or a more granular way is to turn off WiFi and use an app like Google’s Datally on Android to cap data usage. Starting low, around 50MB per day will increase your understanding around the data trade-offs you make and highlight the apps that require more data to perform certain actions.&lt;/p&gt;

&lt;h4 id=&quot;design-implications-2&quot;&gt;Design implications&lt;/h4&gt;

&lt;p&gt;Where possible, avoid using video when SVG animations can be just as effective, scalable and lightweight. For Grab’s passenger verification flow, we decided to move away from a video tutorial and keep data consumption to a minimum through utilising SVG animations. When a video experience is required, like Grab’s feed on the home screen, disabling autoplay and clearly distinguishing the media as video allowed customers to decide on committing data.&lt;/p&gt;

&lt;h2 id=&quot;design-for-inclusivity-&quot;&gt;Design for inclusivity  &lt;/h2&gt;
&lt;h3 id=&quot;mobile-only&quot;&gt;Mobile-only&lt;/h3&gt;

&lt;p&gt;The expression “mobile-first” has been bounced around for the last decade, but in Southeast Asia, “mobile-only” is probably more accurate. Most customers have never owned a tablet or laptop, and mobile numbers are more synonymous with a method of registration over an email address. In the region, people rely more on social media and chat apps to understand broadcast or published news reports, events and recommendations. Customers who sign up for a new Grab account, prefer phone numbers and OTP (one-time-password) registration over providing an email address and password. And anecdotally from interviews conducted at Grab, customers didn’t feel the need for email when communication can take place via SMS, WhatsApp, or other messaging apps.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy-3&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;At Grab, we apply design thinking from a mobile-only perspective for our passenger, merchant,  and driver-partner experiences by understanding our customers’ journeys online and off.  These journeys are synthesized back in the office and sometimes recreated with video and physical artifacts to simulate the customer experience. It’s always helpful to remove smartwatches, put away laptops and use an in-market device that offers a similar experience to your customers.&lt;/p&gt;

&lt;h4 id=&quot;design-implications-3&quot;&gt;Design implications&lt;/h4&gt;

&lt;p&gt;When onboarding new customers, offer a relevant sign-in method for a mobile-only customer, like phone number and social account registration. Grab’s passenger sign-up experience addresses these priorities with phone number first, social accounts second.  &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image7.png&quot; alt=&quot;Grab’s sign-in screen&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Grab’s sign-in screen&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;PC-era icons are also widely misunderstood by mobile-only customers, so avoid floppy disks to imply Save, or a folder to Change Directory as these offer little symbolic meaning. When icons are paired with text, this can often reinforce meaning and quicken recognition.  For example, a pencil icon alone can be confusing, so adding the word “Edit” will provide more clarity.  &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image9.jpg&quot; alt=&quot;Nightfall in Yogyakarta, Indonesia&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Nightfall in Yogyakarta, Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;diversity-and-safety&quot;&gt;Diversity and safety&lt;/h3&gt;

&lt;p&gt;This photo was taken in Yogyakarta, Indonesia. In the evening, women often formed groups to improve personal safety. In an online environment, women often face discrimination, harassment, blackmail, cyberstalking, and more.  Minorities in emerging markets are further marginalised due to employment, literacy, and financial issues.  &lt;/p&gt;

&lt;h4 id=&quot;building-empathy-4&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;Southeast Asia has a very diverse population, and it’s important to understand gender, ethnic,  and class demographics before you plan any research. Research recruitment at Grab involves working with local vendors to recruit diverse groups of customers for interviews and focus groups. When spending time with customers, we try to understand how diversity and safety factors contribute to the experience of the product.&lt;/p&gt;

&lt;p&gt;If you don’t have the time and resources to arrange face-to-face interviews, I’d recommend this article for creating a survey: &lt;a href=&quot;https://medium.com/@anna.sarai.rosenberg/respectful-collection-of-demographic-data-56de9fcb80e2&quot;&gt;Respectful Collection of Demographic Data&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;design-for-inclusivity&quot;&gt;Design for inclusivity&lt;/h4&gt;

&lt;p&gt;Allow people to control how they represent their identities through pseudonym names and avatars. But does this undermine trust on the platform? No, not really. Credit card registration or more recently, Grab’s passenger and driver selfie verification feature has closed the loop on suspect accounts whilst maintaining everyone’s privacy and safety.  &lt;/p&gt;

&lt;p&gt;On the visual design side, our illustration and content guide incorporates diverse representations of ethnic backgrounds, clothing, physical ability, and social class. You can see examples in the app or through our &lt;a href=&quot;https://dribbble.com/grab&quot;&gt;Dribbble page&lt;/a&gt;. For user-generated content, allow people to report and flag abusive material. While data and algorithms can do so much, facts and ethics cannot be policed by machine learning.&lt;/p&gt;

&lt;h3 id=&quot;language&quot;&gt;Language&lt;/h3&gt;

&lt;p&gt;In Southeast Asia and other emerging markets, customers may set their phone to a language which they aspire to learn but may not fully comprehend. Swipe, tap, drag, pinch, and other specific terms relating to interactions might not easily translate into the local language, and English might be the preferred language regardless of comprehension. It’s surprisingly common to attend an interview with a translator but the device’s UI is set to English.  &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image2.jpg&quot; alt=&quot;A Grab pick-up point taken in Medan, Indonesia&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A Grab pick-up point taken in Medan, Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;building-empathy-5&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;If your app supports multiple languages, try setting your phone to a different language but know how to change it back again!  At Grab, we test design robustness by incorporating translated text strings into our mocks. Look for visual cues to infer meaning since some customers might be illiterate or not fully comprehend English.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image8.png&quot; alt=&quot;Grab’s Safety Centre in different languages&quot; style=&quot;width:100%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Grab’s Safety Centre in different languages&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;design-for-different-languages-formats-and-visual-cues&quot;&gt;Design for different languages, formats and visual cues&lt;/h4&gt;

&lt;p&gt;To reduce design debt later on, it’s a good idea to start with the smallest screen size and test the most vulnerable parts of the UI with translated text strings. Keep in mind, dates, times, addresses, and phone numbers may have different formats and require special attention. You can apply multiple visual cues to represent important UI states, such as a change in colour, shape and imagery.&lt;/p&gt;

&lt;h2 id=&quot;design-for-engagement&quot;&gt;Design for engagement&lt;/h2&gt;
&lt;h3 id=&quot;sharing&quot;&gt;Sharing&lt;/h3&gt;

&lt;p&gt;From our research studies, word-of-mouth communication and consuming viral content via Instagram or Facebook was more popular than trawling through search page results. The social aspect is extended to the physical environment where devices can sometimes be shared with more than one person, or in some cases, one mobile is used concurrently with more than one user at a time. In numerous interviews, customers talk about not using biometric authentication so that family members can access their devices.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy-6&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;To understand the layers of personalisation, privacy and security on a device, it’s worth loaning a device from your research team or just borrow a friend’s phone (if they let you!).  How far do you get before you require biometric authentication or a PIN to proceed further? If you decide to wipe a personal device, what steps can you miss out from the setup, and how does that affect your experience post setup?&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image11.png&quot; alt=&quot;Offline to Online: GrabNow connecting with driver&quot; style=&quot;width:60%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Offline to Online: GrabNow connecting with driver&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;design-for-sharing&quot;&gt;Design for sharing&lt;/h4&gt;

&lt;p&gt;If necessary, facilitate device sharing through easy switching of accounts, and enable people to remove or hide private content after use. Allow content to be easily shared for both online and offline in-person situations. Using this approach, &lt;a href=&quot;https://www.grab.com/id/en/press/tech-product/grab-resmi-luncurkan-grabnow-jalan-pintas-berkendara-dengan-grabbike&quot;&gt;GrabNow&lt;/a&gt; allows passengers to find and connect with a nearby driver without having to pre-book and wait for a driver to arrive. This offline to online interaction also saves data and battery for the customer.&lt;/p&gt;

&lt;h3 id=&quot;support-and-tutoring&quot;&gt;Support and tutoring&lt;/h3&gt;

&lt;p&gt;In Southeast Asia, people find troubleshooting issues from inside a help page troublesome and generally prefer human assistance, like speaking to someone through a call centre. The opportunity for face-to-face tutoring on how something works is often highly desired and is much more effective than standard onboarding flows that many apps use. From the many physical phone stores, it’s not uncommon for people to go and ask for help or get apps manually installed onto their device.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy-7&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;Apart from speaking with your customers regularly, always look through the Play and App Store reviews for common issues. Understand your customers’ problems and the jargon they use to describe what happened. If you have a customer support team, the tickets created will be a key indicator of where your customers need the most support.&lt;/p&gt;

&lt;h4 id=&quot;help-and-feedback-design-implications&quot;&gt;Help and Feedback Design implications&lt;/h4&gt;

&lt;p&gt;Make support accessible through a variety of methods: online forms, email, and if possible, allow customers to call in. With in-app or online forms, try to use drop-downs or pre-populated quick responses to reduce typing, triage the type of support, and decrease misunderstanding when a request comes in.  When a customer makes a Grab transport booking for the first time, we assist the customer through step-by-step contextual call-outs.&lt;/p&gt;

&lt;h3 id=&quot;local-aesthetics&quot;&gt;Local aesthetics&lt;/h3&gt;

&lt;p&gt;This photo was taken in Medan, Indonesia, on the day of an important wedding. It was impressive to see hundreds of handcrafted, colourful placards lining the streets for miles, but maybe more admirable that such an occasion was shared with the community and passers-by, and not only for the wedding guests.  &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
    &lt;img src=&quot;/img/driving-sea-forward-through-people-focused-design/image10.jpg&quot; alt=&quot;A wedding celebration flower board in Medan, Indonesia&quot; style=&quot;width:70%&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A wedding celebration flower board in Medan, Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;These types of public displays are not exclusive to weddings in Southeast Asia, vibrant colours and decorative patterns are woven into the fabric of everyday life, indicative of a jovial spirit that many people in the region possess.&lt;/p&gt;

&lt;h4 id=&quot;building-empathy-8&quot;&gt;Building empathy&lt;/h4&gt;

&lt;p&gt;What are some of the immediate patterns and surfaces that exist in your workspace? Looking around your immediate environment can provide an immediate assessment of visual stimuli that can influence your decisions on a day-to-day basis.&lt;/p&gt;

&lt;p&gt;Wall space can be incredibly valuable when you can display photos from your research trip, or find online inspiration to recreate some of the visual imagery from your target markets.  When speaking with your customers, ask to see mobile wallpapers, and think about how fashion could also play a role in determining an aesthetic choice. Lastly, take time out when on a research trip to explore the streets, museums, and absorb some of the local cultures.&lt;/p&gt;

&lt;h4 id=&quot;design-to-delight-and-surprise-customers&quot;&gt;Design to delight and surprise customers&lt;/h4&gt;

&lt;p&gt;Capture local inspiration on research trips to incorporate into visual collections that can be a source of inspiration for colour, imagery, and textures. Find opportunities in your product to delight and engage customers through appropriate images and visuals. Grab’s marketing consent experience leverages illustrative visuals to help customers understand the different categories that require their consent.&lt;/p&gt;

&lt;p&gt;For all our markets, we work with local teams around culturally sensitive visuals and imagery to ensure our content is not offensive or portrays the wrong connotations.&lt;/p&gt;

&lt;h2 id=&quot;my-top-5-for-guerrilla-field-research&quot;&gt;My top 5 for guerrilla field research&lt;/h2&gt;

&lt;p&gt;If you don’t have enough time, stakeholder buy-in or budget to do research, getting out of the office to do your own is sometimes the only answer. Here are my top 5 things to keep in mind.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Don’t jump in. Always start with observation to capture customers’ natural behaviour.&lt;/li&gt;
  &lt;li&gt;Sanity check scripts. Your time and customers’ time is valuable; streamline your script and prepare for u-turns and potential Facebook and Instagram friend requests at the end!  &lt;/li&gt;
  &lt;li&gt;Ask the right people. It’s difficult to know who wants to or has time for your 10-minute intercept. Look for individuals sitting around and not groups if possible (group feedback can be influenced by the most vocal person).&lt;/li&gt;
  &lt;li&gt;Focus on the user. Never multitask when speaking to the user. Jotting notes on an answer sheet is less distracting than using your mobile or laptop (and less dangerous in some places!). Ask permission to record audio if you want to avoid notetaking all together but this does create more work later on.&lt;/li&gt;
  &lt;li&gt;Use insights to enrich understanding. Insights are not trends and should be used in conjunction with quantitative data to validate decision making.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Feel inspired by this article and want to learn more? &lt;a href=&quot;https://grab.careers&quot;&gt;Grab&lt;/a&gt; is hiring across Southeast Asia and Seattle. Connect with me on &lt;a href=&quot;https://www.linkedin.com/in/pjmadeley&quot;&gt;LinkedIn&lt;/a&gt; or Twitter &lt;a href=&quot;https://twitter.com/PhilipMadeley&quot;&gt;@PhilipMadeley&lt;/a&gt; to learn more about design at Grab.&lt;/p&gt;
</description>
        <pubDate>Tue, 05 Nov 2019 10:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/driving-sea-forward-through-people-focused-design</link>
        <guid isPermaLink="true">https://engineering.grab.com/driving-sea-forward-through-people-focused-design</guid>
        
        <category>Design</category>
        
        <category>User Research</category>
        
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Griffin, an Anti-fraud Risk Rule Engine Making Billions of Predictions Daily</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;At Grab, the scale and fast-moving nature of our business means we need to be vigilant about potential risks to our customers and to our business. Some of the things we watch for include promotion abuse, or passenger safety on late-night ride allocations. To overcome these issues, the TIS (Trust/Identity/Safety) taskforce was formed with a group of AI developers dedicated to fraud detection and prevention.&lt;/p&gt;

&lt;p&gt;The team’s mission is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to keep fraudulent users away from our app or services&lt;/li&gt;
  &lt;li&gt;ensure our customers’ safety, and&lt;/li&gt;
  &lt;li&gt;Manage user identities to securely login to the Grab app.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The TIS team’s scope covers not just transport, but also our food, deliver and other Grab verticals.&lt;/p&gt;

&lt;h2 id=&quot;how-we-prevented-fraudulent-transactions-in-the-earlier-days&quot;&gt;How we prevented fraudulent transactions in the earlier days&lt;/h2&gt;

&lt;p&gt;In our early days when Grab was smaller, we used a rules-based approach to block potentially fraudulent transactions. Rules are like boolean conditions that determines if the result will be true or false. These rules were very effective in mitigating fraud risk, and we used to create them manually in the code.&lt;/p&gt;

&lt;p&gt;We started with very simple rules. For example:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rule 1:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; IF a credit card has been declined today

 THEN this card cannot be used for booking
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To quickly incorporate rules in our app or service, we integrated them in our backend service code and deployed our service frequently to use the latest rules.&lt;/p&gt;

&lt;p&gt;It worked really well in the beginning. Our logic was relatively simple, and only one developer managed the changes regularly. It was very lightweight to trigger the rule deployment and enforce the rules.&lt;/p&gt;

&lt;p&gt;However, as the business rapidly expanded, we had to exponentially increase the rule complexity. For example, consider these two new rules:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rule 2:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;IF a credit card has been declined today but this passenger has good booking history

THEN we would still allow this booking to go through, but precharge X amount
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Rule 3:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;IF a credit card has been declined(but paid off) more than twice in the last 3-months

THEN we would still not allow this booking
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The system scans through the rules, one by one, and if it determines that any rule is tripped it will check the other rules. In the example above, if a credit card has been declined more than twice in the last 3-months, the passenger will not be allowed to book even though he has a good booking history.&lt;/p&gt;

&lt;p&gt;Though all rules follow a similar pattern, there are subtle differences in the logic and they enable different decisions. Maintaining these complex rules was getting harder and harder.&lt;/p&gt;

&lt;p&gt;Now imagine we added more rules as shown in the example below. We first check if the device used by the passenger is a high-risk one. e.g using an emulator for booking. If not, we then check the payment method to evaluate the risk (e.g. any declined booking from the credit card), and then make a decision on whether this booking should be precharged or not. If passenger is using a low-risk  device but is in some risky location where we traditionally see a lot of fraud bookings, we would then run some further checks about the passenger booking history to decide if a pre-charge is also needed.&lt;/p&gt;

&lt;p&gt;Now consider that instead of a single passenger, we have thousands of passengers. Each of these passengers can have a large number of rules for review. While not impossible to do, it can be difficult and time-consuming, and it gets exponentially more difficult the more rules you have to take into consideration. Time has to be spent carefully curating these rules.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Rules flow&quot; src=&quot;/img/griffin/image3.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The more rules you add to increase accuracy, the more difficult it becomes to take them all into consideration.&lt;/p&gt;

&lt;p&gt;Our rules were getting 10X more complicated than the example shown above. Consequently, developers had to spend long hours understanding the logic of our rules, and also be very careful to avoid any interference with new rules.&lt;/p&gt;

&lt;p&gt;In the beginning, we implemented rules through a three-step process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Data Scientists and Analysts dived deep into our transaction data, and discovered patterns.&lt;/li&gt;
  &lt;li&gt;They abstracted these patterns and wrote rules in English (e.g. promotion based booking should be limited to 5 bookings and total finished bookings should be greater than 6, otherwise unallocate current ride)&lt;/li&gt;
  &lt;li&gt;Developers implemented these rules and deployed the changes to production&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sometimes, the use of English between steps 2 and 3 caused inaccurate rule implementation (e.g. for “&lt;em&gt;X should be limited to 5&lt;/em&gt;”, should the implementation be &lt;code class=&quot;highlighter-rouge&quot;&gt;X &amp;lt; 5 or  X &amp;lt;= 5&lt;/code&gt;?)&lt;/p&gt;

&lt;p&gt;Once a new rule is deployed, we monitored the performance of the rule. For example,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How often does the rule fire (after minutes, hours, or daily)?&lt;/li&gt;
  &lt;li&gt;Is it over-firing?&lt;/li&gt;
  &lt;li&gt;Does it conflict with other rules?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on implementation, each rule had dependency with other rules. For example, if Rule 1 is fired, we should not continue with Rule 2 and Rule 3.&lt;/p&gt;

&lt;p&gt;As a result, we couldn’t  keep each rule evaluation independent.  We had no way to observe the performance of a rule with other rules interfering. Consider an example where we change Rule 1:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;From&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;IF a credit card has been declined today&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;To&lt;/em&gt;   &lt;code class=&quot;highlighter-rouge&quot;&gt;IF a credit card has been declined this week&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As Rules 2 and 3 depend on Rule 1, their trigger-rate would drop significantly. It means we would have unstable performance metrics for Rule 2 and Rule 3 even though the logic of Rule 2 and Rule 3 does not change. It is very hard for a rule owner to monitor the performance of Rules 2 and Rule 3.&lt;/p&gt;

&lt;p&gt;When it comes to the of A/B testing of a new rule, Data Scientists need to put a lot of effort into cleaning up noise from other rules, but most of the time, it is mission-impossible.&lt;/p&gt;

&lt;p&gt;After several misfiring events (wrong implementation of rules) and ever longer rule development time (weekly), we realized “&lt;em&gt;No one can handle this manually&lt;/em&gt;.“&lt;/p&gt;

&lt;h2 id=&quot;birth-of-griffin-rule-engine&quot;&gt;Birth of Griffin Rule Engine&lt;/h2&gt;

&lt;p&gt;We decided to take a step back, sit down and closely review our daily patterns. We realized that our daily patterns fall into two categories:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Fetching new data:  e.g. “&lt;em&gt;what is the credit card risk score&lt;/em&gt;”, or “&lt;em&gt;how many food bookings has this user ordered in last 7 days&lt;/em&gt;”, and transform this data for easier consumption.&lt;/li&gt;
  &lt;li&gt;Updating/creating rules: e.g. &lt;em&gt;if a credit card risk score is high, decline a booking&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These two categories are essentially divided into two independent components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Data orchestration - collecting/transforming the data from different data sources.&lt;/li&gt;
  &lt;li&gt;Rule-based prediction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Based on these findings, we got started with our Data Orchestrator (open sourced at &lt;a href=&quot;https://github.com/grab/symphony&quot;&gt;https://github.com/grab/symphony&lt;/a&gt;) and Griffin projects.&lt;/p&gt;

&lt;p&gt;The intent of Griffin is to provide data scientists and analysts with a way to add new rules to monitor, prevent, and detect fraud across Grab.&lt;/p&gt;

&lt;p&gt;Griffin allows technical novices to apply their fraud expertise to add very complex rules that can automate the review of rules without manual intervention.&lt;/p&gt;

&lt;p&gt;Griffin  now predicts billions of events every day with 100K+ Queries per second(QPS) at peak time (on only 6 regular &lt;a href=&quot;https://aws.amazon.com/ec2/&quot;&gt;EC2s&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Data scientists and analysts can self-service rule changes on the web portal directly, deploy rules with just a few clicks, experiment and monitor performance in real time.&lt;/p&gt;

&lt;h3 id=&quot;why-we-came-up-with-griffin-instead-of-using-third-party-tools-in-the-market&quot;&gt;Why we came up with Griffin instead of using third-party tools in the market&lt;/h3&gt;

&lt;p&gt;Before we decided to create our in-built tool, we did some research for common &lt;a href=&quot;https://en.wikipedia.org/wiki/Business_rules_engine&quot;&gt;business rule engines&lt;/a&gt; available in the market such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Drools&quot;&gt;Drools&lt;/a&gt; and checked if we should use them. In that process, we found:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Drools has its own Java-based &lt;a href=&quot;https://en.wikipedia.org/wiki/Domain-specific_language&quot;&gt;DSL&lt;/a&gt; with a non-trivial learning curve (whereas our major users are from Python background).&lt;/li&gt;
  &lt;li&gt;Limited [expressive power](https://en.wikipedia.org/wiki/Expressive_power_(computer_science),&lt;/li&gt;
  &lt;li&gt;Limited support for some common math functions (e.g. factorial/ Greatest Common Divisor).&lt;/li&gt;
  &lt;li&gt;Our nature of business needed dynamic dataset for predictions (for example, a rule may need only passenger booking history on Day 1, but it may use passenger booking history, passenger credit balance, and passenger favorite places on Day 2). On the other hand, Drools usually works well with a static list of dataset instead of dynamic dataset.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Given the above constraints, we decided to build our own rule engine which can better fit our needs.&lt;/p&gt;

&lt;h2 id=&quot;griffin-architecture&quot;&gt;Griffin Architecture&lt;/h2&gt;

&lt;p&gt;The diagram depicts the high-level flow of making a prediction through Griffin.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;High-level flow of making a prediction through Griffin&quot; src=&quot;/img/griffin/image10.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;components&quot;&gt;Components&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Data Orchestration: a service that collects all data needed for predictions&lt;/li&gt;
  &lt;li&gt;Rule Engine: a service that makes prediction based on rules&lt;/li&gt;
  &lt;li&gt;Rule Editor: the portal through which users can create/update rules&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;workflow&quot;&gt;Workflow&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Users create/update rules in the Rule Editor web portal, and save the rules in the database.&lt;/li&gt;
  &lt;li&gt;Griffin Rule Engine reloads rules immediately as long as it detects any rule changes.&lt;/li&gt;
  &lt;li&gt;Data Orchestrator sends all dataset (features) needed for a prediction (e.g. whether to block a ride based on passenger past ride pattern, credit card risk) to the Rule Engine&lt;/li&gt;
  &lt;li&gt;Griffin Rule Engine makes a prediction.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;how-you-can-create-rules-using-griffin&quot;&gt;How you can create rules using Griffin&lt;/h2&gt;

&lt;p&gt;In an abstract view, a rule inside Griffin is defined as:&lt;/p&gt;

&lt;p&gt;Rule:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input:JSON =&amp;gt; Result:Boolean
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We allow users (analysts, data scientists) to write Python-based rules on WebUI to accommodate some very complicated rules like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;len(list(filter(lambdax: x \&amp;gt;7, (map(lambdax: math.factorial(x), \[1,2,3,4,5,6\]))))) \&amp;gt;2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This significantly optimizes the expressive power of rules.&lt;/p&gt;

&lt;p&gt;To match and evaluate a rule more efficiently, we also have other key components associated:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scenarios&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Here are some examples: &lt;code class=&quot;highlighter-rouge&quot;&gt;PreBooking&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PostBookingCompletion&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PostFoodDelivery&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Actions such as &lt;code class=&quot;highlighter-rouge&quot;&gt;NotAllowBooking&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;AuthCapture&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SendNotification&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;If a rule result is &lt;em&gt;True&lt;/em&gt;, it returns a list of treatments as selected by users, e.g. AuthCapture and SendNotification (the example below is treatments for one Safety-related rule).The one below is for a checkpoint to detect credit-card risk.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Treatments: AuthCapture&quot; src=&quot;/img/griffin/image4.png&quot; /&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Each checkpoint has a default treatment. If no rule inside this checkpoint is hit, the rule engine would return the default one (in most cases, it is just “&lt;em&gt;do nothing&lt;/em&gt;”).&lt;/li&gt;
  &lt;li&gt;A treatment can only belong to one checkpoint, but one checkpoint can have multiple treatments.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, the graph below demonstrates a checkpoint &lt;code class=&quot;highlighter-rouge&quot;&gt;PaxPreRide&lt;/code&gt; associated with three treatments: &lt;code class=&quot;highlighter-rouge&quot;&gt;Pass&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Decline&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Hold&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Treatments: Adding&quot; src=&quot;/img/griffin/image6.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Segments&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The scope/dimension of a rule. Based on the sample segments below, a rule can be applied only to &lt;code class=&quot;highlighter-rouge&quot;&gt;countries=\[MY,PH\]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;verticals=\[GrabBus, GrabCar\]&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;It can be changed at any time on WebUI as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Segments&quot; src=&quot;/img/griffin/image2.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Values of a rule&lt;/strong&gt;
When a rule is hit, more than just treatments, users also want some dynamic values returned. E.g. a max distance of the ride allowed if we believe this booking is medium risk.&lt;/p&gt;

&lt;h2 id=&quot;does-python-make-griffin-run-slow&quot;&gt;Does Python make Griffin run slow?&lt;/h2&gt;

&lt;p&gt;We picked Python to enjoy its great expressive power and neatness of syntax, but some people ask: Python is slow, would this cause a latency bottleneck?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Our answer is No.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The below graph shows the Latency P99 of Prediction Request from load balancer side(actually the real latency for each prediction is &amp;lt; 6ms, the metrics are peaked at 30ms because some batch requests contain 50 predictions in a single call)&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Prediction Request Latency P99&quot; src=&quot;/img/griffin/image1.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;what-we-did-to-achieve-this&quot;&gt;What we did to achieve this?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The key idea is to make all computations in CPU and memory only (in other words, no extra I/O).&lt;/li&gt;
  &lt;li&gt;We do not fetch the rules from database for each prediction. Instead, we keep a record called &lt;code class=&quot;highlighter-rouge&quot;&gt;dirty_key&lt;/code&gt;, which keeps the latest rule update timestamp. The rule engine would actively check this timestamp and trigger a rule reload only when the &lt;code class=&quot;highlighter-rouge&quot;&gt;dirty_key&lt;/code&gt; timestamp in the DB is newer than the latest rule reload time.&lt;/li&gt;
  &lt;li&gt;Rule engine would not fetch any additional new data, instead, all data should be from Data Orchestrator.&lt;/li&gt;
  &lt;li&gt;So the whole prediction flow is only between CPU &amp;amp; memory (and if the data size is small, it could be on &lt;a href=&quot;https://www.prowesscorp.com/computer-latency-at-a-human-scale&quot;&gt;CPU cache&lt;/a&gt; only).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;Python GIL&lt;/a&gt; essentially enforces a process to have up to one active thread running at a time, no matter how many cores a CPU has. We have &lt;a href=&quot;https://gunicorn.org&quot;&gt;Gunicorn&lt;/a&gt; to wrap our service, so on the Production machine, we have &lt;code class=&quot;highlighter-rouge&quot;&gt;(2x$num_cores) + 1 processes&lt;/code&gt; (see &lt;a href=&quot;http://docs.gunicorn.org/en/latest/design.html#how-many-workers&quot;&gt;Gunicorn Design - How Many Workers?&lt;/a&gt;). The formula is based on the assumption that for a given core, one worker will be reading or writing from the socket while the other worker is processing a request.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The below screenshot is the process snapshot on &lt;a href=&quot;https://aws.amazon.com/ec2/instance-types/c5&quot;&gt;C5.large machine&lt;/a&gt; with 2 vCPU. Note only green processes are active.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Process snapshot on C5.large machine&quot; src=&quot;/img/griffin/image5.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;A lot of trial and error performance tuning:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We used to have &lt;a href=&quot;https://github.com/kennknowles/python-jsonpath-rw&quot;&gt;python-jsonpath-rw&lt;/a&gt; for JSONPath query, but the performance was not strong enough. We switched to &lt;a href=&quot;https://github.com/jmespath/jmespath.py&quot;&gt;jmespath&lt;/a&gt; and observed about 10ms latency reduction.&lt;/li&gt;
  &lt;li&gt;We use &lt;a href=&quot;https://www.sqlalchemy.org&quot;&gt;sqlalchemy&lt;/a&gt; for DB Query and ORM. We enabled cache for some use cases, but turned out it was over-optimized with stale data. We ended up turning off some caching points to ensure the data consistency.&lt;/li&gt;
  &lt;li&gt;For new dict/list creation, we prefer native call (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;{}&lt;/code&gt;/&lt;code class=&quot;highlighter-rouge&quot;&gt;[]&lt;/code&gt;) instead of function call (see the comparison below).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Native call and Function call&quot; src=&quot;/img/griffin/image9.png&quot; /&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Use built-in functions &lt;a href=&quot;https://docs.python.org/3/library/functions.html&quot;&gt;https://docs.python.org/3/library/functions.html&lt;/a&gt;. It is written in C, no one can beat it.&lt;/li&gt;
  &lt;li&gt;Add randomness to rule reload so that not all machines run at the same time causing latency spikes.&lt;/li&gt;
  &lt;li&gt;Caching atomic feature units as they are used so that we don’t have to requery for them each time a checkpoint uses it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-griffin-makes-on-call-engineers-relax&quot;&gt;How Griffin makes on-call engineers relax&lt;/h2&gt;

&lt;p&gt;One of the most popular aspects of Griffin is the WebUI. It opens a door for non-developers to make production changes in real time which significantly boosts organisation productivity. In the past a rule change needed 1 week for code change/test/deployment, now it is just 1 minute.&lt;/p&gt;

&lt;p&gt;But this also introduces extra risks. Anyone can turn the whole checkpoint down, whether unintentionally or maliciously.&lt;/p&gt;

&lt;p&gt;Hence we implemented Shadow Mode and Percentage-based rollout for each rule. Users can put a rule into Shadow Mode to verify the performance without any production impact, and if needed, rollout of a rule can be from 1% all the way to 100%.&lt;/p&gt;

&lt;p&gt;We implemented version control for every rule change, and in case anything unexpected happened, we could rollback to the previous version quickly.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Version control&quot; src=&quot;/img/griffin/image8.png&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Rollback button&quot; src=&quot;/img/griffin/image7.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We also built &lt;a href=&quot;https://en.wikipedia.org/wiki/Role-based_access_control&quot;&gt;RBAC-based&lt;/a&gt; permission system, along with Change Approval flow to make sure any prod change needs at least two people(and approver role has higher permission)&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;

&lt;p&gt;Griffin evolved from a fraud-based rule engine to generic rule engine. It can apply to any rule at Grab. For example, Grab just launched Appeal automation several days ago to reduce 50% of the  human effort it typically takes to review straightforward appeals from our passengers and drivers. It was an unplanned use case, but we are so excited about this.&lt;/p&gt;

&lt;p&gt;This could happen because from the very beginning we designed Griffin with minimized business context, so that it can be generic enough.&lt;/p&gt;

&lt;p&gt;After the launch of this, we observed an amazing adoption rate for various fraud/safety/identity use cases. More interestingly, people now treat Griffin as an automation point for various integration points.&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Oct 2019 17:10:32 +0000</pubDate>
        <link>https://engineering.grab.com/griffin</link>
        <guid isPermaLink="true">https://engineering.grab.com/griffin</guid>
        
        <category>Engineering</category>
        
        <category>Anti-Fraud</category>
        
        <category>Security</category>
        
        <category>Fraud Detection</category>
        
        <category>Data</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Using Grab’s Trust Counter Service to Detect Fraud Successfully</title>
        <description>&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Fraud is not a new phenomenon, but with the rise of the digital economy it has taken different and aggressive forms. Over the last decade, novel ways to exploit technology have appeared, and as a result, millions of people have been impacted and millions of dollars in revenue have been lost. According to &lt;a href=&quot;https://www.acfe.com/press-release.aspx?id%3D4294973129&quot;&gt;ACFE survey&lt;/a&gt;, companies lost USD6.3 billion due to fraud. Organizations lose 5% of its revenue annually due to fraud.&lt;/p&gt;

&lt;p&gt;In this blog, we take a closer look at how we developed an anti-fraud solution using the Counter service, which can be an indispensable tool in the highly complex world of fraud detection.&lt;/p&gt;

&lt;h2 id=&quot;anti-fraud-solution-using-counters&quot;&gt;Anti-fraud solution using counters&lt;/h2&gt;

&lt;p&gt;At Grab, we detect fraud by deploying data science, analytics, and engineering tools to search for anomalous and suspicious transactions, or to identify high-risk individuals who are likely to commit fraud. Grab’s Trust Platform team provides a common anti-fraud solution across a variety of business verticals, such as transportation, payment, food, and safety. The team builds tools for managing data feeds, creates SDK for engineering integration, and builds rules engines and consoles for fraud detection.&lt;/p&gt;

&lt;p&gt;One example of fraudulent behavior could be that of an individual who masquerades as both driver and passenger, and makes cashless payments to get promotions, for example, earn a one dollar rebate in the next transaction.In our system, we analyze real time booking and payment signals, compare it with the historical data of the driver and passenger pair, and create rules using the rule engine. We count the number of driver and passenger pairs at a given time frame. This counter is provided as an input to the rule.If the counter value exceeds a predefined threshold value, the rule evaluates it as a fraud transaction. We send this verdict back to the booking service.&lt;/p&gt;

&lt;h2 id=&quot;the-conventional-method&quot;&gt;The conventional method&lt;/h2&gt;

&lt;p&gt;Fraud detection is a job that requires cross-functional teams like data scientists, data analysts, data engineers, and backend engineers to work together. Usually data scientists or data analysts come up with an offline idea and apply it to real-time traffic. For example, a rule gets invented after brainstorming sessions by data scientists and data analysts. In the conventional method, the rule needs to be communicated to engineers.&lt;/p&gt;

&lt;h2 id=&quot;automated-solution-using-the-counter-service&quot;&gt;Automated solution using the Counter service&lt;/h2&gt;

&lt;p&gt;To overcome the challenges in the conventional method, the Trust platform team decided to come out with the Counter service, a self-service platform, which provides management tools for users, and a computing engine for integrating with the backend services. This service provides an interface, such as a UI based rule editor and data feed, so that analysts can experiment and create rules without interacting with engineers. The platform team also decided to provide different data contracts, APIs, and SDKs to engineers so that the business verticals can use it quickly and easily.&lt;/p&gt;

&lt;h2 id=&quot;the-major-engineering-challenges-faced-in-designing-the-counter-service&quot;&gt;The major engineering challenges faced in designing the Counter service&lt;/h2&gt;

&lt;p&gt;There are millions of transactions happening at Grab every day, which implies we needed to perform billions of fraud and safety detections. As seen from the example shared earlier, most predictions require a group of counters. In the above use case, we need to know how many counts of the cashless payment happened for a driver and passenger pair. Due to the scale of Grab’s business, the potential combinations of drivers and passengers could be exponential. However, this is only one use case. So imagine that there could be hundreds of counters for different use cases. Hence it’s important that we provide a platform for stakeholders to manage counters.&lt;/p&gt;

&lt;p&gt;Read on to learn about some of the common challenges we faced.&lt;/p&gt;

&lt;h3 id=&quot;scalability&quot;&gt;Scalability&lt;/h3&gt;

&lt;p&gt;As mentioned above, we could potentially have an exponential number of passengers and drivers in a single counter. So it’s a great challenge to store the counters in the database, read, and query them in real-time. When there are billions of counter keys across a long period of time, the Trust team had to find a scalable way to write and fetch keys effectively and meet the client’s SLA.&lt;/p&gt;

&lt;h3 id=&quot;self-serving&quot;&gt;Self-serving&lt;/h3&gt;

&lt;p&gt;A counter is usually invented by data scientists or analysts and used by engineers. For example, every time a new type of counter is needed from data scientists, developers need to manually make code changes, such as adding a new stream, capturing related data sets for the counter, and storing it on the fraud service, then doing a deployment to make the counters ready. It usually takes two or more weeks for the whole iteration, and if there are any changes from the data analysts’ side, which happens often, the situation loops again. The team had to come up with a solution to prevent the long loop of manual tasks by coming out with a self-serving interface.&lt;/p&gt;

&lt;h3 id=&quot;manageable-and-extendable&quot;&gt;Manageable and extendable&lt;/h3&gt;

&lt;p&gt;Due to a lack of connection between real-time and offline data, data analysts and data scientists did not have a clear picture of what is written in the counters. That’s because the conventional counter data were stored in Redis database to satisfy the query SLA. They could not track the correctness of counter value, or its history. With the new solution, the stakeholders can get a real-time picture of what is stored in the counters using the data engineering tools.&lt;/p&gt;

&lt;h2 id=&quot;the-machine-learningchallenges-solved-by-the-counter-service&quot;&gt;The Machine Learning challenges solved by the Counter service&lt;/h2&gt;

&lt;p&gt;The Counter service plays an important role in our Machine Learning (ML) workflow.&lt;/p&gt;
&lt;h3 id=&quot;data-consistency-challengeissue&quot;&gt;Data Consistency Challenge/Issue&lt;/h3&gt;

&lt;p&gt;Most of the machine learning workflows need dedicated input data. However, when there is an anti-fraud model that is trained using offline data from the data lake, it is difficult to use the same model in real-time. This is because the model lacks the data contract and the consistency with the data source. In this case, the Counter service becomes a type of data source by providing the value of counters to file system.&lt;/p&gt;

&lt;h3 id=&quot;ml-featuring&quot;&gt;ML featuring&lt;/h3&gt;

&lt;p&gt;Counters are important features for the ML models. Imagine there is a new invention of counters, which data scientists need to evaluate. We need to provide a historical data set for counters to work. The Counter service provides a counter replay feature, which allows data scientists to simulate the counters via historical payload.&lt;/p&gt;

&lt;p&gt;In general, the Counter service is a bridge between online and offline datasets, data scientists, and engineers. There was technical debt with regards to data consistency and automation on the ML pipeline, and the Counter service closed this loop.&lt;/p&gt;

&lt;h2 id=&quot;how-we-designed-the-counter-service&quot;&gt;How we designed the Counter service&lt;/h2&gt;

&lt;p&gt;We followed the principle of asynchronized data ingestion, and synchronized transaction for designing the Counter service.&lt;/p&gt;

&lt;p&gt;The diagram shows how the counters are generated and saved to database.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;How the counters are generated and saved to the database&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image1.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Counter creation workflow&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;User opens the Counter Creation UI and creates a new key &lt;em&gt;“fraud:counter:counter_name”&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Configures required fields.&lt;/li&gt;
  &lt;li&gt;The Counter service monitors the new counter-creation, puts a new counter into load script storage, and starts processing new counter events (see Counter Write below).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Counter write workflow&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The Counter service monitors multiple streams, assembles extra data from online data services (i.e. Common Data Service (CDS), passenger service, hydra service, etc), so that rich dataset would also be available for editors on each stream resource.&lt;/li&gt;
  &lt;li&gt;The Counter Processor evaluates the user-configured expression and writes the evaluated values to the dedicated Grab-Stats stream using the GrabPlugin tool.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Counter read workflow&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Counter read workflow&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image2.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We use Grab-Stats as our storage service. Basically Grab-Stats runs above ScyllaDB, which is a distributed NoSQL data store. We use ScyllaDB because of its good performance on aggregation in memory to deal with the time series dataset. In comparison with in-memory storage like AWS elasticCache, it is 10 times cheaper and as reliable as AWS in terms of stability. The p99 of reading from ScyllaDB is less than 150ms which satisfies our SLA.&lt;/p&gt;

&lt;h2 id=&quot;how-we-improved-the-counter-service-performance&quot;&gt;How we improved the Counter service performance&lt;/h2&gt;

&lt;p&gt;We used the multi-buckets strategy to improve the Counter service performance.&lt;/p&gt;

&lt;h3 id=&quot;background-1&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;There are different time windows when you perform a query. Some counters are time sensitive so that it needs to know what happened in the last 30 or 60 minutes. Some other counters focus on the long term and need to know the events in the last 30 or 90 days.&lt;/p&gt;

&lt;p&gt;From a transactional database perspective, it’s not possible to serve small range as well as long term events at the same time. This is because the more the need for the accuracy of the data and the longer the time range, the more aggregations need to happen on database. Which means we would not be able to satisfy the SLA. Otherwise we will need to block other process which leads to the service downgrade.&lt;/p&gt;

&lt;h3 id=&quot;solution-for-improving-the-query&quot;&gt;Solution for improving the query&lt;/h3&gt;

&lt;p&gt;We resolved this problem by using different granularities of the tables. We pre-aggregated the signals into different time buckets, such as 15min, 1 hour, and 1 day.&lt;/p&gt;

&lt;p&gt;When a request comes in, the time-range of the request will be divided by the buckets, and the results are conquered. For example, if there is a request for 9/10 23:15:20 to 9/12 17:20:18, the handler will query 15min buckets within the hour.  It will query for hourly buckets for the same day. And it will query the daily buckets for the rest of 2 days. This way, we avoid doing heavy aggregations, but still keep the accuracy in 15 minutes level in a scalable response time.&lt;/p&gt;

&lt;h3 id=&quot;counter-service-ui&quot;&gt;Counter service UI&lt;/h3&gt;

&lt;p&gt;We allowed data analysts and data scientists to onboard counters by themselves, from a dedicated web portal. After the counter is submitted, the Counter service takes care of the integration and parsing the logic at runtime.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Counter service UI&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image3.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;backendintegration&quot;&gt;Backend integration&lt;/h3&gt;

&lt;p&gt;We provide SDK for quicker and better integration. The engineers only need to provide the counter identifier ID (which is shown in the UI) and the time duration in the query. Under the hood we provide a GRPC protocol to communicate across services. We divide the query time window to smaller granularities, fetching from different time series tables and then conquering the result. We are also providing a short &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_live&quot;&gt;TTL&lt;/a&gt; cache layer to take the uncommon traffic from client such as network retry or traffic throttle. Our &lt;a href=&quot;https://en.wikipedia.org/wiki/Queries_per_second&quot;&gt;QPS&lt;/a&gt; are designed to target 100K.&lt;/p&gt;

&lt;h3 id=&quot;monitoring-the-counter-service&quot;&gt;Monitoring the Counter service&lt;/h3&gt;

&lt;p&gt;The Counter service dashboard helps to track the human errors while editing the counters in real-time. The Counter service sends alerts to slack channel to notify users if there is any error.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Counter service dashboard&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image4.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We setup Datadog for monitoring multiple system metrics. The figure below shows a portion of stream processing and counter writing. In the example below, the total stream QPS would reach 5k at peak hour, and the total counter saved to storage tier is about 4k. It will keep climbing without an upper limit, when more counters are onboarded.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Counter service dashboard with multiple metrics&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image5.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The Counter service UI portal also helps users to fetch real-time counter results for verification purposes.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Counter service UI&quot; src=&quot;/img/using-grabs-trust-counter-service-to-detect-fraud-successfully/image6.png&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;future-plans&quot;&gt;Future plans&lt;/h2&gt;

&lt;p&gt;Here’s what we plan to do in the near future to improve the Counter service.&lt;/p&gt;

&lt;h3 id=&quot;close-the-ml-workflow-loop&quot;&gt;Close the ML workflow loop&lt;/h3&gt;

&lt;p&gt;As mentioned above, we plan to send the resource payload of the Counter service to the offline data lake, in order to complete the counter replay function for data scientists. We are working on the project called “time traveler”. As the name indicates, it is used not only for serving the online transactional data, but also supports historical data analytics, and provides more flexibility on counter inventions and experiments.&lt;/p&gt;

&lt;p&gt;There are more automation steps we plan to do, such as adding a replay button on the web portal, and hooking up with the offline big data engine to trigger the analytics jobs. The performance metrics will be collected and displayed on the web portal. A single platform would be able to manage both the online and offline data.&lt;/p&gt;

&lt;h3 id=&quot;integration-with-griffin&quot;&gt;Integration with Griffin&lt;/h3&gt;

&lt;p&gt;Griffin is our rule engine. Counters are sometimes an input to a particular rule, and one rule usually needs many counters to work together. We need to provide a better integration with Griffin on backend. We plan to minimize the current engineering effort when using counters on Griffin. A counter then becomes an automated input variable on Griffin, which can be configured on the web portal by any users.&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Oct 2019 14:30:12 +0000</pubDate>
        <link>https://engineering.grab.com/using-grabs-trust-counter-service-to-detect-fraud-successfully</link>
        <guid isPermaLink="true">https://engineering.grab.com/using-grabs-trust-counter-service-to-detect-fraud-successfully</guid>
        
        <category>Engineering</category>
        
        <category>Anti-Fraud</category>
        
        <category>Security</category>
        
        <category>Fraud Detection</category>
        
        <category>Data</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Being a Principal Engineer at Grab</title>
        <description>&lt;p&gt;Over the past few years Grab has grown from a small startup to one of the largest technology companies in South-East Asia. Along with the company’s growth, the number of microservices, features and teams also grew substantially. At the time of writing this blog, we have around 350 microservices powering our super-app.&lt;/p&gt;

&lt;p&gt;A great engineering team is a critical component of our success. As an engineer you have two career paths in front of you: an individual contributor role, or a management role. While a management role is generally better understood, this article clarifies what it means to be a principal engineer at Grab, which is one of the highest levels of our engineering career ladder.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Engineering Career Ladder&quot; src=&quot;/img/about-being-a-principal-engineer-at-grab/image1.jpg&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;improving-the-quality&quot;&gt;Improving the Quality&lt;/h2&gt;
&lt;div align=&quot;center&quot; style=&quot;font-style:italic&quot;&gt;&lt;font color=&quot;A9A9A9&quot;&gt;“You set the standard for engineering excellence in your technical family. Your architectures are exemplary in terms of efficiency, stability, extensibility, testability and the ability to evolve over time. Your software is robust in the presence of failures, scalable, and cost-effective. Your coding practices are exemplary in terms of code organization, clarity, simplicity, error handling, and documentation. You tackle intrinsically hard problems, acquiring expertise as needed. You decompose complex problems into straightforward solutions.” - Grab’s Engineering Career Ladder&lt;/font&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;So, what does a principal engineer do? As your career progresses from junior to senior to lead engineer we have more and more responsibilities; you manage larger and larger systems. For example, junior engineer might manage a specific component of a micro-service. A senior engineer would be tasked with designing and operating an entire micro-service or product. While a lead engineer would typically be concerned with the architecture at a team level.&lt;/p&gt;

&lt;p&gt;Principal engineer level is akin to a senior manager where instead of indirectly managing people (manager of managers) you take care of the architecture of an entire sub-organisation, known as Tech Family/Platform. These Tech Families usually have more than 50 engineers spread across multiple teams and function as a tiny company with their own business owners, designers, product managers, etc.&lt;/p&gt;

&lt;h2 id=&quot;challenging-projects&quot;&gt;Challenging Projects&lt;/h2&gt;

&lt;div align=&quot;center&quot; style=&quot;font-style:italic&quot;&gt;&lt;font color=&quot;A9A9A9&quot;&gt;“You take engineering ownership of projects that may require the work of several teams to implement; you divide responsibilities so that each team can work independently and have the system come together into an integrated whole. Your projects often cross team, tech family, platform, and even R&amp;amp;D center boundaries. You solicit differing views and keep an open mind. You are adept at building consensus.” - Grab’s Engineering Career Ladder&lt;/font&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;As a principal engineer, your job is to solve larger problems and &lt;strong&gt;translate somewhat vague problems&lt;/strong&gt; into a set of actionable items. You might be faced with a large problem such as “improve efficiency and interoperability of Grab’s transportation system.” You will need to understand the problem, the business impact and see how can it be improved. It might require you to design new systems, change existing systems, understand the costs involved and get the right people together to make it happen.&lt;/p&gt;

&lt;p&gt;Solving such a problem all by yourself is pretty much impossible. You have to work with other managers and other engineers together &lt;strong&gt;as a team&lt;/strong&gt; to make it happen. Help your lead/senior engineers to design the right system by giving them a clear objective but let them take care of the system-level architecture.  &lt;/p&gt;

&lt;p&gt;You will also need to work with managers, advise them to get things done, and get the right things prioritised by the team. While you don’t need to be well-versed in project management and agile methodologies, you do need to be able to plan ahead with your teams and have an understanding of how much time a project or migration will take.&lt;/p&gt;

&lt;p&gt;A Tech Family can easily have 20 or more micro-services. You need to have a good understanding of their &lt;strong&gt;functional requirements and interactions&lt;/strong&gt;. This is challenging as learning new things is always “uncomfortable” and takes time. You must reach out to engineers, product managers, and data scientists, ideally face-to-face to build empathy. Keep asking questions and try to understand how things work. You will also need to read the existing documentation and their code.&lt;/p&gt;

&lt;h2 id=&quot;technical-ownership&quot;&gt;Technical Ownership&lt;/h2&gt;

&lt;div align=&quot;center&quot; style=&quot;font-style:italic&quot;&gt;&lt;font color=&quot;A9A9A9&quot;&gt;“You are the origin of significant technical contributions to our architecture and infrastructure. You take technical ownership of the design and quality of the security, performance, availability, and operational aspects of the software built by one or more teams. You identify where your time is needed, transitioning between coding, design, and architecture based on project and team needs. You deliver software in ways that empower teams to self-service, providing clear adoption/migration paths.” - Grab’s Engineering Career Ladder&lt;/font&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;As a principal engineer you work together with the Head of Engineering and managers within the Tech Family and &lt;strong&gt;improve the quality&lt;/strong&gt; of systems across the board. Typically, no-one tells you what needs to be done. You need to identify gaps, raise them and keep improving the systems.&lt;/p&gt;

&lt;p&gt;You also need to learn how to manage your own time better so you can &lt;strong&gt;prioritise effectively&lt;/strong&gt;. This boils down to knowing your strengths, your weaknesses. For example, if you are really good in building distributed systems but have no clue about the latest-and-greatest design in information security, get the right InfoSec engineers in this meeting and consider skipping it yourself. Avoid trying to do everything at once and be in every single meeting you get invited - you still have to review code, design and focus, so plan accordingly.&lt;/p&gt;

&lt;p&gt;You will also need to understand the &lt;strong&gt;business impact&lt;/strong&gt; of your decisions. For example, if you contribute to product features, know how impactful this feature is going to be to the organisation. If you don’t know it - ask the Product Manager responsible for it. If you work on a platform feature, for example improving the build system, know how it will help: saving 30 minutes of build time for every engineer each day is a huge achievement.&lt;/p&gt;

&lt;p&gt;More often than not, you will have to &lt;strong&gt;drive migrations&lt;/strong&gt;, this is akin to code refactoring but on a system-level and will involve a lot of collaboration with the people. Understand what a technical debt is and how it can be mitigated - a good architecture minimises technical debt and in turn accelerates time-to-market and helps business flourish.&lt;/p&gt;

&lt;h2 id=&quot;technical-leadership&quot;&gt;Technical Leadership&lt;/h2&gt;

&lt;div align=&quot;center&quot; style=&quot;font-style:italic&quot;&gt;&lt;font color=&quot;A9A9A9&quot;&gt;“You amplify your impact by leading design reviews for complex software and/or critical features. You probe assumptions, illuminate pitfalls, and foster shared understanding. You align teams toward coherent architectural strategies.” - Grab’s Engineering Career Ladder&lt;/font&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;In Grab we have a process known as RFC (Request For Comments) which allows engineers to submit &lt;strong&gt;designs and ideas&lt;/strong&gt; for a larger audience to debate. This is especially important given that our organisation is spread across several continents with research and development offices in Southeast Asia, the US, India and China. While any engineer is welcome to comment on these RFCs, it is a duty of lead and principal engineers’ to review them on a regular basis. This will help you to expand your knowledge of existing systems and help others with improving their designs.&lt;/p&gt;

&lt;p&gt;Communication is a key skill that you need to keep improving and it is often the Achilles’ heel of many engineers who would rather be doing work in their corner without talking to anyone else. This is perfectly fine for a junior (or even some senior engineers) but it is critical for a principal engineer to communicate. Let’s break this down to a set of specific skills that you’d need to sharpen.&lt;/p&gt;

&lt;p&gt;You need to be able to &lt;strong&gt;write effectively&lt;/strong&gt; in order to convey your ideas to others. This includes knowing your audience and wording it in such a way that readers can understand. A technical design document whose audience are engineers is not written the same way as a design proposal whose audience are product and business managers.&lt;/p&gt;

&lt;p&gt;You need to be able to &lt;strong&gt;publicly present and talk&lt;/strong&gt; about various projects that you are working on. This includes creation of slide decks with good visuals and distilling down months of work to just a couple of slides. The best way of learning this is to get out there and keep presenting your work - you will get better over time.&lt;/p&gt;

&lt;p&gt;You also need to be able to &lt;strong&gt;drive meetings and discussions&lt;/strong&gt; without wasting anyone’s time. As a technical leader, one of your key responsibilities is to get people moving in the same direction and driving consensus during meetings.&lt;/p&gt;

&lt;h2 id=&quot;teaching-and-learning&quot;&gt;Teaching and Learning&lt;/h2&gt;

&lt;div align=&quot;center&quot; style=&quot;font-style:italic&quot;&gt;&lt;font color=&quot;A9A9A9&quot;&gt;“You educate other engineers, both at an individual level and at scale: keeping the engineering community up to date on advanced technical issues, technologies, and trends. Examples include onboarding bootcamps for new hires, interns, specific skill-gap training development, and sharing specialized knowledge to raise the technical bar for other engineers/teams/dev centers.”&lt;/font&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;A principal engineer is a technical leader and as a leader you have the responsibility to &lt;strong&gt;mentor&lt;/strong&gt;, coach fellow engineers, regardless of their level. In addition to code-reviews, you can organise office hours in your team and knowledge sharing sessions where everyone could present something. You could also help with bootcamps and help new hires in getting up-to-speed.&lt;/p&gt;

&lt;p&gt;Most importantly, &lt;strong&gt;you will also need to keep learning&lt;/strong&gt; whichever way works for you - reading journals and papers, blog posts, watching video-recorded talks, attending conferences and browsing through a variety of open-source projects. You will also learn from other Grabbers as even a junior engineer can teach you something, we all have our strengths and weaknesses. Keep improving and working on yourself!&lt;/p&gt;
</description>
        <pubDate>Wed, 25 Sep 2019 18:14:40 +0000</pubDate>
        <link>https://engineering.grab.com/about-being-a-principal-engineer-at-grab</link>
        <guid isPermaLink="true">https://engineering.grab.com/about-being-a-principal-engineer-at-grab</guid>
        
        <category>Career</category>
        
        <category>Engineering</category>
        
        <category>Microservices</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Data First, SLA Always</title>
        <description>&lt;p&gt;Introducing Trailblazer, the Data Engineering team’s solution to implementing change data capture of all upstream databases. In this article, we introduce the reason why we needed to move away from periodic batch ingestion towards a real time solution and show how we achieved this through an end to end streaming pipeline.&lt;/p&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;

&lt;p&gt;Our mission as Grab’s Data Engineering team is to fulfill 100% of SLAs for data availability to our downstream users. Our 40 person team is responsible for providing accurate and reliable data to data analysts and data scientists so that they can produce actionable reports that will help Grab’s leadership team make data-driven decisions. We maintain data for a variety of business intelligence tools such as Tableau, Presto and Holistics as well as predictive algorithms for all of Grab.&lt;/p&gt;

&lt;p&gt;We ingest data from multiple upstream sources, such as relational databases, Kafka or third party applications such as Salesforce or Zendesk. The majority of these source data exists in MySQL and we run ETL pipelines to mirror any updates into our data lake. These pipelines are triggered on an hourly or daily basis and are powered by an in-house Loader application which performs Spark batch ingestion and loading of data from source to sink.&lt;/p&gt;

&lt;p&gt;Problems with the Loader application started to surface when Grab’s data exceeded the petabyte threshold. As such for larger tables, the most practical method to ingest data was to perform ETL only on rows that were updated within a specified timeframe. This is akin to issuing the query&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SELECT * FROM table WHERE updated &amp;gt;= [start_time] AND updated &amp;lt; [end_time]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now imagine two situations. One, firing this query to a huge table without an updated field. Two, firing the same query to the huge table, this time without indexes on the updated field. In the first scenario, the query will never work and we can never perform incremental ingestion on the table based on a timed window. The second scenario carries the dangers of creating high CPU load to replicate the database that we are querying from. Neither has an ideal outcome.&lt;/p&gt;

&lt;p&gt;One other problem that we identified was the unpredictability of growth in data volume. Tables smaller than one gigabyte were ingested by fully scanning the table and overwriting the data in the data lake. This worked out well for us until the table size increased exponentially, at which point our Spark jobs failed due to JDBC timeouts. If we were only dealing with a handful of tables, this issue could have been addressed by switching our data ingestion strategy from full scan to a timed window.&lt;/p&gt;

&lt;p&gt;When assessing the issue, we discovered that there were hundreds of tables running under the full scan strategy, all of them potentially crashing our data system, all time bombs silently waiting to explode.&lt;/p&gt;

&lt;p&gt;The team urgently needed a new approach to ETL. Our Loader application was highly coupled to upstream table characteristics. We needed to find solutions that were truly scalable, which meant decoupling our pipelines from the upstream.&lt;/p&gt;

&lt;h2 id=&quot;change-data-capture-cdc&quot;&gt;Change data capture (CDC)&lt;/h2&gt;

&lt;p&gt;Much like event sourcing, any log change to the database is captured and streamed out for downstream applications to consume. This process is lightweight since any row level update to the table is instantly captured by a real time processor, avoiding the need for large chunked queries on the table. In addition, CDC works regardless of upstream table definition, so we do not need to worry about missing updated columns impacting our data migration process.&lt;/p&gt;

&lt;p&gt;Binary Logs (binlogs) are the CDC agents of MySQL. All updates, insertions or deletions performed on the table are captured as a series of logged events containing the past state of the row and it’s newly modified state. Check out the &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/mysqlbinlog.html&quot;&gt;binlogs reference&lt;/a&gt; to find out more.&lt;/p&gt;

&lt;p&gt;In order to persist all binlogs generated upstream, our team created a Spark Structured Streaming application called Trailblazer. Trailblazer streams all MySQL binlogs to our data lake. These binlogs serve as a foundation for us to build Presto tables for data auditing and help to remove the direct dependency of our batch ETL jobs to the source MySQL.&lt;/p&gt;

&lt;p&gt;Trailblazer is an amalgamation of various data streaming stacks. Binlogs are captured by Debezium which runs on Kafka connect clusters. All binlogs are sent to our Kafka cluster, which is managed by the Data Engineering Infrastructure team and are streamed out to a real time bucket via a Spark structured streaming application. Hourly or daily ETL compaction jobs ingests the change logs from the real time bucket to materialize tables for downstream users to consume.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;CDC in action where binlogs are streamed to Kafka via Debezium before being consumed by Trailblazer streaming &amp;amp; compaction services&quot; src=&quot;/img/data-first-sla-always/image2.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;CDC in action where binlogs are streamed to Kafka via Debezium before being consumed by Trailblazer streaming &amp;amp; compaction services&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;some-statistics&quot;&gt;Some statistics&lt;/h2&gt;

&lt;p&gt;To date, we are streaming hundreds oftables across 60 Spark streaming jobs and with the constant increase in Grab’s database instances, the numbers are expected to keep growing.&lt;/p&gt;

&lt;h2 id=&quot;designing-trailblazer-streams&quot;&gt;Designing Trailblazer streams&lt;/h2&gt;

&lt;p&gt;We built our streaming application using Spark structured streaming 2.3. Structured streaming was designed to remove the technical aspects of provisioning streams. Developers can focus on perfecting business logic without worrying about fundamentals such as checkpoint management or reading and writing to data sources.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Key architecture for Trailblazer streaming&quot; src=&quot;/img/data-first-sla-always/image5.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Key architecture for Trailblazer streaming&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;In the design phase, we made sure to follow several key principles that helped in managing our streams.&lt;/p&gt;

&lt;h3 id=&quot;checkpoints-have-to-be-externally-managed&quot;&gt;Checkpoints have to be externally managed&lt;/h3&gt;

&lt;p&gt;Structured streaming manages checkpoints both in a local directory and in a ‘_metadata’ directory on S3 buckets, such that the state of the stream can be restored in the event of failure and restart.&lt;/p&gt;

&lt;p&gt;This is all well and good, with two exceptions. First, changing the starting point of data ingestion meant ssh-ing into the machine and manipulating metadata, which could be extremely dangerous. Second, we could not assume cluster prevalence since clusters can die and be recreated with data erased from its local disk or the distributed file system.&lt;/p&gt;

&lt;p&gt;Our solution was to do a work around at the application level. All checkpoints will be stored in temporary directories with the existing timestamp appended as path (eg /tmp/checkpoint/job_A/1560697200/… ). A linearly progressive timestamp guarantees that the same directory will never be reused by new instances of the stream. This explains why we never restore its state from local disk but instead, store all checkpoints in a highly available Redis cluster, with key as the Kafka topic and value as a JSON of partition : offset.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Key

debz-schema-A.schema_A.table_B

Value

{&quot;11&quot;:19183566,&quot;12&quot;:19295602,&quot;13&quot;:18992606[[a]](#cmnt1)[[b]](#cmnt2)[[c]](#cmnt3)[[d]](#cmnt4)[[e]](#cmnt5)[[f]](#cmnt6),&quot;14&quot;:19269499,&quot;15&quot;:19197199,&quot;16&quot;:19060873,&quot;17&quot;:19237853,&quot;18&quot;:19107959,&quot;19&quot;:19188181,&quot;0&quot;:19193976,&quot;1&quot;:19072585,&quot;2&quot;:19205764,&quot;3&quot;:19122454,&quot;4&quot;:19231068,&quot;5&quot;:19301523,&quot;6&quot;:19287447,&quot;7&quot;:19418871,&quot;8&quot;:19152003,&quot;9&quot;:19112431,&quot;10&quot;:19151479}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Example of how offsets are stored in Redis as Key : Value pairs&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Fortunately, structured streaming provides the &lt;a href=&quot;https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-StreamingQueryListener.html&quot;&gt;StreamQueryListener class&lt;/a&gt; which we can use to register checkpoints after the completion of each microbatch.&lt;/p&gt;

&lt;h3 id=&quot;streams-must-handle-0-1-or-1-million-data&quot;&gt;Streams must handle 0, 1 or 1 million data&lt;/h3&gt;

&lt;p&gt;Scalability is at the heart of all well-designed applications. Spark streaming jobs are built for scalability in the face of varying data volumes.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;In general, the rate of messages input to Kafka is cyclical across 24 hrs. Streaming jobs should be robust enough to handle data loads during peak hours of the day without breaching microbatch timing&quot; src=&quot;/img/data-first-sla-always/image6.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;In general, the rate of messages input to Kafka is cyclical across 24 hrs. Streaming jobs should be robust enough to handle data loads during peak hours of the day without breaching microbatch timing&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;There are a few settings that we can configure to influence the degree of scalability for a streaming app&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;spark.dynamicAllocation.enabled=true&lt;/em&gt; gives spark autonomy to provision / revoke executors to suit the workload&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-dynamic-allocation.html%23spark.dynamicAllocation.minExecutors&quot;&gt;spark.dynamicAllocation.maxExecutors&lt;/a&gt;&lt;/em&gt; controls the maximum job parallelism&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;maxOffsetsPerTrigger&lt;/em&gt; controls the maximum number of messages ingested from Kafka per microbatch&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;trigger&lt;/em&gt; controls the duration between microbatchs and is a property of the DataStreamWriter class&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-as-key-health-indicator&quot;&gt;Data as key health indicator&lt;/h3&gt;

&lt;p&gt;Scaling the number of streaming jobs without prior collection of performance metrics is a bad idea. There is a high chance that you will discover a dead stream when checking your stream hours after initialization. I’ll cite Murphy’s law as proof.&lt;/p&gt;

&lt;p&gt;Thus we vigilantly monitored our data streams. We used tools such as Datadog for metric monitoring, Slack for oncall issue reporting, PagerDuty for urgent cases and our inhouse data auditor as a service (DASH) for counts discrepancy reporting between streamed and source data. More details on monitoring will be discussed in the later part.&lt;/p&gt;

&lt;h3 id=&quot;streams-are-ephemeral&quot;&gt;Streams are ephemeral&lt;/h3&gt;

&lt;p&gt;Streams may die due to a hundred and one reasons so don’t blame yourself or your programming insecurities. Issues with upstream dependencies, such as a node within your Kafka cluster running out of disk space, could lead to partition unavailability which would crash the application. On one occasion, our streaming application was unable to resolve DNS when writing to AWS S3 storage. This amounted to multiple failures within our Spark job that eventually culminated in the termination of the stream.&lt;/p&gt;

&lt;p&gt;In this case, allow the stream to  shutdown gracefully, send out your alerts and have a mechanism in place to retry the failed stream. We run all streaming jobs on Airflow and any failure to the stream will automatically be retried through a new task issued by the scheduler.&lt;/p&gt;

&lt;p&gt;If you have had experience with large scale management of streams, please leave a comment so we can continue this discussion!&lt;/p&gt;

&lt;h2 id=&quot;monitoring-data-streams&quot;&gt;Monitoring data streams&lt;/h2&gt;

&lt;p&gt;Here are some key features that were set up to monitor our streams.&lt;/p&gt;

&lt;h3 id=&quot;running--active-jobs-ratio&quot;&gt;Running : Active jobs ratio&lt;/h3&gt;

&lt;p&gt;The number of streaming jobs could increase in the future, thus becoming a challenge for the oncall team to track all jobs that are supposed to be up and running.&lt;/p&gt;

&lt;p&gt;One proposal  is  to track the number of jobs in production against the number of jobs that are actually running. By querying MySQL tables, we can filter out all the jobs that are meant to be active. Since Trailblazer streams are spark-submit jobs managed by YARN, we can query YARN’s resource manager REST API to retrieve  all the jobs that are running. We then construct a ratio of running : active jobs and report them to Datadog. If the ratio is not 1 for an extended duration, an alert will be issued for the oncall to take action.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;If the ratio of running : active jobs falls below 1 for a period of time, we will immediately trigger an alert&quot; src=&quot;/img/data-first-sla-always/image4.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;If the ratio of running : active jobs falls below 1 for a period of time, we will immediately trigger an alert&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;microbatch-runtime&quot;&gt;Microbatch runtime&lt;/h3&gt;

&lt;p&gt;We define a 30 second window for each microbatch and track the actual runtime using metrics reported by the query listener. A runtime that exceeds the designated window is a potential indicator that the streaming job is deprived of resources and needs to be scaled up.&lt;/p&gt;

&lt;h3 id=&quot;job-liveliness&quot;&gt;Job liveliness&lt;/h3&gt;

&lt;p&gt;Each job reports its health by emitting a count of 1 heartbeat. This heartbeat is created at the end of every microbatch via a query listener. This process is useful in detecting stale jobs (jobs that are registered as RUNNING in YARN but are actually hung).&lt;/p&gt;

&lt;h3 id=&quot;kafka-offset-divergence&quot;&gt;Kafka offset divergence&lt;/h3&gt;

&lt;p&gt;In order to ensure that the message output rate to the consumer exceeds the message input rate from the producer, we sum up all presently ingested topic-partition offsets and compare that value to the sum of all topic-partition end offsets in Kafka. We then add an alerting logic on top of these metrics to inform the oncall team if the difference between the two values grows too big.&lt;/p&gt;

&lt;p&gt;It is important to track the offset divergence parameter as streams can be lagging. Should the rate of consumption fall below the rate of message production, we would run the risk of falling short of Kafka’s retention window, leading to data losses.&lt;/p&gt;

&lt;h3 id=&quot;hourly-data-checks&quot;&gt;Hourly data checks&lt;/h3&gt;

&lt;p&gt;DASH runs hourly and serves as our first line of defence to detect any data quality issues within the streams. We issue queries to the source database and our streaming layer to confirm that the ID counts of data created within the last hour match.&lt;/p&gt;

&lt;p&gt;DASH helps in the early detection of upstream issues. We have noticed cases where our Debezium connectors failed and our checker reported fewer data than expected since there were no incoming messages to Kafka.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;DASH matches and mismatches reported to Slack&quot; src=&quot;/img/data-first-sla-always/image1.png&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;DASH matches and mismatches reported to Slack&quot; src=&quot;/img/data-first-sla-always/image3.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;DASH matches and mismatches reported to Slack&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;materializing-tables-through-compaction&quot;&gt;Materializing tables through compaction&lt;/h2&gt;

&lt;p&gt;Having CDC data in our data lake does not conclude our responsibilities. Batched compaction allows us to apply all captured CDC, to be available as Presto tables for downstream consumption. The job is set to trigger hourly and process all changes to the database within the past hour.  For example, changes to a record are visible in real-time, but the latest state of the record will not be reflected until the next time a batch job runs. We addressed several issues with streaming during this phase.&lt;/p&gt;

&lt;h3 id=&quot;deduplication-of-data&quot;&gt;Deduplication of data&lt;/h3&gt;

&lt;p&gt;Trailblazer was not built to deliver exactly once guarantees. We ensure that the issues regarding duplicated CDCs are addressed during compaction.&lt;/p&gt;

&lt;h3 id=&quot;availability-of-all-data-until-certain-hour&quot;&gt;Availability of all data until certain hour&lt;/h3&gt;

&lt;p&gt;We want to make sure that downstream pipelines use output data of the hourly batch job only when the pipeline has all records for that hour. In case there is an event that is processed late by streaming, the current pipeline will wait until the data is completed. In this case, we are consciously choosing consistency over availability for our downstream users. For example, missing a few insert booking records in peak hours due to consumer processing delay can generate the wrong downstream results leading to miscalculation in revenue. We want to start  downstream processes only when the data for the hour or day is complete.&lt;/p&gt;

&lt;h3 id=&quot;need-for-latest-state-of-each-event&quot;&gt;Need for latest state of each event&lt;/h3&gt;

&lt;p&gt;Our compaction job performs upserts on the data to ensure that our downstream users can consume  records in their latest state.  &lt;/p&gt;

&lt;h2 id=&quot;future-applications&quot;&gt;Future applications&lt;/h2&gt;

&lt;p&gt;Trailblazer is a milestone for the Data Engineering team as it represents our commitment to achieve large scale data streams to reduce latencies for our end users. Moving ahead, our team will be exploring how we can further optimize streaming jobs by analysing data trends over time and to build applications such as snapshot tables on top of the CDCs being streamed in our data lake.&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Aug 2019 19:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/data-first-sla-always</link>
        <guid isPermaLink="true">https://engineering.grab.com/data-first-sla-always</guid>
        
        <category>Data Pipeline</category>
        
        
        <category>Data Science</category>
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Save Your Place with Grab!</title>
        <description>&lt;p&gt;Do you find it tedious to type and search for your destination or have a hard time remembering that address of the friend you are going to meet? It can be really confusing when it comes to keeping track of so many addresses that you frequent on a regular basis. To solve this pain point, Grab rolled out a new feature called Saved Places in January’19 across SouthEast Asia.&lt;/p&gt;

&lt;p&gt;With Saved Places, you can save an address and also add a label like “Home”, “Work”, “Gym”, etc which makes finding and selecting an address for booking a ride or ordering your favourite food a breeze!&lt;/p&gt;

&lt;h2 id=&quot;never-forget-your-addresses-again&quot;&gt;Never forget your addresses again!&lt;/h2&gt;

&lt;p&gt;To use the feature, fire up your Grab app, head to the “Saved Places” section on the app navigation bar and start adding all your favourite destinations such as your home, your office, your favourite mall or the airport and you are done with the hassle of typing them again.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Save your place with Grab!&quot; src=&quot;/img/save-your-place-with-grab/image6.gif&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Hola! your saved addresses are just a click away to order a ride or your favourite meal.&lt;/p&gt;

&lt;h2 id=&quot;inspiration-behind-the-work&quot;&gt;Inspiration behind the work&lt;/h2&gt;

&lt;p&gt;We at Grab continuously engage with our customers to understand how we can outserve them better. Difficulty in choosing the correct address was one of the key feedback shared by our customers. Our drivers shared funny stories about places that have similar names but outrightly different locations e.g. Sime Road is in Bukit Timah but Simei Road is in Simei almost 20 km away, Nicoll Highway is in Kallang but Nicoll Drive is in Changi almost 20 km away. In this case, even though the users use the address frequently, there remains scope for misselection.&lt;/p&gt;

&lt;h3 id=&quot;data-driven-decisions&quot;&gt;Data-Driven Decisions&lt;/h3&gt;

&lt;p&gt;Our vast repository of data and insights has helped us identify and solve some challenging problems. Our analysis of millions of transport bookings and food orders revealed that customers usually visit five to seven unique locations and order food at one or two addresses.&lt;/p&gt;

&lt;p&gt;One intriguing yet intuitive insight that came out was a set pattern in user’s booking behaviour during weekdays. A set of passengers mostly commute between two addresses, probably going to the office in the morning and coming back home in the evening. These identifiable clusters of pick-up and drop-off locations during peak hours signified our hypothesis of users using a small set of locations for their Grab bookings. The pictures below show such clusters in Singapore and Jakarta where passengers generally commute to and fro in morning and in evening respectively.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Save your place with Grab!&quot; src=&quot;/img/save-your-place-with-grab/image2.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;This insight also motivated us to test out the concept of user created labels which allows the users to mark their saved places with their own labels like “Home”, “Changi Airport”, “Sis’s House” etc. Initial experiment results were extremely encouraging and we got significantly higher usage and repeat rates from users.&lt;/p&gt;

&lt;p&gt;A group of cross functional teams - Analytics, Product, Design, Engineering etc came together, worked backwards from the customer, brainstormed multiple ideas, and finalised a product approach. We then went on to conduct in depth user research and usability testing to ensure that the final product met user expectations and was easy to understand and use.&lt;/p&gt;

&lt;h2 id=&quot;and-users-love-it&quot;&gt;And users love it!&lt;/h2&gt;

&lt;p&gt;Since the launch, we have seen significant user adoption for the feature. More than 14 Million users have saved close to 45 Million saved places. That’s ~3 places per user!&lt;/p&gt;

&lt;p&gt;Customers from Singapore and Myanmar tend to save around 3 addresses each whereas customers from Indonesia, Malaysia, Philippines, Thailand, Vietnam and Cambodia save 2 addresses each. A customer from Indonesia has saved a whopping 1,191 addresses!&lt;/p&gt;

&lt;p&gt;Users across South East Asia have adopted the feature and as of today, a significant portion of our bookings are made using a saved place for either pickup or drop off. If you were curious, here are the most frequently used labels for saving addresses in Singapore (left) and Indonesia (right):&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Save your place with Grab!&quot; src=&quot;/img/save-your-place-with-grab/image3.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Apart from saving home and office addresses our customers are also saving their child’s school address and places of worship. Some of them are also saving their favourite shopping destinations.&lt;/p&gt;

&lt;p&gt;Another observation, as someone may have guessed, is regarding cluster of home addresses. Home addresses in Singapore are evenly scattered across the island (map on upper left) but the same are concentrated in specific pockets of the city in Jakarta (map on lower left). However office addresses are concentrated in specific areas in both cities - CBD and Changi area in Singapore (map on upper right) and along central Jakarta in Jakarta (map on lower right).&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Save your place with Grab!&quot; src=&quot;/img/save-your-place-with-grab/image1.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;this-is-only-the-beginning&quot;&gt;This is only the beginning&lt;/h2&gt;

&lt;p&gt;We’re constantly striving to improve the user experience with Grab and make it as seamless as possible. We have only taken the first steps with Saved Places and the path forward involves deeper understanding of user behaviour with the help of saved places data to create a more personalised experience. This is just the beginning and we’re planning to launch some very innovative features in the coming months.&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Aug 2019 18:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/save-your-place-with-grab</link>
        <guid isPermaLink="true">https://engineering.grab.com/save-your-place-with-grab</guid>
        
        <category>Maps</category>
        
        <category>Data</category>
        
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>No More Forgetting to Input ERP Charges - Hello Automated ERP!</title>
        <description>&lt;p&gt;ERP, standing for Electronic Road Pricing, is a system used to manage road congestion in Singapore. Drivers are charged when they pass through ERP gantries during peak hours. ERP rates vary for different roads and time periods based on the traffic conditions at the time. This encourages people to change their mode of transport, travel route or time of travel during peak hours. ERP is seen as an effective measure in addressing traffic conditions and ensuring drivers continue to have a smooth journey.&lt;/p&gt;

&lt;p&gt;Did you know that Singapore has a total of 79 active ERP gantries? Did you also know that every ERP gantry changes its fare 10 times a day on average? For example, total ERP charges for a journey from Ang Mo Kio to Marina will cost $10 if you leave at 8:50am, but $4 if you leave at 9:00am on a working day!&lt;/p&gt;

&lt;p&gt;Imagine how troublesome it would have been for Grab’s driver-partners who, on top of having to drive and check navigation, would also have had to remember each and every gantry they passed, calculating their total fare and then manually entering the charges to the total ride cost at the end of the ride.&lt;/p&gt;

&lt;p&gt;In fact, based on our driver-partners’ feedback, missing out on ERP charges was listed as one of their top-most pain points. Not only did the drivers find the entire process troublesome, this also led to earnings loss as they would have had to bear the cost of the  ERP fares.&lt;/p&gt;

&lt;p&gt;We’re glad to share that, as of 15th March 2019, we’ve successfully resolved this pain point for our driver-partners by introducing automated ERP fare calculation!&lt;/p&gt;

&lt;p&gt;So, how did we achieve automating the ERP fare calculation for our drivers-partners? How did we manage to reduce the number of trips where drivers would forget to enter ERP fare to almost zero? Read on!&lt;/p&gt;

&lt;h2 id=&quot;how-we-approached-the-problem&quot;&gt;How we approached the Problem&lt;/h2&gt;

&lt;p&gt;The question we wanted to solve was - how do we create an impactful feature to make sure that driver -partners have one less thing to handle when they drive?&lt;/p&gt;

&lt;p&gt;We started by looking at the problem at hand. ERP fares in Singapore are very dynamic; it changes on the basis of day and time.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Caption: Example of ERP fare changes on a normal weekday in Singapore&quot; src=&quot;/img/automated-erp-charges/image1.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Caption: Example of ERP fare changes on a normal weekday in Singapore&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;We wanted to create a system which can identify the dynamic ERP fares at any given time and location, while simultaneously identifying when a driver-partner has passed through any of these gantries.&lt;/p&gt;

&lt;p&gt;However, that wasn’t enough. We wanted this feature to be scalable to every country where Grab is in - like Indonesia, Thailand, Malaysia, Philippines, Vietnam. We started studying the ERP (or tolls - as it is known locally) system in other countries. We realized that every country has its own style of calculating toll. While in Singapore ERP charges for cars and taxis are the same, Malaysia applies different charges for cars and taxis. Similarly, Vietnam has different tolls for 4-seaters and 7-seaters. Indonesia and Thailand have couple gantries where you pay only at one of the gantries.Suppose A and B are couple gantries, if you passed through A, you won’t need to pay at B and vice versa. This is where our Ops team came to the rescue!&lt;/p&gt;

&lt;h2 id=&quot;bootson-the-ground&quot;&gt;Boots on the Ground!&lt;/h2&gt;

&lt;p&gt;Collecting all the ERP or toll data for every country is no small feat, recalls Robinson Kudali, program manager for the project. “We had around 15 people travelling across the region for 2-3 weeks, working on collecting data from every possible source in every country.”&lt;/p&gt;

&lt;p&gt;Getting the right geographical coordinates for every gantry is very important. We track driver GPS pings frequently, identify the nearest road to that GPS ping and check the presence of a gantry using its coordinates. The entire process requires you to be very accurate; incorrect gantry location can easily lead to us miscalculating the fare.&lt;/p&gt;

&lt;p&gt;Bayu Yanuaragi, our regional mapops lead, explains - “To do this, the first step was to identify all toll gates for all expressways &amp;amp; highways in the country. The team used various mapping software to locate and plot all entry &amp;amp; exit gates using map sources, open data and more importantly government data as references. Each gate was manually plotted using satellite imagery and aligned with our road layers in order to extract the coordinates with a unique gantry ID.”&lt;/p&gt;

&lt;p&gt;Location precision is vital in creating the dataset as it dictates whether a toll gate will be detected by the Grab app or not. Next step was to identify the toll charge from one gate to another. Accuracy of toll charge per segment directly reflects on the fare that the passenger pays after the trip.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Caption: ERP gantries visualisation on our map - The purple bars are the gantries that we drew on our map&quot; src=&quot;/img/automated-erp-charges/image2.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Caption: ERP gantries visualisation on our map - The purple bars are the gantries that we drew on our map&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Once the data compilation is done, team would then conduct fieldwork to verify its integrity. If data gaps are identified, modifications would be made accordingly.&lt;/p&gt;

&lt;p&gt;Upon submission of the output, stack engineers would perform higher level quality check of the content in staging.&lt;/p&gt;

&lt;p&gt;Lastly, we worked with a local team of driver-partners who volunteered to make sure the new system is fully operational and the prices are correct. Inconsistencies observed were reported by these driver-partners, and then corrected in our system.&lt;/p&gt;

&lt;h2 id=&quot;closing-the-loop&quot;&gt;Closing the loop&lt;/h2&gt;

&lt;p&gt;Creating a strong dataset did help us in predicting correct fares, but we needed something which allows us to handle the dynamic behavior of the changing toll status too. For example, Singapore government revises ERP fare every quarter, while there could also be ad-hoc changes like activating or deactivating of gantries on an on-going basis.&lt;/p&gt;

&lt;p&gt;Garvee Garg, Product Manager for this feature explains: “Creating a system that solves the current problem isn’t sufficient. Your product should be robust enough to handle all future edge case scenarios too. Hence we thought of building a feedback mechanism with drivers.”&lt;/p&gt;

&lt;p&gt;In case our ERP fare estimate isn’t correct or there are changes in ERPs on-ground, our driver-partners can provide feedback to us. These feedback directly flow to Customer Experience teamwho does the initial investigation, and from there to our Ops team. A dedicated person from Ops team checks the validity of the feedback, and recommends updates. It only takes 1 day on average to update the data from when we receive the feedback from the driver-partner.&lt;/p&gt;

&lt;p&gt;However, validating the driver feedback was a time consuming process. We needed a tool which can ease the life of Ops team by helping them in de-bugging each and every case.&lt;/p&gt;

&lt;p&gt;Hence the ERP Workflow tool came into the picture.&lt;/p&gt;

&lt;p&gt;99% of the time, feedback from our driver-partners are about error cases. When feedback comes in, this tool would allow the Ops team to check the entire ride history of the driver and map driver’s ride trajectory with all the underlying ERP gantries at that particular point of time. The Ops team  would then be able to identify if ERP fare calculated by our system or as said by driver is right or wrong.&lt;/p&gt;

&lt;h2 id=&quot;this-is-only-the-beginning&quot;&gt;This is only the beginning&lt;/h2&gt;

&lt;p&gt;By creating a system that can automatically calculate and key in ERP fares for each trip, Grab is proud to say that our driver-partners can now drive with less hassle and focus more on the road which will bring the ride experience and safety for both the driver and the passengers to a new level!&lt;/p&gt;

&lt;p&gt;The Automated ERP feature is currently live in Singapore and we are now testing it with our driver-partners in Indonesia and Thailand. Next up, we plan to pilot in the Philippines and Malaysia and soon to every country where Grab is in - so stay tuned for even more innovative ideas to enhance your experience on our super app!&lt;/p&gt;

&lt;p&gt;To know more about what Grab has been doing to improve the convenience and experience for both our driver-partners and passengers, check out other stories on this blog!&lt;/p&gt;
</description>
        <pubDate>Wed, 31 Jul 2019 13:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/automated-erp-charges</link>
        <guid isPermaLink="true">https://engineering.grab.com/automated-erp-charges</guid>
        
        <category>Data</category>
        
        <category>Maps</category>
        
        <category>Tech</category>
        
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>How We Built a Logging Stack at Grab</title>
        <description>&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;p&gt;Let me take you back a year ago at Grab. When we lacked any visualizations or metrics for our service logs. When performing a query for a string from the last three days was something only run before you went for a beverage.&lt;/p&gt;

&lt;p&gt;When a service stops responding, Grab’s core problems were and are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We need to know it happened before the customer does.&lt;/li&gt;
  &lt;li&gt;We need to know why it happened.&lt;/li&gt;
  &lt;li&gt;We need to solve our customers’ problems fast.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We had a hodgepodge of log-based solutions for developers when they needed to figure out the above, or why a driver never showed up, or a customer wasn’t receiving our promised promotions. These included logs in a cloud based storage service (which could take hours to retrieve). Or a SAS provider constantly timing out on our queries. Or even asking our SREs to fetch logs from the potential machines for the service engineer, a rather laborious process.&lt;/p&gt;

&lt;p&gt;Here’s what we did with our logs to solve these problems.&lt;/p&gt;

&lt;h2 id=&quot;issues&quot;&gt;Issues&lt;/h2&gt;

&lt;p&gt;Our current size and growth rate ruled out several available logging systems. By size, we mean a LOT of data and a LOT of users who search through hundreds of billions of logs to generate reports. Or who track down that one user who managed to find that pesky corner case in our code.&lt;/p&gt;

&lt;p&gt;When we started this project, we generated 25TB of logging data a day. Our first thought was &lt;em&gt;“Do we really need all of these logs?”&lt;/em&gt;. To this day our feeling is &lt;em&gt;“probably not”&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;However, we can’t always define what another developer can and cannot do. Besides, this gave us an amazing opportunity to build something to allow for all that data!&lt;/p&gt;

&lt;p&gt;Some of our SREs had used the ELK Stack (Elasticsearch / Logstash / Kibana). They thought it could handle our data and access loads, so it was our starting point.&lt;/p&gt;

&lt;h2 id=&quot;how-we-built-a-multi-petabyte-cluster&quot;&gt;How We Built a Multi-Petabyte Cluster&lt;/h2&gt;

&lt;h3 id=&quot;information-gathering&quot;&gt;Information Gathering&lt;/h3&gt;

&lt;p&gt;It started with gathering numbers. How much data did we produce each day? How many days were retained? What’s a reasonable response time to wait for?&lt;/p&gt;

&lt;p&gt;Before starting a project, understand your parameters. This helps you spec out your cluster, get buy-in from higher ups, and increase your success rate when rolling out a product used by the entire engineering organization. Remember, if it’s not better than what they have now, why will they switch?&lt;/p&gt;

&lt;p&gt;A good starting point was opening the floor to our users. What features did they want? If we offered a visualization suite so they can see ERROR event spikes, would they use it? How about alerting them about SEGFAULTs? Hands down the most requested feature was speed; &lt;em&gt;“I want an easy webUI that shows me the user ID when I search for it, and get all the results in &amp;lt;5 seconds!”&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;getting-our-feet-wet&quot;&gt;Getting Our Feet Wet&lt;/h3&gt;

&lt;p&gt;New concerns always pop up during a project. We’re sure someone has correlated the time spent in R&amp;amp;D to the number of problems. We had an always moving target, since as our proof of concept began, our daily logger volume kept increasing.&lt;/p&gt;

&lt;p&gt;Thankfully, using &lt;a href=&quot;https://www.elastic.co/&quot;&gt;Elasticsearch&lt;/a&gt; as our data store meant we could fully utilize horizontal scaling. This let us start with a simple 5 node cluster as we built out our proof-of-concept (POC). Once we were ready to onboard more services, we could move into a larger footprint.&lt;/p&gt;

&lt;p&gt;The specs at the time called for about 80 nodes to handle all our data. But if we designed our system correctly, we’d only need to increase the number of Elasticsearch nodes as we enrolled more customers. Our key operating metrics were CPU utilization, heap memory needed for the JVM, and total disk space.&lt;/p&gt;

&lt;h3 id=&quot;initial-design&quot;&gt;Initial Design&lt;/h3&gt;

&lt;p&gt;First, we set up tooling to use &lt;a href=&quot;https://www.ansible.com/&quot;&gt;Ansible&lt;/a&gt; both to launch a machine and to install and configure Elasticsearch. Then we were ready to scale.&lt;/p&gt;

&lt;p&gt;Our initial goal was to keep the design as simple as possible. Opting to allow each node in our cluster to perform all responsibilities. In this setup each node would behave as all of the four available types:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ingest: Used for transforming and enriching documents before sending them to data nodes for indexing.&lt;/li&gt;
  &lt;li&gt;Coordinator: Proxy node for directing search and indexing requests.&lt;/li&gt;
  &lt;li&gt;Master: Used to control cluster operations and determine a quorum on indexed documents.&lt;/li&gt;
  &lt;li&gt;Data: Nodes that hold the indexed data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These were all design decisions made to move our proof of concept along, but in hindsight they might have created more headaches down the road with troubleshooting, indexing speed, and general stability. Remember to do your homework when spec’ing out your cluster.&lt;/p&gt;

&lt;p&gt;It’s challenging to figure out why you are losing master nodes because someone filled up the field data cache performing a search. Separating your nodes can be a huge help in tracking down your problem.&lt;/p&gt;

&lt;p&gt;We also decided to further reduce complexity by going with ingest nodes over Logstash. But at the time, the documentation wasn’t great so we had a lot of trial and error in figuring out how they work. Particularly as compared to something more battle tested like Logstash.&lt;/p&gt;

&lt;p&gt;If you’re unfamiliar with ingest node design, they are lightweight proxies to your data nodes that accept a bulk payload, perform post-processing on documents,and then send the documents to be indexed by your data nodes. In theory, this helps keep your entire pipeline simple. And in Elasticsearch’s defense, ingest nodes have made massive improvements since we began.&lt;/p&gt;

&lt;p&gt;But adding more ingest nodes means ADDING MORE NODES! This can create a lot of chatter in your cluster and cause more complexity when  troubleshooting problems. We’ve seen when an ingest node failing in an odd way caused larger cluster concerns than just a failed bulk send request.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;This isn’t anything new, but we can’t overstate the usefulness of monitoring. Thankfully, we already had a robust tool called Datadog with an additional integration for Elasticsearch. Seeing your heap utilization over time, then breaking it into smaller graphs to display the field data cache or segment memory, has been a lifesaver. There’s nothing worse than a node falling over due to an OOM with no explanation and just hoping it doesn’t happen again.&lt;/p&gt;

&lt;p&gt;At this point, we’ve built out several dashboards which visualize a wide range of metrics from query rates to index latency. They tell us if we sharply drop on log ingestion or if circuit breakers are tripping. And yes, Kibana has some nice monitoring pages for some cluster stats. But to know each node’s JVM memory utilization on a 400+ node cluster, you need a robust metric system.&lt;/p&gt;

&lt;h2 id=&quot;pitfalls&quot;&gt;Pitfalls&lt;/h2&gt;

&lt;h3 id=&quot;common-problems&quot;&gt;Common Problems&lt;/h3&gt;

&lt;p&gt;There are many blogs about the common problems encountered when creating an Elasticsearch cluster and Elastic does a good job of keeping &lt;a href=&quot;https://elastic.co/blog&quot;&gt;blog posts&lt;/a&gt; up to date. We strongly encourage you to read them. Of course, we ran into classic problems like ensuring our Java objects were compressed (Hints: Don’t exceed 31GB of heap for your JVM and always confirm you’ve enabled compression).&lt;/p&gt;

&lt;p&gt;But we also ran into some interesting problems that were less common. Let’s look at some major concerns you have to deal with at this scale.&lt;/p&gt;

&lt;h3 id=&quot;grabs-problems&quot;&gt;Grab’s Problems&lt;/h3&gt;

&lt;h4 id=&quot;field-data-cache&quot;&gt;Field Data Cache&lt;/h4&gt;

&lt;p&gt;So, things are going well, all your logs are indexing smoothly, and suddenly you’re getting Out Of Memory (OOMs) events on your data nodes. You rush to find out what’s happening, as more nodes crash.&lt;/p&gt;

&lt;p&gt;A visual representation of your JVM heap’s memory usage is very helpful here. You can always hit the Elasticsearch API, but after adding more then 5 nodes to your cluster this kind of breaks down. Also, you don’t want to know what’s going on while a node is down, but what happened before it died.&lt;/p&gt;

&lt;p&gt;Using our graphs, we determined the field data cache went from virtually zero memory used in the heap to 20GB! This forced us to read up on how this value is set, and, as of this writing, the default value is still 100% of the parent heap memory. Basically, this breaks down to allowing 70% of your total heap being allocated to a single search in the form of field data.&lt;/p&gt;

&lt;p&gt;Now, this should be a rare case and it’s very helpful to keep the field names and values in memory for quick lookup. But, if, like us, you have several trillion documents, you might want to watch out.&lt;/p&gt;

&lt;p&gt;From our logs, we tracked down a user who was sorting by the &lt;em&gt;id&lt;/em&gt; field. We believe this is a design decision in how Kibana interacts with Elasticsearch. A good counter argument would be a user wants a quick memory lookup if they search for a document using the &lt;em&gt;id&lt;/em&gt;. But for us, this meant a user could load into memory every ID in the indices over a 14 day period.&lt;/p&gt;

&lt;p&gt;The consequences? 20+GB of data loaded into the heap before the circuit breaker tripped. It then only took 2 queries at a time to knock a node over.&lt;/p&gt;

&lt;p&gt;You can’t disable indexing that field, and you probably don’t want to. But you can prevent users from stumbling into this and disable the &lt;em&gt;id&lt;/em&gt; field in the Kibana advanced settings. And make sure you re-evaluate your circuit breakers. We drastically lowered the available field cache and removed any further issues.&lt;/p&gt;

&lt;h4 id=&quot;translog-compression&quot;&gt;Translog Compression&lt;/h4&gt;

&lt;p&gt;At first glance, compression seems an obvious choice for shipping shards between nodes. Especially if you have the free clock cycles, why not minimize the bandwidth between nodes?&lt;/p&gt;

&lt;p&gt;However, we found compression between nodes can drastically slow down shard transfers. By disabling compression, shipping time for a 50GB shard went from 1h to 20m. This was because Lucene segments are already compressed, a new issue we ran into full force and are actively working with the community to fix. But it’s also a configuration to watch out for in your setup, especially if you want a fast recovery of a shard.&lt;/p&gt;

&lt;h4 id=&quot;segment-memory&quot;&gt;Segment Memory&lt;/h4&gt;

&lt;p&gt;Most of our issues involved the heap memory being exhausted. We can’t stress enough the importance of having visualizations around how the JVM is used. We learned this lesson the hard way around segment memory.&lt;/p&gt;

&lt;p&gt;This is a prime example of why you need to understand your data when building a cluster. We were hitting a lot of OOMs and couldn’t figure out why. We had fixed the field cache issue, but what was using all our RAM?&lt;/p&gt;

&lt;p&gt;There is a reason why having a 16TB data node might be a poorly spec’d machine. Digging into it, we realized we simply allocated too many shards to our nodes. Looking up the total segment memory used per index should give a good idea of how many shards you can put on a node before you start running out of heap space. We calculated on average our 2TB indices used about 5GB of segment memory spread over 30 nodes.&lt;/p&gt;

&lt;p&gt;The numbers have since changed and our layout was tweaked, but we came up with calculations showing we could allocate about 8TB of shards to a node with 32GB heap memory before we running into issues. That’s if you really want to push it, but it’s also a metric used to keep your segment memory per node around 50%. This allows enough memory to run queries without knocking out your data nodes. Naturally this led us to ask “What is using all this segment memory per node?”&lt;/p&gt;

&lt;h4 id=&quot;index-mapping-and-field-types&quot;&gt;Index Mapping and Field Types&lt;/h4&gt;

&lt;p&gt;Could we lower how much segment memory our indices used to cut our cluster operation costs? Using the segments data found in the ES cluster and some simple Python loops, we tracked down the total memory used per field in our index.&lt;/p&gt;

&lt;p&gt;We used a lot of segment memory for the &lt;em&gt;id&lt;/em&gt; field (but can’t do much about that). It also gave us a good breakdown of our other fields. And we realized we indexed fields in completely unnecessary ways. A few fields should have been integers but were keyword fields. We had fields no one would ever search against and which could be dropped from index memory.&lt;/p&gt;

&lt;p&gt;Most importantly, this began our learning process of how tokens and analyzers work in Elasticsearch/Lucene.&lt;/p&gt;

&lt;h4 id=&quot;picking-the-wrong-analyzer&quot;&gt;Picking the Wrong Analyzer&lt;/h4&gt;

&lt;p&gt;By default, we use Elasticsearch’s Standard Analyzer on all analyzed fields. It’s great, offering a very close approximation to how users search and it doesn’t explode your index memory like an N-gram tokenizer would.&lt;/p&gt;

&lt;p&gt;But it does a few things we thought unnecessary, so we thought we could save a significant amount of heap memory. For starters, it keeps the original tokens: the Standard Analyzer would break &lt;strong&gt;IDXVB56KLM&lt;/strong&gt; into tokens &lt;strong&gt;IDXVB&lt;/strong&gt;, &lt;strong&gt;56&lt;/strong&gt;,  and &lt;strong&gt;KLM&lt;/strong&gt;. This usually works well, but it really hurts you if you have a lot of alphanumeric strings.&lt;/p&gt;

&lt;p&gt;We never have a user search for a user ID as a partial value. It would be more useful to only return the entire match of an alphanumeric string. This has the added benefit of only storing the single token in our index memory. This modification alone stripped a whole 1GB off our index memory, or at our scale meant we could eliminate 8 nodes.&lt;/p&gt;

&lt;p&gt;We can’t stress enough how cautious you need to be when changing analyzers on a production system. Throughout this process, end users were confused why search results were no longer returning or returning weird results. There is a nice &lt;a href=&quot;https://github.com/johtani/analyze-api-ui-plugin&quot;&gt;kibana plugin&lt;/a&gt; that gives you a representation of how your tokens look with a different analyzer, or use the build in &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/master/_testing_analyzers.html&quot;&gt;ES tools&lt;/a&gt; to get the same understanding.&lt;/p&gt;

&lt;h4 id=&quot;be-careful-with-cloud-maintainers&quot;&gt;Be Careful with Cloud Maintainers&lt;/h4&gt;

&lt;p&gt;We realized that running a cluster at this scale is expensive. The hardware alone sets you back a lot, but our hidden bigger cost was cross traffic between availability zones.&lt;/p&gt;

&lt;p&gt;Most cloud providers offer different “zones” for your machines to entice you to achieve a High-Availability environment. That’s a very useful thing to have, but you need to do a cost/risk analysis. If you migrate shards from HOT to WARM to COLD nodes constantly, you can really rack up a bill. This alone was about 30% of our total cluster cost, which wasn’t cheap at our scale.&lt;/p&gt;

&lt;p&gt;We re-worked how our indices sat in the cluster. This let us create a different index for each zone and pin logging data so it never left the zone it was generated in. One small tweak to how we stored data cut our costs dramatically. Plus, it was a smaller scope for troubleshooting. We’d know a zone was misbehaving and could focus there vs. looking at everything.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Running our own logging stack started as a challenge. We roughly knew the scale we were aiming for; it wasn’t going to be trivial or easy. A year later, we’ve gone from pipe-dream to production and immensely grown the team’s ELK stack knowledge.&lt;/p&gt;

&lt;p&gt;We could probably fill 30 more pages with odd things we ran into, hacks we implemented, or times we wanted to pull our hair out. But we made it through and provide a superior logging platform to our engineers at a significant price reduction while maintaining a stable platform.&lt;/p&gt;

&lt;p&gt;There are many different ways we could have started knowing what we do now. For example, using Logstash over Ingest nodes, changing default circuit breakers, and properly using heap space to prevent node failures. But hindsight is 20/20 and it’s rare for projects to not change.&lt;/p&gt;

&lt;p&gt;We suggest anyone wanting to revamp their centralized logging system look at the ELK solutions. There is a learning curve, but the scalability is outstanding and having subsecond lookup time for assisting a customer is phenomenal. But, before you begin, do your homework to save yourself weeks of troubleshooting down the road. In the end though, we’ve received nothing but praise from Grab engineers about their experiences with our new logging system.&lt;/p&gt;
</description>
        <pubDate>Wed, 31 Jul 2019 11:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/how-built-logging-stack</link>
        <guid isPermaLink="true">https://engineering.grab.com/how-built-logging-stack</guid>
        
        <category>Logging</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Making Grab’s Everyday App Super</title>
        <description>&lt;p&gt;Grab is &lt;a href=&quot;https://www.grab.com/sg/blog/welcome-to-our-everyday-super-app/&quot;&gt;Southeast Asia’s leading superapp&lt;/a&gt;, providing highly-used daily services such as ride-hailing, food delivery, payments, and more. Our goal is to give people better access to the services that matter to them, with more value and convenience, so we’ve been expanding our ecosystem to include bill payments, hotel bookings, trip planners, and videos - with more to come. We want to outserve our customers - not just by packing the Grab app with useful features and services, but by making the whole experience a unique and personalized one for each of them.&lt;/p&gt;

&lt;p&gt;To realize our super app ambitions, we work with &lt;a href=&quot;https://www.grab.com/sg/press/consumers-drivers/grab-introduces-four-new-services-in-singapore-in-its-super-app/&quot;&gt;partners&lt;/a&gt; who, like us, want to help drive Southeast Asia forward.&lt;/p&gt;

&lt;p&gt;A lot of the collaborative work we do with our partners can be seen in the Grab Feed. This is where we broadcast various types of content about Grab and our partners in an aggregated manner, adding value to the overall user experience. Here’s what the feed looks like:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab super app feed&quot; src=&quot;/img/grab-everyday-super-app/image2.gif&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Waiting for the next promo? Check the Feed.&lt;br /&gt;Looking for news and entertainment? Check the Feed.&lt;br /&gt;Want to know if it's a good time to book a car? CHECK. THE. FEED.&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;As we continue to add more cards, services, and chunks of content into Grab Feed, there’s a risk that our users will find it harder to find the information relevant to them. So we work to ensure that our platform is able to distinguish and show information based on what’s most suited for the user’s profile. This goes back to what has always been our central focus - the customer - and is why we put so much importance in personalising the Grab experience for each of them.&lt;/p&gt;

&lt;p&gt;To excel in a heavily diversified market like Southeast Asia, we leverage on the depth of our data to understand what sorts of information users want to see and when they should see them. In this article we will discuss Grab Feed’s recommendation logic and strategies, as well as its future roadmap.&lt;/p&gt;

&lt;h2 id=&quot;start-your-engines&quot;&gt;Start your Engines&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab super app feed&quot; src=&quot;/img/grab-everyday-super-app/image3.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The problem we’re trying to solve here is known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Recommender_system&quot;&gt;recommendations&lt;/a&gt; problem. In a nutshell, this problem is about inferring the preference of consumers to recommend content and services to them. In Grab Feed, we have different types of content that we want to show to different types of consumers and our challenge is to ensure that everyone gets quality content served to them.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab super app feed&quot; src=&quot;/img/grab-everyday-super-app/image4.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;To solve this, we have built a recommendation engine, which is a system that suggests the type of content a user should consider consuming. In order to make a recommendation, we need to understand three factors:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Users&lt;/strong&gt;. There’s a lot we can infer about our users based on how they’ve used the Grab app, such as the number of rides they’ve taken, the type of food they like to order, the movie voucher deals they’ve purchased, the games they’ve played, and so on. &lt;br /&gt;This information gives us the opportunity to understand our users’ preferences better, enabling us to match their profiles with relevant and suitable content.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Items&lt;/strong&gt;. These are the characteristics of the content. We consider the type of the content (e.g. video, games, rewards) and consumability (e.g. purchase, view, redeem). We also consider other metadata such as store hours for merchants, points to burn for rewards, and GPS coordinates for points of interest.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;. This pertains to the setting in which a user is consuming our content. It could be the time of day, the user’s location, or the current feed category.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Using signals from all these factors, we build a model that returns a ranked set of cards to the user. More on this in the next few sections.&lt;/p&gt;

&lt;h2 id=&quot;understanding-our-user&quot;&gt;Understanding our User&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab super app feed&quot; src=&quot;/img/grab-everyday-super-app/image5.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Interpreting user preference from the signals mentioned above is a whole challenge in itself. It’s important here to note that we are in a constant state of experimentation. Slowly but surely, we are continuing to fine tune how to measure content preferences. That being said, we look at two areas:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Action&lt;/strong&gt;. We firmly believe that not all interactions are made equal. Does liking a card actually mean you like it? Do you like things at the same rate as your friends? What about transactions, are those more preferred? The feed introduces a lot of ways for the users to give feedback to the platform. These events include likes, clicks, swipes, views, transactions, and call-to-actions. &lt;br /&gt;Depending on the model, we can take slightly different approaches. We can learn the importance of each event and aggregate them to have an expected rating, or we can predict the probability of each event and rank accordingly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Recency&lt;/strong&gt;. Old interactions are probably not as useful as new ones. The feed is a product that is constantly evolving, and so are the preferences of our users. Failing to decay the weight of older interactions will give us recommendations that are no longer meaningful to our users.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;optimising-the-experience&quot;&gt;Optimising the Experience&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab super app feed&quot; src=&quot;/img/grab-everyday-super-app/image1.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Building a viable recommendation engine requires several phases. Working iteratively, we are able to create a few core recommendation strategies to produce the final model in determining the content’s relevance to the user. We’ll discuss each strategy in this section.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Popularity&lt;/strong&gt;. This strategy is better known as trending recommendations. We capture online clickstream events over a rolling time window and aggregate the events to show the user what’s popular to everyone at that point in time. Listening to the crowds is generally an effective strategy, but this particular strategy also helps us address the cold start problem by providing recommendations for new feed users.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;User Favourites&lt;/strong&gt;. We understand that our users have different tastes and that users will have content that they engage with more than other users would.  In this strategy, we capture that personal engagement and the user’s evolving preferences.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Collaborative Filtering&lt;/strong&gt;.A key goal in building our everyday super app is to let users experience different services. To allow discoverability, we study similar users to uncover a s et ofsimilar preferences they may have, which we can then use to guide what we show other users.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Habitual Behaviour&lt;/strong&gt;. There will be times where users only want to do a specific thing, and we wouldn’t want them to scroll all the way down just to do it. We’ve built in habitual recommendations to address this. So if users always use the feed to scroll through food choices at lunch or to take a peek at ride peaks (pun intended) on Sunday morning, we’ve still got them covered.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deep Recommendations&lt;/strong&gt;. We’ve shown you how we use Feed data to drive usage across the platform. But what about using the platform data to drive the user feed behaviour? By embedding users’ activities from across our multiple businesses, we’re also able to leverage this data along with clickstream to determine the content preferences for each user.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We apply all these strategies to find out the best recommendations to serve the users either by selection or by aggregation. These decisions are determined through regular experiments and studies of our users.&lt;/p&gt;

&lt;h2 id=&quot;always-learning&quot;&gt;Always Learning&lt;/h2&gt;

&lt;p&gt;We’re constantly learning and relearning about our users. There are a lot of ways to understand behaviour and a lot of different ways to incorporate different strategies, so we’re always iterating on these to deliver the most personal experience on the app.&lt;/p&gt;

&lt;p&gt;To identify a user’s preferences and optimal strategy exposure, we capitalise on our&lt;a href=&quot;https://engineering.grab.com/building-grab-s-experimentation-platform&quot;&gt; Experimentation Platform&lt;/a&gt; to expose different configurations of our Recommendation Engine to different users. To monitor the quality of our recommendations, we measure the impact with online metrics such as interaction, clickthrough, and engagement rates and offline metrics like Recall@Kand Normalized Discounted Cumulative Gain (NDCG).&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;/h2&gt;

&lt;p&gt;Through our experience building out this recommendations platform, we realised that the space was large enough and that there’s a lot of pieces that can continuously be built. To keep improving, we’re already working on the following items:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Multi-objective optimisation for business and technical metrics&lt;/li&gt;
  &lt;li&gt;Building out automation pipelines for hyperparameter optimisation&lt;/li&gt;
  &lt;li&gt;Incorporating online learning for real-time model updates&lt;/li&gt;
  &lt;li&gt;Multi-armed bandits for user personalised recommendation strategies&lt;/li&gt;
  &lt;li&gt;Recsplanation system to allow stakeholders to better understand the system&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Grab is one of Southeast Asia’s fastest growing companies. As its business, partnerships, and offerings continue to grow, the super app real estate problem will only keep on getting bigger. In this post, we discuss how we are addressing that problem by building out a recommendation system that understands our users and personalises the experience for each of them. This system (us included) continues to learn and iterate from our users feedback to deliver the best version for them.&lt;/p&gt;

&lt;p&gt;If you’ve got any feedback, suggestions, or other great ideas, feel free to reach me at justin.bolilia@grab.com. Interested in working on these technologies yourself? Check out our &lt;a href=&quot;https://grab.careers/job-details/?id%3D72866c152804010108099fb6ea2fc56d&quot;&gt;career&lt;/a&gt; page.&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Jul 2019 18:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/grab-everyday-super-app</link>
        <guid isPermaLink="true">https://engineering.grab.com/grab-everyday-super-app</guid>
        
        <category>Super App</category>
        
        <category>Feed</category>
        
        <category>Recommendations</category>
        
        <category>Data Science</category>
        
        <category>Machine Learning</category>
        
        
        <category>Data Science</category>
        
        <category>Product</category>
        
      </item>
    
  </channel>
</rss>
