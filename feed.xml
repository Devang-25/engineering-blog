<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 20 Jan 2022 02:33:28 +0000</pubDate>
    <lastBuildDate>Thu, 20 Jan 2022 02:33:28 +0000</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Biometric authentication - Why do we need it?</title>
        <description>&lt;p&gt;In recent years, Identity and Access Management has gained importance within technology industries as attackers continue to target large corporations in order to gain access to private data and services. To address this issue, the Grab Identity team has been using a 6-digit PIN to authenticate a user during a sensitive transaction such as accessing a GrabPay Wallet. We also use SMS one-time passwords (OTPs) to log a user into the application.&lt;/p&gt;

&lt;p&gt;We look at existing mechanisms that Grab uses to authenticate its users and how biometric authentication helps strengthen application security and save costs. We also look at the various technical decisions taken to ensure the robustness of this feature as well as some key learnings.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The mechanisms we use to authenticate our users have evolved as the Grab Identity team consistently refines our approach. Over the years, we have observed several things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OTP and Personal Identification Number (PIN) are susceptible to hacking and social engineering.&lt;/li&gt;
  &lt;li&gt;These methods have high user friction (e.g. delay or failure to receive SMS, need to launch Facebook/Google).&lt;/li&gt;
  &lt;li&gt;Shared/rented driver accounts cause safety concerns for passengers and increases potential for fraud.&lt;/li&gt;
  &lt;li&gt;High OTP costs at $0.03/SMS.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Social engineering efforts have gotten more advanced - attackers could pretend to be your friends and ask for your OTP or even post phishing advertisements that prompt for your personal information.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/img/biometrics-authentication/image3.png&quot; alt=&quot;Search data flow&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/img/biometrics-authentication/image1.png&quot; alt=&quot;Search data flow&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/biometrics-authentication/image2.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:60%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;With more sophisticated social engineering attacks on the rise, we need solutions that can continue to protect our users and Grab in the long run.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;When we looked into developing solutions for these problems, which was mainly about cost and security, we went back to basics and looked at what a secure system meant.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Knowledge Factor: Something that you know (password, PIN, some other data)&lt;/li&gt;
  &lt;li&gt;Possession Factor: Something physical that you have (device, keycards)&lt;/li&gt;
  &lt;li&gt;Inherent Factor: Something that you are (face ID, fingerprint, voice)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We then compared the various authentication mechanisms that the Grab app currently uses, as shown in the following table:&lt;/p&gt;

&lt;table border=&quot;1&quot; style=&quot;text-align: center&quot;&gt;
&lt;tr style=&quot;text-align:center&quot;&gt;
  &lt;td&gt; &lt;strong&gt;Authentication factor&lt;/strong&gt;&lt;/td&gt;
  &lt;td&gt; &lt;strong&gt;1. Something that you know&lt;/strong&gt; &lt;/td&gt;
  &lt;td&gt; &lt;strong&gt;2. Something physical that you have&lt;/strong&gt; &lt;/td&gt;
  &lt;td&gt; &lt;strong&gt;3. Something that you are&lt;/strong&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;OTP&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;Social&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;PIN&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;Biometrics&lt;/td&gt;
  &lt;td&gt;&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
  &lt;td&gt;✔️&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;With methods based on the knowledge and possession factors, it is still possible for attackers to get users to reveal sensitive account information. On the other hand, biometrics are something you are born with and that makes it more complex to mimic. Hence, we have added biometrics as an additional layer to enhance Grab’s existing authentication methods and build a more secure platform for our users.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;Biometric authentication powered by device biometrics provides a robust platform to enhance trust. This is because modern phones provide a few key features that allow client server trust to be established:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Biometric sensor (fingerprint or face ID).&lt;/li&gt;
  &lt;li&gt;Advent of devices with secure enclaves.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A secure enclave, being a part of the device, is separate from the main operating system (OS) at the kernel level. The enclave is used to store private keys that can be unlocked only by the biometrics on the device.&lt;/p&gt;

&lt;p&gt;Any changes to device security such as changing a PIN or adding another fingerprint will invalidate all prior access to this secure enclave. This means that when we enroll a user in biometrics this way, we can be sure that any payload from said device that matches the public part of said private key is authorised by the user that created it.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/biometrics-authentication/image4.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:60%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/biometrics-authentication/image6.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:60%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;architecture-details&quot;&gt;Architecture details&lt;/h3&gt;

&lt;p&gt;The important part of the approach lies in the enrollment flow. The process is quite simple and can be described in the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create an elevated public/private key pair that requires users authentication.&lt;/li&gt;
  &lt;li&gt;Ask users to authenticate in order to prove they are the device holders.&lt;/li&gt;
  &lt;li&gt;Sign payload with confirmed unlocked private key and send public key to finish enrolling.&lt;/li&gt;
  &lt;li&gt;Store returned reference id in the encrypted shared preferences/keychain.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/biometrics-authentication/image5.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:60%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;p&gt;The key implementation details is as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Grab’s HellfireSDK confirms if the device is not rooted.&lt;/li&gt;
  &lt;li&gt;Uses SHA512withECDSA for hashing algorithm.&lt;/li&gt;
  &lt;li&gt;Encrypted shared preferences/keychain to store data.&lt;/li&gt;
  &lt;li&gt;Secure enclave to store private keys.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These key technologies allow us to create trust between devices and services. The raw biometric data stays within the device and instead sends an encrypted signature of biometry data to Grab for verification purposes.&lt;/p&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;p&gt;Biometric login aims to resolve the many problems highlighted earlier in this article such as reducing user friction and saving SMS OTP costs.&lt;/p&gt;

&lt;p&gt;We are still experimenting with this feature so we do not have insights on business impact yet. However, from early experiment runs, we estimate over 90% adoption rate and a success rate of nearly 90% for biometric logins.&lt;/p&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;p&gt;As methods of executing identity theft or social engineering get more creative, simply using passwords and PINs is not enough. Grab, and many other organisations, are realising that it’s important to augment existing security measures with methods that are inherent and unique to users.&lt;/p&gt;

&lt;p&gt;By using biometrics as an added layer of security in a multi-factor authentication strategy, we can keep our users safe and decrease the probability of successful attacks. Not only do we ensure that the user is a legitimate entity, we also ensure that we protect their privacy by ensuring that the biometric data remains on the user’s device.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;IdentitySDK - this feature will be moved into an SDK so other teams integrate it via plug and play.&lt;/li&gt;
  &lt;li&gt;Standalone biometrics - biometric authentication is currently tightly coupled with PIN i.e. biometric authentication happens in place of PIN if biometric authentication is set up. Therefore, users would never see both PIN and biometric in the same session, which limits our robustness in terms of multi-factor authentication.&lt;/li&gt;
  &lt;li&gt;Integration with DAX and beyond - We plan to enable this feature for all teams who need to use biometric authentication.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Jan 2022 00:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/biometrics-authentication</link>
        <guid isPermaLink="true">https://engineering.grab.com/biometrics-authentication</guid>
        
        <category>Engineering</category>
        
        <category>Security</category>
        
        
        <category>Security</category>
        
      </item>
    
      <item>
        <title>Using real-world patterns to improve matching in theory and practice</title>
        <description>&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;A research publication authored by Tenindra Abeywickrama (Grab), Victor Liang (Grab) and Kian-Lee Tan (NUS) based on their work, which was awarded the Best Scalable Data Science Paper Award for 2021.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Matching the right passengers to the right driver-partners is a critically important task in ride-hailing services. Doing this suboptimally can lead to passengers taking longer to reach their destinations and drivers losing revenue. Perhaps, the most challenging of all is that this is a continuous process with a constant stream of new ride requests and new driver-partners becoming available. This makes computing matchings a very computationally expensive task requiring high throughput.&lt;/p&gt;

&lt;p&gt;We discovered that one component of the typically used algorithm to find matchings has a significant impact on efficiency that has hitherto gone unnoticed. However, we also discovered a useful property of real-world optimal matchings that allows us to improve the algorithm, in an interesting scenario of practice informing theory.&lt;/p&gt;

&lt;h2 id=&quot;a-real-world-example&quot;&gt;A real-world example&lt;/h2&gt;

&lt;p&gt;Let us consider a simple matching algorithm as depicted in Figure 1, where passengers and driver-partners are matched by travel time. In the figure, we have three driver-partners (D1, D2, and D3) and three passengers (P1, P2, and P3).&lt;/p&gt;

&lt;p&gt;Finding the travel time involves computing the fastest route from each driver-partner to each passenger, for example the dotted routes from D1 to P1, P2 and P3 respectively. Finding the assignment of driver-partners to passengers that minimise the overall travel time involves representing the problem in a more abstract way as a bipartite graph shown below.&lt;/p&gt;

&lt;p&gt;In the bipartite graph, the set of passengers and the set of driver-partners form the two bipartite sets, respectively. The edges connecting them represent the travel time of the fastest routes, and their costs are shown in the cost matrix on the right.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig1.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 1. Example driver-to-passenger matching scenario&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Finding the optimal assignment is known as solving the minimum weight bipartite matching problem (also known as the assignment problem). This problem is often solved using a technique called the Kuhn-Munkres (KM) algorithm&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; (also known as the Hungarian Method).&lt;/p&gt;

&lt;p&gt;If we were to run the algorithm on the scenario shown in Figure 1, we would find the optimal matching highlighted in red on the cost matrix shown in the figure. However, there is an important step that we have not paid great attention to so far, and that is the computation of the cost matrix. As it turns out, this step has quite a significant impact on performance in real-world settings.&lt;/p&gt;

&lt;h2 id=&quot;impact-of-the-cost-matrix&quot;&gt;Impact of the cost matrix&lt;/h2&gt;

&lt;p&gt;Past work that solves the assignment problem assumes the cost matrix is given as input, but we observe that the time taken to compute the cost matrix is not always trivial. This is especially true in our real-world scenario. Firstly, matching driver-partners and passengers is a continuous process, as we mentioned earlier. Costs are not fixed; they change over time as driver-partners move and new passenger requests are received.&lt;/p&gt;

&lt;p&gt;This means the matrix must be recomputed each time we attempt a matching (for example every X seconds). Not only is finding the shortest path between a single passenger and driver-partner computationally expensive, we must do this for all pairs of passengers and driver-partners. In fact, in the real world, the time taken to compute the matrix is longer than the time taken to compute the optimal assignment! A simple consideration of time complexity suggests that this is true.&lt;/p&gt;

&lt;p&gt;If m is the number of driver-partners/passengers we are trying to match, the KM algorithm typically runs in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(m^3)&lt;/code&gt;. If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; is the number of nodes in the road network, then computing the cost matrix runs in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(m x n log n)&lt;/code&gt; using Dijkstra’s algorithm&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;We know that n is around 400,000 for Singapore’s road network (and much larger for bigger cities), thus we can reasonably expect &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(m x n log n)&lt;/code&gt; to dominate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(m^3)&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m &amp;lt; 1500&lt;/code&gt;, which is the kind of value for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; we expect in the real-world. We ran experiments on Singapore’s road network to verify this, as shown in Figure 2.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig2a.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig2b.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 2. Proportion of time to compute the matrix vs. assignment for varying m on the Singapore road network&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 2a, we can see that m must be greater than 2500, before the assignment time overtakes the matrix computation time. Even if we use a modern and advanced technique like Contraction Hierarchies&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; to compute the fastest path, the observation holds, as shown in Figure 2b. This shows we can significantly improve overall matching performance if we can reduce the matrix computation time.&lt;/p&gt;

&lt;h2 id=&quot;a-redeeming-intuition-spatial-locality-of-matching&quot;&gt;A redeeming intuition: Spatial locality of matching&lt;/h2&gt;

&lt;p&gt;While studying real-world locations of passengers and driver-partners, we observed an interesting property, which we dubbed “spatial locality of matching”. We find that the passenger assigned to each driver-partner in an optimal matching is one of the nearest passengers to the driver-partner (it might not be the nearest). This makes intuitive sense as passengers and driver-partners will be distributed throughout a city and it’s unlikely that the best match for a particular driver-partner is on the other side of the city.&lt;/p&gt;

&lt;p&gt;In Figure 3, we see an example scenario exhibiting spatial locality of matching. While this is an idealised case to demonstrate the principle, it is not a significant departure from the real-world. From the cost matrix shown, it is very easy to see which assignment will give the lowest total travel time.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig3.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 3. Example driver-partner to passenger matching scenario exhibiting spatial locality of matching&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Now, it begs the question, do we even need to compute the other costs to find the optimal matching? For example, can we avoid computing the cost from D3 to P1, which are very far apart and unlikely to be matched?&lt;/p&gt;

&lt;h2 id=&quot;incremental-kuhn-munkres&quot;&gt;Incremental Kuhn-Munkres&lt;/h2&gt;

&lt;p&gt;As it turns out, there is a way to take advantage of spatial locality of matching to reduce cost computation time. We propose an Incremental KM algorithm that computes costs only when they are required, and (hopefully) avoids computing all of them. Our modified KM algorithm incorporates an inexpensive lower-bounding technique to achieve this without adding significant overhead, as we will elaborate in the next section.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig4.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 4. System overview of Incremental Kuhn-Munkres implementation&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Retrieving objects nearest to a query point by their fastest route is a very well studied problem (commonly referred to as k-Nearest Neighbour search)&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. We employ this concept to implement a priority queue &lt;code&gt;Q&lt;sup&gt;i&lt;/sup&gt;&lt;/code&gt; for each driver &lt;code&gt;u&lt;sub&gt;i&lt;/sub&gt;&lt;/code&gt;, as displayed in Figure 4. These priority queues allow retrieving the nearest passengers by a lower-bound on the travel time. The top of a priority queue implies a lower-bound on the travel time for &lt;strong&gt;all&lt;/strong&gt; passengers that have not been retrieved yet. We can then use this minimum lower-bound as a lower-bound edge cost for all bipartite edges associated with that driver-partner for which we have not computed the exact cost so far.&lt;/p&gt;

&lt;p&gt;Now, the KM algorithm can proceed as usual, using the virtual edge cost implied by the relevant priority queue, to avoid computing the exact edge cost. Of course, there may be circumstances where the virtual edge cost is insufficiently accurate for KM to compute the optimal matching. To solve this, we propose refinement rules that detect when a virtual edge cost is insufficient.&lt;/p&gt;

&lt;p&gt;If a rule is triggered, we refine the queue by retrieving the top element and computing its exact edges; this is where the “incremental” part comes from. In almost all cases, this will also increase the minimum key (lower-bound) in the priority queue.&lt;/p&gt;

&lt;p&gt;If you’re interested in finding out more, you can delve deeper into the pruning rules, inner workings of the algorithm and mathematical proofs of correctness by reading our research paper&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;For now, it suffices to say that the Incremental KM algorithm produces the exact same result as the original KM algorithm. It just does so in an optimistic incremental way, hoping that we can find the result without computing all possible costs. This is perfectly suited to take advantage of spatial locality of matching. Moreover, not only do we save time by avoiding computing exact costs, we avoid computing longer fastest paths/travel times to further away passengers that are more computationally expensive than those for nearby passengers.&lt;/p&gt;

&lt;h2 id=&quot;experimental-investigation&quot;&gt;Experimental investigation&lt;/h2&gt;

&lt;h3 id=&quot;competition&quot;&gt;Competition&lt;/h3&gt;

&lt;p&gt;We conducted a thorough experimental investigation to verify the practical performance of the proposed techniques. We implemented two variants of our Incremental KM technique, differing in the implementation of the priority queue and the shortest path technique used.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IKM-DIJK: Uses Dijkstra’s algorithm to compute shortest paths. Priority queues are simply the priority queue of the Dijkstra’s search from each driver-partner. This adds no overhead over the regular KM algorithm, so any speedup comes for free.&lt;/li&gt;
  &lt;li&gt;IKM-GAC: Uses state-of-the-art lower-bound technique COLT&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; to implement the priority queues and G-tree&lt;sup id=&quot;fnref:4:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, a fast technique to compute shortest paths. The COLT index must be built for each assignment, and this overhead is included in all running times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We compared our proposed variants against the regular KM algorithm using Dijkstra and G-tree, respectively, to compute the entire cost matrix up front. Thus, we can make an apples-to-apples comparison to see how effective our techniques are.&lt;/p&gt;

&lt;h3 id=&quot;datasets&quot;&gt;Datasets&lt;/h3&gt;

&lt;p&gt;We ran experiments using the real-world road network for Singapore. For the Singapore dataset, we also use a real production workload consisting of Grab bookings over a 7-day period from December 2018.&lt;/p&gt;

&lt;h3 id=&quot;performance-evaluation&quot;&gt;Performance evaluation&lt;/h3&gt;

&lt;p&gt;To test our technique on the Singapore workload, we created an assignment problem by first choosing the window size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;W&lt;/code&gt; in seconds. Then, we batched all the bookings in a randomly selected window of that size and used the passenger and driver-partner locations from these bookings to create the bipartite sets. Next, we found an optimal matching using each technique and reported the results averaged over several randomly selected windows for several metrics.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig5.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:70%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 5. Average percentage of the cost matrix computed by each technique vs. batching window size&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 5, we verify that our proposed techniques are indeed computing fewer exact costs compared to their counterparts. Naturally, the original KM variants compute 100% of the matrix.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig6.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:70%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 6. Average running time to find an optimal assignment by each technique vs. batching window size&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 6, we can see the running times of each technique. The results in the figure confirm that the reduced computation of exact costs translates to a significant reduction of running time by over an order of magnitude. This verifies that the time saved is greater than any overhead added. Remember, the improvement of IKM-DIJK comes essentially for free! On the other hand, using IKM-GAC can achieve very low running times.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/using-real-world-patterns-to-improve-matching/fig7.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 7. Maximum throughput supported by each technique vs. batching window size&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 7, we report a slightly different metric. We measure &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt;, the maximum number of passengers/driver-partners that can be batched within the time window &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;W&lt;/code&gt;. This can be considered as the maximum throughput of each technique. Our technique supports significantly higher throughput.&lt;/p&gt;

&lt;p&gt;Note that the improvement is smaller than in other cases because real-world values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; rarely reach these levels, where the assignment time starts to take up a greater proportion of the overall computation time.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In summary, computing assignment costs do indeed have a significant impact on the running time of finding optimal assignments. However, we show that by utilising the spatial locality of matching inherent in real-world assignment problems, we can avoid computing exact costs, unless absolutely necessary, by modifying the KM algorithm to work incrementally.&lt;/p&gt;

&lt;p&gt;We presented an interesting case where practice informs the theory, with our novel modifications to the classical KM algorithm. Moreover, our technique can be potentially applied beyond driver-partner and passenger matching in ride-hailing services.&lt;/p&gt;

&lt;p&gt;For example, the Route Inspection algorithm also uses shortest path edge costs to find a minimum-weight bipartite matching, and our technique could be a drop-in replacement. It would also be interesting to see if these principles can be generalised and applied to other domains where the assignment problem is used.&lt;/p&gt;

&lt;h3 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;This research was jointly conducted between Grab and the Grab-NUS AI Lab within the Institute of Data Science at the National University of Singapore (NUS). Tenindra Abeywickrama was previously a postdoctoral fellow at the lab and now a data scientist with Grab.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Kian-Lee Tan from NUS for co-authoring this paper.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;!-- &lt;placeholder image of Tenindra and Victor with the plaque - Caption: Tenindra and Victor with the Best Scalable Data Science Paper Award, XX 2021&gt; --&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;!-- [^1]: H. W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly 2, 1-2 (1955), 83–97
[^2]: Dijkstra, E.W. A note on two problems in connexion with graphs. Numer. Math. 1, 269–271 (1959)
[^3]:  Robert Geisberger, Peter Sanders, Dominik Schultes, and Daniel Delling. 2008. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. In WEA. 319–333
[^4]:  Tenindra Abeywickrama, Victor Liang, and Kian-Lee Tan. 2021. Optimizing bipartite matching in real-world applications by incremental cost computation. Proc. VLDB Endow. 14, 7 (March 2021), 1150–1158
[^5]:  Tenindra Abeywickrama, Muhammad Aamir Cheema, and Sabine Storandt. 2020. Hierarchical Graph Traversal for Aggregate k Nearest Neighbors Search in Road Networks. In ICAPS. 2–10
[^6]:  Ruicheng Zhong, Guoliang Li, Kian-Lee Tan, Lizhu Zhou, and Zhiguo Gong. 2015. G-Tree: An Efficient and Scalable Index for Spatial Search on Road Networks. IEEE Trans. Knowl. Data Eng. 27, 8 (2015), 2175–2189 --&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;H. W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly 2, 1-2 (1955), 83–97 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Dijkstra, E.W. A note on two problems in connexion with graphs. Numer. Math. 1, 269–271 (1959) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Robert Geisberger, Peter Sanders, Dominik Schultes, and Daniel Delling. 2008. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. In WEA. 319–333 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Ruicheng Zhong, Guoliang Li, Kian-Lee Tan, Lizhu Zhou, and Zhiguo Gong. 2015. G-Tree: An Efficient and Scalable Index for Spatial Search on Road Networks. IEEE Trans. Knowl. Data Eng. 27, 8 (2015), 2175–2189 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:4:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Tenindra Abeywickrama, Victor Liang, and Kian-Lee Tan. 2021. Optimizing bipartite matching in real-world applications by incremental cost computation. Proc. VLDB Endow. 14, 7 (March 2021), 1150–1158 &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Tenindra Abeywickrama, Muhammad Aamir Cheema, and Sabine Storandt. 2020. Hierarchical Graph Traversal for Aggregate k Nearest Neighbors Search in Road Networks. In ICAPS. 2–10 &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 22 Nov 2021 00:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/using-real-world-patterns-to-improve-matching</link>
        <guid isPermaLink="true">https://engineering.grab.com/using-real-world-patterns-to-improve-matching</guid>
        
        <category>Data Science</category>
        
        <category>Research</category>
        
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Designing products and services based on Jobs to be Done</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In 2016, Clayton Christensen, a Harvard Business School professor, wrote a book called &lt;a href=&quot;https://www.amazon.com/Competing-Against-Luck-Innovation-Customer/dp/0062435612&quot;&gt;Competing Against Luck&lt;/a&gt;. In his book, he talked about the kind of jobs that exist in our everyday life and how we can uncover hidden jobs through the act of non-consumption. Non-consumption is the inability for a consumer to fulfil an important Job to be Done (JTBD).&lt;/p&gt;

&lt;p&gt;JTBD is a framework; it is a different way of looking at consumer goals and is based on the notion that people buy products and services to get a job done. In this article, we will walk through what the JTBD framework is, look at an example of a popular JTBD, and look at how we use the JTBD framework in one of Grab’s services.&lt;/p&gt;

&lt;h2 id=&quot;jtbd-framework&quot;&gt;JTBD framework&lt;/h2&gt;

&lt;p&gt;In his book, Clayton Christensen gives the example of the milkshake, as a JTBD example. In the mid-90s, a fast food chain was trying to understand how to improve the milkshakes they were selling and how they could sell more milkshakes. To sell more, they needed to improve the product. To understand the job of the milkshake, they interviewed their customers. They asked their customers why they were buying the milkshakes, and what progress the milkshake would help them make.&lt;/p&gt;

&lt;h3 id=&quot;job-1-to-fill-their-stomachs&quot;&gt;Job 1: To fill their stomachs&lt;/h3&gt;

&lt;p&gt;One of the key insights was the first job, the customers wanted something that could fill their stomachs during their early morning commute to the office. Usually, these car drives would take one to two hours, so they needed something to keep them awake and to keep themselves full.&lt;/p&gt;

&lt;p&gt;In this scenario, the competition could be a banana, but think about the properties of a banana. A banana could fill your stomach but your hands get dirty and sticky after peeling it. Bananas cannot do a good job here. Another competitor could be a Snickers bar, but it is rather unhealthy, and depending on how many bites you take, you could finish it in one minute.&lt;/p&gt;

&lt;p&gt;By understanding the job the milkshake was performing, the restaurant now had a specific way of improving the product. The milkshake could be made milkier so it takes time to drink through a straw. The customer can then enjoy the milkshake throughout the journey; the milkshake is optimised for the job.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/designing-products-and-services-based-on-jtbd/milkshake.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:60%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Milkshake&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;job-2-to-make-children-happy&quot;&gt;Job 2: To make children happy&lt;/h3&gt;

&lt;p&gt;As part of the study, they also interviewed parents who came to buy milkshakes in the afternoon, around 3:00 PM. They found out that the parents were buying the milkshakes to make their children happy.&lt;/p&gt;

&lt;p&gt;By knowing this, they were able to optimise the job by offering a smaller version of the milkshake which came in different flavours like strawberry and chocolate. From this milkshake example, we learn that &lt;em&gt;multiple jobs can exist for one product&lt;/em&gt;. From that, we can make changes to a product to meet those different jobs.&lt;/p&gt;

&lt;h2 id=&quot;jtbd-at-grabfood&quot;&gt;JTBD at GrabFood&lt;/h2&gt;

&lt;p&gt;A team at GrabFood wanted to prioritise which features or products to build, and performed a prioritisation exercise. However, there was a lack of fundamental understanding of why our consumers were using GrabFood or any other food delivery services. To gain deeper insights on this, we conducted a JTBD study.&lt;/p&gt;

&lt;p&gt;We applied the JTBD framework in our research investigation. We used the force diagram framework to find out what job a consumer wanted to achieve and the corresponding push and pull factors driving the consumer’s decision. A job here is defined as the progress that the consumer is trying to make in a particular context.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/designing-products-and-services-based-on-jtbd/force-diagram.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Force diagram&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;There were four key points in the force diagram:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What jobs are people using GrabFood for?&lt;/li&gt;
  &lt;li&gt;What did people use prior to GrabFood to get the jobs done?&lt;/li&gt;
  &lt;li&gt;What pushed them to seek a new solution? What is attractive about this new solution?&lt;/li&gt;
  &lt;li&gt;What are the things that will make them go back to the old product? What are the anxieties of the new product?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By applying this framework, we progressively asked these questions in our interview sessions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Can you remind us of the last time you used GrabFood?&lt;/em&gt; — This was to uncover the situation or the circumstances.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Why did you order this food?&lt;/em&gt; — This was to get down to the core of the need.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Can you tell us, before GrabFood, what did you use to get the same job done?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the interview sessions, we were able to uncover a number of JTBDs, one example was working parents buying food for their families. Before GrabFood, most of them were buying from food vendors directly, but that is a time consuming activity and it adds additional friction to an already busy day. This led them in search of a new solution and GrabFood provided that solution.&lt;/p&gt;

&lt;p&gt;Let’s look at this JTBD in more depth. One anxiety that parents had when ordering GrabFood was the sheer number of choices they had to make in order to check out their order:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/designing-products-and-services-based-on-jtbd/force-diagram-example-1.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Force diagram - inertia, anxiety&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;There was already a solution for this problem: bundles! Food bundles is a well-known concept from the food and beverage industry; items that complement each other are bundled together for a more efficient checkout experience.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/designing-products-and-services-based-on-jtbd/force-diagram-example-2.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Force diagram - pull, push&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;However, not all GrabFood merchants created bundles to solve this problem for their consumers. This was an untapped opportunity for the merchants to solve a critical problem for their consumers. Eureka! We knew that we needed to help merchants create bundles in an efficient way to solve for the consumer’s JTBD.&lt;/p&gt;

&lt;p&gt;We decided to add a functionality to the GrabMerchant app that allowed merchants to create bundles. We built an algorithm that matched complementary items and automatically suggested these bundles to merchants. The merchant only had to tap a button to create a bundle instantly.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/designing-products-and-services-based-on-jtbd/bundle.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Bundle&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The feature was released and thousands of restaurants started adding bundles to their menu. Our JTBD analysis proved to be correct: food and beverage entrepreneurs were now equipped with an essential tool to drive growth and we removed an obstacle for parents to choose GrabFood to solve for their JTBD.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;At Grab, we understand the importance of research. We educate designers and other non-researcher employees to conduct research studies. We also encourage the sharing of research findings, and we ensure that research insights are consumable. By using the JTBD framework and asking questions specifically to understand the job of our consumers and partners, we are able to gain fundamental understanding of why our consumers are using our products and services. This helps us improve our products and services, and optimise it for the jobs that need to be done throughout Southeast Asia.&lt;/p&gt;

&lt;p&gt;This article was written based on an episode of the Grab Design Podcast - a conversation with Grab Lead Researcher Soon Hau Chua. Want to listen to the Grab Design Podcast? Join the team, we’re &lt;a href=&quot;https://grab.careers/&quot;&gt;hiring&lt;/a&gt;!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to &lt;em&gt;Amira Khazali&lt;/em&gt; and &lt;em&gt;Irene&lt;/em&gt; from Tech Learning.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Oct 2021 01:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/designing-products-and-services-based-on-jtbd</link>
        <guid isPermaLink="true">https://engineering.grab.com/designing-products-and-services-based-on-jtbd</guid>
        
        <category>Design</category>
        
        <category>Product</category>
        
        <category>Database</category>
        
        <category>User Research</category>
        
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Search indexing optimisation</title>
        <description>&lt;p&gt;Modern applications commonly utilise various database engines, with each serving a specific need. At Grab Deliveries, MySQL database (DB) is utilised to store canonical forms of data, and Elasticsearch to provide advanced search capabilities. MySQL serves as the primary data storage for raw data, and Elasticsearch as the derived storage.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/search-data-flow.png&quot; alt=&quot;Search data flow&quot; style=&quot;width:50%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Search data flow&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Efforts have been made to synchronise data between MySQL and Elasticsearch. In this post, a series of techniques will be introduced on how to optimise incremental search data indexing.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;The synchronisation of data from the primary data storage to the derived data storage is handled by Food-Puxian, a Data Synchronisation Platform (DSP). In a search service context, it is the synchronisation of data between MySQL and Elasticsearch.&lt;/p&gt;

&lt;p&gt;The data synchronisation process is triggered on every real-time data update to MySQL, which will streamline the updated data to Kafka. DSP consumes the list of Kafka streams and incrementally updates the respective search indexes in Elasticsearch. This process is also known as &lt;em&gt;Incremental Sync&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;kafka-to-dsp&quot;&gt;Kafka to DSP&lt;/h3&gt;

&lt;p&gt;DSP uses Kafka streams to implement Incremental Sync. A stream represents an unbounded, continuously updating data set, which is ordered, replayable and fault-tolerant.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/data-synchronisation-process-using-kafka.png&quot; alt=&quot;Data synchronisation process using Kafka&quot; style=&quot;width:50%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data synchronisation process using Kafka&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The above diagram depicts the process of data synchronisation using Kafka. The Data Producer creates a Kafka stream for every operation done on MySQL and sends it to Kafka in real-time. DSP creates a stream consumer for each Kafka stream and the consumer reads data updates from respective Kafka streams and synchronises them to Elasticsearch.&lt;/p&gt;

&lt;h3 id=&quot;mysql-to-elasticsearch&quot;&gt;MySQL to Elasticsearch&lt;/h3&gt;

&lt;p&gt;Indexes in Elasticsearch correspond to tables in MySQL. MySQL data is stored in tables, while Elasticsearch data is stored in indexes. Multiple MySQL tables are joined to form an Elasticsearch index. The below snippet shows the Entity-Relationship mapping in MySQL and Elasticsearch. Entity A has a one-to-many relationship with entity B. Entity A has multiple associated tables in MySQL, table A1 and A2, and they are joined into a single Elasticsearch index A.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/er-mapping-in-mysql-and-es.png&quot; alt=&quot;ER mapping in MySQL and Elasticsearch&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;ER mapping in MySQL and Elasticsearch&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Sometimes a search index contains both entity A and entity B. In a keyword search query on this index, e.g. “Burger”, objects from both entity A and entity B whose name contains “Burger” are returned in the search response.&lt;/p&gt;

&lt;h2 id=&quot;original-incremental-sync&quot;&gt;Original Incremental Sync&lt;/h2&gt;

&lt;h3 id=&quot;original-kafka-streams&quot;&gt;Original Kafka streams&lt;/h3&gt;

&lt;p&gt;The Data Producers create a Kafka stream for every MySQL table in the ER diagram above. Every time there is an insert, update, or delete operation on the MySQL tables, a copy of the data after the operation executes is sent to its Kafka stream. DSP creates different stream consumers for every Kafka stream since their data structures are different.&lt;/p&gt;

&lt;h3 id=&quot;stream-consumer-infrastructure&quot;&gt;Stream Consumer infrastructure&lt;/h3&gt;

&lt;p&gt;Stream Consumer consists of 3 components.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Event Dispatcher&lt;/strong&gt;: Listens and fetches events from the Kafka stream, pushes them to the Event Buffer and starts a goroutine to run Event Handler for every event whose ID does not exist in the Event Buffer.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Event Buffer&lt;/strong&gt;: Caches events in memory by the primary key (aID, bID, etc). An event is cached in the Buffer until it is picked by a goroutine or replaced when a new event with the same primary key is pushed into the Buffer.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Event Handler&lt;/strong&gt;: Reads an event from the Event Buffer and the goroutine started by the Event Dispatcher handles it.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/stream-consumer-infrastructure.png&quot; alt=&quot;Stream consumer infrastructure&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Stream consumer infrastructure&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;event-buffer-procedure&quot;&gt;Event Buffer procedure&lt;/h3&gt;

&lt;p&gt;Event Buffer consists of many sub buffers, each with a unique ID which is the primary key of the event cached in it. The maximum size of a sub buffer is 1. This allows the Event Buffer to deduplicate events having the same ID in the buffer.&lt;/p&gt;

&lt;p&gt;The below diagram shows the procedure of pushing an event to the Event Buffer. When a new event is pushed to the buffer, the old event sharing the same ID will be replaced. The replaced event is therefore not handled.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/pushing-an-event-to-the-event-buffer.png&quot; alt=&quot;Pushing an event to the Event Buffer&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Pushing an event to the Event Buffer&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;event-handler-procedure&quot;&gt;Event Handler procedure&lt;/h3&gt;

&lt;p&gt;The below flowchart shows the procedures executed by the &lt;em&gt;Event Handler&lt;/em&gt;. It consists of the common handler flow (in white), and additional procedures for object B events (in green). After creating a new Elasticsearch document by data loaded from the database, it will get the original document from Elasticsearch to compare if any field is changed and decide whether it is necessary to send the new document to Elasticsearch.&lt;/p&gt;

&lt;p&gt;When object B event is being handled, on top of the common handler flow, it also cascades the update to the related object A in the Elasticsearch index. We name this kind of operation Cascade Update.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/procedures-executed-by-the-event-handler.png&quot; alt=&quot;Procedures executed by the Event Handler&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Procedures executed by the Event Handler&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;issues-in-the-original-infrastructure&quot;&gt;Issues in the original infrastructure&lt;/h2&gt;

&lt;p&gt;Data in an Elasticsearch index can come from multiple MySQL tables as shown below.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/data-in-an-es-index.png&quot; alt=&quot;Data in an Elasticsearch index&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data in an Elasticsearch index&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The original infrastructure came with a few issues.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Heavy DB load&lt;/strong&gt;: Consumers read from Kafka streams, treat stream events as notifications then use IDs to load data from the DB to create a new Elasticsearch document. Data in the stream events are not well utilised. Loading data from the DB every time to create a new Elasticsearch document results in heavy traffic to the DB. The DB becomes a bottleneck.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data loss&lt;/strong&gt;: Producers send data copies to Kafka in application code. Data changes made via MySQL command-line tool (CLT) or other DB management tools are lost.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tight coupling with MySQL table structure&lt;/strong&gt;: If producers add a new column to an existing table in MySQL and this column needs to be synchronised to Elasticsearch, DSP is not able to capture the data changes of this column until the producers make the code change and add the column to the related Kafka Stream.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Redundant Elasticsearch updates&lt;/strong&gt;: Elasticsearch data is a subset of MySQL data. Producers publish data to Kafka streams even if changes are made on fields that are not relevant to Elasticsearch. These stream events that are irrelevant to Elasticsearch would still be picked up.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Duplicate cascade updates&lt;/strong&gt;: Consider a case where the search index contains both object A and object B. A large number of updates to object B are created within a short span of time. All the updates will be cascaded to the index containing both objects A and B. This will bring heavy traffic to the DB.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;optimised-incremental-sync&quot;&gt;Optimised Incremental Sync&lt;/h2&gt;

&lt;h3 id=&quot;mysql-binlog&quot;&gt;MySQL Binlog&lt;/h3&gt;

&lt;p&gt;MySQL binary log (Binlog) is a set of log files that contain information about data modifications made to a MySQL server instance. It contains all statements that update data. There are two types of binary logging:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Statement-based logging&lt;/strong&gt;: Events contain SQL statements that produce data changes (inserts, updates, deletes).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Row-based logging&lt;/strong&gt;: Events describe changes to individual rows.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Grab Caspian team (Data Tech) has built a Change Data Capture (CDC) system based on MySQL row-based Binlog. It captures all the data modifications made to MySQL tables.&lt;/p&gt;

&lt;h3 id=&quot;current-kafka-streams&quot;&gt;Current Kafka streams&lt;/h3&gt;
&lt;p&gt;The Binlog stream event definition is a common data structure with three main fields: Operation, PayloadBefore and PayloadAfter. The Operation enums are Create, Delete, and Update. Payloads are the data in JSON string format. All Binlog streams follow the same stream event definition. Leveraging PayloadBefore and PayloadAfter in the Binlog event, optimisations of incremental sync on DSP becomes possible.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/binlog-stream-event-main-fields.png&quot; alt=&quot;Binlog stream event main fields&quot; style=&quot;width:30%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Binlog stream event main fields&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;stream-consumer-optimisations&quot;&gt;Stream Consumer optimisations&lt;/h2&gt;

&lt;h3 id=&quot;event-handler-optimisations&quot;&gt;Event Handler optimisations&lt;/h3&gt;

&lt;h4 id=&quot;optimisation-1&quot;&gt;Optimisation 1&lt;/h4&gt;

&lt;p&gt;Remember that there was a redundant Elasticsearch updates issue mentioned above where the Elasticsearch data is a subset of the MySQL data. The first optimisation is to filter out irrelevant stream events by checking if the fields that are different between PayloadBefore and PayloadAfter are in the Elasticsearch data subset.&lt;/p&gt;

&lt;p&gt;Since the payloads in the Binlog event are JSON strings, a data structure only with fields that are present in Elasticsearch data is defined to parse PayloadBefore and PayloadAfter. By comparing the parsed payloads, it is easy to know whether the change is relevant to Elasticsearch.&lt;/p&gt;

&lt;p&gt;The below diagram shows the optimised Event Handler flows. As shown in the blue flow, when an event is handled, PayloadBefore and PayloadAfter are compared first. An event will be processed only if there is a difference between PayloadBefore and PayloadAfter. Since the irrelevant events are filtered, it is unnecessary to get the original document from Elasticsearch.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/event-handler-optimisation-1.png&quot; alt=&quot;Event Handler optimisation 1&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Event Handler optimisation 1&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;achievements&quot;&gt;Achievements&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;No data loss. Changes made via MySQL CLT or other DB manage tools can be captured.&lt;/li&gt;
  &lt;li&gt;No dependency on MySQL table definition. All the data is in JSON string format.&lt;/li&gt;
  &lt;li&gt;No redundant Elasticsearch updates and DB reads.&lt;/li&gt;
  &lt;li&gt;Elasticsearch reads traffic reduced by 90%: Not a need to get the original document from Elasticsearch to compare with the newly created document anymore.&lt;/li&gt;
  &lt;li&gt;55% of irrelevant stream events are filtered out.&lt;/li&gt;
  &lt;li&gt;The DB load is reduced by 55%&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/es-event-updates-for-optimisation-1.png&quot; alt=&quot;Elasticsearch event updates for optimisation 1&quot; style=&quot;width:50%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Elasticsearch event updates for optimisation 1&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;optimisation-2&quot;&gt;Optimisation 2&lt;/h4&gt;

&lt;p&gt;The PayloadAfter in the event provides updated data. This makes us think about whether a completely new Elasticsearch document is needed each time, with its data read from several MySQL tables. The second optimisation is to change to a partial update using data differences from the Binlog event.&lt;/p&gt;

&lt;p&gt;The below diagram shows the Event Handler procedure flow with a partial update. As shown in the red flow, instead of creating a new Elasticsearch document for each event, a check on whether the document exists will be performed first. If the document exists, which happens for the majority of the time, the data is changed in this event, provided the comparison between PayloadBefore and PayloadAfter is updated to the existing Elasticsearch document.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/event-handler-optimisation-2.png&quot; alt=&quot;Event Handler optimisation 2&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Event Handler optimisation 2&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;achievements-1&quot;&gt;Achievements&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Change most Elasticsearch relevant events to partial update: Use data in stream events to update Elasticsearch.&lt;/li&gt;
  &lt;li&gt;Elasticsearch load reduced: Only fields that have been changed will be sent to Elasticsearch.&lt;/li&gt;
  &lt;li&gt;DB load reduced: DB load reduced by 80% based on Optimisation 1.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/es-event-updates-for optimisation-2.png&quot; alt=&quot;Elasticsearch event updates for optimisation 2&quot; style=&quot;width:50%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Elasticsearch event updates for optimisation 2&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;event-buffer-optimisation&quot;&gt;Event Buffer optimisation&lt;/h3&gt;

&lt;p&gt;Instead of replacing the old event, we merge the new event with the old event when the new event is pushed to the Event Buffer.&lt;/p&gt;

&lt;p&gt;The size of each sub buffer in Event Buffer is 1. In this optimisation, the stream event is not treated as a notification anymore. We use the Payloads in the event to perform Partial Updates. The old procedure of replacing old events is no longer suitable for the Binlog stream.&lt;/p&gt;

&lt;p&gt;When the Event Dispatcher pushes a new event to a non-empty sub buffer in the Event Buffer, it will merge event A in the sub buffer and the new event B into a new Binlog event C, whose PayloadBefore is from Event A and PayloadAfter is from Event B.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/merge-operation-for-event-buffer-optimisation.png&quot; alt=&quot;merge-operation-for-event-buffer-optimisation&quot; style=&quot;width:80%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Merge operation for Event Buffer optimisation&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;cascade-update-optimisation&quot;&gt;Cascade Update optimisation&lt;/h3&gt;

&lt;h4 id=&quot;optimisation&quot;&gt;Optimisation&lt;/h4&gt;

&lt;p&gt;We used a new stream to handle cascade update events. When the producer sends data to the Kafka stream, data sharing the same ID will be stored at the same partition. Every DSP service instance has only one stream consumer. When Kafka streams are consumed by consumers, one partition will be consumed by only one consumer. So the Cascade Update events sharing the same ID will be consumed by one stream consumer on the same EC2 instance. With this special mechanism, the in-memory Event Buffer is able to deduplicate most of the Cascade Update events sharing the same ID.&lt;/p&gt;

&lt;p&gt;The flowchart below shows the optimised Event Handler procedure. Highlighted in green is the original flow while purple highlights the current flow with Cascade Update events.
When handling an object B event, instead of cascading update the related object A directly, the Event Handler will send a Cascade Update event to the new stream. The consumer of the new stream will handle the Cascade Update event and synchronise the data of object A to the Elasticsearch.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/event-handler-with-cascade-update-events.png&quot; alt=&quot;Event Handler with Cascade Update events&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Event Handler with Cascade Update events&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;achievements-2&quot;&gt;Achievements&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Cascade Update events deduplicated by 80%.&lt;/li&gt;
  &lt;li&gt;DB load introduced by cascade update is reduced.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/search-indexing-optimisation/cascade-update-events.png&quot; alt=&quot;Cascade Update events&quot; style=&quot;width:50%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Cascade Update events&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In this article four different DSP optimisations are explained. After switching to MySQL Binlog streams provided by the Coban team and optimising Stream Consumer, DSP has saved about 91% DB reads and 90% Elasticsearch reads, and the average queries per second (QPS) of stream traffic processed by Stream Consumer increased from 200 to 800. The max QPS at peak hours could go up to 1000+. With a higher QPS, the duration of processing data and the latency of synchronising data from MySQL to Elasticsearch was reduced. The data synchronisation ability of DSP has greatly improved after optimisation.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to &lt;em&gt;Jun Ying Lim&lt;/em&gt; and &lt;em&gt;Amira Khazali&lt;/em&gt; for proofreading this article.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Sep 2021 01:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/search-indexing-optimisation</link>
        <guid isPermaLink="true">https://engineering.grab.com/search-indexing-optimisation</guid>
        
        <category>Engineering</category>
        
        <category>Data</category>
        
        <category>Database</category>
        
        <category>Optimisation</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Automating Multi-Armed Bandit testing during feature rollout</title>
        <description>&lt;p&gt;A/B testing is an experiment where a random e-commerce platform user is given two versions of a variable: a control group and a treatment group, to discover the optimal version that maximizes conversion. When running A/B testing, you can take the Multi-Armed Bandit optimisation approach to minimise the loss of conversion due to low performance.&lt;/p&gt;

&lt;p&gt;In the traditional software development process, Multi-Armed Bandit (MAB) testing and rolling out a new feature are usually separate processes. The novel Multi-Armed Bandit System for Recommendation solution, hereafter the Multi-Armed Bandit Optimiser, proposes automating the Multi-Armed Bandit testing simultaneously while rolling out the new feature.&lt;/p&gt;

&lt;h2 id=&quot;advantages&quot;&gt;Advantages&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Automates the MAB testing process during new feature rollouts.&lt;/li&gt;
  &lt;li&gt;Selects the optimal parameters based on predefined metrics of each use case, which results in an end-to-end solution without the need for user intervention.&lt;/li&gt;
  &lt;li&gt;Uses the Batched Multi-Armed Bandit and Monte Carlo Simulation, which enables it to process large-scale business scenarios.&lt;/li&gt;
  &lt;li&gt;Uses a feedback loop to automatically collect recommendation metrics from user event logs and to feed them to the Multi-Armed Bandit Optimiser.&lt;/li&gt;
  &lt;li&gt;Uses an adaptive rollout method to automatically roll out the best model to the maximum distribution capacity according to the feedback metrics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;The following diagram illustrates the system architecture.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;System architecture&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image5.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;System architecture&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The novel Multi-Armed Bandit System for Recommendation solution contains three building blocks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stream processing framework&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A lightweight system that performs basic operations on Kafka Streams, such as aggregation, filtering, and mapping. The proposed solution relies on this framework to pre-process raw events published by mobile apps and backend processes into the proper format that can be fed into the feedback loop.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Feedback loop&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A system that calculates the goal metrics and optimises the model traffic distribution. It runs a metrics server which pulls the data from Stalker, which is a time series database that stores the processed events in the last one hour. The metrics server invokes a Spark Job periodically to run the SQL queries that computes the pre-defined goal metrics: the Clickthrough Rate, Conversion Rate and so on, provided by users. The output of the job is dumped into an S3 bucket, and is picked up by optimiser runtime. It runs the Multi-Armed Bandit Optimiser to optimise the model traffic distribution based on the latest goal metrics.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dynamic value receiver, or the GrabX variable&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multi-armed-bandit-optimiser-modules&quot;&gt;Multi-Armed Bandit Optimiser modules&lt;/h2&gt;

&lt;p&gt;The Multi-Armed Bandit Optimiser consists of the following modules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reward Update&lt;/li&gt;
  &lt;li&gt;Batched Multi-Armed Bandit Agent&lt;/li&gt;
  &lt;li&gt;Monte-Carlo Simulation&lt;/li&gt;
  &lt;li&gt;Adaptive Rollout&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Multi-Armed Bandit Optimiser modules&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image4.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Multi-Armed Bandit Optimiser modules&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The goal of the Multi-Armed Bandit Optimisation is to find the optimal Arm that results in the best predefined metrics, and then allocate the maximum traffic to that Arm.&lt;/p&gt;

&lt;p&gt;The solution can be illustrated in the following problem. For K Arm, in which the action space A={1,2,…,K}, the Multi-Arm-Bandit Optimiser goal is to solve the one-shot optimisation problem of &lt;img alt=&quot;Formula&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image2.png&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;reward-update-module&quot;&gt;Reward Update module&lt;/h3&gt;

&lt;p&gt;The Reward Update module collects a batch of the metrics. It calculates the Success and Failure counts, then updates the Beta distribution of each Arm with the Batched Multi-Armed Bandit algorithm.&lt;/p&gt;

&lt;h3 id=&quot;multi-armed-bandit-agent-module&quot;&gt;Multi-Armed Bandit Agent module&lt;/h3&gt;

&lt;p&gt;In the Multi-Armed Bandit Agent module, each Arm’s metrics are modelled as a Beta distribution which is sampled with Thompson Sampling. The Beta distribution formula is:
  &lt;img alt=&quot;Formula&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image1.png&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The Batched Multi-Armed Bandit algorithm updates the Beta distribution with the batch metrics. The optimisation algorithm can be described in the following method.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Batched Multi-Armed Bandit algorithm&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image6.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Batched Multi-Armed Bandit algorithm&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;monte-carlo-simulation-module&quot;&gt;Monte-Carlo Simulation module&lt;/h3&gt;

&lt;p&gt;The Monte-Carlo Simulation module runs the simulation for N repeated times to find the best Arm over a configurable simulation window. Then, it applies the simulated results as each Arm’s distribution percentage for the next round.&lt;/p&gt;

&lt;p&gt;To handle different scenarios, we designed two strategies.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Max strategy: We count each Arm’s Success count’s result in Monte-Carlo Simulation, and then compute the next round distribution according to the success rate.&lt;/li&gt;
  &lt;li&gt;Mean strategy: We average each Arm’s Beta distribution probabilities’s result in Monte-Carlo Simulation, and then compute the next round distribution according to the averaged probabilities of each Arm.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;adaptive-rollout-module&quot;&gt;Adaptive Rollout module&lt;/h3&gt;

&lt;p&gt;The Adaptive Rollout module rolls out the sampled distribution of each Multi-Armed Bandit Arm, in the form of Multi-Armed Bandit Arm Model ID and distribution, to the experimentation platform’s configuration variable. The resulting variable is then read from the online service. The process repeats as it collects feedback from the Adaptive Rollout metrics’ results in the feedback loop.&lt;/p&gt;

&lt;h2 id=&quot;multi-armed-bandit-for-recommendation-solution&quot;&gt;Multi-Armed Bandit for Recommendation Solution&lt;/h2&gt;

&lt;p&gt;In the &lt;em&gt;GrabFood Recommended for You&lt;/em&gt; widget, there are several food recommendation models that categorise lists of merchants. The choice of the model is controlled through experiments at rollout, and the results of the experiments are analysed offline. After the analysis, data scientists and product managers rectify the model choice based on the experiment results.&lt;/p&gt;

&lt;p&gt;The Multi-Armed Bandit System for Recommendation solution improves the process by speeding up the feedback loop with the Multi-Armed Bandit system. Instead of depending on offline data which comes out at T+N, the solution responds to minute-level metrics, and adjusts the model faster.&lt;/p&gt;

&lt;p&gt;This results in an optimal solution faster. The proposed Multi-Armed Bandit for Recommendation solution workflow is illustrated in the following diagram.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot; Multi-Armed Bandit for Recommendation Solution Workflow&quot; src=&quot;/img/multi-armed-bandit-system-recommendation/image3.png&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt; Multi-Armed Bandit for Recommendation solution workflow&lt;/small&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;optimisation-metrics&quot;&gt;Optimisation metrics&lt;/h3&gt;

&lt;p&gt;The GrabFood recommendation uses the Effective Conversion Rate metrics as the optimisation objective. The Effective Conversion Rate is defined as the total number of checkouts through the &lt;em&gt;Recommended for You&lt;/em&gt; widget, divided by the total widget viewed and multiplied by the coverage rate.&lt;/p&gt;

&lt;p&gt;The events of views, clicks, and checkouts are collected over a 30-minute aggregation window and the coverage. A request with a checkout is considered as a success event, while a non-converted request is considered as a failure event.&lt;/p&gt;

&lt;h3 id=&quot;multi-armed-bandit-strategy&quot;&gt;Multi-Armed Bandit strategy&lt;/h3&gt;

&lt;p&gt;With the Multi-Armed Bandit Optimiser, the Beta distribution is selected to model the Effective Conversion Rate. The use of the mean strategy in the Monte-Carlo Simulation results in a more stable distribution.&lt;/p&gt;

&lt;h3 id=&quot;rollout-policy&quot;&gt;Rollout policy&lt;/h3&gt;

&lt;p&gt;The Multi-Armed Bandit Optimiser uses the eater ID as the unique entity, applies a policy and assigns different percentages of eaters to each model, based on computed distribution at the beginning of each loop.&lt;/p&gt;

&lt;h3 id=&quot;fallback-logic&quot;&gt;Fallback logic&lt;/h3&gt;

&lt;p&gt;The Multi-Armed Bandit Optimiser first runs model validation to ensure all candidates are suitable for rolling out. If the scheduled MAB job fails, it falls back to a default distribution that is set to 50-50% for each model.&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Sep 2021 01:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/multi-armed-bandit-system-recommendation</link>
        <guid isPermaLink="true">https://engineering.grab.com/multi-armed-bandit-system-recommendation</guid>
        
        <category>Engineering</category>
        
        <category>Testing</category>
        
        <category>Optimisation</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How We Cut GrabFood.com’s Page JavaScript Asset Sizes by 3x</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Every week, GrabFood.com’s cloud infrastructure serves over &amp;gt;1TB network egress and 175 million requests, which increased our costs. To minimise cloud costs, we had to look at optimising (and reducing) GrabFood.com’s bundle size.&lt;/p&gt;

&lt;p&gt;Any reduction in bundle size helps with:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Faster site loads! (especially for locations with lower mobile broadband speeds)&lt;/li&gt;
  &lt;li&gt;Cost savings for users: Less data required for each site load&lt;/li&gt;
  &lt;li&gt;Cost savings for Grab: Less network egress required to serve users&lt;/li&gt;
  &lt;li&gt;Faster build times: Fewer dependencies -&amp;gt; less code for webpack to bundle -&amp;gt; faster builds&lt;/li&gt;
  &lt;li&gt;Smaller builds: Fewer dependencies -&amp;gt; less code -&amp;gt; smaller builds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After applying the 7 webpack bundle optimisations, we were able to yield the following improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;7% faster page load time from 2600ms to 2400ms&lt;/li&gt;
  &lt;li&gt;66% faster JS static asset load time from 180ms to 60ms&lt;/li&gt;
  &lt;li&gt;3x smaller JS static assets from 750KB to 250KB&lt;/li&gt;
  &lt;li&gt;1.5x less network egress from 1800GB to 1200GB&lt;/li&gt;
  &lt;li&gt;20% less for CloudFront costs from $1750 to $1400&lt;/li&gt;
  &lt;li&gt;1.4x smaller bundle from 40MB to 27MB&lt;/li&gt;
  &lt;li&gt;3.6x faster build time from ~2000s to ~550s&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;One of the biggest factors influencing bundle size is dependencies. As mentioned earlier, fewer dependencies mean fewer lines of code to compile, which result in a smaller bundle size. Thus, to optimise GrabFood.com’s bundle size, we had to look into our dependencies.&lt;/p&gt;

&lt;p&gt;Tldr;&lt;/p&gt;

&lt;p&gt;Jump to &lt;a href=&quot;#step-c-reducing-your-dependencies&quot;&gt;Step C: Reducing your Dependencies&lt;/a&gt; to see the 7 strategies we used to cut down our bundle size.&lt;/p&gt;

&lt;h3 id=&quot;step-a-identify-your-dependencies&quot;&gt;Step A: Identify Your Dependencies&lt;/h3&gt;

&lt;p&gt;In this step, we need to ask ourselves ‘what are our largest dependencies?’. We used the &lt;a href=&quot;https://github.com/webpack-contrib/webpack-bundle-analyzer&quot;&gt;webpack-bundle-analyzer&lt;/a&gt; to inspect GrabFood.com’s bundles. This gave us an overview of all our dependencies and we could easily see which bundle assets were the largest.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image12.png&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Our grabfood.com bundle analyzer output&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;For Next.js, you should use &lt;a href=&quot;https://github.com/vercel/next.js/tree/canary/packages/next-bundle-analyzer&quot;&gt;@next/bundle-analyze&lt;/a&gt; instead.&lt;/li&gt;
  &lt;li&gt;Bundle analysis output allows us to easily inspect what’s in our bundle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What to look out for:&lt;/p&gt;

&lt;p&gt;I: Large dependencies (fairly obvious, because the box size will be large)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;II: Duplicate dependencies (same library that is bundled multiple times across different assets)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image2.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;img/grabfood-bundle/image2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;III: Dependencies that look like they don’t belong (e.g. Why is ‘elliptic’ in my frontend bundle?)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What to avoid:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Isolating dependencies that are very small (e.g. &amp;lt;20kb). Not worth focusing on this due to very meagre returns.
    &lt;ul&gt;
      &lt;li&gt;E.g. Business logic like your React code&lt;/li&gt;
      &lt;li&gt;E.g. Small node dependencies&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-b-investigate-the-usage-of-your-dependencies-where-are-my-dependencies-used&quot;&gt;Step B: Investigate the Usage of Your Dependencies (Where are my Dependencies Used?)&lt;/h3&gt;
&lt;p&gt;In this step, we are trying to answer this question: “Given a dependency, which files and features are making use of it?”.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image10.png&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;a href=&quot;https://pixabay.com/photos/architecture-building-geometric-1868547/&quot;&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Image source&lt;/i&gt;&lt;/figcaption&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;There are two broad approaches that can be used to identify how our dependencies are used:&lt;/p&gt;

&lt;p&gt;I: Top-down approach: “Where does our project use dependency X?”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Conceptually identify which feature(s) requires the use of dependency X.&lt;/li&gt;
  &lt;li&gt;E.g. Given that we have ‘&lt;a href=&quot;https://github.com/hokaccha/node-jwt-simple&quot;&gt;jwt-simple&lt;/a&gt;’ as a dependency, which set of features in my project requires JWT encoding/decoding?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;II: Bottom-up approach: “How did dependency X get used in my project?”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trace dependencies by manually tracing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;require()&lt;/code&gt; statements&lt;/li&gt;
  &lt;li&gt;Alternatively, use dependency visualisation tools such as &lt;a href=&quot;https://github.com/sverweij/dependency-cruiser&quot;&gt;dependency-cruiser&lt;/a&gt; to identify file interdependencies. Note that output can quickly get noisy for any non-trivial project, so use it for inspecting small groups of files (e.g. single domains).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our recommendation is to use a &lt;strong&gt;mix&lt;/strong&gt; of both Top-down and Bottom-up approaches to identify and isolate dependencies.&lt;/p&gt;

&lt;p&gt;Dos:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Be methodical when tracing dependencies: Use a document to track your progress as you manually trace inter-file dependencies.&lt;/li&gt;
  &lt;li&gt;Use dependency visualisation tools like &lt;a href=&quot;https://github.com/sverweij/dependency-cruiser&quot;&gt;dependency-cruiser&lt;/a&gt; to quickly view a given file’s dependencies.&lt;/li&gt;
  &lt;li&gt;Consult Dr. Google if you get stuck somewhere, especially if the dependencies are buried deep in a dependency tree i.e. non-1st-degree dependencies (e.g. “&lt;a href=&quot;https://stackoverflow.com/questions/42492410/why-webpack-includes-elliptic-bn-js-modules-in-my-bundle&quot;&gt;Why webpack includes elliptic bn.js modules in bundle&lt;/a&gt;”)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Don’ts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stick to a single approach - Know when to switch between Top-down and Bottom-up approaches to narrow down the search space.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-c-reducing-your-dependencies&quot;&gt;Step C: Reducing Your Dependencies&lt;/h3&gt;
&lt;p&gt;Now that you know what your largest dependencies are and where they are used, the next step is figuring out how you can shrink your dependencies.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image15.gif&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;a href=&quot;https://i.imgur.com/w8Ydzvb.gif&quot;&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Image source&lt;/i&gt;&lt;/figcaption&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Here are 7 strategies that you can use to reduce your dependencies:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-lazy-load-large-dependencies-and-less-used-dependencies&quot;&gt;Lazy load large dependencies and less-used dependencies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-unify-instances-of-duplicate-modules&quot;&gt;Unify instances of duplicate modules&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-use-libraries-that-are-exported-in-es-modules-format&quot;&gt;Use libraries that are exported in ES Modules format&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-replace-libraries-whose-features-are-already-available-on-the-browser-web-api&quot;&gt;Replace libraries whose features are already available on the Browser Web API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-avoid-large-dependencies-by-changing-your-technical-approach&quot;&gt;Avoid large dependencies by changing your technical approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6-avoid-using-node-dependencies-or-libraries-that-require-node-dependencies&quot;&gt;Avoid using node dependencies or libraries that require node dependencies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7-optimise-your-external-dependencies&quot;&gt;Optimise your external dependencies&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note: These strategies have been listed in ascending order of difficulty - focus on the easy wins first 🙂&lt;/p&gt;

&lt;h4 id=&quot;1-lazy-load-large-dependencies-and-less-used-dependencies&quot;&gt;1. Lazy Load Large Dependencies and Less-used Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image13.png&quot; alt=&quot;When a file adds +2MB worth of dependencies&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When a file adds +2MB worth of dependencies”, &lt;a href=&quot;https://knowyourmeme.com/memes/vault-boy-hold-up&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Similar to how lazy loading is used to break down large React pages to improve page performance, we can also lazy load libraries that are rarely used, or are not immediately used until prior to certain user actions.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;computeHash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createHmac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;computeHash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createHmac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Use of Anti-abuse library prior to sensitive API calls&lt;/li&gt;
  &lt;li&gt;Action: Instead of bundling the anti-abuse library together with the main page asset, we opted to lazy load the library only when we needed to use it (i.e. load the library just before making certain sensitive API calls).&lt;/li&gt;
  &lt;li&gt;Results: Saved 400KB on the main page asset.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Any form of lazy loading will incur some latency on the user, since the asset must be loaded with &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest&quot;&gt;XMLHttpRequest&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-unify-instances-of-duplicate-modules&quot;&gt;2. Unify Instances of Duplicate Modules&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image6.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://knowyourmeme.com/memes/spider-man-pointing-at-spider-man&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If you see the same dependency appearing in multiple assets, consider unifying these duplicate dependencies under a single entrypoint.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;// ComponentOne.jsx&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentTwo.jsx&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;// grabMapsImportFn.js&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentOne.tsx&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentTwo.tsx&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Duplicate ‘grab-maps’ dependencies in bundle&lt;/li&gt;
  &lt;li&gt;Action: We observed that we were bundling the same ‘grab-maps’ dependency in 4 different assets so we refactored the application to use a single entrypoint, ensuring that we only bundled one instance of ‘grab-maps’.&lt;/li&gt;
  &lt;li&gt;Results: Saved 2MB on total bundle size.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Alternative approach: Manually define a new cacheGroup to target a specific module (&lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin/%23split-chunks-example-2&quot;&gt;see more&lt;/a&gt;) with ‘enforce:true’, in order to force webpack to always create a separate chunk for the module. Useful for cases where the single dependency is very large (i.e. &amp;gt;100KB), or when asynchronously loading a module isn’t an option.&lt;/li&gt;
  &lt;li&gt;Certain libraries that appear in multiple assets (e.g. antd) should not be mistaken as identical dependencies. You can verify this by inspecting each module with one another. If the contents are different, then webpack has already done its job of tree-shaking the dependency and only importing code used by our code.&lt;/li&gt;
  &lt;li&gt;Webpack relies on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import()&lt;/code&gt; statement to identify that a given module is to be explicitly bundled as a separate chunk (&lt;a href=&quot;https://webpack.js.org/api/module-methods/%23import-1&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-use-libraries-that-are-exported-in-es-modules-format&quot;&gt;3. Use Libraries that are Exported in ES Modules Format&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image1.gif&quot; alt=&quot;Did you say ‘tree-shaking’?&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Did you say ‘tree-shaking’?”, &lt;a href=&quot;https://www.huffpost.com/entry/commercial-harvesting_n_57a215eee4b04414d1f2df60&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;If a given library has a variant with an ES Module distribution, use that variant instead.&lt;/li&gt;
  &lt;li&gt;ES Modules allows webpack to perform &lt;a href=&quot;https://webpack.js.org/guides/tree-shaking/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://webpack.js.org/guides/tree-shaking/&quot;&gt;tree-shaking&lt;/a&gt; automatically, allowing you to save on your bundle size because unused library code is not bundled.&lt;/li&gt;
  &lt;li&gt;Use &lt;a href=&quot;https://bundlephobia.com/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bundlephobia.com/&quot;&gt;bundlephobia&lt;/a&gt; to quickly ascertain if a given library is tree-shakeable (e.g. ‘&lt;a href=&quot;https://bundlephobia.com/package/lodash-es@4.17.21&quot;&gt;lodash-es&lt;/a&gt;’ vs &lt;a href=&quot;https://bundlephobia.com/package/lodash@4.17.21&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bundlephobia.com/package/lodash@4.17.21&quot;&gt;‘lodash&lt;/a&gt;’)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lodash&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lodash&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;es&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Case: Using Lodash utilities&lt;/li&gt;
  &lt;li&gt;Action: Instead of using the standard ‘lodash’ library, you can swap it out with ‘lodash-es’, which is bundled using ES Modules and is functionally equivalent.&lt;/li&gt;
  &lt;li&gt;Results: Saved 0KB - We were already directly importing individual Lodash functions (e.g. ‘lodash/get’), therefore importing only the code we need. Still, ES Modules is a more convenient way to go about this 👍.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Alternative approach: Use babel plugins (e.g. ‘&lt;a href=&quot;https://www.npmjs.com/package/babel-plugin-transform-imports&quot;&gt;babel-plugin-transform-imports&lt;/a&gt;’) to transform your import statements at build time to selectively import specific code for a given library.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;4-replace-libraries-whose-features-are-already-available-on-the-browser-web-api&quot;&gt;4. Replace Libraries whose Features are Already Available on the Browser Web API&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image3.png&quot; alt=&quot;When you replace axios with fetch&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When you replace axios with fetch”, &lt;a href=&quot;https://knowyourmeme.com/memes/the-future-is-now-old-man&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If you are relying on libraries for functionality that is available on the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API&quot;&gt;Web API&lt;/a&gt;, you should revise your implementation to leverage on the Web API, allowing you to skip certain libraries when bundling, thus saving on bundle size.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;getEndpointData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;getEndpointData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Case: Replacing axios with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; in the anti-abuse library&lt;/li&gt;
  &lt;li&gt;Action: We observed that our anti-abuse library was relying on axios to make web requests. Since our web app is only targeting modern browsers - most of which support &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; (with the notable exception of IE) - we refactored the library’s code to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; exclusively.&lt;/li&gt;
  &lt;li&gt;Results: Saved 15KB on anti-abuse library size.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5-avoid-large-dependencies-by-changing-your-technical-approach&quot;&gt;5. Avoid Large Dependencies by Changing your Technical Approach&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image16.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://knowyourmeme.com/memes/this-is-brilliant-but-i-like-this&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If it is acceptable to change your technical approach, we can avoid using certain dependencies altogether.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;simple&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;encodeCookieData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;encodeCookieData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Encoding for browser cookie persistence&lt;/li&gt;
  &lt;li&gt;Action: As we needed to store certain user preferences in the user’s browser, we previously opted to use JWT encoding; this involved signing JWTs on the client side, which has a hard dependency on ‘crypto’. We revised the implementation to use plain JSON encoding instead, removing the need for ‘crypto’.&lt;/li&gt;
  &lt;li&gt;Results: Saved 250KB per page asset, 13MB in total bundle size.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;6-avoid-using-node-dependencies-or-libraries-that-require-node-dependencies&quot;&gt;6. Avoid Using Node Dependencies or Libraries that Require Node Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image7.png&quot; alt=&quot;“When someone does require(‘crypto’)”&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When someone does require(‘crypto’)”, &lt;a href=&quot;https://www.memecreator.org/meme/yamero0/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;You should not need to use node-related dependencies, unless your application relies on a node dependency directly or indirectly.&lt;/p&gt;

&lt;p&gt;Examples of node dependencies: ‘Buffer’, ‘crypto’, ‘https’ (&lt;a href=&quot;https://nodejs.org/docs/latest-v16.x/api/&quot;&gt;see more&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jsonwebtoken&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decodeJwt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;verify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;some-secret&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;decoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

 &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt_decode&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decodeJwt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt_decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Decoding JWTs on the client side&lt;/li&gt;
  &lt;li&gt;Action: In terms of JWT usage on the client side, we only need to decode JWTs - we do not need any logic related to encoding JWTs. Therefore, we can opt to use libraries that perform just decoding (e.g. ‘&lt;a href=&quot;https://github.com/auth0/jwt-decode&quot;&gt;jwt-decode&lt;/a&gt;’) instead of libraries (e.g. ‘&lt;a href=&quot;https://github.com/auth0/node-jsonwebtoken&quot;&gt;jsonwebtoken&lt;/a&gt;’) that performs the full suite of JWT-related operations (e.g. signing, verifying).&lt;/li&gt;
  &lt;li&gt;Results: Same as in Point 5: Example. (i.e. no need to decode JWTs anymore, since we aren’t using JWT encoding for browser cookie persistence)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;7-optimise-your-external-dependencies&quot;&gt;7. Optimise your External Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image14.png&quot; alt=&quot;“Team: Can you reduce the bundle size further? You:“&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Team: Can you reduce the bundle size further? You: (nervous grin)“, &lt;a href=&quot;https://awesomebyte.com/viral-face-of-the-internet-the-origin-of-hide-the-pain-harold/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We can do a deep-dive into our dependencies to identify possible size optimisations by applying all the aforementioned techniques. If your size optimisation changes get accepted, regardless of whether it’s publicly (e.g. GitHub) or privately hosted (own company library), it’s a win-win for everybody! 🥳&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Creating custom ‘node-forge’ builds for our Anti-abuse library&lt;/li&gt;
  &lt;li&gt;Action: Our Anti-abuse library only uses certain features of ‘node-forge’. Thankfully, the ‘node-forge’ maintainers have provided an easy way to make custom builds that only bundle selective features (&lt;a href=&quot;https://github.com/digitalbazaar/forge/blob/c666282c812d6dc18e97b419b152dd6ad98c802c/webpack.config.js%23L15-L61&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Results: Saved 85KB in Anti-abuse library size and reduced bundle size for all other dependent projects.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-d-verify-that-you-have-modified-the-dependencies&quot;&gt;Step D: Verify that You have Modified the Dependencies&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image9.png&quot; alt=&quot;Now… where did I put that needle?&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Now… where did I put that needle?”, &lt;a href=&quot;https://pixabay.com/photos/haystack-bale-of-straw-fields-hay-401882/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;So, you’ve found some opportunities for major bundle size savings, that’s great!&lt;/p&gt;

&lt;p&gt;But as always, it’s best to be methodical to measure the impact of your changes, and to make sure no features have been broken.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Perform your code changes&lt;/li&gt;
  &lt;li&gt;Build the project again and open the bundle analysis report&lt;/li&gt;
  &lt;li&gt;Verify the state of a given dependency
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Deleted dependency&lt;/strong&gt; - you should not be able to find the dependency&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lazy-loaded dependency&lt;/strong&gt; - you should see the dependency bundled as a separate chunk&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Non-duplicated dependency&lt;/strong&gt; - you should only see a single chunk for the non-duplicated dependency&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Run tests to make sure you didn’t break anything (i.e. unit tests, manual tests)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;other-considerations&quot;&gt;Other Considerations&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Preventive Measures&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Periodically monitor your bundle size to identify increases in bundle size&lt;/li&gt;
  &lt;li&gt;Periodically monitor your site load times to identify increases in site load times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Webpack Configuration Options&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Disable bundling node modules with ‘node: false’
    &lt;ul&gt;
      &lt;li&gt;Only if your project doesn’t already include libraries that rely on node modules.&lt;/li&gt;
      &lt;li&gt;Allows for fast detection when someone tries to use a library that requires node modules, as the build will fail&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experiment with ‘cacheGroups’
    &lt;ul&gt;
      &lt;li&gt;Most default configurations of webpack do a pretty good job of identifying and bundling the most commonly used dependencies into a single chunk (usually called vendor.js)&lt;/li&gt;
      &lt;li&gt;You can experiment with webpack &lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin&quot;&gt;optimisation options&lt;/a&gt; to see if you get better results&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experiment with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import()&lt;/code&gt; ‘Magic Comments’
    &lt;ul&gt;
      &lt;li&gt;You may experiment with &lt;a href=&quot;https://webpack.js.org/api/module-methods/%23magic-comments&quot;&gt;import() magic comments&lt;/a&gt; to modify the behaviour of specific &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import()&lt;/code&gt; statements, although the default setting will do just fine for most cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you can’t remove the dependency:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For all dependencies that must be used, it’s probably best to lazy load all of them so you won’t block the page’s initial rendering (&lt;a href=&quot;https://web.dev/first-contentful-paint/&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image5.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://pixabay.com/photos/zen-meditation-yoga-spirituality-5533537/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To summarise, here’s how you can go about this business of reducing your bundle size.&lt;/p&gt;

&lt;p&gt;Namely…&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Identify Your Dependencies&lt;/li&gt;
  &lt;li&gt;Investigate the Usage of Your Dependencies&lt;/li&gt;
  &lt;li&gt;Reduce Your Dependencies&lt;/li&gt;
  &lt;li&gt;Verify that You have Modified the Dependencies&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And by using these 7 strategies…&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Lazy load large dependencies and less-used dependencies&lt;/li&gt;
  &lt;li&gt;Unify instance of duplicate modules&lt;/li&gt;
  &lt;li&gt;Use libraries that are exported in ES Modules format&lt;/li&gt;
  &lt;li&gt;Replace libraries whose features are already available on the Browser Web API&lt;/li&gt;
  &lt;li&gt;Avoid large dependencies by changing your technical approach&lt;/li&gt;
  &lt;li&gt;Avoid using node dependencies&lt;/li&gt;
  &lt;li&gt;Optimise your external dependencies&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You can have…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Faster page load time (smaller individual pages)&lt;/li&gt;
  &lt;li&gt;Smaller bundle (fewer dependencies)&lt;/li&gt;
  &lt;li&gt;Lower network egress costs (smaller assets)&lt;/li&gt;
  &lt;li&gt;Faster builds (fewer dependencies to handle)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now armed with this information, may your eyes be keen, your bundles be lean, your sites be fast, and your cloud costs be low! 🚀 ✌️&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Han Wu, Melvin Lee, Yanye Li, and Shujuan Cheong for proofreading this article. 🙂&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 29 Jul 2021 01:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/grabfood-bundle-size</link>
        <guid isPermaLink="true">https://engineering.grab.com/grabfood-bundle-size</guid>
        
        <category>Product</category>
        
        <category>Asset Size</category>
        
        <category>Cloud</category>
        
        <category>Optimisation</category>
        
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>Protecting Personal Data in Grab's Imagery</title>
        <description>&lt;h2 id=&quot;image-collection-using-kartaview&quot;&gt;Image Collection Using KartaView&lt;/h2&gt;

&lt;p&gt;A few years ago, we realised a strong demand to better understand the streets where our driver-partners and consumers go, with the purpose to better fulfil their needs and also, to quickly adapt ourselves to the rapidly changing environment in the Southeast Asian cities.&lt;/p&gt;

&lt;p&gt;One way to fulfil that demand was to create an image collection platform named KartaView which is Grab Geo’s platform for geotagged imagery. It empowers collection, indexing, storage, retrieval of imagery, and map data extraction.&lt;/p&gt;

&lt;p&gt;KartaView is a public, partially open-sourced product, used both internally and externally by the OpenStreetMap community and other users. As of 2021, KartaView has public imagery in over 100 countries with various coverage degrees, and 60+ cities of Southeast Asia. Check it out at &lt;a href=&quot;http://www.kartaview.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-1-kartaview-platform.png&quot; alt=&quot;Figure 1 - KartaView platform&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 1 - KartaView platform&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;why-image-blurring-is-important&quot;&gt;Why Image Blurring is Important&lt;/h2&gt;

&lt;p&gt;Incidentally, many people and licence plates are in the collected images, whose privacy is a serious concern. We deeply respect all of them and consequently, we are using image obfuscation as the most effective anonymisation method for ensuring privacy protection.&lt;/p&gt;

&lt;p&gt;Because manually annotating the regions in the picture where faces and licence plates are located is impractical, this problem should be solved using machine learning and engineering techniques. Hence we detect and blur all faces and licence plates which could be considered as personal data.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-2-sample-blurred-picture.jpg&quot; alt=&quot;Figure 2 - Sample blurred picture&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 2 - Sample blurred picture&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In our case, we have a wide range of picture types: regular planar, very wide and 360 pictures in equirectangular format collected with 360 cameras. Also, because we are collecting imagery globally, the vehicle types, licence plates, and human environments are quite diverse in appearance, and are not handled well by off-the-shelf blurring software. So we built our own custom blurring solution which yielded higher accuracy and better cost efficiency overall with respect to blurring of personal data.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-3-equirectangular-image.png&quot; alt=&quot;Figure 3 - Example of equirectangular image where personal data has to be blurred&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 3 - Example of equirectangular image where personal data has to be blurred&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Behind the scenes, in KartaView, there are a set of cool services which can derive useful information from the pictures like image quality, traffic signs, roads, etc. A big part of them are using deep learning algorithms which potentially can be negatively affected by running them over blurred pictures. In fact, based on the assessment we have done so far, the impact is extremely low, similar to the one reported in a well known study of face obfuscation in ImageNet &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h3 id=&quot;outline-of-grabs-blurring-process&quot;&gt;Outline of Grab’s Blurring Process&lt;/h3&gt;

&lt;p&gt;At a high level, this is how Grab goes about the blurring process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Transform each picture into a set of planar images. In this way, we further process all pictures, whatever the format they had, in the same way.&lt;/li&gt;
  &lt;li&gt;Use an object detector able to detect all faces and licence plates in a planar image having a standard field of view.&lt;/li&gt;
  &lt;li&gt;Transform the coordinates of the detected regions into original coordinates and blur those regions.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-4-picture-processing-steps.png&quot; alt=&quot;Figure 4 - Picture’s processing steps&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 4 - Picture’s processing steps&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
In the following section, we are going to describe in detail the interesting aspects of the second step, sharing the challenges and how we were solving them. Let’s start with the first and most important part, the dataset.&lt;/p&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;Our current dataset consists of images from a wide range of cameras, including normal perspective cameras from mobile phones, wide field of view cameras and also 360 degree cameras.&lt;/p&gt;

&lt;p&gt;It is the result of a series of data collections contributed by Grab’s data tagging teams, which may contain 2 classes of dataset that are of interest for us: FACE and LICENSE_PLATE.&lt;/p&gt;

&lt;p&gt;The data was collected using Grab internal tools, stored in queryable databases, making it a system that gives the possibility to revisit and correct the data if necessary, but also making it possible for data engineers to select and filter the data of interest.&lt;/p&gt;

&lt;h4 id=&quot;dataset-evolution&quot;&gt;Dataset Evolution&lt;/h4&gt;

&lt;p&gt;Each iteration of the dataset was made to address certain issues discovered while having models used in a production environment and observing situations where the model lacked in performance.&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Dataset v1&lt;/th&gt;
      &lt;th&gt;Dataset v2&lt;/th&gt;
      &lt;th&gt;Dataset v3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Nr. images&lt;/td&gt;
      &lt;td&gt;15226&lt;/td&gt;
      &lt;td&gt;17636&lt;/td&gt;
      &lt;td&gt;30538&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Nr. of labels&lt;/td&gt;
      &lt;td&gt;64119&lt;/td&gt;
      &lt;td&gt;86676&lt;/td&gt;
      &lt;td&gt;242534&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If the first version was basic, containing a rough tagging strategy we quickly noticed that it was not detecting some special situations that appeared due to the pandemic situation: people wearing masks.&lt;/p&gt;

&lt;p&gt;This led to another round of data annotation to include those scenarios.
The third iteration addressed a broader range of issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Small regions of interest (objects far away from the camera)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/small-region-of-interest.jpg&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Objects in very dark backgrounds&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/objects-in-very-dark-backgrounds.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Rotated objects or even upside down&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/rotated-objects.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Variation of the licence plate design due to images from different countries and regions&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/licence-plate.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;People wearing masks&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/masks.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Faces in the mirror - see below the mirror of the motorcycle&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/faces-in-mirror.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;But the main reason was because of a scenario where the recording had at the start or end (but not only) close-ups of the operator who was checking the camera. This led to images with large regions of interest containing the camera operator’s face - too large to be detected by the model.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/face.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We investigated the dataset structure by splitting the data into bins based on the bbox sizes (in pixels). This made something clear to us: the dataset was unbalanced.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/detection-counts-graph.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We made bins for tag sizes with a stride of 100 pixels and went up to the maximum value present in the dataset which accounted for 1 sample of size 2000 pixels. The majority of the labels were small in size and the higher we would go with the size, the fewer tags we would have. This made it clear that we would need more targeted annotations for our dataset to try to balance it.&lt;/p&gt;

&lt;p&gt;All these scenarios required the tagging team to revisit the data multiple times and also change the tagging strategy by including more tags that were considered at a certain limit. It also required them to pay more attention to small details that may have been missed in a previous iteration.&lt;/p&gt;

&lt;h4 id=&quot;data-splitting&quot;&gt;Data Splitting&lt;/h4&gt;

&lt;p&gt;To better understand the strategy chosen for splitting the data, we also need to understand the source of the data. The images come from different devices that are used in different geographical locations (different countries) and are from a continuous trip recording. The annotation team used an internal tool to visualise the trips image by image and mark the faces and licence plates present in them. We would then have access to all those images and their respective metadata.&lt;/p&gt;

&lt;p&gt;The chosen ratios for splitting are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train 70%&lt;/li&gt;
  &lt;li&gt;Validation 10%&lt;/li&gt;
  &lt;li&gt;Test 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of train images&lt;/td&gt;
      &lt;td&gt;12733&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of validation images&lt;/td&gt;
      &lt;td&gt;1682&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of test images&lt;/td&gt;
      &lt;td&gt;3221&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of labelled classes in train set&lt;/td&gt;
      &lt;td&gt;60630&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of labelled classes in validation set&lt;/td&gt;
      &lt;td&gt;7658&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of of labelled classes in test set&lt;/td&gt;
      &lt;td&gt;18388&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The split is not so trivial as we have some requirements and need to complete some conditions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An image can have multiple tags from one or both classes but must belong to just one subset.&lt;/li&gt;
  &lt;li&gt;The tags should be split as close as possible to the desired ratios.&lt;/li&gt;
  &lt;li&gt;As different images can belong to the same trip in a close geographical relation, we need to force them in the same subset. By doing so, we avoid similar tags in train and test subsets, resulting in incorrect evaluations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h4&gt;

&lt;p&gt;The application of data augmentation plays a crucial role while training the machine learning model. There are mainly three ways in which data augmentation techniques can be applied:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Offline data augmentation - enriching a dataset by physically multiplying some of its images and applying modifications to them.&lt;/li&gt;
  &lt;li&gt;Online data augmentation - on the fly modifications of the image during train time with configurable probability for each modification.&lt;/li&gt;
  &lt;li&gt;Combination of both offline and online data augmentation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In our case, we are using the third option which is a combination of both.&lt;/p&gt;

&lt;p&gt;The first method that contributes to offline augmentation is a method called image view splitting. This is necessary for us due to different image types: perspective camera images, wide field of view images, 360 degree images in equirectangular format. All these formats and field of views with their respective distortions would complicate the data and make it hard for the model to generalise it and also handle different image types that could be added in the future.&lt;/p&gt;

&lt;p&gt;For this, we defined the concept of image views which are an extracted portion (view) of an image with some predefined properties. For example, the perspective projection of 75 by 75 degrees field of view patches from the original image.&lt;/p&gt;

&lt;p&gt;Here we can see a perspective camera image and the image views generated from it:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-5-original-image.png&quot; alt=&quot;Figure 5 - Original image&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 5 - Original image&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-6-image-views-generated.png&quot; alt=&quot;Figure 6 - Two image views generated&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 6 - Two image views generated&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The important thing here is that each generated view is an image on its own with the associated tags. They also have an overlapping area so we have a possibility to contain the same tag in two views but from different perspectives. This brings us to an indirect outcome of the first offline augmentation.&lt;/p&gt;

&lt;p&gt;The second method for offline augmentation is the oversampling of some of the images (views). As mentioned above, we faced the problem of an unbalanced dataset, specifically we were missing tags that occupied high regions of the image, and even though our tagging teams tried to annotate as many as they could find, these were still scarce.&lt;/p&gt;

&lt;p&gt;As our object detection model is an anchor-based detector, we did not even have enough of them to generate the anchor boxes correctly. This could be clearly seen in the accuracy of the previous trained models, as they were performing poorly on bins of big sizes.&lt;/p&gt;

&lt;p&gt;By randomly oversampling images that contained big tags, up to a minimum required number, we managed to have better anchors and increase the recall for those scenarios. As described below, the chosen object detector for blurring was YOLOv4 which offers a large variety of online augmentations. The online augmentations used are saturation, exposure, hue, flip and mosaic.&lt;/p&gt;

&lt;h3 id=&quot;model&quot;&gt;Model&lt;/h3&gt;

&lt;p&gt;As of summer of 2021, the “go to” solution for object detection in images are convolutional neural networks (CNN), being a mature solution able to fulfil the needs efficiently.&lt;/p&gt;

&lt;h4 id=&quot;architecture&quot;&gt;Architecture&lt;/h4&gt;

&lt;p&gt;Most CNN based object detectors have three main parts: Backbone, Neck and (Dense or Sparse Prediction) Heads. From the input image, the backbone extracts features which can be combined in the neck part to be used by the prediction heads to predict object bounding-boxes and their labels.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-7-anatomy-of-object-detectors.png&quot; alt=&quot;Figure 7 - Anatomy of one and two-stage object detectors&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 7 - Anatomy of one and two-stage object detectors&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;
The backbone is usually a CNN classification network pretrained on some dataset, like ImageNet-1K. The neck combines features from different layers in order to produce rich representations for both large and small objects. Since the objects to be detected have varying sizes, the topmost features are too coarse to represent smaller objects, so the first CNN based object detectors were fairly weak in detecting small sized objects. The multi-scale, pyramid hierarchy is inherent to CNNs so Tsung-Yi Lin et al &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; introduced the Feature Pyramid Network which at marginal costs combines features from multiple scales and makes predictions on them. This or improved variants of this technique is used by most detectors nowadays. The head part does the predictions for bounding boxes and their labels.&lt;/p&gt;

&lt;p&gt;YOLO is part of the anchor-based one-stage object detectors family being developed originally in Darknet, an open source neural network framework written in C and CUDA. Back in 2015, it was the first end-to-end differentiable network of this kind that offered a joint learning of object bounding boxes and their labels.&lt;/p&gt;

&lt;p&gt;One reason for the big success of newer YOLO versions is that the authors carefully merged new ideas into one architecture, the overall speed of the model being always the north star.&lt;/p&gt;

&lt;p&gt;YOLOv4 introduces several changes to its v3 predecessor:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Backbone - CSPDarknet53: YOLOv3 Darknet53 backbone was modified to use Cross Stage Partial Network (CSPNet &lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;) strategy, which aims to achieve richer gradient combinations by letting the gradient flow propagate through different network paths.&lt;/li&gt;
  &lt;li&gt;Multiple configurable augmentation and loss function types, so called “Bag of freebies”, which by changing the training strategy can yield higher accuracy without impacting the inference time.&lt;/li&gt;
  &lt;li&gt;Configurable necks and different activation functions, they call “Bag of specials”.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;insights&quot;&gt;Insights&lt;/h4&gt;

&lt;p&gt;For this task, we found that YOLOv4 gave a good compromise between speed and accuracy as it has doubled the speed of a more accurate two-stage detector while maintaining a very good overall precision/recall. For blurring, the main metric for model selection was the overall recall, while precision and intersection over union (IoU) of the predicted box comes second as we want to catch all personal data even if some are wrong. Having a multitude of possibilities to configure the detector architecture and train it on our own dataset we conducted several experiments with different configurations for backbones, necks, augmentations and loss functions to come up with our current solution.&lt;/p&gt;

&lt;p&gt;We faced challenges in training a good model as the dataset posed a large object/box-level scale imbalance, small objects being over-represented in the dataset. As described in &lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; and &lt;sup id=&quot;fnref:4:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, this affects the scales of the estimated regions and the overall detection performance. In &lt;sup id=&quot;fnref:6:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; several solutions are proposed for this out of which the SPP &lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; blocks and PANet &lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; neck used in YOLOv4 together with heavy offline data augmentation increased the performance of the actual model in comparison to the former ones.&lt;/p&gt;

&lt;p&gt;As we have evaluated, the model still has some issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Occlusion of the object, either by the camera view, head accessories or other elements:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/occlusion.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;These cases would need extra annotations in the dataset, just like the faces or licence plates that are really close to the camera and occupy a large region of interest in the image.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As we have a limited number of annotations of close objects to the camera view, the model has incorrectly learnt this, sometimes producing false positives in these situations:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/annotation.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Again, one solution for this would be to include more of these scenarios in the dataset.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h2&gt;

&lt;p&gt;Grab spends a lot of effort ensuring privacy protection for its users so we are always looking for ways to further improve our related models and processes.&lt;/p&gt;

&lt;p&gt;As far as efficiency is concerned, there are multiple directions to consider for both the dataset and the model. There are two main factors that drive the costs and the quality: further development of the dataset for additional edge cases (e.g. more training data of people wearing masks) and the operational costs of the model.&lt;/p&gt;

&lt;p&gt;As the vast majority of current models require a fully labelled dataset, this puts a large work effort on the Data Entry team before creating a new model. Our dataset increased 4x for its third version, but still there is room for improvement as described in the Dataset section.&lt;/p&gt;

&lt;p&gt;As Grab extends its operations in more cities, new data is collected that has to be processed, this puts an increased focus on running detection models more efficiently.&lt;/p&gt;

&lt;p&gt;Directions to pursue to increase our efficiency could be the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As plenty of unlabelled data is available from imagery collection, a natural direction to explore is self-supervised visual representation learning techniques to derive a general vision backbone with superior transferring performance for our subsequent tasks as detection, classification.&lt;/li&gt;
  &lt;li&gt;Experiment with optimisation techniques like pruning and quantisation to get a faster model without sacrificing too much on accuracy.&lt;/li&gt;
  &lt;li&gt;Explore new architectures: YOLOv5, EfficientDet or Swin-Transformer for Object Detection.&lt;/li&gt;
  &lt;li&gt;Introduce semi-supervised learning techniques to improve our model performance on the long tail of the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Bharat Singh, Larry S. Davis. An Analysis of Scale Invariance in Object Detection - SNIP. &lt;a href=&quot;https://arxiv.org/abs/1711.08189v2&quot;&gt;arXiv:1711.08189v2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Zhenda Xie et al. Self-Supervised Learning with Swin Transformers.  &lt;a href=&quot;https://arxiv.org/abs/2105.04553v2&quot;&gt;arXiv:2105.04553v2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Kaiyu Yang et al. Study of Face Obfuscation in ImageNet: &lt;a href=&quot;https://arxiv.org/abs/2103.06191&quot;&gt;arxiv.org/abs/2103.06191&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Nitish S. Mutha &lt;a href=&quot;http://blog.nitishmutha.com/equirectangular/360degree/2017/06/12/How-to-project-Equirectangular-image-to-rectilinear-view.html&quot;&gt;How to map Equirectangular projection to Rectilinear projection&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Alexey Bochkovskiy et al.. YOLOv4: Optimal Speed and Accuracy of Object Detection. &lt;a href=&quot;https://arxiv.org/abs/2004.10934v1&quot;&gt;arXiv:2004.10934v1&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Tsung-Yi Lin et al. Feature Pyramid Networks for Object Detection. &lt;a href=&quot;https://arxiv.org/abs/1612.03144v2&quot;&gt;arXiv:1612.03144v2&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:4:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Chien-Yao Wang et al. CSPNet: A New Backbone that can Enhance Learning Capability of CNN. &lt;a href=&quot;https://arxiv.org/abs/1911.11929v1&quot;&gt;arXiv:1911.11929v1&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Kemal Oksuz et al.. Imbalance Problems in Object Detection: A Review. &lt;a href=&quot;https://arxiv.org/abs/1909.00169v3&quot;&gt;arXiv:1909.00169v3&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:6:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Kaiming He et al. Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. &lt;a href=&quot;https://arxiv.org/abs/1406.4729v4&quot;&gt;arXiv:1406.4729v4&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Shu Liu et al. Path Aggregation Network for Instance Segmentation. &lt;a href=&quot;https://arxiv.org/abs/1803.01534v4&quot;&gt;arXiv:1803.01534v4&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 26 Jul 2021 00:40:00 +0000</pubDate>
        <link>https://engineering.grab.com/protecting-personal-data-in-grabs-imagery</link>
        <guid isPermaLink="true">https://engineering.grab.com/protecting-personal-data-in-grabs-imagery</guid>
        
        <category>Engineering</category>
        
        <category>Machine Learning</category>
        
        <category>Data</category>
        
        <category>Datasets</category>
        
        <category>Data Science</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Processing ETL tasks with Ratchet</title>
        <description>&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;At Grab, the Lending team is focused towards building products that help finance various segments of users, such as Passengers, Drivers, or Merchants, based on their needs. The team builds products that enable users to avail funds in a seamless and hassle-free way. In order to achieve this, multiple lending microservices continuously interact with each other. Each microservice handles different responsibilities, such as providing offers, storing user information, disbursing availed amounts to a user’s account, and many more.&lt;/p&gt;

&lt;p&gt;In this tech blog, we will discuss what &lt;em&gt;Data&lt;/em&gt; and &lt;em&gt;Extract, Transform and Load (ETL)&lt;/em&gt; pipelines are and how they are used for processing multiple tasks in the Lending Team at Grab. We will also discuss &lt;em&gt;&lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Ratchet&lt;/a&gt;&lt;/em&gt;, which is a Go library, that helps us in building data pipelines and handling ETL tasks. Let’s start by covering the basis of Data and ETL pipelines.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-data-pipeline&quot;&gt;What is a Data Pipeline?&lt;/h2&gt;

&lt;p&gt;A Data pipeline is used to describe a system or a process that moves data from one platform to another. In between platforms, data passes through multiple steps based on defined requirements, where it may be subjected to some kind of modification. All the steps in a Data pipeline are automated, and the output from one step acts as an input for the next step.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image1.png&quot; alt=&quot;Data Pipeline&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data Pipeline (Source: &lt;a href=&quot;https://hazelcast.com/glossary/data-pipeline/&quot;&gt;Hazelcast&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;what-is-an-etl-pipeline&quot;&gt;What is an ETL Pipeline?&lt;/h2&gt;

&lt;p&gt;An ETL pipeline is a type of Data pipeline that consists of 3 major steps, namely extraction of data from a source, transformation of that data into the desired format, and finally loading the transformed data to the destination. The destination is also known as the &lt;em&gt;sink&lt;/em&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image3.jpg&quot; alt=&quot;Extract-Transform-Load&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Extract-Transform-Load (Source: &lt;a href=&quot;https://www.tatvasoft.com/blog/etl-process-extract-transform-load/&quot;&gt;TatvaSoft&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The combination of steps in an ETL pipeline provides functions to assure that the business requirements of the application are achieved.&lt;/p&gt;

&lt;p&gt;Let’s briefly look at each of the steps involved in the ETL pipeline.&lt;/p&gt;

&lt;h3 id=&quot;data-extraction&quot;&gt;Data Extraction&lt;/h3&gt;

&lt;p&gt;Data extraction is used to fetch data from one or multiple sources with ease. The source of data can vary based on the requirement. Some of the commonly used data sources are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Database&lt;/li&gt;
  &lt;li&gt;Web-based storage (S3, Google cloud, etc)&lt;/li&gt;
  &lt;li&gt;Files&lt;/li&gt;
  &lt;li&gt;User Feeds, CRM, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data format can also vary from one use case to another. Some of the most commonly used data formats are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SQL&lt;/li&gt;
  &lt;li&gt;CSV&lt;/li&gt;
  &lt;li&gt;JSON&lt;/li&gt;
  &lt;li&gt;XML&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once data is extracted in the desired format, it is ready to be fed to the transformation step.&lt;/p&gt;

&lt;h3 id=&quot;data-transformation&quot;&gt;Data Transformation&lt;/h3&gt;

&lt;p&gt;Data transformation involves applying a set of rules and techniques to convert the extracted data into a more meaningful and structured format for use. The extracted data may not always be ready to use. In order to transform the data, one of the following techniques may be used:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Filtering out unnecessary data.&lt;/li&gt;
  &lt;li&gt;Preprocessing and cleaning of data.&lt;/li&gt;
  &lt;li&gt;Performing validations on data.&lt;/li&gt;
  &lt;li&gt;Deriving a new set of data from the existing one.&lt;/li&gt;
  &lt;li&gt;Aggregating data from multiple sources into a single uniformly structured format.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;data-loading&quot;&gt;Data Loading&lt;/h3&gt;

&lt;p&gt;The final step of an ETL pipeline involves moving the transformed data to a sink where it can be accessed for its use. Based on requirements, a sink can be one of the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Database&lt;/li&gt;
  &lt;li&gt;File&lt;/li&gt;
  &lt;li&gt;Web-based storage (S3, Google cloud, etc)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An ETL pipeline may or may not have a loadstep based on its requirements. When the transformed data needs to be stored for further use, the loadstep is used to move the transformed data to the storage of choice. However, in some cases, the transformed data may not be needed for any further use and thus, the loadstep can be skipped.&lt;/p&gt;

&lt;p&gt;Now that you understand the basics, let’s go over how we, in the Grab Lending team, use an ETL pipeline.&lt;/p&gt;

&lt;h2 id=&quot;why-use-ratchet&quot;&gt;Why Use Ratchet?&lt;/h2&gt;

&lt;p&gt;At Grab, we use Golang for most of our backend services. Due to Golang’s simplicity, execution speed, and concurrency support, it is a great choice for building data pipeline systems to perform custom ETL tasks.&lt;/p&gt;

&lt;p&gt;Given that &lt;em&gt;&lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Ratchet&lt;/a&gt;&lt;/em&gt; is also written in Go, it allows us to easily build custom data pipelines.&lt;/p&gt;

&lt;p&gt;Go channels are connecting each stage of processing, so the syntax for sending data is intuitive for anyone familiar with Go. All data being sent and received is in JSON, providing a nice balance of flexibility and consistency.&lt;/p&gt;

&lt;h2 id=&quot;utilising-ratchet-for-etl-tasks&quot;&gt;Utilising Ratchet for ETL Tasks&lt;/h2&gt;

&lt;p&gt;We use Ratchet for multiple ETL tasks like batch processing, restructuring and rescheduling of loans, creating user profiles, and so on. One of the backend services, named &lt;strong&gt;Azkaban&lt;/strong&gt;, is responsible for handling various ETL tasks.&lt;/p&gt;

&lt;p&gt;Ratchet uses &lt;em&gt;Data Processors&lt;/em&gt; for building a pipeline consisting of multiple stages. Data Processors each run in their own &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;goroutine&lt;/code&gt; so all of the data is processed concurrently. Data Processors are organised into stages, and those stages are run within a pipeline. For building an ETL pipeline, each of the three steps (Extract, Transform and Load) use a Data Processor for implementation. Ratchet provides a set of built-in, useful Data Processors, while also providing an interface to implement your own. Usually, the transform stage uses a Custom Data Processor.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image4.png&quot; alt=&quot;Data Processors in Ratchet&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data Processors in Ratchet (Source: &lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Github&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Let’s take a look at one of these tasks to understand how we utilise Ratchet for processing an ETL task.&lt;/p&gt;

&lt;h2 id=&quot;whitelisting-merchants-through-etl-pipelines&quot;&gt;Whitelisting Merchants Through ETL Pipelines&lt;/h2&gt;

&lt;p&gt;Whitelisting essentially means making the product available to the user by mapping an offer to the user ID. If a merchant in Thailand receives an option to opt for Cash Loan, it is done by whitelisting that merchant. In order to whitelist our merchants, our Operations team uses an internal portal to upload a CSV file with the user IDs of the merchants and other required information. This CSV file is generated by our internal Data and Risk team and handed over to the Operations team. Once the CSV file is uploaded, the user IDs present in the file are whitelisted within minutes. However, a lot of work goes in the background to make this possible.&lt;/p&gt;

&lt;h3 id=&quot;data-extraction-1&quot;&gt;Data Extraction&lt;/h3&gt;

&lt;p&gt;Once the Operations team uploads the CSV containing a list of merchant users to be whitelisted, the file is stored in S3 and an entry is created on the Azkaban service with the document ID of the uploaded file.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image5.png&quot; alt=&quot;File upload by Operations team&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;File upload by Operations team&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The data extraction step makes use of a Custom CSV Data Processor that uses the document ID to first create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PreSignedUrl&lt;/code&gt; and then uses it to fetch the data from S3. The data extracted is in bytes and we use commas as the delimiter to format the CSV data.&lt;/p&gt;

&lt;h3 id=&quot;data-transformation-1&quot;&gt;Data Transformation&lt;/h3&gt;

&lt;p&gt;In order to transform the data, we define a Custom Data Processor that we call a &lt;em&gt;Transformer&lt;/em&gt; for each ETL pipeline. Transformers are responsible for applying all necessary transformations to the data before it is ready for loading. The transformations applied in the merchant whitelisting transformers are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convert data from bytes to struct.&lt;/li&gt;
  &lt;li&gt;Check for presence of all mandatory fields in the received data.&lt;/li&gt;
  &lt;li&gt;Perform validation on the data received.&lt;/li&gt;
  &lt;li&gt;Make API calls to external microservices for whitelisting the merchant.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As mentioned earlier, the CSV file is uploaded manually by the Operations team. Since this is a manual process, it is prone to human errors. Validation of data in the data transformation step helps avoid these errors and not propagate them further up the pipeline. Since CSV data consists of multiple rows, each row passes through all the steps mentioned above.&lt;/p&gt;

&lt;h3 id=&quot;data-loading-1&quot;&gt;Data Loading&lt;/h3&gt;

&lt;p&gt;Whenever the merchants are whitelisted, we don’t need to store the transformed data. As a result, we don’t have a loadstep for this ETL task, so we just use an Empty Data Processor. However, this is just one of many use cases that we have. In cases where the transformed data needs to be stored for further use, the loadstep will have a Custom Data Processor, which will be responsible for storing the data.&lt;/p&gt;

&lt;h2 id=&quot;connecting-all-stages&quot;&gt;Connecting All Stages&lt;/h2&gt;

&lt;p&gt;After defining our Data Processors for each of the steps in the ETL pipeline, the final piece is to connect all the stages together. As stated earlier, the ETL tasks have different ETL pipelines and each ETL pipeline consists of 3 stages defined by their Data Processors.&lt;/p&gt;

&lt;p&gt;In order to connect these 3 stages, we define a &lt;strong&gt;Job Processor&lt;/strong&gt; for each ETL pipeline. A Job Processor represents the entire ETL pipeline and encompasses Data Processors for each of the 3 stages. Each Job Processor implements the following methods:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetSource&lt;/code&gt;: Assigns the Data Processor for the Extraction stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetTransformer&lt;/code&gt;: Assigns the Data Processor for the Transformation stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetDestination&lt;/code&gt;: Assigns the Data Processor for the Load stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Execute&lt;/code&gt;: Runs the ETL pipeline.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image2.png&quot; alt=&quot;Job processors containing Data Processor for each stage in ETL&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Job processors containing Data Processor for each stage in ETL&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;When the &lt;strong&gt;Azkaban&lt;/strong&gt; service is initialised, we run the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetSource()&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetTransformer()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SetDestination()&lt;/code&gt; methods for each of the Job Processors defined. When an ETL task is triggered, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Execute()&lt;/code&gt; method of the corresponding Job Processor is run. This triggers the ETL pipeline and gradually runs the 3 stages of ETL pipeline. For each stage, the Data Processor assigned during initialisation is executed.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;ETL pipelines help us in streamlining various tasks in our team. As showcased through the example in the above section, an ETL pipeline breaks a task into multiple stages and divides the responsibilities across these stages.&lt;/p&gt;

&lt;p&gt;In cases where a task fails in the middle of the process, ETL pipelines help us determine the cause of the failure quickly and accurately. With ETL pipelines, we have reduced the manual effort required for validating data at each step and avoiding propagation of errors towards the end of the pipeline.&lt;/p&gt;

&lt;p&gt;Through the use of ETL pipelines and schedulers, we at Lending have been able to automate the entire pipeline for many tasks to run at scheduled intervals without any manual effort involved at all. This has helped us tremendously in reducing human errors, increasing the throughput of the system and making the backend flow more reliable. As we continue to automate more and more of our tasks that have tightly defined stages, we foresee a growth in our ETL pipelines usage.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.alooma.com/blog/what-is-a-data-pipeline&quot;&gt;https://www.alooma.com/blog/what-is-a-data-pipeline&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://rkulla.blogspot.com/2016/01/data-pipeline-and-etl-tasks-in-go-using.html&quot;&gt;http://rkulla.blogspot.com/2016/01/data-pipeline-and-etl-tasks-in-go-using&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/swlh/etl-pipeline-and-data-pipeline-comparison-bf89fa240ce9&quot;&gt;https://medium.com/swlh/etl-pipeline-and-data-pipeline-comparison-bf89fa240ce9&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Jul 2021 03:21:10 +0000</pubDate>
        <link>https://engineering.grab.com/processing-etl-tasks-with-ratchet</link>
        <guid isPermaLink="true">https://engineering.grab.com/processing-etl-tasks-with-ratchet</guid>
        
        <category>Pipelines</category>
        
        <category>Data</category>
        
        <category>ETL</category>
        
        <category>Engineering</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>App Modularisation at Scale</title>
        <description>&lt;p&gt;Grab a coffee ☕️, sit back and enjoy reading. 😃&lt;/p&gt;

&lt;p&gt;Wanna know how we improved our app’s build time performance and developer experience at Grab? Continue reading…&lt;/p&gt;

&lt;h2 id=&quot;where-it-all-began&quot;&gt;Where it all began&lt;/h2&gt;

&lt;p&gt;Imagine you are working on an app that grows continuously as more and more features are added to it, it becomes challenging to manage the code at some point. Code conflicts increase due to coupling, development slows down, releases take longer to ship, collaboration becomes difficult, and so on.&lt;/p&gt;

&lt;p&gt;Grab superapp is one such app that offers many services like booking taxis, ordering food, payments using an e-wallet, transferring money to friends/families, paying at merchants, and many more, across Southeast Asia.&lt;/p&gt;

&lt;p&gt;Grab app followed a monolithic architecture initially where the entire code was held in a single module containing all the UI and business logic for almost all of its features. But as the app grew, new developers were hired, and more features were built, it became difficult to work on the codebase. We had to think of better ways to maintain the codebase, and that’s when the team decided to modularise the app to solve the issues faced.&lt;/p&gt;

&lt;h2 id=&quot;what-is-modularisation&quot;&gt;What is Modularisation?&lt;/h2&gt;

&lt;p&gt;Breaking the monolithic app module into smaller, independent, and interchangeable modules to segregate functionality so that every module is responsible for executing a specific functionality and will contain everything necessary to execute that functionality.&lt;/p&gt;

&lt;p&gt;Modularising the Grab app was not an easy task as it brought many challenges along with it because of its complicated structure due to the high amount of code coupling.&lt;/p&gt;

&lt;h2 id=&quot;approach-and-design&quot;&gt;Approach and Design&lt;/h2&gt;

&lt;p&gt;We divided the task into the following sub-tasks to ensure that only one out of many functionalities in the app was impacted at a time.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Setting up the infrastructure by creating &lt;strong&gt;Base/Core modules&lt;/strong&gt; for Networking, Analytics, Experimentation, Storage, Config, and so on.&lt;/li&gt;
  &lt;li&gt;Building &lt;strong&gt;Shared Library modules&lt;/strong&gt; for Styling, Common-UI, Utils, etc.&lt;/li&gt;
  &lt;li&gt;Incrementally building &lt;strong&gt;Feature modules&lt;/strong&gt; for user-facing features like Payments Home, Wallet Top Up, Peer-to-Merchant (P2M) Payments, GrabCard and many others.&lt;/li&gt;
  &lt;li&gt;Creating &lt;strong&gt;Kit modules&lt;/strong&gt; to enable inter-module communication. This step helped us in building the feature modules in parallel.&lt;/li&gt;
  &lt;li&gt;Finally, the &lt;strong&gt;App module&lt;/strong&gt; was used as a hub to connect all the other modules together using dependency injection (Dagger).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/app-modularisation-at-scale/image1.png&quot; alt=&quot;Modularised app structure&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Modularised app structure&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In the above diagram, &lt;em&gt;payments-home&lt;/em&gt;, &lt;em&gt;wallet top-up&lt;/em&gt;, and &lt;em&gt;grabcard&lt;/em&gt; are different features provided by the Grab app. &lt;em&gt;top-up-kit&lt;/em&gt; and &lt;em&gt;grabcard-kit&lt;/em&gt; are bridges that expose functionalities from &lt;em&gt;topup&lt;/em&gt; and &lt;em&gt;grabcard&lt;/em&gt; modules to the payments-home module, respectively.&lt;/p&gt;

&lt;p&gt;In the process of modularising the Grab app, we ensured that a feature module did not directly depend on other feature modules so that they could be built in parallel using the available CPU cores of the machine, hence reducing the overall build time of the app.&lt;/p&gt;

&lt;p&gt;With the &lt;em&gt;Kit&lt;/em&gt; module approach, we separated our code into independent layers by depending only on abstractions instead of concrete implementation.&lt;/p&gt;

&lt;h2 id=&quot;modularisation-benefits&quot;&gt;Modularisation Benefits&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Faster build times and hence faster CI&lt;/strong&gt;: Gradle build system compiles only the changed modules and uses the binaries of all the non-affected modules from its cache. So the compilation becomes faster as independent modules are run in parallel on different threads.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fine dependency graph&lt;/strong&gt;: Dependencies of a module are well defined.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reusability across other apps&lt;/strong&gt;: Modules can be used across different apps by converting them into an AAR/SDK.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scale and maintainability&lt;/strong&gt;: Teams can work independently on the modules owned by them without blocking each other.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Well-defined code ownership&lt;/strong&gt;: Easier to define ownership per module in the codebase.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;limitations&quot;&gt;Limitations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Requires more effort and time to modularise an app.&lt;/li&gt;
  &lt;li&gt;Separate configuration files to be maintained for each module.&lt;/li&gt;
  &lt;li&gt;Gradle sync time starts to grow.&lt;/li&gt;
  &lt;li&gt;IDE becomes very slow and its memory usage goes up a lot.&lt;/li&gt;
  &lt;li&gt;Parallel execution of the module depends on the machine’s capabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;where-we-are-now&quot;&gt;Where we are now&lt;/h2&gt;

&lt;p&gt;There are more than 1,000 modules in the Grab app and are still counting.&lt;/p&gt;

&lt;p&gt;At Grab, we have many sub-teams which take care of different features available in the app. Grab Financial Group (GFG) is one such sub-team that handles everything related to payments in the app. For example: P2P &amp;amp; P2M money transfers, e-Wallet activation, KYC, and so on.&lt;/p&gt;

&lt;p&gt;We started modularising payments further in July 2020 as it was already bombarded with too many features and it was difficult for the team to work on the single payments module. The result of payments modularisation is shown in the following chart.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/app-modularisation-at-scale/image2.png&quot; alt=&quot;Build time graph of payments module&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Build time graph of payments module&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;As of today, we have about 200+ modules in GFG and more than 95% of the modules take less than 15s to build.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Modularisation has helped us a lot in reducing the overall build time of the app and also, in improving the developer experience by breaking dependencies and allowing us to define code ownership. Having said that, modularisation is not an easy or a small task, especially for large projects with legacy code. However, with careful planning and the right design, modularisation can help in forming a well-structured and maintainable project.&lt;/p&gt;

&lt;p&gt;Hope you enjoyed reading. Don’t forget to 👏.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://proandroiddev.com/build-a-modular-android-app-architecture-25342d99de82&quot;&gt;https://proandroiddev.com/build-a-modular-android-app-architecture-25342d99de82&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/google-developer-experts/modularizing-android-applications-9e2d18f244a0&quot;&gt;https://medium.com/google-developer-experts/modularizing-android-applications-9e2d18f244a0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@mydogtom/modularization-part-1-application-structure-overview-9e465909a9bc&quot;&gt;https://medium.com/@mydogtom/modularization-part-1-application-structure-overview-9e465909a9bc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jul 2021 00:04:40 +0000</pubDate>
        <link>https://engineering.grab.com/app-modularisation-at-scale</link>
        <guid isPermaLink="true">https://engineering.grab.com/app-modularisation-at-scale</guid>
        
        <category>App</category>
        
        <category>Build Time</category>
        
        <category>Engineering</category>
        
        <category>Monorepo</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Reshaping Chat Support for Our Users</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The Grab support team plays a key role in ensuring our users receive support when things don’t go as expected or whenever there are questions on our products and services.&lt;/p&gt;

&lt;p&gt;In the past, when users required real-time support, their only option was to call our hotline and wait in the queue to talk to an agent. But voice support has its downsides: sometimes it is complex to describe an issue in the app, and it requires the user’s full attention on the call.&lt;/p&gt;

&lt;p&gt;With chat messaging apps growing massively in the last years, chat has become the expected support channel users are familiar with. It offers real-time support with the option of multitasking and easily explaining the issue by sharing pictures and documents. Compared to voice support, chat provides access to the conversation for future reference.&lt;/p&gt;

&lt;p&gt;With chat growth, building a chat system tailored to our support needs and integrated with internal data, seemed to be the next natural move.&lt;/p&gt;

&lt;p&gt;In our previous articles, we covered the tech challenges of &lt;a href=&quot;https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web&quot;&gt;building the chat platform for the web&lt;/a&gt;, our &lt;a href=&quot;https://engineering.grab.com/customer-support-workforce-routing&quot;&gt;workforce routing system&lt;/a&gt; and &lt;a href=&quot;https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml&quot;&gt;improving agent efficiency with machine learning&lt;/a&gt;. In this article, we will explain our approach and key learnings when building our in-house chat for support from a Product and Design angle.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image6.gif&quot; alt=&quot;A glimpse at agent and user experience&quot; style=&quot;width:80%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A glimpse at agent and user experience&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;why-reinvent-the-wheel&quot;&gt;Why Reinvent the Wheel&lt;/h2&gt;

&lt;p&gt;We wanted to deliver a product that would fully delight our users. That’s why we decided to build an in-house chat tool that can:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Prevent chat disconnections and ensure a consistent chat experience&lt;/strong&gt;: Building a native chat experience allowed us to ensure a stable chat session, even when users leave the app. Besides, leveraging on the existing Grab chat infrastructure helped us achieve this fast and ensure the chat experience is consistent throughout the app. You can read more about the chat architecture &lt;a href=&quot;https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improve productivity and provide faster support turnarounds&lt;/strong&gt;: By building the agent experience in the CRM tool, we could reduce the number of tools the support team uses and build features tailored to our internal processes. This helped to provide faster help for our users.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Allow integration with internal systems and services&lt;/strong&gt;: Chat can be easily integrated with in-house AI models or chatbot, which helps us personalise the user experience and improve agent productivity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Route our users to the best support specialist available&lt;/strong&gt;: Our newly built routing system accounts for all the use cases we were wishing for such as prioritising certain requests, better distribution of the chat load during peak hours, making changes at scale and ensuring each chat is routed to the best support specialist available.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;fail-fast-with-an-mvp&quot;&gt;Fail Fast with an MVP&lt;/h2&gt;

&lt;p&gt;Before building a full-fledged solution, we needed to prove the concept, an MVP that would have the key features and yet, would not take too much effort if it fails. To kick start our experiment, we established the success criteria for our MVP; how do we measure its success or failure?&lt;/p&gt;

&lt;h3 id=&quot;defining-what-success-looks-like&quot;&gt;Defining What Success Looks Like&lt;/h3&gt;

&lt;p&gt;Any experiment requires a hypothesis - something you’re trying to prove or disprove and it should relate to your final product. To tailor the final product around the success criteria, we need to understand how success is measured in our situation. In our case, disconnections during chat support was one of the key challenges faced so our hypothesis was:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/reshaping-chat-support/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;starting-with-design-sprint&quot;&gt;Starting with Design Sprint&lt;/h3&gt;

&lt;p&gt;Our design sprint aimed to &lt;strong&gt;solutionise a series of problem statements, and generate a prototype to validate our hypothesis&lt;/strong&gt;. To spark ideation, we run sketching exercises such as &lt;a href=&quot;https://designsprintkit.withgoogle.com/methodology/phase3-sketch/crazy-8s&quot;&gt;Crazy 8&lt;/a&gt;, &lt;a href=&quot;https://designsprintkit.withgoogle.com/methodology/phase3-sketch/solution-sketch&quot;&gt;Solution sketch&lt;/a&gt; and end off with sharing and voting.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image12.jpg&quot; style=&quot;width:60%&quot; /&gt;
    &lt;img src=&quot;/img/reshaping-chat-support/image1.jpg&quot; style=&quot;width:60%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Some of the prototypes built during the Design sprint&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;defining-mvp-scope-to-run-the-experiment&quot;&gt;Defining MVP Scope to Run the Experiment&lt;/h3&gt;

&lt;p&gt;To test our hypothesis quickly, we had to cut the scope by focusing on the basic functionality of allowing chat message exchanges with one agent.&lt;/p&gt;

&lt;p&gt;Here is the main flow and a sneak peek of the design:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image13.jpg&quot; alt=&quot;Accepting chats&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Accepting chats&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image8.gif&quot; alt=&quot;Handling concurrent chats&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Handling concurrent chats&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-we-learnt-from-the-experiment&quot;&gt;What We Learnt from the Experiment&lt;/h3&gt;

&lt;p&gt;During the experiment, we had to constantly put ourselves in our users’ shoes as ‘we are not our users’. We decided to shadow our chat support agents and get a sense of the potential issues our users actually face. By doing so, we learnt a lot about how the tool was used and spotted several problems to address in the next iterations.&lt;/p&gt;

&lt;p&gt;In the end, &lt;strong&gt;the experiment confirmed our hypothesis that having a native in-app chat was more stable than the previous chat in use&lt;/strong&gt;, resulting in a better user experience overall.&lt;/p&gt;

&lt;h2 id=&quot;starting-with-the-end-in-mind&quot;&gt;Starting with the End in Mind&lt;/h2&gt;

&lt;p&gt;Once the experiment was successful, we focused on scaling. We defined the most critical jobs to be done for our users so that we could scale the product further. When designing solutions to tackle each of them, we ensured that the product would be flexible enough to address future pain points. Would this work for more channels, more users, more products, more countries?&lt;/p&gt;

&lt;p&gt;Before scaling, the problems to solve were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring the performance of the system in real-time&lt;/strong&gt;, so that swift operational changes can be made to ensure users receive fast support;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Routing each chat to the best agent available&lt;/strong&gt;, considering skills, occupancy, as well as issue prioritisation. You can read more about the our routing system design &lt;a href=&quot;https://engineering.grab.com/customer-support-workforce-routing&quot;&gt;here&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easily communicate with users and show empathy&lt;/strong&gt;, for which we built file-sharing capabilities for both users and agents, as well as allowing emojis, which create a more personalised experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scaling-efficiently&quot;&gt;Scaling Efficiently&lt;/h2&gt;

&lt;p&gt;We broke down the chat support journey to determine what areas could be improved.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/reshaping-chat-support/image10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reducing-waiting-time&quot;&gt;Reducing Waiting Time&lt;/h3&gt;

&lt;p&gt;When analysing the current wait time, we realised that when there was a surge in support requests, the average waiting time increased drastically. In these cases, most users would be unresponsive by the time an agent finally attends to them.&lt;/p&gt;

&lt;p&gt;To solve this problem, the team worked on a dynamic queue limit concept based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Little%2527s_law&quot;&gt;Little’s law&lt;/a&gt;. The idea is that considering the number of incoming chats and the agents’ capacity, we can forecast the number of users we can handle in a reasonable time, and prevent the remaining from initiating a chat. When this happens, we ensure there’s a backup channel for support so that no user is left unattended.&lt;/p&gt;

&lt;p&gt;This allowed us to &lt;strong&gt;reduce chat waiting time by ~30% and reduce unresponsive users by ~7%&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reducing-time-to-reply&quot;&gt;Reducing Time to Reply&lt;/h3&gt;

&lt;p&gt;A big part of the chat time is spent typing the message to send to the user. Although the previous tool had templated messages, we observed that 85% of them were free-typed. This is because agents felt the templates were impersonal and wanted to add their personal style to the messages.&lt;/p&gt;

&lt;p&gt;With this information in mind, we knew we could help by providing autocomplete suggestions  while the agents are typing. We built a machine learning based feature that considers several factors such as user type, the entry point to support, and the last messages exchanged, to suggest how the agent should complete the sentence. When this feature was first launched, we &lt;strong&gt;reduced the average chat time by 12%&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;Read &lt;a href=&quot;https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml&quot;&gt;this&lt;/a&gt; to find out more about how we built this machine learning feature, from defining the problem space to its implementation.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image11.gif&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;reducing-the-overall-chat-time&quot;&gt;Reducing the Overall Chat Time&lt;/h3&gt;

&lt;p&gt;Looking at the average chat time, we realised that there was still room for improvement. How can we help our agents to manage their time better so that we can reduce the waiting time for users in the queue?&lt;/p&gt;

&lt;p&gt;We needed to provide visibility of chat durations so that our agents could manage their time better. So, we added a timer at the top of each chat window to indicate how long the chat was taking.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image15.png&quot; alt=&quot;Timer in the minimised chat&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Timer in the minimised chat&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;We also added nudges to remind agents that they had other users to attend to while they were in the chat.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image2.png&quot; alt=&quot;Timer in the maximised chat&quot; style=&quot;width:80%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Timer in the maximised chat&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;By providing visibility via prompts and colour-coded indicators to prevent exceeding the expected chat duration, we &lt;strong&gt;reduced the average chat time by 22%&lt;/strong&gt;!&lt;/p&gt;

&lt;h2 id=&quot;what-we-learnt-from-this-project&quot;&gt;What We Learnt from this Project&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Start with the end in mind.&lt;/strong&gt; When you embark on a big project like this, have a clear vision of how the end state looks like and plan each step backwards. How does success look like and how are we going to measure it? How do we get there?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data is king.&lt;/strong&gt; Data helped us spot issues in real-time and guided us through all the iterations following the MVP. It helped us prioritise the most impactful problems and take the right design decisions. Instrumentation must be part of your MVP scope!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remote user testing is better than no user testing at all.&lt;/strong&gt; Ideally, you want to do user testing in the exact environment your users will be using the tool but a pandemic might make things a bit more complex. Don’t let this stop you! The qualitative feedback we received from real users, even with a prototype on a video call, helped us optimise the tool for their needs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Address the root cause, not the symptoms.&lt;/strong&gt; Whenever you are tasked with solving a big problem, break it down into its components by asking “Why?” until you find the root cause. In the first phases, we realised the tool had a longer chat time compared to 3rd party softwares. By iteratively splitting the problem into smaller ones, we were able to address the root causes instead of the symptoms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Shadow your users whenever you can.&lt;/strong&gt; By looking at the users in action, we learned a ton about their creative ways to go around the tool’s limitations. This allowed us to iterate further on the design and help them be more efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Of course, this would not have been possible without the incredible work of several teams: GS TF, GS, Comms platform, Driver and Merchant teams.
&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Jul 2021 00:18:20 +0000</pubDate>
        <link>https://engineering.grab.com/reshaping-chat-support</link>
        <guid isPermaLink="true">https://engineering.grab.com/reshaping-chat-support</guid>
        
        <category>Product</category>
        
        <category>Design</category>
        
        <category>Chat Support</category>
        
        
        <category>Product</category>
        
      </item>
    
  </channel>
</rss>
