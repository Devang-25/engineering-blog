<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 30 Jul 2021 03:03:04 +0000</pubDate>
    <lastBuildDate>Fri, 30 Jul 2021 03:03:04 +0000</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>How We Cut GrabFood.com’s Page JavaScript Asset Sizes by 3x</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Every week, GrabFood.com’s cloud infrastructure serves over &amp;gt;1TB network egress and 175 million requests, which increased our costs. To minimise cloud costs, we had to look at optimising (and reducing) GrabFood.com’s bundle size.&lt;/p&gt;

&lt;p&gt;Any reduction in bundle size helps with:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Faster site loads! (especially for locations with lower mobile broadband speeds)&lt;/li&gt;
  &lt;li&gt;Cost savings for users: Less data required for each site load&lt;/li&gt;
  &lt;li&gt;Cost savings for Grab: Less network egress required to serve users&lt;/li&gt;
  &lt;li&gt;Faster build times: Fewer dependencies -&amp;gt; less code for webpack to bundle -&amp;gt; faster builds&lt;/li&gt;
  &lt;li&gt;Smaller builds: Fewer dependencies -&amp;gt; less code -&amp;gt; smaller builds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After applying the 7 webpack bundle optimisations, we were able to yield the following improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;7% faster page load time from 2600ms to 2400ms&lt;/li&gt;
  &lt;li&gt;66% faster JS static asset load time from 180ms to 60ms&lt;/li&gt;
  &lt;li&gt;3x smaller JS static assets from 750KB to 250KB&lt;/li&gt;
  &lt;li&gt;1.5x less network egress from 1800GB to 1200GB&lt;/li&gt;
  &lt;li&gt;20% less for CloudFront costs from $1750 to $1400&lt;/li&gt;
  &lt;li&gt;1.4x smaller bundle from 40MB to 27MB&lt;/li&gt;
  &lt;li&gt;3.6x faster build time from ~2000s to ~550s&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;One of the biggest factors influencing bundle size is dependencies. As mentioned earlier, fewer dependencies mean fewer lines of code to compile, which result in a smaller bundle size. Thus, to optimise GrabFood.com’s bundle size, we had to look into our dependencies.&lt;/p&gt;

&lt;p&gt;Tldr;&lt;/p&gt;

&lt;p&gt;Jump to &lt;a href=&quot;#step-c-reducing-your-dependencies&quot;&gt;Step C: Reducing your Dependencies&lt;/a&gt; to see the 7 strategies we used to cut down our bundle size.&lt;/p&gt;

&lt;h3 id=&quot;step-a-identify-your-dependencies&quot;&gt;Step A: Identify Your Dependencies&lt;/h3&gt;

&lt;p&gt;In this step, we need to ask ourselves ‘what are our largest dependencies?’. We used the &lt;a href=&quot;https://github.com/webpack-contrib/webpack-bundle-analyzer&quot;&gt;webpack-bundle-analyzer&lt;/a&gt; to inspect GrabFood.com’s bundles. This gave us an overview of all our dependencies and we could easily see which bundle assets were the largest.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image12.png&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Our grabfood.com bundle analyzer output&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;For Next.js, you should use &lt;a href=&quot;https://github.com/vercel/next.js/tree/canary/packages/next-bundle-analyzer&quot;&gt;@next/bundle-analyze&lt;/a&gt; instead.&lt;/li&gt;
  &lt;li&gt;Bundle analysis output allows us to easily inspect what’s in our bundle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What to look out for:&lt;/p&gt;

&lt;p&gt;I: Large dependencies (fairly obvious, because the box size will be large)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;II: Duplicate dependencies (same library that is bundled multiple times across different assets)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image2.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;img/grabfood-bundle/image2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;III: Dependencies that look like they don’t belong (e.g. Why is ‘elliptic’ in my frontend bundle?)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/grabfood-bundle/image8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What to avoid:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Isolating dependencies that are very small (e.g. &amp;lt;20kb). Not worth focusing on this due to very meagre returns.
    &lt;ul&gt;
      &lt;li&gt;E.g. Business logic like your React code&lt;/li&gt;
      &lt;li&gt;E.g. Small node dependencies&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-b-investigate-the-usage-of-your-dependencies-where-are-my-dependencies-used&quot;&gt;Step B: Investigate the Usage of Your Dependencies (Where are my Dependencies Used?)&lt;/h3&gt;
&lt;p&gt;In this step, we are trying to answer this question: “Given a dependency, which files and features are making use of it?”.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image10.png&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;a href=&quot;https://pixabay.com/photos/architecture-building-geometric-1868547/&quot;&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Image source&lt;/i&gt;&lt;/figcaption&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;There are two broad approaches that can be used to identify how our dependencies are used:&lt;/p&gt;

&lt;p&gt;I: Top-down approach: “Where does our project use dependency X?”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Conceptually identify which feature(s) requires the use of dependency X.&lt;/li&gt;
  &lt;li&gt;E.g. Given that we have ‘&lt;a href=&quot;https://github.com/hokaccha/node-jwt-simple&quot;&gt;jwt-simple&lt;/a&gt;’ as a dependency, which set of features in my project requires JWT encoding/decoding?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;II: Bottom-up approach: “How did dependency X get used in my project?”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trace dependencies by manually tracing &lt;code class=&quot;highlighter-rouge&quot;&gt;import()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;require()&lt;/code&gt; statements&lt;/li&gt;
  &lt;li&gt;Alternatively, use dependency visualisation tools such as &lt;a href=&quot;https://github.com/sverweij/dependency-cruiser&quot;&gt;dependency-cruiser&lt;/a&gt; to identify file interdependencies. Note that output can quickly get noisy for any non-trivial project, so use it for inspecting small groups of files (e.g. single domains).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our recommendation is to use a &lt;strong&gt;mix&lt;/strong&gt; of both Top-down and Bottom-up approaches to identify and isolate dependencies.&lt;/p&gt;

&lt;p&gt;Dos:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Be methodical when tracing dependencies: Use a document to track your progress as you manually trace inter-file dependencies.&lt;/li&gt;
  &lt;li&gt;Use dependency visualisation tools like &lt;a href=&quot;https://github.com/sverweij/dependency-cruiser&quot;&gt;dependency-cruiser&lt;/a&gt; to quickly view a given file’s dependencies.&lt;/li&gt;
  &lt;li&gt;Consult Dr. Google if you get stuck somewhere, especially if the dependencies are buried deep in a dependency tree i.e. non-1st-degree dependencies (e.g. “&lt;a href=&quot;https://stackoverflow.com/questions/42492410/why-webpack-includes-elliptic-bn-js-modules-in-my-bundle&quot;&gt;Why webpack includes elliptic bn.js modules in bundle&lt;/a&gt;”)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Don’ts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stick to a single approach - Know when to switch between Top-down and Bottom-up approaches to narrow down the search space.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-c-reducing-your-dependencies&quot;&gt;Step C: Reducing Your Dependencies&lt;/h3&gt;
&lt;p&gt;Now that you know what your largest dependencies are and where they are used, the next step is figuring out how you can shrink your dependencies.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image15.gif&quot; alt=&quot;Our grabfood.com bundle analyzer output&quot; style=&quot;width:90%&quot; /&gt; &lt;a href=&quot;https://i.imgur.com/w8Ydzvb.gif&quot;&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Image source&lt;/i&gt;&lt;/figcaption&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Here are 7 strategies that you can use to reduce your dependencies:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-lazy-load-large-dependencies-and-less-used-dependencies&quot;&gt;Lazy load large dependencies and less-used dependencies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-unify-instances-of-duplicate-modules&quot;&gt;Unify instances of duplicate modules&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-use-libraries-that-are-exported-in-es-modules-format&quot;&gt;Use libraries that are exported in ES Modules format&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-replace-libraries-whose-features-are-already-available-on-the-browser-web-api&quot;&gt;Replace libraries whose features are already available on the Browser Web API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-avoid-large-dependencies-by-changing-your-technical-approach&quot;&gt;Avoid large dependencies by changing your technical approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6-avoid-using-node-dependencies-or-libraries-that-require-node-dependencies&quot;&gt;Avoid using node dependencies or libraries that require node dependencies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7-optimise-your-external-dependencies&quot;&gt;Optimise your external dependencies&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note: These strategies have been listed in ascending order of difficulty - focus on the easy wins first 🙂&lt;/p&gt;

&lt;h4 id=&quot;1-lazy-load-large-dependencies-and-less-used-dependencies&quot;&gt;1. Lazy Load Large Dependencies and Less-used Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image13.png&quot; alt=&quot;When a file adds +2MB worth of dependencies&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When a file adds +2MB worth of dependencies”, &lt;a href=&quot;https://knowyourmeme.com/memes/vault-boy-hold-up&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Similar to how lazy loading is used to break down large React pages to improve page performance, we can also lazy load libraries that are rarely used, or are not immediately used until prior to certain user actions.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;computeHash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createHmac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;computeHash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;crypto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createHmac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Use of Anti-abuse library prior to sensitive API calls&lt;/li&gt;
  &lt;li&gt;Action: Instead of bundling the anti-abuse library together with the main page asset, we opted to lazy load the library only when we needed to use it (i.e. load the library just before making certain sensitive API calls).&lt;/li&gt;
  &lt;li&gt;Results: Saved 400KB on the main page asset.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Any form of lazy loading will incur some latency on the user, since the asset must be loaded with &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest&quot;&gt;XMLHttpRequest&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-unify-instances-of-duplicate-modules&quot;&gt;2. Unify Instances of Duplicate Modules&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabfood-bundle/image6.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://knowyourmeme.com/memes/spider-man-pointing-at-spider-man&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If you see the same dependency appearing in multiple assets, consider unifying these duplicate dependencies under a single entrypoint.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;// ComponentOne.jsx&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentTwo.jsx&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;// grabMapsImportFn.js&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;grab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;maps&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentOne.tsx&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ComponentTwo.tsx&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMapsImportFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabMaps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;grabMaps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Marker&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Duplicate ‘grab-maps’ dependencies in bundle&lt;/li&gt;
  &lt;li&gt;Action: We observed that we were bundling the same ‘grab-maps’ dependency in 4 different assets so we refactored the application to use a single entrypoint, ensuring that we only bundled one instance of ‘grab-maps’.&lt;/li&gt;
  &lt;li&gt;Results: Saved 2MB on total bundle size.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Alternative approach: Manually define a new cacheGroup to target a specific module (&lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin/%23split-chunks-example-2&quot;&gt;see more&lt;/a&gt;) with ‘enforce:true’, in order to force webpack to always create a separate chunk for the module. Useful for cases where the single dependency is very large (i.e. &amp;gt;100KB), or when asynchronously loading a module isn’t an option.&lt;/li&gt;
  &lt;li&gt;Certain libraries that appear in multiple assets (e.g. antd) should not be mistaken as identical dependencies. You can verify this by inspecting each module with one another. If the contents are different, then webpack has already done its job of tree-shaking the dependency and only importing code used by our code.&lt;/li&gt;
  &lt;li&gt;Webpack relies on the &lt;code class=&quot;highlighter-rouge&quot;&gt;import()&lt;/code&gt; statement to identify that a given module is to be explicitly bundled as a separate chunk (&lt;a href=&quot;https://webpack.js.org/api/module-methods/%23import-1&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-use-libraries-that-are-exported-in-es-modules-format&quot;&gt;3. Use Libraries that are Exported in ES Modules Format&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image1.gif&quot; alt=&quot;Did you say ‘tree-shaking’?&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Did you say ‘tree-shaking’?”, &lt;a href=&quot;https://www.huffpost.com/entry/commercial-harvesting_n_57a215eee4b04414d1f2df60&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;If a given library has a variant with an ES Module distribution, use that variant instead.&lt;/li&gt;
  &lt;li&gt;ES Modules allows webpack to perform &lt;a href=&quot;https://webpack.js.org/guides/tree-shaking/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://webpack.js.org/guides/tree-shaking/&quot;&gt;tree-shaking&lt;/a&gt; automatically, allowing you to save on your bundle size because unused library code is not bundled.&lt;/li&gt;
  &lt;li&gt;Use &lt;a href=&quot;https://bundlephobia.com/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bundlephobia.com/&quot;&gt;bundlephobia&lt;/a&gt; to quickly ascertain if a given library is tree-shakeable (e.g. ‘&lt;a href=&quot;https://bundlephobia.com/package/lodash-es@4.17.21&quot;&gt;lodash-es&lt;/a&gt;’ vs &lt;a href=&quot;https://bundlephobia.com/package/lodash@4.17.21&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bundlephobia.com/package/lodash@4.17.21&quot;&gt;‘lodash&lt;/a&gt;’)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lodash&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lodash&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;es&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Case: Using Lodash utilities&lt;/li&gt;
  &lt;li&gt;Action: Instead of using the standard ‘lodash’ library, you can swap it out with ‘lodash-es’, which is bundled using ES Modules and is functionally equivalent.&lt;/li&gt;
  &lt;li&gt;Results: Saved 0KB - We were already directly importing individual Lodash functions (e.g. ‘lodash/get’), therefore importing only the code we need. Still, ES Modules is a more convenient way to go about this 👍.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Alternative approach: Use babel plugins (e.g. ‘&lt;a href=&quot;https://www.npmjs.com/package/babel-plugin-transform-imports&quot;&gt;babel-plugin-transform-imports&lt;/a&gt;’) to transform your import statements at build time to selectively import specific code for a given library.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;4-replace-libraries-whose-features-are-already-available-on-the-browser-web-api&quot;&gt;4. Replace Libraries whose Features are Already Available on the Browser Web API&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image3.png&quot; alt=&quot;When you replace axios with fetch&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When you replace axios with fetch”, &lt;a href=&quot;https://knowyourmeme.com/memes/the-future-is-now-old-man&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If you are relying on libraries for functionality that is available on the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API&quot;&gt;Web API&lt;/a&gt;, you should revise your implementation to leverage on the Web API, allowing you to skip certain libraries when bundling, thus saving on bundle size.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;getEndpointData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;axios&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;getEndpointData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;response&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Case: Replacing axios with &lt;code class=&quot;highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; in the anti-abuse library&lt;/li&gt;
  &lt;li&gt;Action: We observed that our anti-abuse library was relying on axios to make web requests. Since our web app is only targeting modern browsers - most of which support &lt;code class=&quot;highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; (with the notable exception of IE) - we refactored the library’s code to use &lt;code class=&quot;highlighter-rouge&quot;&gt;fetch()&lt;/code&gt; exclusively.&lt;/li&gt;
  &lt;li&gt;Results: Saved 15KB on anti-abuse library size.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5-avoid-large-dependencies-by-changing-your-technical-approach&quot;&gt;5. Avoid Large Dependencies by Changing your Technical Approach&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image16.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://knowyourmeme.com/memes/this-is-brilliant-but-i-like-this&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;If it is acceptable to change your technical approach, we can avoid using certain dependencies altogether.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;simple&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;encodeCookieData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;encodeCookieData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Encoding for browser cookie persistence&lt;/li&gt;
  &lt;li&gt;Action: As we needed to store certain user preferences in the user’s browser, we previously opted to use JWT encoding; this involved signing JWTs on the client side, which has a hard dependency on ‘crypto’. We revised the implementation to use plain JSON encoding instead, removing the need for ‘crypto’.&lt;/li&gt;
  &lt;li&gt;Results: Saved 250KB per page asset, 13MB in total bundle size.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;6-avoid-using-node-dependencies-or-libraries-that-require-node-dependencies&quot;&gt;6. Avoid Using Node Dependencies or Libraries that Require Node Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image7.png&quot; alt=&quot;“When someone does require(‘crypto’)”&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“When someone does require(‘crypto’)”, &lt;a href=&quot;https://www.memecreator.org/meme/yamero0/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;You should not need to use node-related dependencies, unless your application relies on a node dependency directly or indirectly.&lt;/p&gt;

&lt;p&gt;Examples of node dependencies: ‘Buffer’, ‘crypto’, ‘https’ (&lt;a href=&quot;https://nodejs.org/docs/latest-v16.x/api/&quot;&gt;see more&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jsonwebtoken&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decodeJwt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;verify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'some-secret'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;decoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

 &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt_decode&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;jwt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decodeJwt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;jwt_decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Decoding JWTs on the client side&lt;/li&gt;
  &lt;li&gt;Action: In terms of JWT usage on the client side, we only need to decode JWTs - we do not need any logic related to encoding JWTs. Therefore, we can opt to use libraries that perform just decoding (e.g. ‘&lt;a href=&quot;https://github.com/auth0/jwt-decode&quot;&gt;jwt-decode&lt;/a&gt;’) instead of libraries (e.g. ‘&lt;a href=&quot;https://github.com/auth0/node-jsonwebtoken&quot;&gt;jsonwebtoken&lt;/a&gt;’) that performs the full suite of JWT-related operations (e.g. signing, verifying).&lt;/li&gt;
  &lt;li&gt;Results: Same as in Point 5: Example. (i.e. no need to decode JWTs anymore, since we aren’t using JWT encoding for browser cookie persistence)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;7-optimise-your-external-dependencies&quot;&gt;7. Optimise your External Dependencies&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image14.png&quot; alt=&quot;“Team: Can you reduce the bundle size further? You:“&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Team: Can you reduce the bundle size further? You: (nervous grin)“, &lt;a href=&quot;https://awesomebyte.com/viral-face-of-the-internet-the-origin-of-hide-the-pain-harold/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We can do a deep-dive into our dependencies to identify possible size optimisations by applying all the aforementioned techniques. If your size optimisation changes get accepted, regardless of whether it’s publicly (e.g. GitHub) or privately hosted (own company library), it’s a win-win for everybody! 🥳&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scenario: Creating custom ‘node-forge’ builds for our Anti-abuse library&lt;/li&gt;
  &lt;li&gt;Action: Our Anti-abuse library only uses certain features of ‘node-forge’. Thankfully, the ‘node-forge’ maintainers have provided an easy way to make custom builds that only bundle selective features (&lt;a href=&quot;https://github.com/digitalbazaar/forge/blob/c666282c812d6dc18e97b419b152dd6ad98c802c/webpack.config.js%23L15-L61&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Results: Saved 85KB in Anti-abuse library size and reduced bundle size for all other dependent projects.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-d-verify-that-you-have-modified-the-dependencies&quot;&gt;Step D: Verify that You have Modified the Dependencies&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image9.png&quot; alt=&quot;Now… where did I put that needle?&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;“Now… where did I put that needle?”, &lt;a href=&quot;https://pixabay.com/photos/haystack-bale-of-straw-fields-hay-401882/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;So, you’ve found some opportunities for major bundle size savings, that’s great!&lt;/p&gt;

&lt;p&gt;But as always, it’s best to be methodical to measure the impact of your changes, and to make sure no features have been broken.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Perform your code changes&lt;/li&gt;
  &lt;li&gt;Build the project again and open the bundle analysis report&lt;/li&gt;
  &lt;li&gt;Verify the state of a given dependency
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Deleted dependency&lt;/strong&gt; - you should not be able to find the dependency&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lazy-loaded dependency&lt;/strong&gt; - you should see the dependency bundled as a separate chunk&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Non-duplicated dependency&lt;/strong&gt; - you should only see a single chunk for the non-duplicated dependency&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Run tests to make sure you didn’t break anything (i.e. unit tests, manual tests)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;other-considerations&quot;&gt;Other Considerations&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Preventive Measures&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Periodically monitor your bundle size to identify increases in bundle size&lt;/li&gt;
  &lt;li&gt;Periodically monitor your site load times to identify increases in site load times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Webpack Configuration Options&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Disable bundling node modules with ‘node: false’
    &lt;ul&gt;
      &lt;li&gt;Only if your project doesn’t already include libraries that rely on node modules.&lt;/li&gt;
      &lt;li&gt;Allows for fast detection when someone tries to use a library that requires node modules, as the build will fail&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experiment with ‘cacheGroups’
    &lt;ul&gt;
      &lt;li&gt;Most default configurations of webpack do a pretty good job of identifying and bundling the most commonly used dependencies into a single chunk (usually called vendor.js)&lt;/li&gt;
      &lt;li&gt;You can experiment with webpack &lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin/&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://webpack.js.org/plugins/split-chunks-plugin&quot;&gt;optimisation options&lt;/a&gt; to see if you get better results&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Experiment with &lt;code class=&quot;highlighter-rouge&quot;&gt;import()&lt;/code&gt; ‘Magic Comments’
    &lt;ul&gt;
      &lt;li&gt;You may experiment with &lt;a href=&quot;https://webpack.js.org/api/module-methods/%23magic-comments&quot;&gt;import() magic comments&lt;/a&gt; to modify the behaviour of specific &lt;code class=&quot;highlighter-rouge&quot;&gt;import()&lt;/code&gt; statements, although the default setting will do just fine for most cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you can’t remove the dependency:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For all dependencies that must be used, it’s probably best to lazy load all of them so you won’t block the page’s initial rendering (&lt;a href=&quot;https://web.dev/first-contentful-paint/&quot;&gt;see more&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;&lt;img src=&quot;/img/grabfood-bundle/image5.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;&lt;a href=&quot;https://pixabay.com/photos/zen-meditation-yoga-spirituality-5533537/&quot;&gt;Image source&lt;/a&gt;&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To summarise, here’s how you can go about this business of reducing your bundle size.&lt;/p&gt;

&lt;p&gt;Namely…&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Identify Your Dependencies&lt;/li&gt;
  &lt;li&gt;Investigate the Usage of Your Dependencies&lt;/li&gt;
  &lt;li&gt;Reduce Your Dependencies&lt;/li&gt;
  &lt;li&gt;Verify that You have Modified the Dependencies&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And by using these 7 strategies…&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Lazy load large dependencies and less-used dependencies&lt;/li&gt;
  &lt;li&gt;Unify instance of duplicate modules&lt;/li&gt;
  &lt;li&gt;Use libraries that are exported in ES Modules format&lt;/li&gt;
  &lt;li&gt;Replace libraries whose features are already available on the Browser Web API&lt;/li&gt;
  &lt;li&gt;Avoid large dependencies by changing your technical approach&lt;/li&gt;
  &lt;li&gt;Avoid using node dependencies&lt;/li&gt;
  &lt;li&gt;Optimise your external dependencies&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You can have…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Faster page load time (smaller individual pages)&lt;/li&gt;
  &lt;li&gt;Smaller bundle (fewer dependencies)&lt;/li&gt;
  &lt;li&gt;Lower network egress costs (smaller assets)&lt;/li&gt;
  &lt;li&gt;Faster builds (fewer dependencies to handle)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now armed with this information, may your eyes be keen, your bundles be lean, your sites be fast, and your cloud costs be low! 🚀 ✌️&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Han Wu, Melvin Lee, Yanye Li, and Shujuan Cheong for proofreading this article. 🙂&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 29 Jul 2021 01:20:00 +0000</pubDate>
        <link>https://engineering.grab.com/grabfood-bundle-size</link>
        <guid isPermaLink="true">https://engineering.grab.com/grabfood-bundle-size</guid>
        
        <category>Product</category>
        
        <category>Asset Size</category>
        
        <category>Cloud</category>
        
        <category>Optimisation</category>
        
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>Protecting Personal Data in Grab's Imagery</title>
        <description>&lt;h2 id=&quot;image-collection-using-kartaview&quot;&gt;Image Collection Using KartaView&lt;/h2&gt;

&lt;p&gt;A few years ago, we realised a strong demand to better understand the streets where our driver-partners and consumers go, with the purpose to better fulfil their needs and also, to quickly adapt ourselves to the rapidly changing environment in the Southeast Asian cities.&lt;/p&gt;

&lt;p&gt;One way to fulfil that demand was to create an image collection platform named KartaView which is Grab Geo’s platform for geotagged imagery. It empowers collection, indexing, storage, retrieval of imagery, and map data extraction.&lt;/p&gt;

&lt;p&gt;KartaView is a public, partially open-sourced product, used both internally and externally by the OpenStreetMap community and other users. As of 2021, KartaView has public imagery in over 100 countries with various coverage degrees, and 60+ cities of Southeast Asia. Check it out at &lt;a href=&quot;http://www.kartaview.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-1-kartaview-platform.png&quot; alt=&quot;Figure 1 - KartaView platform&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 1 - KartaView platform&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;why-image-blurring-is-important&quot;&gt;Why Image Blurring is Important&lt;/h2&gt;

&lt;p&gt;Incidentally, many people and licence plates are in the collected images, whose privacy is a serious concern. We deeply respect all of them and consequently, we are using image obfuscation as the most effective anonymisation method for ensuring privacy protection.&lt;/p&gt;

&lt;p&gt;Because manually annotating the regions in the picture where faces and licence plates are located is impractical, this problem should be solved using machine learning and engineering techniques. Hence we detect and blur all faces and licence plates which could be considered as personal data.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-2-sample-blurred-picture.jpg&quot; alt=&quot;Figure 2 - Sample blurred picture&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 2 - Sample blurred picture&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In our case, we have a wide range of picture types: regular planar, very wide and 360 pictures in equirectangular format collected with 360 cameras. Also, because we are collecting imagery globally, the vehicle types, licence plates, and human environments are quite diverse in appearance, and are not handled well by off-the-shelf blurring software. So we built our own custom blurring solution which yielded higher accuracy and better cost efficiency overall with respect to blurring of personal data.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-3-equirectangular-image.png&quot; alt=&quot;Figure 3 - Example of equirectangular image where personal data has to be blurred&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 3 - Example of equirectangular image where personal data has to be blurred&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Behind the scenes, in KartaView, there are a set of cool services which can derive useful information from the pictures like image quality, traffic signs, roads, etc. A big part of them are using deep learning algorithms which potentially can be negatively affected by running them over blurred pictures. In fact, based on the assessment we have done so far, the impact is extremely low, similar to the one reported in a well known study of face obfuscation in ImageNet &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h3 id=&quot;outline-of-grabs-blurring-process&quot;&gt;Outline of Grab’s Blurring Process&lt;/h3&gt;

&lt;p&gt;At a high level, this is how Grab goes about the blurring process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Transform each picture into a set of planar images. In this way, we further process all pictures, whatever the format they had, in the same way.&lt;/li&gt;
  &lt;li&gt;Use an object detector able to detect all faces and licence plates in a planar image having a standard field of view.&lt;/li&gt;
  &lt;li&gt;Transform the coordinates of the detected regions into original coordinates and blur those regions.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-4-picture-processing-steps.png&quot; alt=&quot;Figure 4 - Picture’s processing steps&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 4 - Picture’s processing steps&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
In the following section, we are going to describe in detail the interesting aspects of the second step, sharing the challenges and how we were solving them. Let’s start with the first and most important part, the dataset.&lt;/p&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;Our current dataset consists of images from a wide range of cameras, including normal perspective cameras from mobile phones, wide field of view cameras and also 360 degree cameras.&lt;/p&gt;

&lt;p&gt;It is the result of a series of data collections contributed by Grab’s data tagging teams, which may contain 2 classes of dataset that are of interest for us: FACE and LICENSE_PLATE.&lt;/p&gt;

&lt;p&gt;The data was collected using Grab internal tools, stored in queryable databases, making it a system that gives the possibility to revisit and correct the data if necessary, but also making it possible for data engineers to select and filter the data of interest.&lt;/p&gt;

&lt;h4 id=&quot;dataset-evolution&quot;&gt;Dataset Evolution&lt;/h4&gt;

&lt;p&gt;Each iteration of the dataset was made to address certain issues discovered while having models used in a production environment and observing situations where the model lacked in performance.&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Dataset v1&lt;/th&gt;
      &lt;th&gt;Dataset v2&lt;/th&gt;
      &lt;th&gt;Dataset v3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Nr. images&lt;/td&gt;
      &lt;td&gt;15226&lt;/td&gt;
      &lt;td&gt;17636&lt;/td&gt;
      &lt;td&gt;30538&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Nr. of labels&lt;/td&gt;
      &lt;td&gt;64119&lt;/td&gt;
      &lt;td&gt;86676&lt;/td&gt;
      &lt;td&gt;242534&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If the first version was basic, containing a rough tagging strategy we quickly noticed that it was not detecting some special situations that appeared due to the pandemic situation: people wearing masks.&lt;/p&gt;

&lt;p&gt;This led to another round of data annotation to include those scenarios.
The third iteration addressed a broader range of issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Small regions of interest (objects far away from the camera)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/small-region-of-interest.jpg&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Objects in very dark backgrounds&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/objects-in-very-dark-backgrounds.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Rotated objects or even upside down&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/rotated-objects.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Variation of the licence plate design due to images from different countries and regions&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/licence-plate.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;People wearing masks&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/masks.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Faces in the mirror - see below the mirror of the motorcycle&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/faces-in-mirror.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;But the main reason was because of a scenario where the recording had at the start or end (but not only) close-ups of the operator who was checking the camera. This led to images with large regions of interest containing the camera operator’s face - too large to be detected by the model.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/face.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We investigated the dataset structure by splitting the data into bins based on the bbox sizes (in pixels). This made something clear to us: the dataset was unbalanced.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/detection-counts-graph.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We made bins for tag sizes with a stride of 100 pixels and went up to the maximum value present in the dataset which accounted for 1 sample of size 2000 pixels. The majority of the labels were small in size and the higher we would go with the size, the fewer tags we would have. This made it clear that we would need more targeted annotations for our dataset to try to balance it.&lt;/p&gt;

&lt;p&gt;All these scenarios required the tagging team to revisit the data multiple times and also change the tagging strategy by including more tags that were considered at a certain limit. It also required them to pay more attention to small details that may have been missed in a previous iteration.&lt;/p&gt;

&lt;h4 id=&quot;data-splitting&quot;&gt;Data Splitting&lt;/h4&gt;

&lt;p&gt;To better understand the strategy chosen for splitting the data, we also need to understand the source of the data. The images come from different devices that are used in different geographical locations (different countries) and are from a continuous trip recording. The annotation team used an internal tool to visualise the trips image by image and mark the faces and licence plates present in them. We would then have access to all those images and their respective metadata.&lt;/p&gt;

&lt;p&gt;The chosen ratios for splitting are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train 70%&lt;/li&gt;
  &lt;li&gt;Validation 10%&lt;/li&gt;
  &lt;li&gt;Test 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of train images&lt;/td&gt;
      &lt;td&gt;12733&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of validation images&lt;/td&gt;
      &lt;td&gt;1682&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of test images&lt;/td&gt;
      &lt;td&gt;3221&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of labelled classes in train set&lt;/td&gt;
      &lt;td&gt;60630&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of labelled classes in validation set&lt;/td&gt;
      &lt;td&gt;7658&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of of labelled classes in test set&lt;/td&gt;
      &lt;td&gt;18388&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The split is not so trivial as we have some requirements and need to complete some conditions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An image can have multiple tags from one or both classes but must belong to just one subset.&lt;/li&gt;
  &lt;li&gt;The tags should be split as close as possible to the desired ratios.&lt;/li&gt;
  &lt;li&gt;As different images can belong to the same trip in a close geographical relation, we need to force them in the same subset. By doing so, we avoid similar tags in train and test subsets, resulting in incorrect evaluations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h4&gt;

&lt;p&gt;The application of data augmentation plays a crucial role while training the machine learning model. There are mainly three ways in which data augmentation techniques can be applied:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Offline data augmentation - enriching a dataset by physically multiplying some of its images and applying modifications to them.&lt;/li&gt;
  &lt;li&gt;Online data augmentation - on the fly modifications of the image during train time with configurable probability for each modification.&lt;/li&gt;
  &lt;li&gt;Combination of both offline and online data augmentation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In our case, we are using the third option which is a combination of both.&lt;/p&gt;

&lt;p&gt;The first method that contributes to offline augmentation is a method called image view splitting. This is necessary for us due to different image types: perspective camera images, wide field of view images, 360 degree images in equirectangular format. All these formats and field of views with their respective distortions would complicate the data and make it hard for the model to generalise it and also handle different image types that could be added in the future.&lt;/p&gt;

&lt;p&gt;For this, we defined the concept of image views which are an extracted portion (view) of an image with some predefined properties. For example, the perspective projection of 75 by 75 degrees field of view patches from the original image.&lt;/p&gt;

&lt;p&gt;Here we can see a perspective camera image and the image views generated from it:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-5-original-image.png&quot; alt=&quot;Figure 5 - Original image&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 5 - Original image&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-6-image-views-generated.png&quot; alt=&quot;Figure 6 - Two image views generated&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 6 - Two image views generated&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The important thing here is that each generated view is an image on its own with the associated tags. They also have an overlapping area so we have a possibility to contain the same tag in two views but from different perspectives. This brings us to an indirect outcome of the first offline augmentation.&lt;/p&gt;

&lt;p&gt;The second method for offline augmentation is the oversampling of some of the images (views). As mentioned above, we faced the problem of an unbalanced dataset, specifically we were missing tags that occupied high regions of the image, and even though our tagging teams tried to annotate as many as they could find, these were still scarce.&lt;/p&gt;

&lt;p&gt;As our object detection model is an anchor-based detector, we did not even have enough of them to generate the anchor boxes correctly. This could be clearly seen in the accuracy of the previous trained models, as they were performing poorly on bins of big sizes.&lt;/p&gt;

&lt;p&gt;By randomly oversampling images that contained big tags, up to a minimum required number, we managed to have better anchors and increase the recall for those scenarios. As described below, the chosen object detector for blurring was YOLOv4 which offers a large variety of online augmentations. The online augmentations used are saturation, exposure, hue, flip and mosaic.&lt;/p&gt;

&lt;h3 id=&quot;model&quot;&gt;Model&lt;/h3&gt;

&lt;p&gt;As of summer of 2021, the “go to” solution for object detection in images are convolutional neural networks (CNN), being a mature solution able to fulfil the needs efficiently.&lt;/p&gt;

&lt;h4 id=&quot;architecture&quot;&gt;Architecture&lt;/h4&gt;

&lt;p&gt;Most CNN based object detectors have three main parts: Backbone, Neck and (Dense or Sparse Prediction) Heads. From the input image, the backbone extracts features which can be combined in the neck part to be used by the prediction heads to predict object bounding-boxes and their labels.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/figure-7-anatomy-of-object-detectors.png&quot; alt=&quot;Figure 7 - Anatomy of one and two-stage object detectors&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 7 - Anatomy of one and two-stage object detectors&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;
The backbone is usually a CNN classification network pretrained on some dataset, like ImageNet-1K. The neck combines features from different layers in order to produce rich representations for both large and small objects. Since the objects to be detected have varying sizes, the topmost features are too coarse to represent smaller objects, so the first CNN based object detectors were fairly weak in detecting small sized objects. The multi-scale, pyramid hierarchy is inherent to CNNs so Tsung-Yi Lin et al &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; introduced the Feature Pyramid Network which at marginal costs combines features from multiple scales and makes predictions on them. This or improved variants of this technique is used by most detectors nowadays. The head part does the predictions for bounding boxes and their labels.&lt;/p&gt;

&lt;p&gt;YOLO is part of the anchor-based one-stage object detectors family being developed originally in Darknet, an open source neural network framework written in C and CUDA. Back in 2015, it was the first end-to-end differentiable network of this kind that offered a joint learning of object bounding boxes and their labels.&lt;/p&gt;

&lt;p&gt;One reason for the big success of newer YOLO versions is that the authors carefully merged new ideas into one architecture, the overall speed of the model being always the north star.&lt;/p&gt;

&lt;p&gt;YOLOv4 introduces several changes to its v3 predecessor:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Backbone - CSPDarknet53: YOLOv3 Darknet53 backbone was modified to use Cross Stage Partial Network (CSPNet &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;) strategy, which aims to achieve richer gradient combinations by letting the gradient flow propagate through different network paths.&lt;/li&gt;
  &lt;li&gt;Multiple configurable augmentation and loss function types, so called “Bag of freebies”, which by changing the training strategy can yield higher accuracy without impacting the inference time.&lt;/li&gt;
  &lt;li&gt;Configurable necks and different activation functions, they call “Bag of specials”.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;insights&quot;&gt;Insights&lt;/h4&gt;

&lt;p&gt;For this task, we found that YOLOv4 gave a good compromise between speed and accuracy as it has doubled the speed of a more accurate two-stage detector while maintaining a very good overall precision/recall. For blurring, the main metric for model selection was the overall recall, while precision and intersection over union (IoU) of the predicted box comes second as we want to catch all personal data even if some are wrong. Having a multitude of possibilities to configure the detector architecture and train it on our own dataset we conducted several experiments with different configurations for backbones, necks, augmentations and loss functions to come up with our current solution.&lt;/p&gt;

&lt;p&gt;We faced challenges in training a good model as the dataset posed a large object/box-level scale imbalance, small objects being over-represented in the dataset. As described in &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; and &lt;sup id=&quot;fnref:4:1&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, this affects the scales of the estimated regions and the overall detection performance. In &lt;sup id=&quot;fnref:6:1&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; several solutions are proposed for this out of which the SPP &lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; blocks and PANet &lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; neck used in YOLOv4 together with heavy offline data augmentation increased the performance of the actual model in comparison to the former ones.&lt;/p&gt;

&lt;p&gt;As we have evaluated, the model still has some issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Occlusion of the object, either by the camera view, head accessories or other elements:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/occlusion.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;These cases would need extra annotations in the dataset, just like the faces or licence plates that are really close to the camera and occupy a large region of interest in the image.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As we have a limited number of annotations of close objects to the camera view, the model has incorrectly learnt this, sometimes producing false positives in these situations:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/protecting-personal-data-in-grabs-imagery/annotation.png&quot; /&gt;&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Again, one solution for this would be to include more of these scenarios in the dataset.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h2&gt;

&lt;p&gt;Grab spends a lot of effort ensuring privacy protection for its users so we are always looking for ways to further improve our related models and processes.&lt;/p&gt;

&lt;p&gt;As far as efficiency is concerned, there are multiple directions to consider for both the dataset and the model. There are two main factors that drive the costs and the quality: further development of the dataset for additional edge cases (e.g. more training data of people wearing masks) and the operational costs of the model.&lt;/p&gt;

&lt;p&gt;As the vast majority of current models require a fully labelled dataset, this puts a large work effort on the Data Entry team before creating a new model. Our dataset increased 4x for its third version, but still there is room for improvement as described in the Dataset section.&lt;/p&gt;

&lt;p&gt;As Grab extends its operations in more cities, new data is collected that has to be processed, this puts an increased focus on running detection models more efficiently.&lt;/p&gt;

&lt;p&gt;Directions to pursue to increase our efficiency could be the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As plenty of unlabelled data is available from imagery collection, a natural direction to explore is self-supervised visual representation learning techniques to derive a general vision backbone with superior transferring performance for our subsequent tasks as detection, classification.&lt;/li&gt;
  &lt;li&gt;Experiment with optimisation techniques like pruning and quantisation to get a faster model without sacrificing too much on accuracy.&lt;/li&gt;
  &lt;li&gt;Explore new architectures: YOLOv5, EfficientDet or Swin-Transformer for Object Detection.&lt;/li&gt;
  &lt;li&gt;Introduce semi-supervised learning techniques to improve our model performance on the long tail of the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Bharat Singh, Larry S. Davis. An Analysis of Scale Invariance in Object Detection - SNIP. &lt;a href=&quot;https://arxiv.org/abs/1711.08189v2&quot;&gt;arXiv:1711.08189v2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Zhenda Xie et al. Self-Supervised Learning with Swin Transformers.  &lt;a href=&quot;https://arxiv.org/abs/2105.04553v2&quot;&gt;arXiv:2105.04553v2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Kaiyu Yang et al. Study of Face Obfuscation in ImageNet: &lt;a href=&quot;https://arxiv.org/abs/2103.06191&quot;&gt;arxiv.org/abs/2103.06191&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Nitish S. Mutha &lt;a href=&quot;http://blog.nitishmutha.com/equirectangular/360degree/2017/06/12/How-to-project-Equirectangular-image-to-rectilinear-view.html&quot;&gt;How to map Equirectangular projection to Rectilinear projection&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Alexey Bochkovskiy et al.. YOLOv4: Optimal Speed and Accuracy of Object Detection. &lt;a href=&quot;https://arxiv.org/abs/2004.10934v1&quot;&gt;arXiv:2004.10934v1&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Tsung-Yi Lin et al. Feature Pyramid Networks for Object Detection. &lt;a href=&quot;https://arxiv.org/abs/1612.03144v2&quot;&gt;arXiv:1612.03144v2&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:4:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Chien-Yao Wang et al. CSPNet: A New Backbone that can Enhance Learning Capability of CNN. &lt;a href=&quot;https://arxiv.org/abs/1911.11929v1&quot;&gt;arXiv:1911.11929v1&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Kemal Oksuz et al.. Imbalance Problems in Object Detection: A Review. &lt;a href=&quot;https://arxiv.org/abs/1909.00169v3&quot;&gt;arXiv:1909.00169v3&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:6:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Kaiming He et al. Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. &lt;a href=&quot;https://arxiv.org/abs/1406.4729v4&quot;&gt;arXiv:1406.4729v4&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Shu Liu et al. Path Aggregation Network for Instance Segmentation. &lt;a href=&quot;https://arxiv.org/abs/1803.01534v4&quot;&gt;arXiv:1803.01534v4&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 26 Jul 2021 00:40:00 +0000</pubDate>
        <link>https://engineering.grab.com/protecting-personal-data-in-grabs-imagery</link>
        <guid isPermaLink="true">https://engineering.grab.com/protecting-personal-data-in-grabs-imagery</guid>
        
        <category>Engineering</category>
        
        <category>Machine Learning</category>
        
        <category>Data</category>
        
        <category>Datasets</category>
        
        <category>Data Science</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Processing ETL tasks with Ratchet</title>
        <description>&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;At Grab, the Lending team is focused towards building products that help finance various segments of users, such as Passengers, Drivers, or Merchants, based on their needs. The team builds products that enable users to avail funds in a seamless and hassle-free way. In order to achieve this, multiple lending microservices continuously interact with each other. Each microservice handles different responsibilities, such as providing offers, storing user information, disbursing availed amounts to a user’s account, and many more.&lt;/p&gt;

&lt;p&gt;In this tech blog, we will discuss what &lt;em&gt;Data&lt;/em&gt; and &lt;em&gt;Extract, Transform and Load (ETL)&lt;/em&gt; pipelines are and how they are used for processing multiple tasks in the Lending Team at Grab. We will also discuss &lt;em&gt;&lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Ratchet&lt;/a&gt;&lt;/em&gt;, which is a Go library, that helps us in building data pipelines and handling ETL tasks. Let’s start by covering the basis of Data and ETL pipelines.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-data-pipeline&quot;&gt;What is a Data Pipeline?&lt;/h2&gt;

&lt;p&gt;A Data pipeline is used to describe a system or a process that moves data from one platform to another. In between platforms, data passes through multiple steps based on defined requirements, where it may be subjected to some kind of modification. All the steps in a Data pipeline are automated, and the output from one step acts as an input for the next step.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image1.png&quot; alt=&quot;Data Pipeline&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data Pipeline (Source: &lt;a href=&quot;https://hazelcast.com/glossary/data-pipeline/&quot;&gt;Hazelcast&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;what-is-an-etl-pipeline&quot;&gt;What is an ETL Pipeline?&lt;/h2&gt;

&lt;p&gt;An ETL pipeline is a type of Data pipeline that consists of 3 major steps, namely extraction of data from a source, transformation of that data into the desired format, and finally loading the transformed data to the destination. The destination is also known as the &lt;em&gt;sink&lt;/em&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image3.jpg&quot; alt=&quot;Extract-Transform-Load&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Extract-Transform-Load (Source: &lt;a href=&quot;https://www.tatvasoft.com/blog/etl-process-extract-transform-load/&quot;&gt;TatvaSoft&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The combination of steps in an ETL pipeline provides functions to assure that the business requirements of the application are achieved.&lt;/p&gt;

&lt;p&gt;Let’s briefly look at each of the steps involved in the ETL pipeline.&lt;/p&gt;

&lt;h3 id=&quot;data-extraction&quot;&gt;Data Extraction&lt;/h3&gt;

&lt;p&gt;Data extraction is used to fetch data from one or multiple sources with ease. The source of data can vary based on the requirement. Some of the commonly used data sources are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Database&lt;/li&gt;
  &lt;li&gt;Web-based storage (S3, Google cloud, etc)&lt;/li&gt;
  &lt;li&gt;Files&lt;/li&gt;
  &lt;li&gt;User Feeds, CRM, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data format can also vary from one use case to another. Some of the most commonly used data formats are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SQL&lt;/li&gt;
  &lt;li&gt;CSV&lt;/li&gt;
  &lt;li&gt;JSON&lt;/li&gt;
  &lt;li&gt;XML&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once data is extracted in the desired format, it is ready to be fed to the transformation step.&lt;/p&gt;

&lt;h3 id=&quot;data-transformation&quot;&gt;Data Transformation&lt;/h3&gt;

&lt;p&gt;Data transformation involves applying a set of rules and techniques to convert the extracted data into a more meaningful and structured format for use. The extracted data may not always be ready to use. In order to transform the data, one of the following techniques may be used:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Filtering out unnecessary data.&lt;/li&gt;
  &lt;li&gt;Preprocessing and cleaning of data.&lt;/li&gt;
  &lt;li&gt;Performing validations on data.&lt;/li&gt;
  &lt;li&gt;Deriving a new set of data from the existing one.&lt;/li&gt;
  &lt;li&gt;Aggregating data from multiple sources into a single uniformly structured format.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;data-loading&quot;&gt;Data Loading&lt;/h3&gt;

&lt;p&gt;The final step of an ETL pipeline involves moving the transformed data to a sink where it can be accessed for its use. Based on requirements, a sink can be one of the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Database&lt;/li&gt;
  &lt;li&gt;File&lt;/li&gt;
  &lt;li&gt;Web-based storage (S3, Google cloud, etc)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An ETL pipeline may or may not have a loadstep based on its requirements. When the transformed data needs to be stored for further use, the loadstep is used to move the transformed data to the storage of choice. However, in some cases, the transformed data may not be needed for any further use and thus, the loadstep can be skipped.&lt;/p&gt;

&lt;p&gt;Now that you understand the basics, let’s go over how we, in the Grab Lending team, use an ETL pipeline.&lt;/p&gt;

&lt;h2 id=&quot;why-use-ratchet&quot;&gt;Why Use Ratchet?&lt;/h2&gt;

&lt;p&gt;At Grab, we use Golang for most of our backend services. Due to Golang’s simplicity, execution speed, and concurrency support, it is a great choice for building data pipeline systems to perform custom ETL tasks.&lt;/p&gt;

&lt;p&gt;Given that &lt;em&gt;&lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Ratchet&lt;/a&gt;&lt;/em&gt; is also written in Go, it allows us to easily build custom data pipelines.&lt;/p&gt;

&lt;p&gt;Go channels are connecting each stage of processing, so the syntax for sending data is intuitive for anyone familiar with Go. All data being sent and received is in JSON, providing a nice balance of flexibility and consistency.&lt;/p&gt;

&lt;h2 id=&quot;utilising-ratchet-for-etl-tasks&quot;&gt;Utilising Ratchet for ETL Tasks&lt;/h2&gt;

&lt;p&gt;We use Ratchet for multiple ETL tasks like batch processing, restructuring and rescheduling of loans, creating user profiles, and so on. One of the backend services, named &lt;strong&gt;Azkaban&lt;/strong&gt;, is responsible for handling various ETL tasks.&lt;/p&gt;

&lt;p&gt;Ratchet uses &lt;em&gt;Data Processors&lt;/em&gt; for building a pipeline consisting of multiple stages. Data Processors each run in their own &lt;code class=&quot;highlighter-rouge&quot;&gt;goroutine&lt;/code&gt; so all of the data is processed concurrently. Data Processors are organised into stages, and those stages are run within a pipeline. For building an ETL pipeline, each of the three steps (Extract, Transform and Load) use a Data Processor for implementation. Ratchet provides a set of built-in, useful Data Processors, while also providing an interface to implement your own. Usually, the transform stage uses a Custom Data Processor.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image4.png&quot; alt=&quot;Data Processors in Ratchet&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Data Processors in Ratchet (Source: &lt;a href=&quot;https://github.com/dailyburn/ratchet&quot;&gt;Github&lt;/a&gt;)&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Let’s take a look at one of these tasks to understand how we utilise Ratchet for processing an ETL task.&lt;/p&gt;

&lt;h2 id=&quot;whitelisting-merchants-through-etl-pipelines&quot;&gt;Whitelisting Merchants Through ETL Pipelines&lt;/h2&gt;

&lt;p&gt;Whitelisting essentially means making the product available to the user by mapping an offer to the user ID. If a merchant in Thailand receives an option to opt for Cash Loan, it is done by whitelisting that merchant. In order to whitelist our merchants, our Operations team uses an internal portal to upload a CSV file with the user IDs of the merchants and other required information. This CSV file is generated by our internal Data and Risk team and handed over to the Operations team. Once the CSV file is uploaded, the user IDs present in the file are whitelisted within minutes. However, a lot of work goes in the background to make this possible.&lt;/p&gt;

&lt;h3 id=&quot;data-extraction-1&quot;&gt;Data Extraction&lt;/h3&gt;

&lt;p&gt;Once the Operations team uploads the CSV containing a list of merchant users to be whitelisted, the file is stored in S3 and an entry is created on the Azkaban service with the document ID of the uploaded file.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image5.png&quot; alt=&quot;File upload by Operations team&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;File upload by Operations team&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The data extraction step makes use of a Custom CSV Data Processor that uses the document ID to first create a &lt;code class=&quot;highlighter-rouge&quot;&gt;PreSignedUrl&lt;/code&gt; and then uses it to fetch the data from S3. The data extracted is in bytes and we use commas as the delimiter to format the CSV data.&lt;/p&gt;

&lt;h3 id=&quot;data-transformation-1&quot;&gt;Data Transformation&lt;/h3&gt;

&lt;p&gt;In order to transform the data, we define a Custom Data Processor that we call a &lt;em&gt;Transformer&lt;/em&gt; for each ETL pipeline. Transformers are responsible for applying all necessary transformations to the data before it is ready for loading. The transformations applied in the merchant whitelisting transformers are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convert data from bytes to struct.&lt;/li&gt;
  &lt;li&gt;Check for presence of all mandatory fields in the received data.&lt;/li&gt;
  &lt;li&gt;Perform validation on the data received.&lt;/li&gt;
  &lt;li&gt;Make API calls to external microservices for whitelisting the merchant.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As mentioned earlier, the CSV file is uploaded manually by the Operations team. Since this is a manual process, it is prone to human errors. Validation of data in the data transformation step helps avoid these errors and not propagate them further up the pipeline. Since CSV data consists of multiple rows, each row passes through all the steps mentioned above.&lt;/p&gt;

&lt;h3 id=&quot;data-loading-1&quot;&gt;Data Loading&lt;/h3&gt;

&lt;p&gt;Whenever the merchants are whitelisted, we don’t need to store the transformed data. As a result, we don’t have a loadstep for this ETL task, so we just use an Empty Data Processor. However, this is just one of many use cases that we have. In cases where the transformed data needs to be stored for further use, the loadstep will have a Custom Data Processor, which will be responsible for storing the data.&lt;/p&gt;

&lt;h2 id=&quot;connecting-all-stages&quot;&gt;Connecting All Stages&lt;/h2&gt;

&lt;p&gt;After defining our Data Processors for each of the steps in the ETL pipeline, the final piece is to connect all the stages together. As stated earlier, the ETL tasks have different ETL pipelines and each ETL pipeline consists of 3 stages defined by their Data Processors.&lt;/p&gt;

&lt;p&gt;In order to connect these 3 stages, we define a &lt;strong&gt;Job Processor&lt;/strong&gt; for each ETL pipeline. A Job Processor represents the entire ETL pipeline and encompasses Data Processors for each of the 3 stages. Each Job Processor implements the following methods:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SetSource&lt;/code&gt;: Assigns the Data Processor for the Extraction stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformer&lt;/code&gt;: Assigns the Data Processor for the Transformation stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SetDestination&lt;/code&gt;: Assigns the Data Processor for the Load stage.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Execute&lt;/code&gt;: Runs the ETL pipeline.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/processing-etl-tasks-with-ratchet/image2.png&quot; alt=&quot;Job processors containing Data Processor for each stage in ETL&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Job processors containing Data Processor for each stage in ETL&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;When the &lt;strong&gt;Azkaban&lt;/strong&gt; service is initialised, we run the &lt;code class=&quot;highlighter-rouge&quot;&gt;SetSource()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformer()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SetDestination()&lt;/code&gt; methods for each of the Job Processors defined. When an ETL task is triggered, the &lt;code class=&quot;highlighter-rouge&quot;&gt;Execute()&lt;/code&gt; method of the corresponding Job Processor is run. This triggers the ETL pipeline and gradually runs the 3 stages of ETL pipeline. For each stage, the Data Processor assigned during initialisation is executed.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;ETL pipelines help us in streamlining various tasks in our team. As showcased through the example in the above section, an ETL pipeline breaks a task into multiple stages and divides the responsibilities across these stages.&lt;/p&gt;

&lt;p&gt;In cases where a task fails in the middle of the process, ETL pipelines help us determine the cause of the failure quickly and accurately. With ETL pipelines, we have reduced the manual effort required for validating data at each step and avoiding propagation of errors towards the end of the pipeline.&lt;/p&gt;

&lt;p&gt;Through the use of ETL pipelines and schedulers, we at Lending have been able to automate the entire pipeline for many tasks to run at scheduled intervals without any manual effort involved at all. This has helped us tremendously in reducing human errors, increasing the throughput of the system and making the backend flow more reliable. As we continue to automate more and more of our tasks that have tightly defined stages, we foresee a growth in our ETL pipelines usage.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.alooma.com/blog/what-is-a-data-pipeline&quot;&gt;https://www.alooma.com/blog/what-is-a-data-pipeline&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://rkulla.blogspot.com/2016/01/data-pipeline-and-etl-tasks-in-go-using.html&quot;&gt;http://rkulla.blogspot.com/2016/01/data-pipeline-and-etl-tasks-in-go-using&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/swlh/etl-pipeline-and-data-pipeline-comparison-bf89fa240ce9&quot;&gt;https://medium.com/swlh/etl-pipeline-and-data-pipeline-comparison-bf89fa240ce9&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Jul 2021 03:21:10 +0000</pubDate>
        <link>https://engineering.grab.com/processing-etl-tasks-with-ratchet</link>
        <guid isPermaLink="true">https://engineering.grab.com/processing-etl-tasks-with-ratchet</guid>
        
        <category>Pipelines</category>
        
        <category>Data</category>
        
        <category>ETL</category>
        
        <category>Engineering</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>App Modularisation at Scale</title>
        <description>&lt;p&gt;Grab a coffee ☕️, sit back and enjoy reading. 😃&lt;/p&gt;

&lt;p&gt;Wanna know how we improved our app’s build time performance and developer experience at Grab? Continue reading…&lt;/p&gt;

&lt;h2 id=&quot;where-it-all-began&quot;&gt;Where it all began&lt;/h2&gt;

&lt;p&gt;Imagine you are working on an app that grows continuously as more and more features are added to it, it becomes challenging to manage the code at some point. Code conflicts increase due to coupling, development slows down, releases take longer to ship, collaboration becomes difficult, and so on.&lt;/p&gt;

&lt;p&gt;Grab superapp is one such app that offers many services like booking taxis, ordering food, payments using an e-wallet, transferring money to friends/families, paying at merchants, and many more, across Southeast Asia.&lt;/p&gt;

&lt;p&gt;Grab app followed a monolithic architecture initially where the entire code was held in a single module containing all the UI and business logic for almost all of its features. But as the app grew, new developers were hired, and more features were built, it became difficult to work on the codebase. We had to think of better ways to maintain the codebase, and that’s when the team decided to modularise the app to solve the issues faced.&lt;/p&gt;

&lt;h2 id=&quot;what-is-modularisation&quot;&gt;What is Modularisation?&lt;/h2&gt;

&lt;p&gt;Breaking the monolithic app module into smaller, independent, and interchangeable modules to segregate functionality so that every module is responsible for executing a specific functionality and will contain everything necessary to execute that functionality.&lt;/p&gt;

&lt;p&gt;Modularising the Grab app was not an easy task as it brought many challenges along with it because of its complicated structure due to the high amount of code coupling.&lt;/p&gt;

&lt;h2 id=&quot;approach-and-design&quot;&gt;Approach and Design&lt;/h2&gt;

&lt;p&gt;We divided the task into the following sub-tasks to ensure that only one out of many functionalities in the app was impacted at a time.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Setting up the infrastructure by creating &lt;strong&gt;Base/Core modules&lt;/strong&gt; for Networking, Analytics, Experimentation, Storage, Config, and so on.&lt;/li&gt;
  &lt;li&gt;Building &lt;strong&gt;Shared Library modules&lt;/strong&gt; for Styling, Common-UI, Utils, etc.&lt;/li&gt;
  &lt;li&gt;Incrementally building &lt;strong&gt;Feature modules&lt;/strong&gt; for user-facing features like Payments Home, Wallet Top Up, Peer-to-Merchant (P2M) Payments, GrabCard and many others.&lt;/li&gt;
  &lt;li&gt;Creating &lt;strong&gt;Kit modules&lt;/strong&gt; to enable inter-module communication. This step helped us in building the feature modules in parallel.&lt;/li&gt;
  &lt;li&gt;Finally, the &lt;strong&gt;App module&lt;/strong&gt; was used as a hub to connect all the other modules together using dependency injection (Dagger).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/app-modularisation-at-scale/image1.png&quot; alt=&quot;Modularised app structure&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Modularised app structure&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In the above diagram, &lt;em&gt;payments-home&lt;/em&gt;, &lt;em&gt;wallet top-up&lt;/em&gt;, and &lt;em&gt;grabcard&lt;/em&gt; are different features provided by the Grab app. &lt;em&gt;top-up-kit&lt;/em&gt; and &lt;em&gt;grabcard-kit&lt;/em&gt; are bridges that expose functionalities from &lt;em&gt;topup&lt;/em&gt; and &lt;em&gt;grabcard&lt;/em&gt; modules to the payments-home module, respectively.&lt;/p&gt;

&lt;p&gt;In the process of modularising the Grab app, we ensured that a feature module did not directly depend on other feature modules so that they could be built in parallel using the available CPU cores of the machine, hence reducing the overall build time of the app.&lt;/p&gt;

&lt;p&gt;With the &lt;em&gt;Kit&lt;/em&gt; module approach, we separated our code into independent layers by depending only on abstractions instead of concrete implementation.&lt;/p&gt;

&lt;h2 id=&quot;modularisation-benefits&quot;&gt;Modularisation Benefits&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Faster build times and hence faster CI&lt;/strong&gt;: Gradle build system compiles only the changed modules and uses the binaries of all the non-affected modules from its cache. So the compilation becomes faster as independent modules are run in parallel on different threads.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fine dependency graph&lt;/strong&gt;: Dependencies of a module are well defined.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reusability across other apps&lt;/strong&gt;: Modules can be used across different apps by converting them into an AAR/SDK.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scale and maintainability&lt;/strong&gt;: Teams can work independently on the modules owned by them without blocking each other.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Well-defined code ownership&lt;/strong&gt;: Easier to define ownership per module in the codebase.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;limitations&quot;&gt;Limitations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Requires more effort and time to modularise an app.&lt;/li&gt;
  &lt;li&gt;Separate configuration files to be maintained for each module.&lt;/li&gt;
  &lt;li&gt;Gradle sync time starts to grow.&lt;/li&gt;
  &lt;li&gt;IDE becomes very slow and its memory usage goes up a lot.&lt;/li&gt;
  &lt;li&gt;Parallel execution of the module depends on the machine’s capabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;where-we-are-now&quot;&gt;Where we are now&lt;/h2&gt;

&lt;p&gt;There are more than 1,000 modules in the Grab app and are still counting.&lt;/p&gt;

&lt;p&gt;At Grab, we have many sub-teams which take care of different features available in the app. Grab Financial Group (GFG) is one such sub-team that handles everything related to payments in the app. For example: P2P &amp;amp; P2M money transfers, e-Wallet activation, KYC, and so on.&lt;/p&gt;

&lt;p&gt;We started modularising payments further in July 2020 as it was already bombarded with too many features and it was difficult for the team to work on the single payments module. The result of payments modularisation is shown in the following chart.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/app-modularisation-at-scale/image2.png&quot; alt=&quot;Build time graph of payments module&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Build time graph of payments module&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;As of today, we have about 200+ modules in GFG and more than 95% of the modules take less than 15s to build.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Modularisation has helped us a lot in reducing the overall build time of the app and also, in improving the developer experience by breaking dependencies and allowing us to define code ownership. Having said that, modularisation is not an easy or a small task, especially for large projects with legacy code. However, with careful planning and the right design, modularisation can help in forming a well-structured and maintainable project.&lt;/p&gt;

&lt;p&gt;Hope you enjoyed reading. Don’t forget to 👏.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://proandroiddev.com/build-a-modular-android-app-architecture-25342d99de82&quot;&gt;https://proandroiddev.com/build-a-modular-android-app-architecture-25342d99de82&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/google-developer-experts/modularizing-android-applications-9e2d18f244a0&quot;&gt;https://medium.com/google-developer-experts/modularizing-android-applications-9e2d18f244a0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@mydogtom/modularization-part-1-application-structure-overview-9e465909a9bc&quot;&gt;https://medium.com/@mydogtom/modularization-part-1-application-structure-overview-9e465909a9bc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jul 2021 00:04:40 +0000</pubDate>
        <link>https://engineering.grab.com/app-modularisation-at-scale</link>
        <guid isPermaLink="true">https://engineering.grab.com/app-modularisation-at-scale</guid>
        
        <category>App</category>
        
        <category>Build Time</category>
        
        <category>Engineering</category>
        
        <category>Monorepo</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Reshaping Chat Support for Our Users</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The Grab support team plays a key role in ensuring our users receive support when things don’t go as expected or whenever there are questions on our products and services.&lt;/p&gt;

&lt;p&gt;In the past, when users required real-time support, their only option was to call our hotline and wait in the queue to talk to an agent. But voice support has its downsides: sometimes it is complex to describe an issue in the app, and it requires the user’s full attention on the call.&lt;/p&gt;

&lt;p&gt;With chat messaging apps growing massively in the last years, chat has become the expected support channel users are familiar with. It offers real-time support with the option of multitasking and easily explaining the issue by sharing pictures and documents. Compared to voice support, chat provides access to the conversation for future reference.&lt;/p&gt;

&lt;p&gt;With chat growth, building a chat system tailored to our support needs and integrated with internal data, seemed to be the next natural move.&lt;/p&gt;

&lt;p&gt;In our previous articles, we covered the tech challenges of &lt;a href=&quot;https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web&quot;&gt;building the chat platform for the web&lt;/a&gt;, our &lt;a href=&quot;https://engineering.grab.com/customer-support-workforce-routing&quot;&gt;workforce routing system&lt;/a&gt; and &lt;a href=&quot;https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml&quot;&gt;improving agent efficiency with machine learning&lt;/a&gt;. In this article, we will explain our approach and key learnings when building our in-house chat for support from a Product and Design angle.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image6.gif&quot; alt=&quot;A glimpse at agent and user experience&quot; style=&quot;width:80%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A glimpse at agent and user experience&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;why-reinvent-the-wheel&quot;&gt;Why Reinvent the Wheel&lt;/h2&gt;

&lt;p&gt;We wanted to deliver a product that would fully delight our users. That’s why we decided to build an in-house chat tool that can:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Prevent chat disconnections and ensure a consistent chat experience&lt;/strong&gt;: Building a native chat experience allowed us to ensure a stable chat session, even when users leave the app. Besides, leveraging on the existing Grab chat infrastructure helped us achieve this fast and ensure the chat experience is consistent throughout the app. You can read more about the chat architecture &lt;a href=&quot;https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improve productivity and provide faster support turnarounds&lt;/strong&gt;: By building the agent experience in the CRM tool, we could reduce the number of tools the support team uses and build features tailored to our internal processes. This helped to provide faster help for our users.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Allow integration with internal systems and services&lt;/strong&gt;: Chat can be easily integrated with in-house AI models or chatbot, which helps us personalise the user experience and improve agent productivity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Route our users to the best support specialist available&lt;/strong&gt;: Our newly built routing system accounts for all the use cases we were wishing for such as prioritising certain requests, better distribution of the chat load during peak hours, making changes at scale and ensuring each chat is routed to the best support specialist available.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;fail-fast-with-an-mvp&quot;&gt;Fail Fast with an MVP&lt;/h2&gt;

&lt;p&gt;Before building a full-fledged solution, we needed to prove the concept, an MVP that would have the key features and yet, would not take too much effort if it fails. To kick start our experiment, we established the success criteria for our MVP; how do we measure its success or failure?&lt;/p&gt;

&lt;h3 id=&quot;defining-what-success-looks-like&quot;&gt;Defining What Success Looks Like&lt;/h3&gt;

&lt;p&gt;Any experiment requires a hypothesis - something you’re trying to prove or disprove and it should relate to your final product. To tailor the final product around the success criteria, we need to understand how success is measured in our situation. In our case, disconnections during chat support was one of the key challenges faced so our hypothesis was:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/reshaping-chat-support/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;starting-with-design-sprint&quot;&gt;Starting with Design Sprint&lt;/h3&gt;

&lt;p&gt;Our design sprint aimed to &lt;strong&gt;solutionise a series of problem statements, and generate a prototype to validate our hypothesis&lt;/strong&gt;. To spark ideation, we run sketching exercises such as &lt;a href=&quot;https://designsprintkit.withgoogle.com/methodology/phase3-sketch/crazy-8s&quot;&gt;Crazy 8&lt;/a&gt;, &lt;a href=&quot;https://designsprintkit.withgoogle.com/methodology/phase3-sketch/solution-sketch&quot;&gt;Solution sketch&lt;/a&gt; and end off with sharing and voting.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image12.jpg&quot; style=&quot;width:60%&quot; /&gt;
    &lt;img src=&quot;/img/reshaping-chat-support/image1.jpg&quot; style=&quot;width:60%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Some of the prototypes built during the Design sprint&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;defining-mvp-scope-to-run-the-experiment&quot;&gt;Defining MVP Scope to Run the Experiment&lt;/h3&gt;

&lt;p&gt;To test our hypothesis quickly, we had to cut the scope by focusing on the basic functionality of allowing chat message exchanges with one agent.&lt;/p&gt;

&lt;p&gt;Here is the main flow and a sneak peek of the design:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image13.jpg&quot; alt=&quot;Accepting chats&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Accepting chats&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image8.gif&quot; alt=&quot;Handling concurrent chats&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Handling concurrent chats&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-we-learnt-from-the-experiment&quot;&gt;What We Learnt from the Experiment&lt;/h3&gt;

&lt;p&gt;During the experiment, we had to constantly put ourselves in our users’ shoes as ‘we are not our users’. We decided to shadow our chat support agents and get a sense of the potential issues our users actually face. By doing so, we learnt a lot about how the tool was used and spotted several problems to address in the next iterations.&lt;/p&gt;

&lt;p&gt;In the end, &lt;strong&gt;the experiment confirmed our hypothesis that having a native in-app chat was more stable than the previous chat in use&lt;/strong&gt;, resulting in a better user experience overall.&lt;/p&gt;

&lt;h2 id=&quot;starting-with-the-end-in-mind&quot;&gt;Starting with the End in Mind&lt;/h2&gt;

&lt;p&gt;Once the experiment was successful, we focused on scaling. We defined the most critical jobs to be done for our users so that we could scale the product further. When designing solutions to tackle each of them, we ensured that the product would be flexible enough to address future pain points. Would this work for more channels, more users, more products, more countries?&lt;/p&gt;

&lt;p&gt;Before scaling, the problems to solve were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring the performance of the system in real-time&lt;/strong&gt;, so that swift operational changes can be made to ensure users receive fast support;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Routing each chat to the best agent available&lt;/strong&gt;, considering skills, occupancy, as well as issue prioritisation. You can read more about the our routing system design &lt;a href=&quot;https://engineering.grab.com/customer-support-workforce-routing&quot;&gt;here&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easily communicate with users and show empathy&lt;/strong&gt;, for which we built file-sharing capabilities for both users and agents, as well as allowing emojis, which create a more personalised experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scaling-efficiently&quot;&gt;Scaling Efficiently&lt;/h2&gt;

&lt;p&gt;We broke down the chat support journey to determine what areas could be improved.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/reshaping-chat-support/image10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reducing-waiting-time&quot;&gt;Reducing Waiting Time&lt;/h3&gt;

&lt;p&gt;When analysing the current wait time, we realised that when there was a surge in support requests, the average waiting time increased drastically. In these cases, most users would be unresponsive by the time an agent finally attends to them.&lt;/p&gt;

&lt;p&gt;To solve this problem, the team worked on a dynamic queue limit concept based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Little%2527s_law&quot;&gt;Little’s law&lt;/a&gt;. The idea is that considering the number of incoming chats and the agents’ capacity, we can forecast the number of users we can handle in a reasonable time, and prevent the remaining from initiating a chat. When this happens, we ensure there’s a backup channel for support so that no user is left unattended.&lt;/p&gt;

&lt;p&gt;This allowed us to &lt;strong&gt;reduce chat waiting time by ~30% and reduce unresponsive users by ~7%&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reducing-time-to-reply&quot;&gt;Reducing Time to Reply&lt;/h3&gt;

&lt;p&gt;A big part of the chat time is spent typing the message to send to the user. Although the previous tool had templated messages, we observed that 85% of them were free-typed. This is because agents felt the templates were impersonal and wanted to add their personal style to the messages.&lt;/p&gt;

&lt;p&gt;With this information in mind, we knew we could help by providing autocomplete suggestions  while the agents are typing. We built a machine learning based feature that considers several factors such as user type, the entry point to support, and the last messages exchanged, to suggest how the agent should complete the sentence. When this feature was first launched, we &lt;strong&gt;reduced the average chat time by 12%&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;Read &lt;a href=&quot;https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml&quot;&gt;this&lt;/a&gt; to find out more about how we built this machine learning feature, from defining the problem space to its implementation.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image11.gif&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;reducing-the-overall-chat-time&quot;&gt;Reducing the Overall Chat Time&lt;/h3&gt;

&lt;p&gt;Looking at the average chat time, we realised that there was still room for improvement. How can we help our agents to manage their time better so that we can reduce the waiting time for users in the queue?&lt;/p&gt;

&lt;p&gt;We needed to provide visibility of chat durations so that our agents could manage their time better. So, we added a timer at the top of each chat window to indicate how long the chat was taking.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
   &lt;img src=&quot;/img/reshaping-chat-support/image15.png&quot; alt=&quot;Timer in the minimised chat&quot; style=&quot;width:80%&quot; /&gt;
   &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Timer in the minimised chat&lt;/i&gt;&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;We also added nudges to remind agents that they had other users to attend to while they were in the chat.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/reshaping-chat-support/image2.png&quot; alt=&quot;Timer in the maximised chat&quot; style=&quot;width:80%&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Timer in the maximised chat&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;By providing visibility via prompts and colour-coded indicators to prevent exceeding the expected chat duration, we &lt;strong&gt;reduced the average chat time by 22%&lt;/strong&gt;!&lt;/p&gt;

&lt;h2 id=&quot;what-we-learnt-from-this-project&quot;&gt;What We Learnt from this Project&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Start with the end in mind.&lt;/strong&gt; When you embark on a big project like this, have a clear vision of how the end state looks like and plan each step backwards. How does success look like and how are we going to measure it? How do we get there?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data is king.&lt;/strong&gt; Data helped us spot issues in real-time and guided us through all the iterations following the MVP. It helped us prioritise the most impactful problems and take the right design decisions. Instrumentation must be part of your MVP scope!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remote user testing is better than no user testing at all.&lt;/strong&gt; Ideally, you want to do user testing in the exact environment your users will be using the tool but a pandemic might make things a bit more complex. Don’t let this stop you! The qualitative feedback we received from real users, even with a prototype on a video call, helped us optimise the tool for their needs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Address the root cause, not the symptoms.&lt;/strong&gt; Whenever you are tasked with solving a big problem, break it down into its components by asking “Why?” until you find the root cause. In the first phases, we realised the tool had a longer chat time compared to 3rd party softwares. By iteratively splitting the problem into smaller ones, we were able to address the root causes instead of the symptoms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Shadow your users whenever you can.&lt;/strong&gt; By looking at the users in action, we learned a ton about their creative ways to go around the tool’s limitations. This allowed us to iterate further on the design and help them be more efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Of course, this would not have been possible without the incredible work of several teams: CSE, CE, Comms platform, Driver and Merchant teams.
&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Jul 2021 00:18:20 +0000</pubDate>
        <link>https://engineering.grab.com/reshaping-chat-support</link>
        <guid isPermaLink="true">https://engineering.grab.com/reshaping-chat-support</guid>
        
        <category>Product</category>
        
        <category>Design</category>
        
        <category>Chat Support</category>
        
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>Debugging High Latency Due to Context Leaks</title>
        <description>&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Market-Store is an in-house developed general purpose feature store that is used to serve real-time computed machine learning (ML) features. Market-Store has a stringent SLA around latency, throughput, and availability as it empowers ML models, which are used in Dynamic Pricing and Consumer Experience.&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;p&gt;As Grab continues to grow, introducing new ML models and handling increased traffic, Market-Store started to experience high latency. Market-Store’s SLA states that 99% of transactions should be within 200ms, but our latency increased to 2 seconds. This affected the availability and accuracy of our models that rely on Market-Store for real-time features.&lt;/p&gt;

&lt;h3 id=&quot;latency-issue&quot;&gt;Latency Issue&lt;/h3&gt;

&lt;p&gt;We used different metrics and logs to debug the latency issue but could not find any abnormalities that directly correlated to the API’s performance. We discovered that the problem went away temporarily when we restarted the service. But during the next peak period, the service began to struggle once again and the problem became more prominent as Market-Store’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Queries_per_second&quot;&gt;query per second (QPS)&lt;/a&gt; increased.&lt;/p&gt;

&lt;p&gt;The following graph shows an increase in the memory used with time over 12 hours. Even as the system load receded, memory usage continued to increase.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/market-store/image2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The continuous increase in memory consumption indicated the possibility of a memory leak, which occurs when memory is allocated but not returned after its use is over. This results in consistently increasing consumed memory until the service runs out of memory and crashes.&lt;/p&gt;

&lt;p&gt;Although we could restart the service and resolve the issue temporarily, the increasing memory use suggested a deeper underlying root cause. This meant that we needed to conduct further investigation with tools that could provide deeper insights into the memory allocations.&lt;/p&gt;

&lt;h2 id=&quot;debugging-using-go-tools&quot;&gt;Debugging Using Go Tools&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://golang.org/pkg/net/http/pprof/&quot;&gt;PPROF&lt;/a&gt; is a profiling tool by Golang that helps to visualise and analyse profiles from Go programmes. A profile is a collection of stack traces showing the call sequences in your programme that eventually led to instances of a particular event i.e. allocation. It also provides details such as Heap and CPU information, which could provide insights into the bottlenecks of the Go programme.&lt;/p&gt;

&lt;p&gt;By default, PPROF is enabled on all Grab Go services, making it the ideal tool to use in our scenario. To understand how memory is allocated, we used PPROF to generate Market-Store’s Heap profile, which can be used to understand how inuse memory was allocated for the programme.&lt;/p&gt;

&lt;p&gt;You can collect the Heap profile by running this command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;go tool pprof 'http://localhost:6060/debug/pprof/heap'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The command then generates the Heap profile information as shown in the diagram below:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;../img/market-store/image1.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;From this diagram, we noticed that a lot of memory was allocated and held by the child context created from Async Library even after the tasks were completed.&lt;/p&gt;

&lt;p&gt;In Market-Store, we used the &lt;a href=&quot;https://github.com/grab/async&quot;&gt;Async Library&lt;/a&gt;, a Grab open-source library, which typically used to run concurrent tasks. Any contexts created by the Async Library should be cleaned up after the background tasks are completed. This way, memory would be returned to the service.&lt;/p&gt;

&lt;p&gt;However, as shown in the diagram, memory was not being returned, resulting in a memory leak, which explains the increasing memory usage even as Market-Store’s system load decreased.&lt;/p&gt;

&lt;h3 id=&quot;uncovering-the-real-issue&quot;&gt;Uncovering the Real Issue&lt;/h3&gt;

&lt;p&gt;So we knew that Market-Store’s latency was affected, but we didn’t know why. From the first graph, we saw that memory usage continued to grow even as Market-Store’s system load decreased. Then, PPROF showed us that the memory held by contexts was not cleaned up, resulting in a memory leak.&lt;/p&gt;

&lt;p&gt;Through our investigations, we drew a correlation between the increase in memory usage and a degradation in the server’s API latency. In other words, the memory leak resulted in a high memory consumption and eventually, caused the latency issue.&lt;/p&gt;

&lt;p&gt;However, there was no change in our service that would have impacted how contexts are created and cleaned up. So what caused the memory leak?&lt;/p&gt;

&lt;h2 id=&quot;debugging-the-memory-leak&quot;&gt;Debugging the Memory Leak&lt;/h2&gt;

&lt;p&gt;We needed to look into the Async Library and how it worked. For Market-Store, we updated the cache asynchronously for the write-around caching mechanism. We use the Async Library for running the update tasks in the background.&lt;/p&gt;

&lt;p&gt;The following code snippet explains how the Async Library works:&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;async&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Consume&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Background&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runtime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NumCPU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// Consume runs the tasks with a specific max concurrency&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Consume&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;chan&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

   &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Invoke&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;make&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;chan&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrentTasks&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;make&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

       &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code ...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ContinueWith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

       &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Invoke&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NewTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cancel&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WithCancel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;go&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Note: Code that is not relevant to this article was replaced with &lt;code class=&quot;highlighter-rouge&quot;&gt;code&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As seen in the code snippet above, the Async Library initialises the &lt;code class=&quot;highlighter-rouge&quot;&gt;Consume&lt;/code&gt; method with a background context, which is then passed to all its runners. Background contexts are empty and do not track or have links to child contexts that are created from them.&lt;/p&gt;

&lt;p&gt;In Market-Store, we use background contexts because they are not bound by request contexts and can continue running even after a request context is cleaned up. This means that once the task has finished running, the memory consumed by child contexts would be freed up, avoiding the issue of memory leaks altogether.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/market-store/image3.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;identifying-the-cause-of-the-memory-leak&quot;&gt;Identifying the Cause of the Memory Leak&lt;/h3&gt;

&lt;p&gt;Upon further digging, we discovered an &lt;a href=&quot;https://github.com/grab/async/commit/d7b10a27c97049564607012efaceb28ccd32e980&quot;&gt;MR&lt;/a&gt; that was merged into the library to address a task cancellation issue. As shown in the code snippet below, the &lt;code class=&quot;highlighter-rouge&quot;&gt;Consume&lt;/code&gt; method had been modified such that task contexts were being passed to the runners, instead of the empty background contexts.&lt;/p&gt;

&lt;div class=&quot;language-go highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Consume&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;chan&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Invoke&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taskCtx&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;make&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;chan&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrentTasks&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;make&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concurrency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

         &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code ...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;taskCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ContinueWith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;interface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

            &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;// code...&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before we explain the code snippet, we should briefly explain what Golang contexts are. A &lt;a href=&quot;https://golang.org/pkg/context/&quot;&gt;context&lt;/a&gt; is a standard Golang package that carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes. We should always remember to cancel contexts after using them.&lt;/p&gt;

&lt;h4 id=&quot;importance-of-context-cancellation&quot;&gt;Importance of Context Cancellation&lt;/h4&gt;

&lt;p&gt;When a context is cancelled, all contexts derived from it are also cancelled. This means that there will be no unaccounted contexts or links and it can be achieved by using the Async Library’s &lt;code class=&quot;highlighter-rouge&quot;&gt;CancelFunc&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The Async Library’s &lt;code class=&quot;highlighter-rouge&quot;&gt;CancelFunc&lt;/code&gt; method will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cancel the created child context and its children&lt;/li&gt;
  &lt;li&gt;Remove the parent reference from the child context&lt;/li&gt;
  &lt;li&gt;Stop any associated timers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We should always make sure to call the &lt;code class=&quot;highlighter-rouge&quot;&gt;CancelFunc&lt;/code&gt; method after using contexts, to ensure that contexts and memory are not leaked.&lt;/p&gt;

&lt;h4 id=&quot;explaining-the-impact-of-the-mr&quot;&gt;Explaining the Impact of the MR&lt;/h4&gt;

&lt;p&gt;In the previous code snippet, we see that task contexts are passed to runners and they are not being cancelled. The Async Library created task contexts from non-empty contexts, which means the task contexts are tracked by the parent contexts. So, even if the work associated with these task contexts is complete, they will not be cleaned up by the system (garbage collected).&lt;/p&gt;

&lt;p&gt;As we started using task contexts instead of background contexts and did not cancel them, the memory used by these contexts was never returned, thus resulting in a memory leak.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/market-store/image5.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It took us several tries to debug and investigate the root cause of Market-Store’s high latency issue and through this incident, we learnt several important things that would help prevent a memory leak from recurring.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Always cancel the contexts you’ve created. Leaving it to garbage collection (system cleanup) may result in unexpected memory leaks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Go profiling can provide plenty of insights about your programme, especially when you’re not sure where to start troubleshooting.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Always benchmark your dependencies when integrating or updating the versions to ensure they don’t have any performance bottlenecks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to &lt;em&gt;Chip Dong Lim&lt;/em&gt; for his contributions and for designing the GIFs included in this article.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Jun 2021 00:08:20 +0000</pubDate>
        <link>https://engineering.grab.com/debugging-high-latency-market-store</link>
        <guid isPermaLink="true">https://engineering.grab.com/debugging-high-latency-market-store</guid>
        
        <category>Engineering</category>
        
        <category>Latency</category>
        
        <category>Debugging</category>
        
        <category>Memory Leak</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Building a Hyper Self-Service, Distributed Tracing and Feedback System for Rule &amp; Machine Learning (ML) Predictions</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In Grab, the Trust, Identity, Safety, and Security (TISS) is a team of software engineers and AI developers working on fraud detection, login identity check, safety issues, etc. There are many TISS services, like grab-fraud, grab-safety, and grab-id. They make billions of business decisions daily using the &lt;a href=&quot;https://engineering.grab.com/griffin&quot;&gt;Griffin rule engine&lt;/a&gt;, which determines if a passenger can book a trip, get a food promotion, or if a driver gets a delivery booking.&lt;/p&gt;

&lt;p&gt;There is a natural demand to log down all these important business decisions, store them and query them interactively or in batches. Data analysts and scientists need to use the data to train their machine learning models. RiskOps and customer service teams can query the historical data and help consumers.&lt;/p&gt;

&lt;p&gt;That’s where Archivist comes in; it is a new tracing, statistics and feedback system for rule and machine learning-based predictions. It is reliable and performant. Its innovative data schema is flexible for storing events from different business scenarios. Finally, it provides a user-friendly UI, which has access control for classified data.&lt;/p&gt;

&lt;p&gt;Here are the impacts Archivist has already made:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Currently, there are 2 teams with a total of 5 services and about 50 business scenarios using Archivist. The scenarios include fraud prevention (e.g. DriverBan, PassengerBan), payment checks (e.g. PayoutBlockCheck, PromoCheck), and identity check events like PinTrigger.&lt;/li&gt;
  &lt;li&gt;It takes only a few minutes to onboard a new business scenario (event type), by using the configuration page on the user portal. Previously, it took at least 1 to 2 days.&lt;/li&gt;
  &lt;li&gt;Each day, Archivist logs down 80 million logs to the ElasticSearch cluster, which is about 200GB of data.&lt;/li&gt;
  &lt;li&gt;Each week, Customer Experience (CE)/Risk Ops goes to the user portal and checks Archivist logs for about 2,000 distinct customers. They can search based on numerous dimensions such as the Passenger/DriverID, phone number, request ID, booking code and payment fingerprint.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Each day, TISS services make billions of business decisions (predictions), based on the Griffin rule engine and ML models.&lt;/p&gt;

&lt;p&gt;After the predictions are made, there are still some tough questions for these services to answer.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If Risk Ops believes a prediction is false-positive, a consumer could be banned. If this happens, how can consumers or Risk Ops report or feedback this information to the new rule and ML model training quickly?&lt;/li&gt;
  &lt;li&gt;As CustomService/Data Scientists investigating any tickets opened due to TISS predictions/decisions, how do you know which rules and data were used? E.g. why the passenger triggered a selfie, or why a booking was blocked.&lt;/li&gt;
  &lt;li&gt;After Data Analysts/Data Scientists (DA/DS) launch a new rule/model, how can they track the performance in fine-granularity and in real-time? E.g. week-over-week rule performance in a country or city.&lt;/li&gt;
  &lt;li&gt;How can DA/DS access all prediction data for data analysis or model training?&lt;/li&gt;
  &lt;li&gt;How can the system keep up with Grab’s business launch speed, with maximum self-service?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;p&gt;To answer the questions above, TISS services previously used company-wide Kibana to log predictions.  For example, a log looks like: &lt;code class=&quot;highlighter-rouge&quot;&gt;PassengerID:123,Scenario:PinTrigger,Decision:Trigger,...&lt;/code&gt;. This logging method had some obvious issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Logs in plain text don’t have any structure and are not friendly to ML model training as most ML models need processed data to make accurate predictions.&lt;/li&gt;
  &lt;li&gt;Furthermore, there is no fine-granularity access control for developers in Kibana.&lt;/li&gt;
  &lt;li&gt;Developers, DA and DS have no access control while CEs have no access at all. So CE cannot easily see the data and DA/DS cannot easily process the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To address all the Kibana log issues, we developed ActionTrace, a code library with a well-structured data schema. The logs, also called documents, are stored in a dedicated ElasticSearch cluster with access control implemented. However, after using it for a while, we found that it still needed some improvements.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Each business scenario involves different types of entities and ActionTrace is not fully self-service. This means that a lot of development work was needed to support fast-launching business scenarios. Here are some examples:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The main entities in the taxi business are Driver and Passenger,&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The main entities in the food business can be Merchant, Driver and Consumer.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;All these entities will need to be manually added into the ActionTrace data schema.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt; Each business scenario may have their own custom information logged. Because there is no overlap, each of them will correspond to a new field in the data schema. For example:
    &lt;ul&gt;
      &lt;li&gt;For any scenario involving payment, a valid payment method and expiration date is logged.&lt;/li&gt;
      &lt;li&gt;For the taxi business, the geohash is logged.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;  To store the log data from ActionTrace, different teams need to set up and manage their own ElasticSearch clusters. This increases hardware and maintenance costs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;There was a simple Web UI created for viewing logs from ActionTrace, but there was still no access control in fine granularity.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;We developed Archivist, a new tracing, statistics, and feedback system for ML/rule-based prediction events. It’s centralised, performant and flexible. It answers all the issues mentioned above, and it is an improvement over all the existing solutions we have mentioned previously.&lt;/p&gt;

&lt;p&gt;The key improvements are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User-defined entities and custom fields
    &lt;ul&gt;
      &lt;li&gt;There are no predefined entity types. Users can define up to 5 entity types (E.g. PassengerId, DriverId, PhoneNumber, PaymentMethodId, etc.).&lt;/li&gt;
      &lt;li&gt;Similarly, there are a limited number of custom data fields to use, in addition to the common data fields shared by all business scenarios.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A dedicated service shared by all other services
    &lt;ul&gt;
      &lt;li&gt;Each service writes its prediction events to a Kafka stream. Archivist then reads the stream and writes to the ElasticSearch cluster.&lt;/li&gt;
      &lt;li&gt;The data writes are buffered, so it is easy to handle traffic surges in peak time.&lt;/li&gt;
      &lt;li&gt;Different services share the same Elastic Cloud Enterprise (ECE) cluster, but they create their own daily file indices so the costs can be split fairly.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Better support for data mining, prediction stats and feedback
    &lt;ul&gt;
      &lt;li&gt;Kafka stream data are simultaneously written to AWS S3. DA/DS can use the PrestoDB SQL query engine to mine the data.&lt;/li&gt;
      &lt;li&gt;There is an internal web portal for viewing Archivist logs. Customer service teams and Ops can use no-risk data to address CE tickets, while DA, DS and developers can view high-risk data for code/rule debugging.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A reduction of development days to support new business launches
    &lt;ul&gt;
      &lt;li&gt;Previously, it took a week to modify and deploy the ActionTrace data schema. Now, it only takes several minutes to configure event schemas in the user portal.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Saves time in RiskOps/CE investigations
    &lt;ul&gt;
      &lt;li&gt;With the new web UI which has access control in place, the different roles in the company, like Customer service and Data analysts, can access the Archivist events with different levels of permissions.&lt;/li&gt;
      &lt;li&gt;It takes only a few clicks for them to find the relevant events that impact the drivers/passengers.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;architecture-details&quot;&gt;Architecture Details&lt;/h3&gt;

&lt;p&gt;Archivist’s system architecture is shown in the diagram below.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/archivist/image7.png&quot; alt=&quot;Archivist system architecture&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Archivist system architecture&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Different services (like fraud-detection, safety-allocation, etc.) use a simple SDK to write data to a Kafka stream (the left side of the diagram).&lt;/li&gt;
  &lt;li&gt;In the centre of Archivist is an event processor. It reads data from Kafka, and writes them to ElasticSearch (ES).&lt;/li&gt;
  &lt;li&gt;The Kafka stream writes to the Amazon S3 data lake, so DA/DS can use the Presto SQL query engine to query them.&lt;/li&gt;
  &lt;li&gt;The user portal (bottom right) can be used to view the Archivist log and update configurations. It also sends all the web requests to the API Handler in the centre.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following diagram shows how internal and external users use Archivist as well as the interaction between the &lt;a href=&quot;https://engineering.grab.com/griffin&quot;&gt;Griffin rule engine&lt;/a&gt; and Archivist.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/archivist/image11.png&quot; alt=&quot;Archivist use cases&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Archivist use cases&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;flexible-event-schema&quot;&gt;Flexible Event Schema&lt;/h3&gt;

&lt;p&gt;In Archivist, a prediction/decision is called an event. The event schema can be divided into 3 main parts conceptually.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Data partitioning: Fields like &lt;code class=&quot;highlighter-rouge&quot;&gt;service_name&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;event_type&lt;/code&gt; categorise data by services and business scenarios.
    &lt;table class=&quot;table&quot;&gt;
   &lt;thead&gt;
     &lt;tr&gt;
       &lt;th&gt;Field name&lt;/th&gt;
       &lt;th&gt;Type&lt;/th&gt;
       &lt;th&gt;Example&lt;/th&gt;
       &lt;th&gt;Notes&lt;/th&gt;
     &lt;/tr&gt;
   &lt;/thead&gt;
   &lt;tbody&gt;
     &lt;tr&gt;
       &lt;td&gt;service_name&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;GrabFraud&lt;/td&gt;
       &lt;td&gt;Name of the Service&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;event_type&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;PreRide&lt;/td&gt;
       &lt;td&gt;PaxBan/SafeAllocation&lt;/td&gt;
     &lt;/tr&gt;
   &lt;/tbody&gt;
 &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Business decision making: &lt;code class=&quot;highlighter-rouge&quot;&gt;request_id&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;decisions&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;reasons&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;event_content&lt;/code&gt; are used to record the business decision, the reason and the context (E.g. The input features of machine learning algorithms).
    &lt;table class=&quot;table&quot;&gt;
   &lt;thead&gt;
     &lt;tr&gt;
       &lt;th&gt;Field name&lt;/th&gt;
       &lt;th&gt;Type&lt;/th&gt;
       &lt;th&gt;Example&lt;/th&gt;
       &lt;th&gt;Notes&lt;/th&gt;
     &lt;/tr&gt;
   &lt;/thead&gt;
   &lt;tbody&gt;
     &lt;tr&gt;
       &lt;td&gt;request_id&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;a16756e8-efe2-472b-b614-ec6ae08a5912&lt;/td&gt;
       &lt;td&gt;a 32-digit id for web requests&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;event_content&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;Event context&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;decisions&lt;/td&gt;
       &lt;td&gt;[string]&lt;/td&gt;
       &lt;td&gt;[&quot;NotAllowBook&quot;, &quot;SMS&quot;]&lt;/td&gt;
       &lt;td&gt;A list&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;reasons&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;json payload string of the response from engine.&lt;/td&gt;
     &lt;/tr&gt;
   &lt;/tbody&gt;
 &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Customisation: Archivist provides user-defined entities and custom fields that we feel are sufficient and flexible for handling different business scenarios.
    &lt;table class=&quot;table&quot;&gt;
   &lt;thead&gt;
     &lt;tr&gt;
       &lt;th&gt;Field name&lt;/th&gt;
       &lt;th&gt;Type&lt;/th&gt;
       &lt;th&gt;Example&lt;/th&gt;
       &lt;th&gt;Notes&lt;/th&gt;
     &lt;/tr&gt;
   &lt;/thead&gt;
   &lt;tbody&gt;
     &lt;tr&gt;
       &lt;td&gt;entity_type_1&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;Passenger&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;entity_id_1&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;12151&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;entity_type_2&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;Driver&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;entity_id_2&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;341521-rdxf36767&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;...&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;entity_id_5&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;custom_field_type_1&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;“MessageToUser”&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;custom_field_1&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&quot;please contact Ops&quot;&lt;/td&gt;
       &lt;td&gt;User defined fields&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;custom_field_type_2&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;“Prediction rule:”&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;custom_field_2&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;“ML rule: 123, version:2”&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;...&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
     &lt;tr&gt;
       &lt;td&gt;custom_field_6&lt;/td&gt;
       &lt;td&gt;string&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
     &lt;/tr&gt;
   &lt;/tbody&gt;
 &lt;/table&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;a-user-portal-to-support-querying-prediction-stats-and-feedback&quot;&gt;A User Portal to Support Querying, Prediction Stats and Feedback&lt;/h3&gt;

&lt;p&gt;DA, DS, Ops and CE can access the internal user portal to see the prediction events, individually and on an aggregated city level.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/archivist/image5.gif&quot; alt=&quot;A snapshot of the Archivist logs showing the aggregation of the data in each city&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A snapshot of the Archivist logs showing the aggregation of the data in each city&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;There are graphs on the portal, showing the rule/model performance on individual customers over a period of time.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/archivist/image10.gif&quot; alt=&quot;Rule performance on a customer over a period of time&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Rule performance on a customer over a period of time&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;how-to-use-archivist-for-your-service&quot;&gt;How to Use Archivist for Your Service&lt;/h2&gt;

&lt;p&gt;If you want to get onboard Archivist, the coding effort is minimal. Here is an example of a code snippet to log an event:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/archivist/image2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/archivist/image2.png&quot; alt=&quot;Code snippet to log an event&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Code snippet to log an event&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;lessons&quot;&gt;Lessons&lt;/h2&gt;

&lt;p&gt;During the implementation of Archivist, we learnt some things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A good system needs to support multi-tenants from the beginning. Originally, we thought we could use just one Kafka stream, and put all the documents from different teams into one ElasticSearch (ES) index. But after one team insisted on keeping their data separately from others, we created more Kafka streams and ES indexes. We realised that this way, it’s easier for us to manage data and share the cost fairly.&lt;/li&gt;
  &lt;li&gt;Shortly after we launched Archivist, there was an incident where the ES data writes were choked. Because each document write is a goroutine, the number of goroutines increased to 400k and the memory usage reached 100% within minutes. We added a patch (2 lines of code) to limit the maximum number of goroutines in our system. Since then, we haven’t had any more severe incidents in Archivist.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 24 May 2021 00:11:20 +0000</pubDate>
        <link>https://engineering.grab.com/building-hyper-self-service-distributed-tracing-feedback-system</link>
        <guid isPermaLink="true">https://engineering.grab.com/building-hyper-self-service-distributed-tracing-feedback-system</guid>
        
        <category>Engineering</category>
        
        <category>Machine Learning</category>
        
        <category>Statistics</category>
        
        <category>Distributed Tracing</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Our Journey to Continuous Delivery at Grab (Part 2)</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab&quot;&gt;In the first part of this blog post&lt;/a&gt;, you’ve read about the improvements made to our build and staging deployment process, and how plenty of manual tasks routinely taken by engineers have been automated with &lt;em&gt;Conveyor&lt;/em&gt;: an in-house continuous delivery solution.&lt;/p&gt;

&lt;p&gt;This new post begins with the introduction of the hermeticity principle for our deployments, and how it improves the confidence with promoting changes to production. Changes sent to production via Conveyor’s deployment pipelines are then described in detail.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/our-journey-to-continuous-delivery-at-grab-part2/image11.png&quot; alt=&quot;Overview of Grab delivery process&quot; style=&quot;width:90%&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Overview of Grab delivery process&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Finally, looking back at the engineering efficiency improvements around velocity and reliability over the last 2 years, we answer the big question - was the investment on a custom continuous delivery solution like Conveyor the right decision for Grab?&lt;/p&gt;

&lt;h2 id=&quot;improving-confidence-in-our-production-deployments-with-hermeticity&quot;&gt;Improving Confidence in our Production Deployments with Hermeticity&lt;/h2&gt;

&lt;p&gt;The term &lt;em&gt;deployment hermeticity&lt;/em&gt; is borrowed from build systems. A build system is called hermetic if builds always produce the same artefacts regardless of changes in the environment they run on. Similarly, we call our deployments hermetic if they always result in the same deployed artefacts regardless of the environment’s change or the number of times they are executed.&lt;/p&gt;

&lt;p&gt;The behaviour of a service is rarely controlled by a single variable. The application that makes up your service is an important driver of its behaviour, but its configuration is an important contributor, for example. The behaviour for traditional microservices at Grab is dictated mainly by 3 versioned artefacts: application code, static and dynamic configuration.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/our-journey-to-continuous-delivery-at-grab-part2/image14.png&quot; /&gt;&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Conveyor has been integrated with the systems that operate changes in each of these parameters. By tracking all 3 parameters at every deployment, Conveyor can reproducibly deploy microservices with similar behaviour: its deployments are hermetic.&lt;/p&gt;

&lt;p&gt;Building upon this property, Conveyor can ensure that all deployments made to production have been tested before with the same combination of parameters. This is valuable to us:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An outcome of staging deployments for a specific set of parameters is a good predictor of outcomes in production deployments for the same set of parameters and thus it makes testing in staging more relevant.&lt;/li&gt;
  &lt;li&gt;Rollbacks are hermetic; we never rollback to a combination of parameters that has not been used previously.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the past, incidents had resulted from an application rollback not compatible with the current dynamic configuration version; this was aggravating since rollbacks are expected to be a safe recovery mechanism. The introduction of hermetic deployments has largely eliminated this category of problems.&lt;/p&gt;

&lt;p&gt;Hermeticity is maintained by registering the deployment parameters as artefacts after each successfully completed pipeline. Users must then select one of the registered deployment metadata to promote to production.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At this point, you might be wondering: why not use a single pipeline that includes both staging and production deployments? This was indeed how it started, with a single pipeline spanning multiple environments. However, engineers soon complained about it.&lt;/p&gt;

&lt;p&gt;The most obvious reason for the complaint was that less than 20% of changes deployed in staging will make their way to production. This meant that engineers would have toil associated with each completed staging deployment since the pipeline must be manually cancelled rather than continued to production.&lt;/p&gt;

&lt;p&gt;The other reason is that this multi-environment pipeline approach reduced flexibility when promoting changes to production. There are different ways to apply changes to a cluster. For example, lengthy pipelines that refresh instances can be used to deploy any combination of changes, while there are quicker pipelines restricted to dynamic configuration changes (such as feature flags rollouts). Regardless of the order in which the changes are made and how they are applied, Conveyor tracks the change.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Eventually, engineers promote a deployment artefact to production. However they do not need to apply changes in the same sequence with which were applied to staging. Furthermore, to prevent erroneous actions, Conveyor presents only changes that can be applied with the requested pipeline (and sometimes, no changes are available). Not being forced into a specific method of deploying changes is one of added benefits of hermetic deployments.&lt;/p&gt;

&lt;h2 id=&quot;returning-to-our-journey-towards-engineering-efficiency&quot;&gt;Returning to Our Journey Towards Engineering Efficiency&lt;/h2&gt;

&lt;p&gt;If you can recall, the first part of this blog post series ended with a description of staging deployment. Our deployment to production starts with a verification that we uphold our hermeticity principle, as explained above.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our production deployment pipelines can run for several hours for large clusters with rolling releases (few run for days), so we start by acquiring locks to ensure there are no concurrent deployments for any given cluster.&lt;/p&gt;

&lt;p&gt;Before making any changes to the environment, we automatically generate release notes, giving engineers a chance to abort if the wrong set of changes are sent to production.&lt;/p&gt;

&lt;p&gt;The pipeline next waits for a deployment slot. Early on, engineers adopted deployment windows that coincide with office hours, such that if anything goes wrong, there is always someone on hand to help. Prior to the introduction of Conveyor, however, engineers would manually ask a Slack bot for approval. This interaction is now automated, and the only remaining action left is for the engineer to approve that the deployment can proceed via a single click, in line with our hands-off deployment principle.&lt;/p&gt;

&lt;p&gt;When the canary is in production, Conveyor automates monitoring it. This process is similar to the one already discussed &lt;a href=&quot;https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab&quot;&gt;in the first part of this blog post&lt;/a&gt;: Engineers can configure a set of alerts that Conveyor will keep track of. As soon as any one of the alerts is triggered, Conveyor automatically rolls back the service.&lt;/p&gt;

&lt;p&gt;If no alert is raised for the duration of the monitoring period, Conveyor waits again for a deployment slot. It then publishes the release notes for that deployment and completes the deployments for the cluster. After the lock is released and the deployment registered, the pipeline finally comes to its successful completion.&lt;/p&gt;

&lt;h2 id=&quot;benefits-of-our-journey-towards-engineering-efficiency&quot;&gt;Benefits of Our Journey Towards Engineering Efficiency&lt;/h2&gt;

&lt;p&gt;All these improvements made over the last 2 years have reduced the effort spent by engineers on deployment while also reducing the failure rate of our deployments.&lt;/p&gt;

&lt;p&gt;If you are an engineer working on DevOps in your organisation, you know how hard it can be to measure the impact you made on your organisation. To estimate the time saved by our pipelines, we can model the activities that were previously done manually with a rudimentary weighted graph. In this graph, each edge carries a probability of the activity being performed (100% when unspecified), while each vertex carries the time taken for that activity.&lt;/p&gt;

&lt;p&gt;Focusing on our regular staging deployments only, such a graph would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The overall amount of effort automated by the staging pipelines (&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image1.png&quot; alt=&quot;&quot; /&gt;) is represented in the graph above. It can be converted into the equation below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This equation shows that for each staging deployment, around 16 minutes of work have been saved. Similarly, for regular production deployments, we find that 67 minutes of work were saved for each deployment:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image13.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Moreover, efficiency was not the only benefit brought by the use of deployment pipelines for our traditional microservices. Surprisingly perhaps, the rate of failures related to production changes is progressively reducing while the amount of production changes that were made with Conveyor increased across the organisation (starting at 1.5% of failures per deployments, and finishing at 0.3% on average over the last 3 months for the period of data collected):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image15.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;keep-calm-and-automate&quot;&gt;Keep Calm and Automate&lt;/h2&gt;

&lt;p&gt;Since the first draft for this post was written, we’ve made many more improvements to our pipelines. We’ve begun automating Database Migrations; we’ve extended our set of hermetic variables to Amazon Machine Image (AMI) updates; and we’re working towards supporting container deployments.&lt;/p&gt;

&lt;p&gt;Through automation, all of Conveyor’s deployment pipelines have contributed to save more than 5,000 man-days of efforts in 2020 alone, across all supported teams. That’s around 20 man-years worth of effort, which is around 3 times the capacity of the team working on the project! Investments in our automation pipelines have more than paid for themselves, and the gains go up every year as more workflows are automated and more teams are onboarded.&lt;/p&gt;

&lt;p&gt;If Conveyor has saved efforts for engineering teams, has it then helped to improve velocity? I had opened the first part of this blog post with figures on the deployment funnel for microservice teams at Grab, towards the end of 2018. So where do the figures stand today for these teams?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/our-journey-to-continuous-delivery-at-grab-part2/image16.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the span of 2 years, the average number of build and staging deployment performed each day has not varied much. However, in the last 3 months of 2020, engineers have sent twice more changes to production than they did for the same period in 2018.&lt;/p&gt;

&lt;p&gt;Perhaps the biggest recognition received by the team working on the project, was from Grab’s engineers themselves. In the 2020 internal NPS survey for engineering experience at Grab, Conveyor received the highest score of any tools (built in-house or not).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;All these improvements in efficiency for our engineers would never have been possible without the hard work of all team members involved in the project, past and present: Tanun Chalermsinsuwan, Aufar Gilbran, Deepak Ramakrishnaiah, Repon Kumar Roy (Kowshik), Su Han, Voislav Dimitrijevikj, Stanley Goh, Htet Aung Shine, Evan Sebastian, Qijia Wang, Oscar Ng, Jacob Sunny, Subhodip Mandal and many others who have contributed and collaborated with them.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 10 May 2021 08:10:20 +0000</pubDate>
        <link>https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab-part2</link>
        <guid isPermaLink="true">https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab-part2</guid>
        
        <category>Deployment</category>
        
        <category>CI</category>
        
        <category>Continuous Integration</category>
        
        <category>Continuous Deployment</category>
        
        <category>Deployment Process</category>
        
        <category>Continuous Delivery</category>
        
        <category>Multi Cloud</category>
        
        <category>Hermetic Deployments</category>
        
        <category>Automation</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How We Improved Agent Chat Efficiency with Machine Learning</title>
        <description>&lt;p&gt;In previous articles (see &lt;a href=&quot;https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web&quot;&gt;Grab’s in-house chat platform&lt;/a&gt;, &lt;a href=&quot;https://engineering.grab.com/customer-support-workforce-routing&quot;&gt;workforce routing&lt;/a&gt;), we shared how chat has grown to become one of the primary channels for support in the last few years.&lt;/p&gt;

&lt;p&gt;With continuous chat growth and a new in-house tool, helping our agents be more efficient and productive was key to ensure a faster support time for our users and scale chat even further.&lt;/p&gt;

&lt;p&gt;Starting from the analysis on the usage of another third-party tool as well as some shadowing sessions, we realised that building a templated-based feature wouldn’t help. We needed to offer personalisation capabilities, as our consumer support specialists care about their writing style and tone, and using templates often feels robotic.&lt;/p&gt;

&lt;p&gt;We decided to build a machine learning model, called &lt;strong&gt;SmartChat&lt;/strong&gt;, which offers contextual suggestions by leveraging several sources of internal data, helping our chat specialists type much faster, and hence serving more consumers.&lt;/p&gt;

&lt;p&gt;In this article, we are going to explain the process from problem discovery to design iterations, and share how the model was implemented from both a data science and software engineering perspective.&lt;/p&gt;

&lt;h2 id=&quot;how-smartchat-works&quot;&gt;How SmartChat Works&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../img/smartchat/image7.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;diving-deeper-into-the-problem&quot;&gt;Diving Deeper into the Problem&lt;/h2&gt;

&lt;p&gt;Agent productivity became a key part in the process of scaling chat as a channel for support.&lt;/p&gt;

&lt;p&gt;After splitting chat time into all its components, we noted that agent typing time represented a big portion of the chat support journey, making it the perfect problem to tackle next.&lt;/p&gt;

&lt;p&gt;After some analysis on the usage of the third-party chat tool, we found out that even with functionalities such as canned messages, &lt;strong&gt;85% of the messages were still free typed&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Hours of shadowing sessions also confirmed that the consumer support specialists liked to add their own flair. They would often use the template and adjust it to their style, which took more time than just writing it on the spot. With this in mind, it was obvious that templates wouldn’t be too helpful, unless they provided some degree of personalisation.&lt;/p&gt;

&lt;p&gt;We needed something that reduces typing time and also:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Allows some degree of personalisation&lt;/strong&gt;, so that answers don’t seem robotic and repeated.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Works with multiple languages and nuances&lt;/strong&gt;, considering Grab operates in 8 markets, even some of the English markets have some slight differences in commonly used words.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;It’s contextual to the problem&lt;/strong&gt; and takes into account the user type, issue reported, and even the time of the day.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ideally doesn’t require any maintenance effort&lt;/strong&gt;, such as having to keep templates updated whenever there’s a change in policies.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Considering the constraints, &lt;strong&gt;this seemed to be the perfect candidate for a machine learning-based functionality&lt;/strong&gt;, which predicts sentence completion by considering all the context about the user, issue and even the latest messages exchanged.&lt;/p&gt;

&lt;h2 id=&quot;usability-is-key&quot;&gt;Usability is Key&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../img/smartchat/image3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To fulfil the hypothesis, there are a few design considerations:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Minimising the learning curve for agents.&lt;/li&gt;
  &lt;li&gt;Avoiding visual clutter if recommendations are not relevant.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To increase the probability of predicting an agent’s message, one of the design explorations is to allow agents to select the top 3 predictions (Design 1). To onboard agents, we designed a quick tip to activate SmartChat using keyboard shortcuts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/smartchat/image4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By displaying the top 3 recommendations, we learnt that it slowed agents down as they started to read all options even if the recommendations were not helpful. Besides, by triggering this component upon every recommendable text, it became a distraction as they were forced to pause.&lt;/p&gt;

&lt;p&gt;In our next design iteration, we decided to leverage and reuse the interaction of SmartChat from a familiar platform that agents are using - Gmail’s Smart Compose. As agents are familiar with Gmail, the learning curve for this feature would be less steep. For first time users, agents will see a “Press tab” tooltip, which will activate the text recommendation. The tooltip will disappear after 5 times of use.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/smartchat/image6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To relearn the shortcut, agents can hover over the recommended text.&lt;img src=&quot;../img/smartchat/image9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-we-track-progress&quot;&gt;How We Track Progress&lt;/h2&gt;

&lt;p&gt;Knowing that this feature would come in multiple iterations, we had to find ways to track how well we were doing progressively, so we decided to measure the different components of chat time.&lt;/p&gt;

&lt;p&gt;We realised that the agent typing time is affected by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Percentage of characters saved&lt;/strong&gt;. This tells us that the model predicted correctly, and also saved time. This metric should increase as the model improves.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model’s effectiveness&lt;/strong&gt;. The agent writes the least number of characters possible before getting the right suggestion, which should decrease as the model learns.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Acceptance rate&lt;/strong&gt;. This tells us how many messages were written with the help of the model. It is a good proxy for feature usage and model capabilities.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt;. If the suggestion is not shown in about 100-200ms, the agent would not notice the text and keep typing.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../img/smartchat/image8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The architecture involves support specialists initiating the fetch suggestion request, which is sent for evaluation to the machine learning model through API gateway. This ensures that only authenticated requests are allowed to go through and also ensures that we have proper rate limiting applied.&lt;/p&gt;

&lt;p&gt;We have an internal platform called &lt;strong&gt;Catwalk&lt;/strong&gt;, which is a microservice that offers the capability to execute machine learning models as a HTTP service. We used the Presto query engine to calculate and analyse the results from the experiment.&lt;/p&gt;

&lt;h2 id=&quot;designing-the-machine-learning-model&quot;&gt;Designing the Machine Learning Model&lt;/h2&gt;

&lt;p&gt;I am sure all of us can remember an experiment we did in school when we had to catch a falling ruler. For those who have not done this experiment, feel free to try &lt;a href=&quot;https://www.youtube.com/watch?v%3DLheOjO2DJD0&quot;&gt;it&lt;/a&gt; at home! The purpose of this experiment is to define a ballpark number for typical human reaction time (equations also included in the video link).&lt;/p&gt;

&lt;p&gt;Typically, the human reaction time ranges from 100ms to 300ms, with a median of about 250ms (read more &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374455/&quot;&gt;here&lt;/a&gt;). Hence, we decided to set the upper bound for SmartChat response time to be 200ms while deciding the approach. Otherwise, the experience would be affected as the agents would notice a delay in the suggestions. To achieve this, we had to manage the model’s complexity and ensure that it achieves the optimal time performance.&lt;/p&gt;

&lt;p&gt;Taking into consideration network latencies, the machine learning model would need to churn out predictions in less than 100ms, in order for the entire product to achieve a maximum 200ms refresh rate.&lt;/p&gt;

&lt;p&gt;As such, a few key components were considered:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model Tokenisation
    &lt;ul&gt;
      &lt;li&gt;Model input/output tokenisation needs to be implemented along with the model’s core logic so that it is done in one network request.&lt;/li&gt;
      &lt;li&gt;Model tokenisation needs to be lightweight and cheap to compute.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model Architecture
    &lt;ul&gt;
      &lt;li&gt;This is a typical sequence-to-sequence (seq2seq) task so the model needs to be complex enough to account for the auto-regressive nature of seq2seq tasks.&lt;/li&gt;
      &lt;li&gt;We could not use pure attention-based models, which are usually state of the art for seq2seq tasks, as they are bulky and computationally expensive.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model Service
    &lt;ul&gt;
      &lt;li&gt;The model serving platform should be executed on a low-level, highly performant framework.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our proposed solution considers the points listed above. We have chosen to develop in Tensorflow (TF), which is a well-supported framework for machine learning models and application building.&lt;/p&gt;

&lt;p&gt;For Latin-based languages, we used a simple whitespace tokenizer, which is serialisable in the TF graph using the &lt;code class=&quot;highlighter-rouge&quot;&gt;tensorflow-text&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow_text as text

tokenizer = text.WhitespaceTokenizer()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the model architecture, we considered a few options but eventually settled for a simple recurrent neural network architecture (RNN), in an Encoder-Decoder structure:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Whitespace tokenisation&lt;/li&gt;
      &lt;li&gt;Single layered Bi-Directional RNN&lt;/li&gt;
      &lt;li&gt;Gated-Recurrent Unit (GRU) Cell&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Single layered Uni-Directional RNN&lt;/li&gt;
      &lt;li&gt;Gated-Recurrent Unit (GRU) Cell&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimisation&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Teacher-forcing in training, Greedy decoding in production&lt;/li&gt;
      &lt;li&gt;Trained with a cross-entropy loss function&lt;/li&gt;
      &lt;li&gt;Using ADAM (Kingma and Ba) optimiser&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To provide context for the sentence completion tasks, we provided the following features as model inputs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Past conversations between the chat agent and the user&lt;/li&gt;
  &lt;li&gt;Time of the day&lt;/li&gt;
  &lt;li&gt;User type (Driver-partners, Consumers, etc.)&lt;/li&gt;
  &lt;li&gt;Entrypoint into the chat (e.g. an article on cancelling a food order)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These features give the model the ability to generalise beyond a simple language model, with additional context on the nature of contact for support. Such experiences also provide a better user experience and a more customised user experience.&lt;/p&gt;

&lt;p&gt;For example, the model is better aware of the nature of time in addressing “Good &lt;strong&gt;{Morning/Afternoon/Evening}&lt;/strong&gt;” given the time of the day input, as well as being able to interpret meal times in the case of food orders. E.g. “We have contacted the driver, your &lt;strong&gt;{breakfast/lunch/dinner}&lt;/strong&gt; will be arriving shortly”.&lt;/p&gt;

&lt;h2 id=&quot;typeahead-solution-for-the-user-interface&quot;&gt;Typeahead Solution for the User Interface&lt;/h2&gt;

&lt;p&gt;With our goal to provide a seamless experience in showing suggestions to accepting them, we decided to implement a typeahead solution in the chat input area. This solution had to be implemented with the ReactJS library, as the internal web-app used by our support specialist for handling chats is built in React.&lt;/p&gt;

&lt;p&gt;There were a few ways to achieve this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Modify the Document Object Model (DOM) using Javascript to show suggestions by positioning them over the &lt;code class=&quot;highlighter-rouge&quot;&gt;input&lt;/code&gt; HTML tag based on the cursor position.&lt;/li&gt;
  &lt;li&gt;Use a content editable &lt;code class=&quot;highlighter-rouge&quot;&gt;div&lt;/code&gt; and have the suggestion &lt;code class=&quot;highlighter-rouge&quot;&gt;span&lt;/code&gt; render conditionally.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After evaluating the complexity in both approaches, the second solution seemed to be the better choice, as it is more aligned with the React way of doing things: avoid DOM manipulations as much as possible.&lt;/p&gt;

&lt;p&gt;However, when a suggestion is accepted we would still need to update the content editable div through DOM manipulation. It cannot be added to React’s state as it creates a laggy experience for the user to visualise what they type.&lt;/p&gt;

&lt;p&gt;Here is a code snippet for the implementation:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import React, { Component } from 'react';
import liveChatInstance from './live-chat';

export class ChatInput extends Component {
 constructor(props) {
   super(props);
   this.state = {
     suggestion: '',
   };
 }

 getCurrentInput = () =&amp;gt; {
   const { roomID } = this.props;
   const inputDiv = document.getElementById(`input_content_${roomID}`);
   const suggestionSpan = document.getElementById(
     `suggestion_content_${roomID}`,
   );

   // put the check for extra safety in case suggestion span is accidentally cleared
   if (suggestionSpan) {
     const range = document.createRange();
     range.setStart(inputDiv, 0);
     range.setEndBefore(suggestionSpan);
     return range.toString(); // content before suggestion span in input div
   }
   return inputDiv.textContent;
 };

 handleKeyDown = async e =&amp;gt; {
   const { roomID } = this.props;
   // tab or right arrow for accepting suggestion
   if (this.state.suggestion &amp;amp;&amp;amp; (e.keyCode === 9 || e.keyCode === 39)) {
     e.preventDefault();
     e.stopPropagation();
     this.insertContent(this.state.suggestion);
     this.setState({ suggestion: '' });
   }
   const parsedValue = this.getCurrentInput();
   // space
   if (e.keyCode === 32 &amp;amp;&amp;amp; !this.state.suggestion &amp;amp;&amp;amp; parsedValue) {
     // fetch suggestion
     const prediction = await liveChatInstance.getSmartComposePrediction(
       parsedValue.trim(), roomID);
     this.setState({ suggestion: prediction })
   }
 };

 insertContent = content =&amp;gt; {
   // insert content behind cursor
   const { roomID } = this.props;
   const inputDiv = document.getElementById(`input_content_${roomID}`);
   if (inputDiv) {
     inputDiv.focus();
     const sel = window.getSelection();
     const range = sel.getRangeAt(0);
     if (sel.getRangeAt &amp;amp;&amp;amp; sel.rangeCount) {
       range.insertNode(document.createTextNode(content));
       range.collapse();
     }
   }
 };

 render() {
   const { roomID } = this.props;
   return (
     &amp;lt;div className=&quot;message_wrapper&quot;&amp;gt;
       &amp;lt;div
         id={`input_content_${roomID}`}
         role={'textbox'}
         contentEditable
         spellCheck
         onKeyDown={this.handleKeyDown}
       &amp;gt;
         {!!this.state.suggestion.length &amp;amp;&amp;amp; (
           &amp;lt;span
             contentEditable={false}
             id={`suggestion_content_${roomID}`}
           &amp;gt;
             {this.state.suggestion}
           &amp;lt;/span&amp;gt;
         )}
       &amp;lt;/div&amp;gt;
     &amp;lt;/div&amp;gt;
   );
 }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The solution uses the spacebar as the trigger for fetching the suggestion from the ML model and stores them in a React state. The ML model prediction is then rendered in a dynamically rendered span.&lt;/p&gt;

&lt;p&gt;We used the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/getSelection&quot;&gt;window.getSelection()&lt;/a&gt; and &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Selection/getRangeAt&quot;&gt;range&lt;/a&gt; APIs to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Find the current input value&lt;/li&gt;
  &lt;li&gt;Insert the suggestion&lt;/li&gt;
  &lt;li&gt;Clear the input to type a new message&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The implementation has also considered the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt;. API calls are made on every space character to fetch the prediction. To reduce the number of API calls, we also cached the prediction until it differs from the user input.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recover placeholder&lt;/strong&gt;. There are data fields that are specific to the agent and consumer, such as agent name and user phone number, and these data fields are replaced by placeholders for model training. The implementation recovers the placeholders in the prediction before showing it on the UI.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Control rollout&lt;/strong&gt;. Since rollout is by percentage per country, the implementation has to ensure that only certain users can access predictions from their country chat model.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Aggregate and send metrics&lt;/strong&gt;. Metrics are gathered and sent for each chat message.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;The initial experiment results suggested that we managed to save 20% of characters, which improved the &lt;strong&gt;efficiency of our agents by 12%&lt;/strong&gt; as they were able to resolve the queries faster. These numbers exceeded our expectations and as a result, we decided to move forward by rolling SmartChat out regionally.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h2&gt;

&lt;p&gt;In the upcoming iteration, we are going to focus on &lt;strong&gt;non-Latin language support&lt;/strong&gt;, &lt;strong&gt;caching&lt;/strong&gt;, and &lt;strong&gt;continuous training&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Non-Latin Language Support and Caching&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The current model only works with Latin languages, where sentences consist of space-separated words. We are looking to provide support for non-Latin languages such as Thai and Vietnamese. The result would also be cached in the frontend to reduce the number of API calls, providing the prediction faster for the agents.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Continuous Training&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The current machine learning model is built with training data derived from historical chat data. In order to teach the model and improve the metrics mentioned in our goals, we will enhance the model by letting it learn from data gathered in day-to-day chat conversations. Along with this, we are going to train the model to give better responses by providing more context about the conversations.&lt;/p&gt;

&lt;p&gt;Seeing how effective this solution has been for our chat agents, we would also like to expose this to the end consumers to help them express their concerns faster and improve their overall chat experience.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to &lt;a href=&quot;mailto:matthew.yeow@grabtaxi.com&quot;&gt;Kok Keong Matthew Yeow&lt;/a&gt;, who helped to build the architecture and implementation in a scalable way.&lt;/small&gt;
—-&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Apr 2021 00:08:30 +0000</pubDate>
        <link>https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml</link>
        <guid isPermaLink="true">https://engineering.grab.com/how-we-improved-agent-chat-efficiency-with-ml</guid>
        
        <category>Engineering</category>
        
        <category>Machine Learning</category>
        
        <category>Consumer Support</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How Grab Leveraged Performance Marketing Automation to Improve Conversion Rates by 30%</title>
        <description>&lt;p&gt;Grab, Southeast Asia’s leading superapp, is a hyperlocal three-sided marketplace that operates across hundreds of cities in Southeast Asia. Grab started out as a taxi hailing company back in 2012 and in less than a decade, the business has evolved tremendously and now offers a diverse range of services for consumers’ everyday needs.&lt;/p&gt;

&lt;p&gt;To fuel our business growth in newer service offerings such as GrabFood, GrabMart and GrabExpress, user acquisition efforts play a pivotal role in ensuring we create a sustainable Grab ecosystem that balances the marketplace dynamics between our consumers, driver-partners and merchant-partners.&lt;/p&gt;

&lt;p&gt;Part of our user growth strategy is centred around our efforts in running direct-response app campaigns to increase trials on our superapp offerings. Executing these campaigns brings about a set of unique challenges against the diverse cultural backdrop present in Southeast Asia, challenging the team to stay hyperlocal in our strategies while driving user volumes at scale. To address these unique challenges, Grab’s performance marketing team is constantly seeking ways to leverage automation and innovate on our operations, improving our marketing efficiency and effectiveness.&lt;/p&gt;

&lt;h2 id=&quot;managing-grabs-ever-expanding-business-geographical-coverage-and-new-user-acquisition&quot;&gt;Managing Grab’s Ever-expanding Business, Geographical Coverage and New User Acquisition&lt;/h2&gt;

&lt;p&gt;Grab’s ever-expanding services, extensive geographical coverage and hyperlocal strategies result in an extremely dynamic, yet complex ad account structure. This also means that whenever there is a new business vertical launch or hyperlocal campaign, the team would spend valuable hours rolling out a large volume of new ads across our accounts in the region.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/learn-how-grab-leveraged-performance-marketing-automation/image1.jpg&quot; alt=&quot;Sample Google Ads account structure&quot; /&gt; &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A sample of our Google Ads account structure.&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The granular structure of our Google Ads account provided us with flexibility to execute hyperlocal strategies, but this also resulted in thousands of ad groups that had to be individually maintained.&lt;/p&gt;

&lt;p&gt;In 2019, Grab’s growth was simply outpacing our team’s resources and we finally hit a bottleneck. This challenged the team to take a step back and make the decision to pursue a fully automated solution built on the following principles for long term sustainability:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Building ad-tech solutions in-house instead of acquiring off-the-shelf solutions&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Grab’s unique business model calls for several tailor-made features, none of which the existing ad tech solutions were able to provide.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Shifting our mindset to focus on the infinite game&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;In order to sustain the exponential volume in the ads we run, we had to seek the path of automation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our very first automation project, we decided to look into automating creative refresh and upload for our Google Ads account. With thousands of ad groups running multiple creatives each, this had become a growing problem for the team. Overtime, manually monitoring these creatives and refreshing them on a regular basis had become impossible.&lt;/p&gt;

&lt;h2 id=&quot;the-automation-fundamentals&quot;&gt;The Automation Fundamentals&lt;/h2&gt;

&lt;p&gt;Grab’s superapp nature means that any automation solution fundamentally needs to be robust:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Performance-driven&lt;/strong&gt; - to maintain and improve conversion efficiency over time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt; -  to fit needs across business verticals and hyperlocal execution&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inclusivity&lt;/strong&gt; - to account for future service launches and marketing tech (e.g. product feeds and more)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt; - to account for future geography/campaign coverage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With these in mind, we incorporated them in our requirements for the custom creative automation tool we planned to build.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Performance-driven&lt;/strong&gt; - while many advertising platforms, such as Google’s App Campaigns, have built-in algorithms to prevent low-performing creatives from being served, the fundamental bottleneck lies in the speed in which these low-performing creatives can be replaced with new assets to improve performance. Thus, solving this bottleneck would become the primary goal of our tool.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Flexibility&lt;/strong&gt; - to accommodate our broad range of services, geographies and marketing objectives, a mapping logic would be required to make sure the right creatives are added into the right campaigns.&lt;/p&gt;

    &lt;p&gt;To solve this, we relied on a standardised creative naming convention, using key attributes in the file name to map an asset to a specific campaign and ad group based on:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Market&lt;/li&gt;
      &lt;li&gt;City&lt;/li&gt;
      &lt;li&gt;Service type&lt;/li&gt;
      &lt;li&gt;Language&lt;/li&gt;
      &lt;li&gt;Creative theme&lt;/li&gt;
      &lt;li&gt;Asset type&lt;/li&gt;
      &lt;li&gt;Campaign optimisation goal&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Inclusivity&lt;/strong&gt; - to address coverage of future service offerings and interoperability with existing ad-tech vendors, we designed and built our tool conforming to many industry API and platform standards.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt; - to ensure full coverage of future geographies/campaigns, the in-house solution’s frontend and backend had to be robust enough to handle volume. Working hand in glove with Google, the solution was built by leveraging multiple APIs including Google Ads and Youtube to host and replace low-performing assets across our ad groups. The solution was then deployed on AWS’ serverless compute engine.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;enter-cara&quot;&gt;Enter CARA&lt;/h2&gt;

&lt;p&gt;CARA is an automation tool that scans for any low-performing creatives and replaces them with new assets from our creative library:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/learn-how-grab-leveraged-performance-marketing-automation/image2.jpg&quot; alt=&quot;CARA Workflow&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A sneak peek of how CARA works&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In a controlled experimental launch, we saw nearly &lt;strong&gt;2,000&lt;/strong&gt; underperforming assets automatically replaced across more than &lt;strong&gt;8,000&lt;/strong&gt; active ad groups, translating to an &lt;strong&gt;18-30%&lt;/strong&gt; increase in clickthrough and conversion rates.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/learn-how-grab-leveraged-performance-marketing-automation/image3.jpg&quot; alt=&quot;Subset of results from CARA experimental launch&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A subset of results from CARA's experimental launch&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Through automation, Grab’s performance marketing team has been able to significantly improve clickthrough and conversion rates while saving valuable man-hours. We have also established a scalable foundation for future growth. The best part? We are just getting started.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored on behalf of the performance marketing team @ Grab. Special thanks to the CRM data analytics team, particularly Milhad Miah and Vaibhav Vij for making this a reality.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;join-us&quot;&gt;Join Us&lt;/h2&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 22 Mar 2021 00:13:30 +0000</pubDate>
        <link>https://engineering.grab.com/learn-how-grab-leveraged-performance-marketing-automation</link>
        <guid isPermaLink="true">https://engineering.grab.com/learn-how-grab-leveraged-performance-marketing-automation</guid>
        
        <category>Automation</category>
        
        <category>Engineering</category>
        
        <category>Marketing</category>
        
        
        <category>Engineering</category>
        
      </item>
    
  </channel>
</rss>
