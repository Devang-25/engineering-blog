<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 13 Oct 2020 13:01:35 +0000</pubDate>
    <lastBuildDate>Tue, 13 Oct 2020 13:01:35 +0000</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>Optimally scaling Kafka consumer applications</title>
        <description>&lt;p&gt;Earlier this year, we took you on a journey on how we built and deployed our event sourcing and stream processing framework at Grab. We’re happy to share that we’re able to reliably maintain our uptime and continue to service close to 400 billion events a week. We haven’t stopped there though. To ensure that we can scale our framework as the Grab business continuously grows, we have spent efforts optimizing our infrastructure.&lt;/p&gt;

&lt;p&gt;In this article, we will dive deeper into our Kubernetes infrastructure setup for our &lt;a href=&quot;https://engineering.grab.com/plumbing-at-scale&quot;&gt;stream processing framework&lt;/a&gt;. We will cover why and how we focus on optimal scalability and availability of our infrastructure.&lt;/p&gt;

&lt;h2 id=&quot;quick-architecture-recap&quot;&gt;Quick Architecture Recap&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Coban Platform Architecture&quot; src=&quot;/img/optimally-scaling-kafka-consumer-applications/image2.png&quot; /&gt;
    &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The Coban platform provides lightweight &lt;a href=&quot;https://medium.com/learning-the-go-programming-language/writing-modular-go-programs-with-plugins-ec46381ee1a9&quot;&gt;Golang plugin&lt;/a&gt; architecture-based data processing pipelines running in Kubernetes. These are essentially Kafka consumer pods that consume data, process it, and then materialize the results into various sinks (RDMS, other Kafka topics).&lt;/p&gt;

&lt;h2 id=&quot;anatomy-of-a-processing-pod&quot;&gt;Anatomy of a Processing Pod&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Anatomy of a Processing Pod&quot; src=&quot;/img/optimally-scaling-kafka-consumer-applications/image1.png&quot; /&gt;
    &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Each stream processing pod (the smallest unit of a pipeline’s deployment) has three top level components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trigger&lt;/strong&gt;: An interface that connects directly to the source of the data and converts it into an event channel.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: This is the app’s entry point and the orchestrator of the pod. It manages the worker pools, triggers, event channels, and lifecycle events.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pipeline plugin&lt;/strong&gt;: This is provided by the user, and conforms to a contract that the platform team publishes. It contains the domain logic for the pipeline and houses the pipeline orchestration defined by a user based on our Stream Processing Framework.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;optimal-scaling&quot;&gt;Optimal Scaling&lt;/h3&gt;

&lt;p&gt;We initially architected our Kubernetes setup around &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale&quot;&gt;horizontal pod autoscaling&lt;/a&gt; (HPA), which scales the number of pods per deployment based on CPU and memory usage. HPA keeps CPU and memory per pod specified in the deployment manifest and scales horizontally as the load changes.&lt;/p&gt;

&lt;p&gt;These were the areas of application wastage we observed on our platform:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As Grab’s traffic is uneven, we’d always have to provision for peak traffic. As users would not (or could not) always account for ramps, they would be fairly liberal with setting limit values (CPU and memory), leading to resource wastage.&lt;/li&gt;
  &lt;li&gt;Pods often had uneven traffic distribution despite fairly even partition load distribution in Kafka. The Stream Processing Framework(SPF) is essentially Kafka consumers consuming from Kafka topics, hence the number of pods scaling in and out resulted in unequal partition load per pod.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vertically-scaling-with-fixed-number-of-pods&quot;&gt;Vertically Scaling with Fixed Number of Pods&lt;/h3&gt;

&lt;p&gt;We initially kept the number of pods for a pipeline equal to the number of partitions in the topic the pipeline consumes from. This ensured even distribution of partitions to each pod providing balanced consumption. In order to abstract this from the end user, we automated the application deployment process to directly call the Kafka API to fetch the number of partitions during runtime.&lt;/p&gt;

&lt;p&gt;After achieving a fixed number of pods for the pipeline, we wanted to move away from HPA. We wanted our pods to scale up and down as the load increases or decreases without any manual intervention. &lt;a href=&quot;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler&quot;&gt;Vertical pod autoscaling&lt;/a&gt; (VPA) solves this problem as it relieves us from any manual operation for setting up resources for our deployment.&lt;/p&gt;

&lt;p&gt;We just deploy the application and let VPA handle the resources required for its operation. It’s known to not be very susceptible to quick load changes as it trains its model to monitor the deployment’s load trend over a period of time before recommending an optimal resource. This process ensures the optimal resource allocation for our pipelines considering the historic trends on throughput.&lt;/p&gt;

&lt;p&gt;We saw a &lt;em&gt;~45%&lt;/em&gt; reduction in our total resource usage vs resource requested after moving to VPA with a fixed number of pods from HPA.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Anatomy of a Processing Pod&quot; src=&quot;/img/optimally-scaling-kafka-consumer-applications/image3.png&quot; /&gt;
    &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;managing-availability&quot;&gt;Managing Availability&lt;/h3&gt;

&lt;p&gt;We broadly classify our workloads as latency sensitive (critical) and latency tolerant (non-critical). As a result, we could optimize scheduling and cost efficiency using &lt;a href=&quot;https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption&quot;&gt;priority classes&lt;/a&gt; and &lt;a href=&quot;https://github.com/kubernetes-sigs/cluster-proportional-autoscaler&quot;&gt;overprovisioning&lt;/a&gt; on heterogeneous node types on AWS.&lt;/p&gt;

&lt;h2 id=&quot;kubernetes-priority-classes&quot;&gt;Kubernetes Priority Classes&lt;/h2&gt;

&lt;p&gt;The main cost of running EKS in AWS is attributed to the EC2 machines that form the worker nodes for the Kubernetes cluster. Running &lt;a href=&quot;https://aws.amazon.com/ec2/pricing/on-demand&quot;&gt;On-Demand&lt;/a&gt; brings all the guarantees of instance availability but it is definitely very expensive. Hence, our first action to drive cost optimisation was to include &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html&quot;&gt;Spot instances&lt;/a&gt; in our worker node group.&lt;/p&gt;

&lt;p&gt;With the uncertainty of losing a spot instance, we started assigning priority to our various applications. We then let the user choose the priority of their pipeline depending on their use case. Different priorities would result in different node affinity to different kinds of instance groups (On-Demand/Spot). For example, Critical pipelines (latency sensitive) run on On-Demand worker node groups and Non-critical pipelines (latency tolerant) on Spot instance worker node groups.&lt;/p&gt;

&lt;p&gt;We use priority class as a method of preemption, as well as a node affinity that chooses a certain priority pipeline for the node group to deploy to.&lt;/p&gt;

&lt;h2 id=&quot;overprovisioning&quot;&gt;Overprovisioning&lt;/h2&gt;

&lt;p&gt;With spot instances running we realised a need to make our cluster quickly respond to failures. We wanted to achieve quick rescheduling of evicted pods, hence we added overprovisioning to our cluster. This means we keep some noop pods occupying free space running in our worker node groups for the quick scheduling of evicted or deploying pods.&lt;/p&gt;

&lt;p&gt;The overprovisioned pods are the lowest priority pods, thus can be preempted by any pod waiting in the queue for scheduling. We used cluster proportional autoscaler to decide the right number of these overprovisioned pods, which scales up and down proportionally to cluster size (i.e number of nodes and CPU in worker node group). This relieves us from tuning the number of these noop pods as the cluster scales up or down over the period keeping the free space proportional to current cluster capacity.&lt;/p&gt;

&lt;p&gt;Lastly, overprovisioning also helped improve the deployment time because there is no  dependency on the time required for &lt;a href=&quot;https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html&quot;&gt;Auto Scaling Groups&lt;/a&gt; (ASG) to add a new node to the cluster every time we want to deploy a new application.&lt;/p&gt;

&lt;h2 id=&quot;future-improvements&quot;&gt;Future Improvements&lt;/h2&gt;

&lt;p&gt;Evolution is an ongoing process. In the next few months, we plan to work on custom resources for combining VPA and fixed deployment size. Our current architecture setup works fine for now, but we would like to create a more tuneable in-house &lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources&quot;&gt;CRD&lt;/a&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources&quot;&gt;(Custom Resource Definition)&lt;/a&gt; for VPA that incorporates rightsizing our Kubernetes deployment horizontally.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored By Shubham Badkur on behalf of the Coban team at Grab - Ryan Ooi, Karan Kamath, Hui Yang, Yuguang Xiao, Jump Char, Jason Cusick, Shrinand Thakkar, Dean Barlan, Shivam Dixit, Andy Nguyen, and Ravi Tandon.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Oct 2020 02:13:54 +0000</pubDate>
        <link>https://engineering.grab.com/optimally-scaling-kafka-consumer-applications</link>
        <guid isPermaLink="true">https://engineering.grab.com/optimally-scaling-kafka-consumer-applications</guid>
        
        <category>Event Sourcing</category>
        
        <category>Stream Processing</category>
        
        <category>Kubernetes</category>
        
        <category>Backend</category>
        
        <category>Platform</category>
        
        <category>Go</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Our Journey to Continuous Delivery at Grab (Part 1)</title>
        <description>&lt;p&gt;This blog post is a two-part presentation of the effort that went into improving the &lt;a href=&quot;https://continuousdelivery.com/&quot;&gt;continuous delivery&lt;/a&gt; processes for backend services at Grab in the past two years. In the first part, we take stock of where we started two years ago and describe the software and tools we created while introducing some of the integrations we’ve done to automate our software delivery in our staging environment.
&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;post-quotations&quot;&gt;
  &lt;i&gt;Continuous Delivery is the ability to get changes of all types—including new features, configuration changes, bug fixes and experiments—into production, or into the hands of users, safely and quickly in a sustainable way.&lt;/i&gt;
  &lt;br /&gt;
  &lt;i&gt;— &lt;a href=&quot;https://continuousdelivery.com/&quot;&gt;continuousdelivery.com&lt;/a&gt;&lt;/i&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;br /&gt;
As a backend engineer at Grab, nothing matters more than the ability to innovate quickly and safely. Around the end of 2018, Grab’s transportation and deliveries backend architecture consisted of roughly 270 services (the majority being microservices). The deployment process was lengthy, required careful inputs and clear communication. The care needed to push changes in production and the risk associated with manual operations led to the introduction of a Slack bot to coordinate deployments. The bot ensures that deployments occur only during off-peak and within work hours:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Overview of the Grab Delivery Process&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image4.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Overview of the Grab Delivery Process&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Once the build was completed, engineers who desired to deploy their software to the Staging environment would copy release versions from the build logs, and paste them in a Jenkins job’s parameter. Tests needed to be manually triggered from another dedicated Jenkins job.&lt;/p&gt;

&lt;p&gt;Prior to production deployments, engineers would generate their release notes via a script and update them manually in a wiki document. Deployments would be scheduled through interactions with a Slack bot that controls release notes and deployment windows. Production deployments were made once again by pasting the correct parameters into two dedicated Jenkins jobs, one for the canary (a.k.a. one-box) deployment and the other for the full deployment, spread one hour apart. During the monitoring phase, engineers would continuously observe metrics reported on our dashboards.&lt;/p&gt;

&lt;p&gt;In spite of the fragmented process and risky manual operations impacting our velocity and stability, around 614 builds were running each business day and changes were deployed on our staging environment at an average rate of 300 new code releases per business day, while production changes averaged a rate of 28 new code releases per business day.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Our Deployment Funnel, Towards the End of 2018&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image10.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Our Deployment Funnel, Towards the End of 2018&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;These figures meant that, on average, it took 10 business days between each service update in production, and only 10% of the staging deployments were eventually promoted to production.&lt;/p&gt;

&lt;h2 id=&quot;automating-continuous-deployments-at-grab&quot;&gt;Automating Continuous Deployments at Grab&lt;/h2&gt;

&lt;p&gt;With an increased focus on Engineering efficiency, in 2018 we started an internal initiative to address frictions in deployments that became known as Conveyor. To build Conveyor with a small team of engineers, we had to rely on an already mature platform which exhibited properties that are desirable to us to achieve our mission.&lt;/p&gt;

&lt;h3 id=&quot;hands-off-deployments&quot;&gt;Hands-off deployments&lt;/h3&gt;

&lt;p&gt;Deployments should be an afterthought. Engineers should be as removed from the process as possible, and whenever possible, decisions should be taken early, during the code review process. The machine will do the heavy lifting, and only when it can’t decide for itself, should the engineer be involved. Notifications can be leveraged to ensure that engineers are only informed when something goes wrong and a human decision is required.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Hands-off Deployment Principle&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image12.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Hands-off Deployment Principle&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;confidence-in-deployments&quot;&gt;Confidence in Deployments&lt;/h3&gt;

&lt;p&gt;Grab’s focus on gathering internal Engineering NPS feedback helped us collect valuable metrics. One of the metrics we cared about was our engineers’ confidence in their production deployments. A team’s entire deployment process to production could last for more than a day and may extend up to a week for teams with large infrastructures running critical services. The possibility of losing progress in deployments when individual steps may last for hours is detrimental to the improvement of Engineering efficiency in the organisation. The deployment automation platform is the bedrock of that confidence. If the platform itself fails regularly or does provide a path of upgrade that is transparent to end-users, any features built on top of it would suffer from these downtimes and ultimately erode confidence in deployments.&lt;/p&gt;

&lt;h3 id=&quot;tailored-to-most-but-extensible-for-the-few&quot;&gt;Tailored To Most But Extensible For The Few&lt;/h3&gt;

&lt;p&gt;Our backend engineering teams are working on diverse stacks, and so are their deployment processes. Right from the start, we wanted our product to benefit the largest population of engineers that had adopted the same process, so as to maximize returns on our investments. To ease adoption, we decided to tailor a deployment pipeline such that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It would model the exact sequence of manual processes followed by this population of engineers.&lt;/li&gt;
  &lt;li&gt;Switching to use that pipeline should require as little work as possible by service teams.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However, in cases where this model would not fit a team’s specific process, our deployment platform should be open and extensible and support new customizations even when they are not originally supported by the product’s ecosystem.&lt;/p&gt;

&lt;h3 id=&quot;cloud-agnosticity&quot;&gt;Cloud-Agnosticity&lt;/h3&gt;

&lt;p&gt;While we were going to target a specific process and team, to ensure that our solution would stand the test of time, we needed to ensure that our solution would support the variety of environments currently used in production. This variety was also likely to increase, and we wanted a platform that would mature together with the rest of our ecosystem.&lt;/p&gt;

&lt;h2 id=&quot;overview-of-conveyor&quot;&gt;Overview Of Conveyor&lt;/h2&gt;

&lt;h3 id=&quot;setting-sail-with-spinnaker&quot;&gt;Setting Sail With Spinnaker&lt;/h3&gt;

&lt;p&gt;Conveyor is based on &lt;a href=&quot;https://spinnaker.io/&amp;amp;usg=AOvVaw1a93_1MJmR_1SZQ0mlu4Ow&quot;&gt;Spinnaker&lt;/a&gt;, an open-source, multi-cloud continuous delivery platform. We’ve chosen Spinnaker over other platforms because it is a mature deployment platform with no single point of failure, supports complex workflows (referred to as pipelines in Spinnaker), and already supports a large array of cloud providers. Since Spinnaker is open-source and extensible, it allowed us to add the features we needed for the specificity of our ecosystem.&lt;/p&gt;

&lt;p&gt;To further ease adoption within our organization, we built a tailored  user interface and created our own domain-specific language (DSL) to manage its pipelines as code.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Outline of Conveyor's Architecture&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image3.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Outline of Conveyor's Architecture&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;onboarding-to-a-simpler-interface&quot;&gt;Onboarding To A Simpler Interface&lt;/h3&gt;

&lt;p&gt;Spinnaker comes with its own interface, it has all the features an engineer would want from an advanced continuous delivery system. However, Spinnaker interface is vastly different from Jenkins and makes for a steep learning curve.&lt;/p&gt;

&lt;p&gt;To reduce our barrier to adoption, we decided early on to create a simple interface for our users. In this interface, deployment pipelines take the center stage of our application. Pipelines are objects managed by Spinnaker, they model the different steps in the workflow of each deployment. Each pipeline is made up of stages that can be assembled like lego-bricks to form the final pipeline. An instance of a pipeline is called an execution.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Conveyor dashboard. Sensitive information like authors and service names are redacted.&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image2.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Conveyor Dashboard&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;With this interface, each engineer can focus on what matters to them immediately: the pipelines they have started, or those started by other teammates working on the same services as they are. Conveyor also provides a search bar (on the top) and filters (on the left) that work in concert to explore all pipelines executed at Grab.&lt;/p&gt;

&lt;p&gt;We adopted a consistent set of colours to model all information in our interface:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;blue: represent stages that are currently running;&lt;/li&gt;
  &lt;li&gt;red: stages that have failed or important information;&lt;/li&gt;
  &lt;li&gt;yellow: stages that require human interaction;&lt;/li&gt;
  &lt;li&gt;and finally, in green: stages that were successfully completed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Conveyor also provides a task and notifications area, where all stages requiring human intervention are listed in one location. Manual interactions are often no more than just YES or NO questions:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Conveyor tasks. Sensitive information like author/service names is redacted.&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image9.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Conveyor Tasks&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Finally, in addition to supporting automated deployments, we greatly simplified the start of manual deployments. Instead of being required to copy/paste information, each parameter can be selected on the interface from a set of predefined items, sorted chronologically, and presented with contextual information to help engineers in their decision.&lt;/p&gt;

&lt;p&gt;Several parameters are required for our deployments and their values are selected from the UI to ensure correctness.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Simplified manual deployments&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image8.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Simplified Manual Deployments&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ease-of-adoption-with-our-pipeline-as-code-dsl&quot;&gt;Ease Of Adoption With Our Pipeline-As-Code DSL&lt;/h3&gt;

&lt;p&gt;Ease of adoption for the team is not simply about the learning curve of the new tools. We needed to make it easy for teams to configure their services to deploy with Conveyor. Since we focused on automating tasks that were already performed manually, we needed only to configure the layer that would enable the integration.&lt;/p&gt;

&lt;p&gt;We set on creating a pipeline-as-code implementation when none were widely being developed in the Spinnaker community. It’s interesting to see that two years on, this idea has grown in parallel in the community, with the birth of other &lt;a href=&quot;https://docs.armory.io/docs/spinnaker/using-dinghy/&quot;&gt;pipeline-as-code implementations&lt;/a&gt;. Our pipeline-as-code is referred to as the Pipeline DSL, and its configuration is located inside each team’s repository. Artificer is the name of our Pipeline DSL interpreter and it runs with every change inside our monorepository:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Artificer: Our Pipeline DSL&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image6.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Artificer: Our Pipeline DSL&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Pipelines are being updated at every commit if necessary.&lt;/p&gt;

&lt;p&gt;Creating a &lt;code class=&quot;highlighter-rouge&quot;&gt;conveyor.jsonnet&lt;/code&gt; file within the service’s directory of our monorepository with the few lines below is all that’s required for Artificer to do its work and get the benefits of automation provided by Conveyor’s pipeline:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'default.libsonnet'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;service-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
       &lt;span class=&quot;s2&quot;&gt;&quot;group-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
&lt;p&gt;&lt;em&gt;Sample minimal &lt;code class=&quot;highlighter-rouge&quot;&gt;conveyor.jsonnet&lt;/code&gt; configuration to onboard services.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In this file, engineers simply specify the name of their service and the group that a user should belong to, to have deployment rights for the service.&lt;/p&gt;

&lt;p&gt;Once the build is completed, teams can log in to Conveyor and start manual deployments of their services with our pipelines. Three pipelines are provided by default: the integration pipeline used for tests and developments, the staging pipeline used for pre-production tests, and the production pipeline for production deployment.&lt;/p&gt;

&lt;p&gt;Thanks to the simplicity of this minimal configuration file, we were able to generate these configuration files for all existing services of our monorepository. This resulted in the automatic onboarding of a large number of teams and was a major contributing factor to the adoption of Conveyor throughout our organisation.&lt;/p&gt;

&lt;h2 id=&quot;our-journey-to-engineering-efficiency-for-backend-services&quot;&gt;Our Journey To Engineering Efficiency (for backend services)&lt;/h2&gt;

&lt;p&gt;The sections below relate some of the improvements in engineering efficiency we’ve delivered since Conveyor’s inception. They were not made precisely in this order but for readability, they have been mapped to each step of the software development lifecycle.&lt;/p&gt;

&lt;h3 id=&quot;automate-deployments-at-build-time&quot;&gt;Automate Deployments at Build Time&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Continuous Integration Job&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image7.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Continuous Integration Job&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Continuous delivery begins with a pushed code commit in our trunk-based development flow. Whenever a developer pushes changes onto their development branch or onto the trunk, a continuous integration job is triggered on Jenkins. The products of this job (binaries, docker images, etc) are all uploaded into our artefact repositories. We’ve made two additions to our continuous integration process.&lt;/p&gt;

&lt;p&gt;The first modification happens at the step “Upload &amp;amp; Register artefacts”. At this step, each artefact created is now registered in Conveyor with its associated metadata. When and if an engineer needs to trigger a deployment manually, Conveyor can display the list of versions to choose from, eliminating the need for error-prone manual inputs:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot; Staging&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image5.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Staging&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Each selectable version shows contextual information: title, author, version and link to the code change where it originated. During registration, the commit time is also recorded and used to order entries chronologically in the interface. To ensure this integration is not a single point of failure for deployments, manual input is still available optionally.&lt;/p&gt;

&lt;p&gt;The second modification implements one of the essential feature continuous delivery: your deployments should happen often, automatically. Engineers are now given the possibility to start automatic deployments once continuous integration has successfully completed, by simply modifying their project’s continuous integration settings:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s2&quot;&gt;&quot;AfterBuild&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;AutoDeploy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s2&quot;&gt;&quot;OnDiff&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s2&quot;&gt;&quot;OnLand&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;TYPE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;conveyor&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// other settings...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
&lt;p&gt;&lt;em&gt;Sample settings needed to trigger auto-deployments. &lt;code class=&quot;highlighter-rouge&quot;&gt;Diff&lt;/code&gt; refers to code review submissions, and &lt;code class=&quot;highlighter-rouge&quot;&gt;Land&lt;/code&gt; refers to merged code changes.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h3 id=&quot;staging-pipeline&quot;&gt;Staging Pipeline&lt;/h3&gt;

&lt;p&gt;Before deploying a new artefact to a service in production, changes are validated on the staging environment. During the staging deployment, we verify that canary (one-box) deployments and full deployments with automated smoke and functional tests suites.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Staging Pipeline&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image1.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Staging Pipeline&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We start by acquiring a deployment lock for this service and this environment. This prevents another deployment of the same service on the same environment to happen concurrently, other deployments will be waiting in a FIFO queue until the lock is released.&lt;/p&gt;

&lt;p&gt;The stage &lt;em&gt;“Compute Changeset”&lt;/em&gt; ensures that the deployment is not a rollback. It verifies that the new version deployed does not correspond to a rollback by comparing the ancestry of the commits provided during the artefact registration at build time: since we automate deployments after the build process has completed, cases of rollback may occur when two changes are created in quick succession and the latest build completes earlier than the older one.&lt;/p&gt;

&lt;p&gt;After the stage &lt;em&gt;“Deploy Canary”&lt;/em&gt; has completed, smoke test run. There are three kinds of tests executed at different stages of the pipeline: smoke, functional and security tests. Smoke tests directly reach the canary instance’s endpoint, by-passing load-balancers. If the smoke tests fail, the canary is immediately rolled back and this deployment is terminated.&lt;/p&gt;

&lt;p&gt;All tests are generated from the same builds as the artefact being tested and their versions must match during testing. To ensure that the right version of the test run and distinguish between the different kind of tests to perform, we provide additional metadata that will be passed by Conveyor to the tests system, known internally as Gandalf:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'default.libsonnet'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;service-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;group-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_smoke_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/smoke/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_functional_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/functional/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_security_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/security/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
&lt;p&gt;&lt;em&gt;Sample &lt;code class=&quot;highlighter-rouge&quot;&gt;conveyor.jsonnet&lt;/code&gt; configuration with integration tests added.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Additionally, in parallel to the execution of the smoke tests, the canary is also being monitored from the moment its deployment has completed and for a predetermined duration. We leverage our integration with Datadog to allow engineers to select the alerts to monitor. If an alert is triggered during the monitoring period, and while the tests are executed, the canary is again rolled back, and the pipeline is terminated. Engineers can specify the alerts by adding them to the &lt;code class=&quot;highlighter-rouge&quot;&gt;conveyor.jsonnet&lt;/code&gt; configuration file together with the monitoring duration:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'default.libsonnet'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;service-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;group-name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_smoke_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/smoke/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_functional_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/functional/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;gandalf_security_tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;repo.internal/path/to/my/security/tests&quot;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;stg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;duration_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;alarms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;datadog&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;alert_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12345678&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;datadog&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;alert_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23456789&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
&lt;p&gt;&lt;em&gt;Sample &lt;code class=&quot;highlighter-rouge&quot;&gt;conveyor.jsonnet&lt;/code&gt; configuration with alerts in staging added.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;When the smoke tests and monitor pass and the deployment of new artefacts is completed, the pipeline execution triggers functional and security tests. Unlike smoke tests, functional &amp;amp; security tests run only after that step, as they communicate with the cluster through load-balancers, impersonating other services.&lt;/p&gt;

&lt;p&gt;Before releasing the lock, release notes are generated to inform engineers of the delta of changes between the version they just released and the one currently running in production. Once the lock is released, the stage &lt;em&gt;“Check Policies”&lt;/em&gt; verifies that the parameters and variable of the deployment obeys a specific set of criteria, for example: if its service metadata is up-to-date in our service inventory, or if the base image used during deployment is sufficiently recent.&lt;/p&gt;

&lt;p&gt;Here’s how the policy stage, the engine, and the providers interact with each other:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Check Policy Stage&quot; src=&quot;/img/our-journey-to-continuous-delivery-at-grab/image11.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Check Policy Stage&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Spinnaker, each event of a pipeline’s execution updates the pipeline’s state in the database. The current state of the pipeline can be fetched by its API as a single JSON document, describing all information related to its execution: including its parameters, the contextual information related to each stage or even the response from the various interfacing components. The role of our &lt;em&gt;“Policy Check”&lt;/em&gt; stage is to query this JSON representation of the pipeline, to extract and transform the variables which are forwarded to our policy engine for validation. Our policy engine gathers judgements passed by different policy providers. If the validation by the policy engine fails, the deployment is not rolled back this time; however, promotion to production is not possible and the pipeline is immediately terminated.&lt;/p&gt;

&lt;p&gt;The journey through staging deployment finally ends with the stage &lt;em&gt;“Register Deployment”&lt;/em&gt;. This stage registers that a successful deployment was made in our staging environment as an artefact. Similarly to the policy check above, certain parameters of the deployment are picked up and consolidated into this document. We use this kind of artefact as proof for upcoming production deployment.&lt;/p&gt;

&lt;h3 id=&quot;continuing-our-journey-to-engineering-efficiency&quot;&gt;Continuing Our Journey to Engineering Efficiency&lt;/h3&gt;

&lt;p&gt;With the advancements made in continuous integration and deployment to staging, Conveyor has reduced the efforts needed by our engineers to just three clicks in its interface, when automated deployment is used. Even when the deployment is triggered manually, Conveyor gives the assurance that the parameters selected are valid and it does away with copy/pasting and human interactions across heterogeneous tools.&lt;/p&gt;

&lt;p&gt;In the sequel to this blog post, we’ll dive into the improvements that we’ve made to our production deployments and introduce a crucial concept that led to the creation of our proof for successful staging deployment. Finally, we’ll cover the impact that Conveyor had on the continuous delivery of our backend services, by comparing our deployment velocity when we started two years ago versus where we are today.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;All these improvements in efficiency for our engineers would never have been possible without the hard work of all team members involved in the project, past and present: Evan Sebastian, Tanun Chalermsinsuwan, Aufar Gilbran, Deepak Ramakrishnaiah, Repon Kumar Roy (Kowshik), Su Han, Voislav Dimitrijevikj, Qijia Wang, Oscar Ng, Jacob Sunny, Subhodip Mandal, and many others who have contributed and collaborated with them.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Wed, 23 Sep 2020 10:23:44 +0000</pubDate>
        <link>https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab</link>
        <guid isPermaLink="true">https://engineering.grab.com/our-journey-to-continuous-delivery-at-grab</guid>
        
        <category>Deployment</category>
        
        <category>CI</category>
        
        <category>Continuous Integration</category>
        
        <category>Continuous Deployment</category>
        
        <category>Deployment Process</category>
        
        <category>Cloud Agnostic</category>
        
        <category>Spinnaker</category>
        
        <category>Continuous Delivery</category>
        
        <category>Multi Cloud</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Uncovering the truth behind Lua and Redis data consistency</title>
        <description>&lt;p&gt;Our team at Grab uses Redis as one of our message queues. The Redis server is deployed in a master/replica setup. Quite recently, we have been noticing a spike in the CPU usage of the Redis replicas every time we deploy our service, even when the replicas are not in use and when there’s no read traffic to it. However, the issue is resolved once we reboot the replica.&lt;/p&gt;

&lt;p&gt;Because a reboot of the replica fixes the issue every time, we thought that it might be due to some Elasticache replication issues and didn’t pursue further. However, a recent Redis failover brought this to our attention again. After the failover, the problematic replica becomes the new master and its CPU immediately goes to 100% with the read traffic, which essentially means the cluster is not functional after the failover. And this time we investigated the issue with new vigour. What we found in our investigation led us to deep dive into the details of Redis replication and its implementation of Hash.&lt;/p&gt;

&lt;p&gt;Did you know that Redis master/replica can become inconsistent in certain scenarios?&lt;/p&gt;

&lt;p&gt;Did you know the encoding of Hash objects on the master and the replica are different even if the writing operations are exactly the same and in the same order? Read on to find out why.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;The following graph shows the CPU utilization of the master vs. the replica immediately after our service is deployed.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/uncovering-the-truth-behind-lua-and-redis-data-consistency/cpuUtilization.png&quot; alt=&quot;Architecture diagram&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;CPU Utilization&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;From the graph, you can see the following CPU usage trends. Replica’s CPU usage:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Increases immediately after our service is deployed.&lt;/li&gt;
  &lt;li&gt;Spikes higher than the master after a certain time.&lt;/li&gt;
  &lt;li&gt;Get’s back to normal after a reboot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cursory-investigation&quot;&gt;Cursory investigation&lt;/h2&gt;

&lt;p&gt;Because the spike occurs only when we deploy our service, we scrutinised all the scripts that were triggered immediately after the deployment. Lua monitor script was identified as a possible suspect. The script redistributes inactive service instances’ messages in the queue to active service instances so that messages can be processed by other healthy instances.&lt;/p&gt;

&lt;p&gt;We ran a few experiments related to the Lua monitor script using the Redis &lt;a href=&quot;https://redis.io/commands/monitor&quot;&gt;monitor&lt;/a&gt; command to compare the script’s behaviour on master and the replica. A side note, because this command causes performance degradation, use it with discretion. Coming back to the script, we were surprised to note that the monitor script behaves differently between the master and the replica:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Redis executes the script separately on the master and the replica. We expected the script to execute only on master and the resulting changes to be replicated to the secondary.&lt;/li&gt;
  &lt;li&gt;The Redis command &lt;code class=&quot;highlighter-rouge&quot;&gt;HGETALL&lt;/code&gt; used in the script returns the hash keys in a different order on master compared to the replica.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Due to the above reasons, the script causes data inconsistencies between the master and its replica. From that point on, the data between the master and the replica keeps diverging till they become completely distinct. Due to the inconsistency, the data on the secondary does not get deleted correctly thereby growing into an extremely large dataset. Any further operations on the large dataset requires a higher CPU usage, which explains why the replica’s CPU usage is higher than the master.&lt;/p&gt;

&lt;p&gt;During replica reboots, the data gets synced and consistent again, which is why the CPU usage gets to normal values after rebooting.&lt;/p&gt;

&lt;h2 id=&quot;diving-deeper-on-hgetall&quot;&gt;Diving deeper on HGETALL&lt;/h2&gt;

&lt;p&gt;We knew that the keys of a hash are not ordered and we should not rely on the order. But it still puzzled us that the order is different even when the writing sequence is the same between the master and the replica. Plus the fact that the orders are always the same in our local environment with a similar setup made us even more curious.&lt;/p&gt;

&lt;p&gt;So to better understand the underlying magic of Redis and to avoid similar bugs in the future, we decided to hammer on and read the Redis source code to get more details.&lt;/p&gt;

&lt;h2 id=&quot;hgetall-command-handling-code&quot;&gt;HGETALL command handling code&lt;/h2&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;HGETALL&lt;/code&gt; command is handled by the function &lt;code class=&quot;highlighter-rouge&quot;&gt;genericHgetallCommand&lt;/code&gt; and it further calls &lt;code class=&quot;highlighter-rouge&quot;&gt;hashTypeNext&lt;/code&gt; to iterate through the Hash object. A snippet of the code is shown as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/* Move to the next entry in the hash. Return C_OK when the next entry
 * could be found and C_ERR when the iterator reaches the end. */
int hashTypeNext(hashTypeIterator *hi) {
    if (hi-&amp;gt;encoding == OBJ_ENCODING_ZIPLIST) {
        // call zipListNext
    } else if (hi-&amp;gt;encoding == OBJ_ENCODING_HT) {
        // call dictNext
    } else {
        serverPanic(&quot;Unknown hash encoding&quot;);
    }
    return C_OK;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the code snippet, you can see that the Redis Hash object actually has two underlying representations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ZIPLIST&lt;/li&gt;
  &lt;li&gt;HASHTABLE (dict)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A bit of research online helped us understand that, to save memory, Redis chooses between the two hash representations based on the following limits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;By default, Redis stores the Hash object as a &lt;a href=&quot;https://redis.io/topics/memory-optimization&quot;&gt;zipped list&lt;/a&gt; when the hash has less than 512 entries and when each element’s size is smaller than 64 bytes.&lt;/li&gt;
  &lt;li&gt;If either limit is exceeded, Redis converts the list to a &lt;a href=&quot;https://github.com/antirez/redis/blob/3.2/src/t_hash.c#L40&quot;&gt;hashtable&lt;/a&gt;, and this is irreversible. That is, Redis won’t convert the hashtable back to a list again, even if the entries/size falls below the limit.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;eureka-moment&quot;&gt;Eureka moment&lt;/h2&gt;

&lt;p&gt;Based on this understanding, we checked the encoding of the problematic hash in staging.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;stg-bookings-qu-002.pcxebj.0001.apse1.cache.amazonaws.com:6379&amp;gt; object encoding queue_stats
&quot;hashtable&quot;

stg-bookings-qu-001.pcxebj.0001.apse1.cache.amazonaws.com:6379&amp;gt; object encoding queue_stats
&quot;ziplist&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;To our surprise, the encodings of the Hash object on the master and its replica were different.&lt;/strong&gt; Which means if we add or delete elements in the hash, the sequence of the keys won’t be the same due to hashtable operation vs. list operation!&lt;/p&gt;

&lt;p&gt;Now that we have identified the root cause, we were still curious about the difference in encoding between the master and the replica.&lt;/p&gt;

&lt;h3 id=&quot;how-could-the-underlying-representations-be-different&quot;&gt;How could the underlying representations be different?&lt;/h3&gt;

&lt;p&gt;We reasoned, “&lt;em&gt;If the master and its replica’s writing operations are exactly the same and in the same order, why are the underlying representations still different?&lt;/em&gt;”&lt;/p&gt;

&lt;p&gt;To answer this, we further looked through the Redis source to find all the possible places that a Hash object’s representation could be changed and soon found the following code snippet:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/* Load a Redis object of the specified type from the specified file.
 * On success a newly allocated object is returned, otherwise NULL. */
robj *rdbLoadObject(int rdbtype, rio *rdb) {
  //...
  if (rdbtype == RDB_TYPE_HASH) {
    //...
    o = createHashObject();  // ziplist

    /* Too many entries? Use a hash table. */
    if (len &amp;gt; server.hash_max_ziplist_entries)
        hashTypeConvert(o, OBJ_ENCODING_HT);

    //...
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Reading through the code we understand the following behaviour:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When restoring from an RDB file, Redis creates a ziplist first for Hash objects.&lt;/li&gt;
  &lt;li&gt;Only when the size of the Hash object is greater than the &lt;code class=&quot;highlighter-rouge&quot;&gt;hash_max_ziplist_entries&lt;/code&gt;, the ziplist is converted to a hashtable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, if you have a Redis Hash object encoded as a &lt;code class=&quot;highlighter-rouge&quot;&gt;hashtable&lt;/code&gt; with its length less than &lt;code class=&quot;highlighter-rouge&quot;&gt;hash_max_ziplist_entries&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;(512)&lt;/code&gt; in the master, when you set up a replica, it is encoded as a &lt;code class=&quot;highlighter-rouge&quot;&gt;ziplist&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We were able to verify this behaviour in our local setup as well.&lt;/p&gt;

&lt;h3 id=&quot;how-did-we-fix-it&quot;&gt;How did we fix it?&lt;/h3&gt;

&lt;p&gt;We could use the following two approaches to address this issue:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Enable&lt;a href=&quot;https://redis.io/commands/eval#replicating-commands-instead-of-scripts&quot;&gt; script effect replication mode&lt;/a&gt;. This tells Redis to replicate the commands generated by the script instead of running the whole script on the replica. One disadvantage to using this approach is that it adds network traffic between the master and the replica.&lt;/li&gt;
  &lt;li&gt;Ensure the behaviour of the Lua monitor script is deterministic. In our case, we can do this by sorting the outputs of HKEYS/HGETALL.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We chose the latter approach because:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Hash object is pretty small ( &amp;lt; 30 elements) so the sorting overhead is low, less than 1ms for 100 elements based on our tests.&lt;/li&gt;
  &lt;li&gt;Replicating our script effect would end up replicating thousands of Redis writing commands on the secondary causing a much higher overhead compared to replicating just the script.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After the fix, the CPU usage of the replica remained in range after each deployment. This also prevented the Redis cluster from being destroyed in the event of a master failover.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key takeaways&lt;/h2&gt;

&lt;p&gt;In addition to writing clear and maintainable code, it’s equally important to understand the underlying storage layer that you are dealing with to produce efficient and bug-free code.&lt;/p&gt;

&lt;p&gt;The following are some of the key learnings on Redis:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Redis does not guarantee the consistency between master and its replica nodes when Lua scripts are used. You have to ensure that the behaviour of the scripts are deterministic to avoid data inconsistency.&lt;/li&gt;
  &lt;li&gt;Redis replicates the whole Lua script instead of the resulting commands to the replica. However, this is the default behaviour and you can disable it.&lt;/li&gt;
  &lt;li&gt;To save memory, Redis uses different representations for Hash. Your Hash object could be stored as a list in memory or a hashtable. This is not guaranteed to be the same across the master and its replicas.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Sep 2020 08:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/uncovering-the-truth-behind-lua-and-redis-data-consistency</link>
        <guid isPermaLink="true">https://engineering.grab.com/uncovering-the-truth-behind-lua-and-redis-data-consistency</guid>
        
        <category>Redis</category>
        
        <category>Lua Scripts</category>
        
        <category>High CPU Usage</category>
        
        <category>Data Consistency</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Securing and managing multi-cloud Presto Clusters with Grab’s DataGateway</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Data is the lifeblood of Grab and the insights we gain from it drive all the most critical business decisions made by Grabbers and our leaders every day.&lt;/p&gt;

&lt;p&gt;Grab’s Data Engineering (DE) team is responsible for maintaining the data platform, which consists of data pipelines, job schedulers, and the query/computation engines that are the key components for generating insights from data. SQL is the core language for analytics at Grab and as of early 2020, our Presto platform serves about 200 user groups that add up to 500 users who run 350,000 queries every day. These queries span across 10,000 tables that process up to 1PB of data daily.&lt;/p&gt;

&lt;p&gt;In 2016, we started the DataGateway project to enable us to manage data access for the hundreds of Grabbers who needed access to &lt;a href=&quot;https://aws.amazon.com/big-data/what-is-presto/&quot;&gt;Presto&lt;/a&gt; for their work. Since then, DataGateway has grown to become much more than just an access control mechanism for Presto. In this blog, we want to share what we’ve achieved since the initial launch of the project.&lt;/p&gt;

&lt;h2 id=&quot;the-problems-we-wanted-to-solve&quot;&gt;The problems we wanted to solve&lt;/h2&gt;

&lt;p&gt;As we were reviewing the key challenges around data access in Grab and assessing possible solutions, we came up with this prioritized list of user requirements we wanted to work on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use a single endpoint to serve everyone.&lt;/li&gt;
  &lt;li&gt;Manage user access to clusters, schemas, tables, and fields.&lt;/li&gt;
  &lt;li&gt;Provide seamless user experience when presto clusters are scaled up/down, in/out, or provisioned/decommissioned.&lt;/li&gt;
  &lt;li&gt;Capture audit trail of user activities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To provide Grabbers with the critical need of interactive querying, as well as performing extract, transform, load (ETL) jobs, we evaluated several technologies. Presto was among the ones we evaluated, and was what we eventually chose although it didn’t meet all of our requirements out of the box. In order to address these gaps, we came up with the idea of a security gateway for the Presto compute engine that could also act as a load balancer/proxy, this is how we ended up creating the DataGateway.&lt;/p&gt;

&lt;p&gt;DataGateway is a service that sits between clients and Presto clusters. It is essentially a smart HTTP proxy server that is an abstraction layer on top of the Presto clusters that handles the following actions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Parse incoming SQL statements to get requested schemas, tables, and fields.&lt;/li&gt;
  &lt;li&gt;Manage user Access Control List (ACL) to limit users’ data access by checking against the SQL parsing results.&lt;/li&gt;
  &lt;li&gt;Manage users’ cluster access.&lt;/li&gt;
  &lt;li&gt;Redirect users’ traffic to the authorized clusters.&lt;/li&gt;
  &lt;li&gt;Show meaningful error messages to users whenever the query is rejected or exceptions from clusters are encountered.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;anatomy-of-datagateway&quot;&gt;Anatomy of DataGateway&lt;/h2&gt;

&lt;p&gt;The DataGateway’s key components are as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;API Service&lt;/li&gt;
  &lt;li&gt;SQL Parser&lt;/li&gt;
  &lt;li&gt;Auth framework&lt;/li&gt;
  &lt;li&gt;Administration UI&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We leveraged Kubernetes to run all these components as microservices.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 1. DataGateway Key Components&quot; height=&quot;90%&quot; width=&quot;90%&quot; src=&quot;/img/data-gateway/image3.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 1. DataGateway Key Components&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;api-service&quot;&gt;API Service&lt;/h3&gt;

&lt;p&gt;This is the component that manages all users and cluster-facing processes. We integrated this service with the Presto API, which means it appears to be the same as a Presto cluster to a client. It accepts query requests from clients, gets the parsing result and runs authorization from the SQL Parser and the Auth Framework.&lt;/p&gt;

&lt;p&gt;If everything is good to go, the API Service forwards queries to the assigned clusters and continues the entire query process.&lt;/p&gt;

&lt;h3 id=&quot;auth-framework&quot;&gt;Auth Framework&lt;/h3&gt;

&lt;p&gt;This handles both authentication and authorization requests. It stores the ACL of users and communicates with the API Service and the SQL Parser to run the entire authentication process. But why is it a microservice instead of a module in API Service, you ask? It’s because we keep evolving the security checks at Grab to ensure that everything is compliant with our security requirements, especially when dealing with data.&lt;/p&gt;

&lt;p&gt;We wanted to make it flexible to fulfill ad-hoc requests from the security team without affecting the API Service. Furthermore, there are different authentication methods out there that we might need to deal with (OAuth2, SSO, you name it). The API Service supports multiple authentication frameworks that enable different authentication methods for different users.&lt;/p&gt;

&lt;h3 id=&quot;sql-parser&quot;&gt;SQL Parser&lt;/h3&gt;

&lt;p&gt;This is a SQL parsing engine to get schema, tables, and fields by reading SQL statements. Since Presto SQL parsing works differently in each version, we would compile multiple SQL Parsers that are identical to the Presto clusters we run. The SQL Parser becomes the single source of truth.&lt;/p&gt;

&lt;h3 id=&quot;admin-ui&quot;&gt;Admin UI&lt;/h3&gt;

&lt;p&gt;This is a UI for Presto administrators to manage clusters and user access, as well as to select an authentication framework, making it easier for the administrators to deal with the entire ecosystem.&lt;/p&gt;

&lt;h2 id=&quot;how-we-deployed-datagateway-using-kubernetes&quot;&gt;How we deployed DataGateway using Kubernetes&lt;/h2&gt;

&lt;p&gt;In the past couple of years, we’ve had significant growth in workloads from analysts and data scientists. As we were very enthusiastic about Kubernetes, DataGateway was chosen as one of the earliest services for deployment in Kubernetes. DataGateway in Kubernetes is known to be highly available and fully scalable to handle traffic from users and systems.&lt;/p&gt;

&lt;p&gt;We also tested the &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough&quot;&gt;HPA feature of Kubernetes&lt;/a&gt;, which is a dynamic scaling feature to scale in or out the number of pods based on actual traffic and resource consumption.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 2. DataGateway deployment using Kubernetes&quot; height=&quot;90%&quot; width=&quot;90%&quot; src=&quot;/img/data-gateway/image1.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 2. DataGateway deployment using Kubernetes&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;functionality-of-datagateway&quot;&gt;Functionality of DataGateway&lt;/h2&gt;

&lt;p&gt;This section highlights some of the ways we use DataGateway to manage our Presto ecosystem efficiently.&lt;/p&gt;

&lt;h3 id=&quot;restrict-users-based-on-schematable-level-access&quot;&gt;Restrict users based on Schema/Table level access&lt;/h3&gt;

&lt;p&gt;In a setup where a Presto cluster is deployed on &lt;a href=&quot;https://aws.amazon.com/emr&quot;&gt;AWS Amazon Elastic MapReduce (EMR)&lt;/a&gt; or &lt;a href=&quot;https://aws.amazon.com/eks&quot;&gt;Elastic Kubernetes Service (EKS)&lt;/a&gt;, we configure an &lt;a href=&quot;https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html&quot;&gt;IAM&lt;/a&gt; role and attach it to the EMR or EKS nodes. The IAM role is set to limit the access to S3 storage. However, the IAM only provides bucket-level and file-level control; it doesn’t meet our requirements to have schema, table, and column-level ACLs. That’s how DataGateway is found useful in such scenarios.&lt;/p&gt;

&lt;p&gt;One of the DataGateway services is an SQL Parser. As previously covered, this is a service that parses and digs out schemas and tables involved in a query. The API service receives the parsing result and checks against the ACL of users, and decides whether to allow or reject the query. This is a remarkable improvement in our security control since we now have another layer to restrict access, on top of the S3 storage. We’ve implemented an SQL-based access control down to table level.&lt;/p&gt;

&lt;p&gt;As shown in the Figure 3, user A is trying run a SQL statement &lt;code class=&quot;highlighter-rouge&quot;&gt;select * from locations.cities&lt;/code&gt;. The SQL Parser reads the statement and tells the API service that user A is trying to read data from the table &lt;code class=&quot;highlighter-rouge&quot;&gt;cities&lt;/code&gt; in the schema &lt;code class=&quot;highlighter-rouge&quot;&gt;locations&lt;/code&gt;. Then, the API service checks against the ACL of user A. The service finds that user A has only read access to table &lt;code class=&quot;highlighter-rouge&quot;&gt;countries&lt;/code&gt; in schema &lt;code class=&quot;highlighter-rouge&quot;&gt;locations&lt;/code&gt;. Eventually, the API service denies this attempt because user A doesn’t have read access to table &lt;code class=&quot;highlighter-rouge&quot;&gt;cities&lt;/code&gt; in the schema &lt;code class=&quot;highlighter-rouge&quot;&gt;locations&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 3. An example of how to check user access to run SQL statements&quot; height=&quot;90%&quot; width=&quot;90%&quot; src=&quot;/img/data-gateway/image5.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 3. An example of how to check user access to run SQL statements&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The above flow shows an access denied result because the user doesn’t have the appropriate permissions.&lt;/p&gt;

&lt;h3 id=&quot;seamless-user-experience-during-the-emr-migration&quot;&gt;Seamless User Experience during the EMR migration&lt;/h3&gt;

&lt;p&gt;We use AWS EMR to deploy Presto as an SQL query engine since deployment is really easy. However, without DataGateway, any EMR operations such as terminations, new cluster deployment, config changes, and version upgrades, would require quite a bit of user involvement. We would sometimes need users to make changes on their side. For example, request users to change the endpoints to connect to suitable clusters.&lt;/p&gt;

&lt;p&gt;With DataGateway, ACLs exist for each of the user accounts. The ACL includes the list of EMR clusters that users are allowed to access. As a Presto access management platform, here the DataGateway redirects user traffics to an appropriate cluster based on the ACL, like a proxy. Users always connect to the same endpoint we offer, which is the DataGateway. To switch over from one cluster to another, we just need to edit the cluster ACL and everything is handled seamlessly.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 4. Cluster switching using DataGateway&quot; height=&quot;90%&quot; width=&quot;90%&quot; src=&quot;/img/data-gateway/image4.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 4. Cluster switching using DataGateway&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Figure 4 highlights the case when we’re switching EMR from one cluster to another. No changes are required from users.&lt;/p&gt;

&lt;p&gt;We executed the migration of our entire Presto platform from an AWS EMR instance to another AWS EMR instance using the same methodology. The migrations were executed with little to no disruption for our users. We were able to move 40 clusters with hundreds of users. They were able to issue millions of queries daily in a few phases over a couple of months.&lt;/p&gt;

&lt;p&gt;In most cases, users didn’t have to make any changes on their end, they just continued using Presto as usual while we made the changes in the background.&lt;/p&gt;

&lt;h3 id=&quot;multi-cloud-data-lakepresto-cluster-maintenance&quot;&gt;Multi-Cloud Data Lake/Presto Cluster maintenance&lt;/h3&gt;

&lt;p&gt;Recently, we started to build and maintain data lakes not just in one cloud, but two - in AWS and Azure. Since most end-users are AWS-based, and each team has their own AWS sub-account to run their services and workloads, it would be a nightmare to bridge all the connections and access routes between these two clouds from end-to-end, sub-account by sub-account.&lt;/p&gt;

&lt;p&gt;Here, the DataGateway plays the role of the multi-cloud gateway. Since all end-users’ AWS sub-accounts have peered to DataGateway’s network, everything becomes much easier to handle.&lt;/p&gt;

&lt;p&gt;For end-users, they retain the same Presto connection profile. The DE team then handles the connection setup from DataGateway to Azure, and also the deployment of Presto clusters in Azure.&lt;/p&gt;

&lt;p&gt;When all is set, end-users use the same endpoint to DataGateway. We offer a feature called &lt;em&gt;Cluster Switch&lt;/em&gt; that allows users to switch between AWS Presto cluster and Azure Presto Cluster on the fly by filling in parameters on the connection string. This feature allows users to switch to their target Presto cluster without any endpoint changes. The switch works instantly whenever they do the change. That means users can run different queries in different clusters based on their requirements.&lt;/p&gt;

&lt;p&gt;This feature has helped the DE team to maintain Presto Cluster easily. We can spin up different Presto clusters for different teams, so that each team has their own query engine to run their queries with dedicated resources.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 5. Sub-account connections and Queries&quot; height=&quot;75%&quot; width=&quot;75%&quot; src=&quot;/img/data-gateway/image6.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 5. Sub-account connections and Queries&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Figure 5 shows an example of how sub-accounts connect to DataGateway and run queries on resources in different clouds and clusters.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Figure 6. Sample scenario without DataGateway&quot; height=&quot;90%&quot; width=&quot;90%&quot; src=&quot;/img/data-gateway/image2.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Figure 6. Sample scenario without DataGateway&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Figure 6 shows a scenario of what would happen if DataGatway doesn’t exist. Each of the accounts would have to maintain its own connections, &lt;a href=&quot;https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html&quot;&gt;Virtual Private C&lt;/a&gt;&lt;a href=&quot;https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html&quot;&gt;loud (VPC)&lt;/a&gt; peering, and express link to connect to our Presto resources.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;DataGateway is playing a key role in Grab’s entire Presto ecosystem. It helps us manage user access and cluster selections on a single endpoint, ensuring that everyone is running their Presto queries on the same place. It also helps distribute workload to different types and versions of Presto clusters.&lt;/p&gt;

&lt;p&gt;When we started to deploy the DataGateway on Kubernetes, our vision for the Presto ecosystem underwent an epic change as it further motivated us to continuously improve. Since then, we’ve had new ideas on deployment method/pipeline, microservice implementations, scaling strategy, resource control, we even made use of Kubernetes and designed an on-demand, container-based Presto cluster provisioning engine. We’ll share this in another engineering blog, so do stay tuned!.&lt;/p&gt;

&lt;p&gt;We also made crucial enhancements on data access control as we extended Presto’s access controls down to the schema/table-level.&lt;/p&gt;

&lt;p&gt;In day-to-day operations, especially when we started to implement data lake in multiple clouds, DataGateway solved a lot of implementation issues. DataGateway made it simpler to switch a user’s Presto cluster from one cloud to another or allow a user to use a different Presto cluster using parameters. DataGateway allowed us to provide a seamless experience to our users.&lt;/p&gt;

&lt;p&gt;Looking forward, we’ve more and more ideas for our Presto ecosystem, such Spark DataGateway or AWS Athena integrations, to keep our data safe at any time and to provide our users with a smoother experience when dealing with data used for analysis or research.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored by Vinnson Lee on behalf of the Presto Development Team at Grab - Edwin Law, Qui Hieu Nguyen, Rahul Penti, Wenli Wan, Wang Hui and the Data Engineering Team.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Aug 2020 08:12:56 +0000</pubDate>
        <link>https://engineering.grab.com/data-gateway</link>
        <guid isPermaLink="true">https://engineering.grab.com/data-gateway</guid>
        
        <category>Engineering</category>
        
        <category>Presto</category>
        
        <category>Data</category>
        
        <category>Data Pipeline</category>
        
        <category>Access Control</category>
        
        <category>Workload Distribution</category>
        
        <category>Cluster</category>
        
        
        <category>Engineering</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Go Modules- A guide for monorepos (Part 2)</title>
        <description>&lt;p&gt;This is the second post on the Go module series, which highlights Grab’s experience working with Go modules in a multi-module monorepo. In this article, we’ll focus on suggested solutions for catching unexpected changes to the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file and addressing dependency issues. We’ll also cover automatic upgrades and other learnings uncovered from the initial obstacles in using Go modules.&lt;/p&gt;

&lt;h2 id=&quot;vendoring-process-issues&quot;&gt;Vendoring process issues&lt;/h2&gt;

&lt;p&gt;Our previous vendoring process fell solely on the developer who wanted to add or update a dependency. However, it was often the case that the developer came across many unexpected changes, due to previous vendoring attempts, accidental imports and changes to dependencies.&lt;/p&gt;

&lt;p&gt;The developer would then have to resolve these issues before being able to make a change, costing time and causing frustration with the process. It became clear that it wasn’t practical to expect the developer to catch all of the potential issues while vendoring, especially since Go modules itself was new and still in development.&lt;/p&gt;

&lt;h2 id=&quot;avoiding-unexpected-changes&quot;&gt;Avoiding unexpected changes&lt;/h2&gt;

&lt;p&gt;Reluctantly, we added a check to our CI process which ran on every merge request. This helped ensure that there are no unexpected changes required to go mod. This added time to every build and often flagged a failure, but it saved a lot of post-merge hassle. We then realized that we should have done this from the beginning.&lt;/p&gt;

&lt;p&gt;Since we hadn’t enabled Go modules for builds yet, we couldn’t rely on the &lt;a href=&quot;https://godoc.org/cmd/go%23hdr-Maintaining_module_requirements&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\mod=readonly&lt;/code&gt;&lt;/a&gt; flag. We implemented the check by running &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod vendor&lt;/code&gt; and then checking the resulting difference.&lt;/p&gt;

&lt;p&gt;If there were any changes to &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; or the vendor directory, the merge request would get rejected. This worked well in ensuring the integrity of our &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;roadblocks-and-learnings&quot;&gt;Roadblocks and learnings&lt;/h2&gt;

&lt;p&gt;However, as this was the first time we were using Go modules on our CI system, it uncovered some more problems.&lt;/p&gt;

&lt;h3 id=&quot;private-repository-access&quot;&gt;Private repository access&lt;/h3&gt;

&lt;p&gt;There was the problem of accessing private repositories. We had to ensure that the CI system was able to clone all of our private repositories as well as the main monorepo, by adding the relevant SSH deploy keys to the repository.&lt;/p&gt;

&lt;h3 id=&quot;false-positives&quot;&gt;False positives&lt;/h3&gt;

&lt;p&gt;The check sometimes fired &lt;code class=&quot;highlighter-rouge&quot;&gt;false positives&lt;/code&gt; - detecting a go mod failure when there were no changes. This was often due to network issues, especially when the modules are hosted by less reliable third-party servers. This is somewhat solved in Go 1.13 onwards with the introduction of &lt;a href=&quot;https://golang.org/cmd/go/%23hdr-Module_downloading_and_verification&quot;&gt;proxy servers&lt;/a&gt;, but our workaround was simply to retry the command several times.&lt;/p&gt;

&lt;p&gt;We also avoided adding dependencies hosted by a domain that we haven’t seen before, unless absolutely necessary.&lt;/p&gt;

&lt;h3 id=&quot;inconsistent-go-versions&quot;&gt;Inconsistent Go versions&lt;/h3&gt;

&lt;p&gt;We found several inconsistencies between Go versions - running go mod vendor on one Go version gave different results to another. One example was a &lt;a href=&quot;https://github.com/golang/go/issues/29278&quot;&gt;change to the checksums&lt;/a&gt;. These inconsistencies are less common now, but still remain between Go 1.12 and later versions. The only solution is to stick to a single version when running the vendoring process.&lt;/p&gt;

&lt;h2 id=&quot;automated-upgrades&quot;&gt;Automated upgrades&lt;/h2&gt;

&lt;p&gt;There are benefits to using Go modules for vendoring. It’s faster than previous solutions, better supported by the community and it’s part of the language, so it doesn’t require any extra tools or wrappers to use it.&lt;/p&gt;

&lt;p&gt;One of the most useful benefits from using Go modules is that it enables automated upgrades of dependencies in the go.mod file - and it becomes more useful as more third-party modules adopt Go modules and semantic versioning.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/go-module-a-guide-for-monorepos-part-2/image1.png&quot; alt=&quot;Automated updates workflow&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Automated updates workflow&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;We call our solution for automating updates at Grab the AutoVend Bot. It is built around a single Go command, &lt;code class=&quot;highlighter-rouge&quot;&gt;go list -m -u all&lt;/code&gt;, which finds and lists available updates to the dependencies listed in &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; (add &lt;code class=&quot;highlighter-rouge&quot;&gt;\json&lt;/code&gt; for JSON output). We integrated the bot with our development workflow and change-request system to take the output from this command and create merge requests automatically, one per update.&lt;/p&gt;

&lt;p&gt;Once the merge request is approved (by a human, after verifying the test results), the bot would push the change. We have hundreds of dependencies in our main monorepo module, so we’ve scheduled it to run a small number each day so we’re not overwhelmed.&lt;/p&gt;

&lt;p&gt;By reducing the manual effort required to update dependencies to almost nothing, we have been able to apply hundreds of updates to our dependencies, and ensure our most critical dependencies are on the latest version. This not only helps keep our dependencies free from bugs and security flaws, but it makes future updates far easier and less impactful by reducing the set of changes needed.&lt;/p&gt;

&lt;h2 id=&quot;in-summary&quot;&gt;In Summary&lt;/h2&gt;

&lt;p&gt;Using Go modules for vendoring has given us valuable and low-risk exposure to the feature. We have been able to detect and solve issues early, without affecting our regular builds, and develop tooling that’ll help us in future.&lt;/p&gt;

&lt;p&gt;Although Go modules is part of the standard Go toolchain, it shouldn’t be viewed as a complete &lt;em&gt;off the shelf&lt;/em&gt; solution that can be dropped into a codebase, especially a monorepo.&lt;/p&gt;

&lt;p&gt;Like many other Go tools, the Modules feature comprises many small, focused tools that work best when combined together with other code. By embracing this concept and leveraging things like go list, go mod graph and go mod vendor, Go modules can be made to integrate into existing workflows, and deliver the benefits of structured versioning and reproducible builds.&lt;/p&gt;

&lt;p&gt;I hope you have enjoyed this article on using Go modules and vendoring within a monorepo.&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;

&lt;h4 id=&quot;credits&quot;&gt;Credits&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The cute Go gopher logo for this blog’s cover image was inspired by Renee French’s original work.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 12 Aug 2020 10:02:00 +0000</pubDate>
        <link>https://engineering.grab.com/go-module-a-guide-for-monorepos-part-2</link>
        <guid isPermaLink="true">https://engineering.grab.com/go-module-a-guide-for-monorepos-part-2</guid>
        
        <category>Go</category>
        
        <category>Monorepo</category>
        
        <category>Vendoring</category>
        
        <category>Vendors</category>
        
        <category>Libraries</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>The journey of deploying Apache Airflow at Grab</title>
        <description>&lt;p&gt;At Grab, we use &lt;a href=&quot;https://airflow.apache.org&quot;&gt;Apache Airflow&lt;/a&gt; to schedule and orchestrate the ingestion and transformation of data,  train machine learning models, and the copy data between clouds. There are many engineering teams at Grab that use Airflow, each of which originally had their own Airflow instance.&lt;/p&gt;

&lt;p&gt;The proliferation of independently managed Airflow instances resulted in inefficient use of resources, where each team ended up solving the same problems of logging, scaling, monitoring, and more. From this morass came the idea of having a single dedicated team to manage all the Airflow instances for anyone in Grab that wants to use Airflow as a scheduling tool.&lt;/p&gt;

&lt;p&gt;We designed and implemented an Apache Airflow-based scheduling and orchestration platform that currently runs close to 20 Airflow instances for different teams at Grab. Sounds interesting? What follows is a brief history.&lt;/p&gt;

&lt;h2 id=&quot;early-days&quot;&gt;Early days&lt;/h2&gt;

&lt;p&gt;Circa 2018, we were running a few hundred Directed Acyclic Graphs (DAGs) on one Airflow instance in the Data Engineering team. There was no dedicated team to maintain it, and no Airflow expert in our team. We were struggling to maintain our Airflow instance, which was causing many jobs to fail every day. We were facing issues with library management, scaling, managing and syncing artefacts across all Airflow components, upgrading Airflow versions, deployment, rollbacks, etc.&lt;/p&gt;

&lt;p&gt;After a few postmortem reports, we realized that we needed a dedicated team to maintain our Airflow. This was how our Airflow team was born.&lt;/p&gt;

&lt;p&gt;In the initial months, we dedicated ourselves to stabilizing our Airflow environment. During this process, we realized that Airflow has a steep learning curve and requires time and effort to understand and maintain properly. Also, we found that tweaking of Airflow configurations required a thorough understanding of Airflow internals.&lt;/p&gt;

&lt;p&gt;We felt that for the benefit of everyone at Grab, we should leverage what we learned about Airflow to help other teams at Grab; there was no need for anyone else to go through the same struggles we did. That’s when we started thinking about managing Airflow for other teams.&lt;/p&gt;

&lt;p&gt;We talked to the Data Science and Engineering teams who were also running Airflow to schedule their jobs. Almost all the teams were struggling to maintain their Airflow instance. A few teams didn’t have enough technical expertise to maintain their instance. The Data Scientists and Analysts that we spoke to were more than happy to outsource the overhead of Airflow maintenance and wanted to focus more on their Data Science use cases instead.&lt;/p&gt;

&lt;p&gt;We started working with one of the Data Science teams and initiated the discussion to create a dockerized Airflow instance and run it on our Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;We created the Airflow instance and maintained it for them. Later, we were approached by two more teams to help with their Airflow instances. This was the trigger for us to design and create a platform on which we can efficiently manage Airflow instances for different teams.&lt;/p&gt;

&lt;h2 id=&quot;current-state&quot;&gt;Current state&lt;/h2&gt;

&lt;p&gt;As mentioned, we are currently serving close to 20 Airflow instances for various teams on this platform and leverage Apache Airflow to schedule thousands of daily jobs.  Each Airflow instance is currently scheduling 1k to 60k daily jobs. Also, new teams can quickly try out Airflow without worrying about infrastructure and maintenance overhead. Let’s go through the important aspects of this platform such as design considerations, architecture, deployment, scalability, dependency management, monitoring and alerting, and more.&lt;/p&gt;

&lt;h3 id=&quot;design-considerations&quot;&gt;Design considerations&lt;/h3&gt;

&lt;p&gt;The initial step we took towards building our scheduling platform was to define a set of expectations and guidelines around ownership, infrastructure, authentication, common artifacts and CI/CD, to name a few.&lt;/p&gt;

&lt;p&gt;These were the considerations we had in mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deploy containerized Airflow instances on Kubernetes cluster to isolate Airflow instances at the team level. It should scale up and scale out according to usage.&lt;/li&gt;
  &lt;li&gt;Each team can have different sets of jobs that require specific dependencies on the Airflow server.&lt;/li&gt;
  &lt;li&gt;Provide common CI/CD templates to build, test, and deploy Airflow instances. These CI/CD templates should be flexible enough to be extended by users and modified according to their use case.&lt;/li&gt;
  &lt;li&gt;Common plugins, operators, hooks, sensors will be shipped to all Airflow instances. Moreover, each team can have its own plugins, operators, hooks, and sensors.&lt;/li&gt;
  &lt;li&gt;Support LDAP based authentication as it is natively supported by Apache Airflow. Each team can authenticate Airflow UI by their LDAP credentials.&lt;/li&gt;
  &lt;li&gt;Use the Hashicorp Vault to store Airflow specific secrets. Inject these secrets via sidecar in Airflow servers.&lt;/li&gt;
  &lt;li&gt;Use ELK stack to access all application logs and infrastructure logs.&lt;/li&gt;
  &lt;li&gt;Datadog and PagerDuty will be used for monitoring and alerting.&lt;/li&gt;
  &lt;li&gt;Ingest job statistics such as total number of jobs scheduled, no of failed jobs, no of successful jobs, active DAGs, etc. into the data lake and will be accessible via Presto.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/the-journey-of-deploying-apache-airflow-at-Grab/image2.png&quot; alt=&quot;Architecture diagram&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Architecture diagram&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;infrastructure-management&quot;&gt;Infrastructure management&lt;/h3&gt;

&lt;p&gt;Initially, we started deploying Airflow instances on  Kubernetes clusters managed via &lt;a href=&quot;https://github.com/kubernetes/kops&quot;&gt;Kubernetes Operations (KOPS)&lt;/a&gt;. Later, we migrated to Amazon EKS to reduce the overhead of managing the Kubernetes control plane. Each Kubernetes namespace deploys one Airflow instance.&lt;/p&gt;

&lt;p&gt;We chose Terraform to manage infrastructure as code. We deployed each Airflow instance using Terraform modules, which include a &lt;strong&gt;helm_release&lt;/strong&gt; Terraform resource on top of our customized Airflow Helm Chart.&lt;/p&gt;

&lt;p&gt;Each Airflow instance connects to its own Redis and RDS. RDS is responsible for storing Airflow metadata and Redis is acting as a celery broker between Airflow scheduler and Airflow workers.&lt;/p&gt;

&lt;p&gt;The Hashicorp Vault is used to store secrets required by Airflow instances and injected via sidecar by each Airflow component. The ELK stack stores all logs related to Airflow instances and is used for troubleshooting any instance. Datadog, Slack, and PagerDuty are used to send alerts.&lt;/p&gt;

&lt;p&gt;Presto is used to access job statistics, such as numbers on scheduled jobs, failed jobs, successful jobs, and active DAGs, to help each team to analyze their usage and stability of their jobs.&lt;/p&gt;

&lt;h3 id=&quot;doing-things-at-scale&quot;&gt;Doing things at scale&lt;/h3&gt;

&lt;p&gt;There are two kinds of scaling we need to talk about:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;scaling of Airflow instances on a resource level handling different loads&lt;/li&gt;
  &lt;li&gt;scaling in terms of teams served on the platform&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To scale Airflow instances, we set the request and the limit of each Airflow component allowing any of the components to scale up easily. To scale out Airflow workers, we decided to enable the horizontal pod autoscaler (HPA) using Memory and CPU parameters. The cluster autoscaler on EKS helps in scaling the platform to accommodate more teams.&lt;/p&gt;

&lt;p&gt;Moreover, we categorized all our Airflow instances in three sizes (small, medium, and large) to efficiently use the resources. This was based on how many hourly/daily jobs it scheduled. Each Airflow instance type has a specific RDS instance type and storage, Redis instance type and CPU and memory, request/limit for scheduler, worker, web server, and flower. There are different Airflow configurations for each instance type to optimize the given resources to the Airflow instance.&lt;/p&gt;

&lt;h3 id=&quot;airflow-image-and-version-management&quot;&gt;Airflow image and version management&lt;/h3&gt;

&lt;p&gt;The Airflow team builds and releases one common base Docker image for each Airflow version. The base image has Airflow installed with specific versions, as well as common Python packages, plugins, helpers, tests, patches, and so on.&lt;/p&gt;

&lt;p&gt;Each team has their customized Docker image on top of the base image. In their customized Docker image, they can update the Python packages and can download other artifacts that they require. Each Airflow instance will be deployed using the team’s customized image.&lt;/p&gt;

&lt;p&gt;There are common CI/CD templates provided by the Airflow team to build the customized image, run unit tests, and deploy Airflow instances from their GitLab pipeline.&lt;/p&gt;

&lt;p&gt;To upgrade the Airflow version, the Airflow team reviews and studies the changelog of the released Airflow version, note down the important features and its impacts, open issues, bugs, and workable solutions. Later, we build and release the base Docker image using the new Airflow version.&lt;/p&gt;

&lt;p&gt;We support only one Airflow version for all Airflow instances to have less maintenance overhead. In the case of minor or major versions, we support one old and new versions until the retirement period.&lt;/p&gt;

&lt;h3 id=&quot;how-do-we-deploy&quot;&gt;How do we deploy&lt;/h3&gt;

&lt;p&gt;There is a deployment ownership guideline that explains the schedule of deployments and the corresponding PICs. All teams have agreed on this guideline and share the responsibility with the Airflow Team.&lt;/p&gt;

&lt;p&gt;There are two kinds of deployment:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DAG deployment&lt;/strong&gt;: This is part of the common GitLab CI/CD template. The Airflow team doesn’t trigger the DAG deployment, it’s fully owned by the teams.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Airflow instance deployment&lt;/strong&gt;: The Airflow instance deployment is required in these scenarios:
    &lt;ol&gt;
      &lt;li&gt;update in base Docker image&lt;/li&gt;
      &lt;li&gt;add/update in Python packages by any team&lt;/li&gt;
      &lt;li&gt;customization in the base image by any team&lt;/li&gt;
      &lt;li&gt;change in Airflow configurations&lt;/li&gt;
      &lt;li&gt;change in the resource of scheduler, worker, web server or flower&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;base-docker-image-update&quot;&gt;Base Docker image update&lt;/h4&gt;

&lt;p&gt;The Airflow team maintains the base Docker image on the AWS Elastic Container Registry. The GitLab CI/CD builds the updated base image whenever the Airflow team changes the base image. The base image is validated by automated deployment on the test environment and automated smoke test. The Airflow instance owner of each team needs to trigger their build and deployment pipeline to apply the base image changes on their Airflow instance.&lt;/p&gt;

&lt;h4 id=&quot;python-package-additions-or-updates&quot;&gt;Python package additions or updates&lt;/h4&gt;

&lt;p&gt;Each team can add or update their Python dependencies. The Gitlab CI/CD pipeline builds a new image with updated changes. The Airflow instance owner manually triggers the deployment from their CI/CD pipeline. There is a flag to make it automated deployment as well.&lt;/p&gt;

&lt;h4 id=&quot;based-image-customization&quot;&gt;Based image customization&lt;/h4&gt;

&lt;p&gt;Each team can add any customizations on the base image. Similar to the above scenario, the Gitlab CI/CD pipeline builds a new image with updated changes. The Airflow instance owner manually triggers the deployment from their CI/CD pipeline. To automate the deployment, a flag is made available.&lt;/p&gt;

&lt;h4 id=&quot;configuration-airflow-and-airflow-component-resource-changes&quot;&gt;Configuration Airflow and Airflow component resource changes&lt;/h4&gt;

&lt;p&gt;To optimize the Airflow instances, the Airflow Team makes changes to the Airflow configurations and resources of any of the Airflow components. The Airflow configurations and resources are also part of the Terraform code. Atlantis (&lt;a href=&quot;https://www.runatlantis.io/&quot;&gt;https://www.runatlantis.io/&lt;/a&gt;) deploys the Airflow instances with Terraform changes.&lt;/p&gt;

&lt;p&gt;There is no downtime in any form of deployment and doesn’t impact the running tasks and the Airflow UI.&lt;/p&gt;

&lt;h3 id=&quot;testing&quot;&gt;Testing&lt;/h3&gt;

&lt;p&gt;During the process of making our first Airflow stable, we started exploring testing in Airflow. We wanted to validate the correctness of DAGs, duplicate DAG IDs, checking typos and cyclicity in DAGs, etc. We then later wrote the tests by ourselves and published a detailed blog in several channels: &lt;a href=&quot;https://blog.usejournal.com/testing-in-airflow-part-1-dag-validation-tests-dag-definition-tests-and-unit-tests-2aa94970570c&quot;&gt;usejournal (part1)&lt;/a&gt; and &lt;a href=&quot;https://medium.com/@chandukavar/testing-in-airflow-part-2-integration-tests-and-end-to-end-pipeline-tests-af0555cd1a82&quot;&gt;medium (part2)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These tests are available in the base image and run in the GitLab pipeline from the user’s repository to validate their DAGs. The unit tests run using the common GitLab CI/CD template provided by the Airflow team.&lt;/p&gt;

&lt;h3 id=&quot;monitoring--alerting&quot;&gt;Monitoring &amp;amp; alerting&lt;/h3&gt;

&lt;p&gt;Our scheduling platform runs the Airflow instance for many critical jobs scheduled by each team. It’s important for us to monitor all Airflow instances and alert respective stakeholders in case of any failure.&lt;/p&gt;

&lt;p&gt;We use a Datadog for monitoring and alerting. To create a common Datadog dashboard, it is required to pass tags with metrics from Airflow and till Airflow 1.10.x, it doesn’t support tagging to Datadog metrics.&lt;/p&gt;

&lt;p&gt;We have contributed to the community to enable Datadog support and it will be released in Airflow 2.0.0 (&lt;a href=&quot;https://github.com/apache/airflow/pull/7376&quot;&gt;https://github.com/apache/Airflow/pull/7376&lt;/a&gt;). We internally patched this pull request and created the common Datadog dashboard.&lt;/p&gt;

&lt;p&gt;There are three categories of metrics that we are interested in:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;EKS cluster metrics&lt;/strong&gt;: It includes total In-Service Nodes, allocated CPU cores, allocated Memory, Node status, CPU/Memory request vs limit, Node disk and Memory pressure, Rx-Tx packets dropped/errors, etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Host Metrics&lt;/strong&gt;: These metrics are for each host participating in the EKS cluster. It includes Host CPU/Memory utilization, Host free memory, System disk, and EBS IOPS, etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Airflow instance metrics&lt;/strong&gt;: These metrics are for each Airflow instance. It includes scheduler heartbeats, DagBag size, DAG processing import errors, DAG processing time, open/used slots in a pool, each pod’s Memory/CPU usage, CPU and Memory utilization of metadata DB, database connections as well as the number of workers, active/paused DAGs, successful/failed/queued/running tasks, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/the-journey-of-deploying-apache-airflow-at-Grab/image1.png&quot; alt=&quot;Sample Datadog dashboard&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Sample Datadog dashboard&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;We alert respective stakeholders and oncalls using Slack and PagerDuty.&lt;/p&gt;

&lt;h3 id=&quot;benefits&quot;&gt;Benefits&lt;/h3&gt;

&lt;p&gt;These are the benefits of having our own Scheduling Platform:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scaling&lt;/strong&gt;: HPA on Airflow workers running on EKS with autoscaler helps Airflow workers to scale automatically to theoretically infinite scale. This enables teams to run thousands of DAGs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;: Centralized logging using Kibana.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Better Isolation&lt;/strong&gt;: Separate Docker images for each team provide better isolation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Better Customization&lt;/strong&gt;: All teams are provided with a mechanism to customize their Airflow worker environment according to their requirements.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Downtime&lt;/strong&gt;: Rolling upgrade and termination period on Airflow workers helps in zero downtime during the deployment.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Efficient usage of infrastructure&lt;/strong&gt;: Each team doesn’t need to allocate infrastructure for Airflow instances. All Airflow instances are deployed on one shared EKS cluster.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Less maintenance overhead for users&lt;/strong&gt;:  Users can focus on their core work and don’t need to spend time maintaining Airflow instances and it’s resources.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Common plugins and helpers&lt;/strong&gt;: All common plugins and helpers available to use on Airflow instances. Each team doesn’t need to add.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Designing and implementing our own scheduling platform started with many challenges and unknowns. We were not sure about the scale we were aiming for, the heterogeneous workload from each team, or the level of triviality or complexity we were going to be faced. After two years, we have successfully built and productionized a scalable scheduling platform that helps teams at Grab to schedule their workload.&lt;/p&gt;

&lt;p&gt;We have many failure stories, odd things we ran into, hacks and workarounds we patched. But, we went through it and provided a cost-effective and scalable scheduling platform with low maintenance overhead to all teams at Grab.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;Moving ahead, we will be exploring to add the following capabilities:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;REST APIs to enable teams to access their Airflow instance programmatically and have better integration with other tools and frameworks.&lt;/li&gt;
  &lt;li&gt;Support of dynamic DAGs at scale to help in decreasing the DAG maintenance overhead.&lt;/li&gt;
  &lt;li&gt;Template-based engine to act as a middle layer between the scheduling platform and external systems. It will have a set of templates to generate DAGs which helps in better integration with the external system.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We suggest anyone who is running multiple Airflow instances within different teams to look at this approach and build the centralized scheduling platform. Before you begin,  review the feasibility of building the centralized platform as it requires a vision, a lot of effort, and cross-communication with many teams.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored by Chandulal Kavar on behalf of the Airflow team at Grab - Charles Martinot, Vinnson Lee, Akash Sihag, Piyush Gupta, Pramiti Goel, Dewin Goh, QuiHieu Nguyen, James Anh-Tu Nguyen, and the Data Engineering Team.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Tue, 14 Jul 2020 10:34:40 +0000</pubDate>
        <link>https://engineering.grab.com/the-journey-of-deploying-apache-airflow-at-Grab</link>
        <guid isPermaLink="true">https://engineering.grab.com/the-journey-of-deploying-apache-airflow-at-Grab</guid>
        
        <category>Engineering</category>
        
        <category>Data Pipeline</category>
        
        <category>Scheduling</category>
        
        <category>Airflow</category>
        
        <category>Kubernetes</category>
        
        <category>Platform</category>
        
        
        <category>Engineering</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>How we built our in-house chat platform for the web</title>
        <description>&lt;p&gt;At Grab, we’ve built an in-house chat platform to help connect our passengers with drivers during a booking, as well as with their friends and family for social sharing purposes.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image6.png&quot; alt=&quot;P2P chat for the Angbow campaign and GrabHitch chat&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;P2P chat for the Angbow campaign and GrabHitch chat&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;We wanted to focus on our customer support chat experience, and so we replaced the third-party live chat tool that we’ve used for years with our newly developed chat platform. As a part of this initiative, we extended this platform for the web to integrate with our internal Customer Support portal.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image3.png&quot; alt=&quot;Sample chat between a driver and a customer support agent&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Sample chat between a driver and a customer support agent&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;This is the first time we introduced chat on the web, and we faced a few challenges while building it. In this article, we’ll go over some of these challenges and how we solved them.&lt;/p&gt;

&lt;h2 id=&quot;current-architecture&quot;&gt;Current Architecture&lt;/h2&gt;

&lt;p&gt;A vast majority of the communication from our Grab Passenger and Driver apps happens via TCP. Our TCP gateway takes care of processing all the incoming messages, authenticating, and routing them to the respective services. Our TCP connections are unicast, which means there is only one active connection possible per user at any point in time. This served us well, as we only allow our users to log in from one device at a time.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image2.png&quot; alt=&quot;A TL;DR version of our current system&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;A TL;DR version of our current system&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;However, this model breaks on the web since our users can have multiple tabs open at the same time, and each would establish a new socket connection. Due to the unicast nature of our TCP connections, the older tabs would get disconnected and wouldn’t receive any messages from our servers. Our Customer Support agents love their tabs and have a gazillion open at any time. This behaviour would be too disruptive for them.&lt;/p&gt;

&lt;p&gt;The obvious answer was to change our TCP connection strategy to multicast. We took a look at this and quickly realised that it was going to be a huge undertaking and could introduce a lot of unknowns for us to deal with.&lt;/p&gt;

&lt;p&gt;We had to consider a different approach for the web and zeroed in on a hybrid approach with a little known Javascript APIs called &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/SharedWorker&quot;&gt;SharedWorker&lt;/a&gt; and &lt;a href=&quot;https://developers.google.com/web/updates/2016/09/broadcastchannel&quot;&gt;BroadcastChannel&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;understanding-the-basics&quot;&gt;Understanding the basics&lt;/h2&gt;

&lt;p&gt;Before we jump in, let’s take a quick detour to review some of the terminologies that we’ll be using in this post.&lt;/p&gt;

&lt;p&gt;If you’re familiar with how WebWorker works, feel free to skip ahead to the next section. For the uninitiated, JavaScript on the browser runs in a single-threaded environment. Workers are a mechanism to introduce background, OS-level threads in the browser. Creating a worker in JavaScript is simple. Let’s look at it with an example:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//instantiate a worker&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;WebWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;./worker.js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Ping&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Message from the worker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// and in  worker.js&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;onMessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;pong&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The worker API comes with a handy &lt;code class=&quot;highlighter-rouge&quot;&gt;postMessage&lt;/code&gt; method which can be used to pass messages between the main thread and worker thread. Workers are a great way to add concurrency in a JavaScript application and help in speeding up an expensive process in the background.&lt;/p&gt;

&lt;p&gt;Note: While the method looks similar, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Worker/postMessage&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;worker.postMessage&lt;/code&gt;&lt;/a&gt; is not the same as &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;window.postMessage&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-sharedworker&quot;&gt;What is a SharedWorker?&lt;/h3&gt;

&lt;p&gt;SharedWorker is similar to a WebWorker and spawns an OS thread, but as the name indicates, it’s shared across browser contexts. In other words, there is only one instance of that worker running for that domain across tabs/windows. The API is similar to WebWorker but has a few subtle differences.&lt;/p&gt;

&lt;p&gt;SharedWorkers internally use &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/MessagePort&quot;&gt;MessagePort&lt;/a&gt; to pass messages between the worker thread and the main thread. There are two ports- one for sending a message to the main thread and the other to receive. Let’s explore it with an example:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;mySharedWorker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SharedWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;./worker.js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;mySharedWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;mySharedWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;onconnect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// Handle messages from the main thread&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onmessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;handleEventFromMainThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Message from the main thread&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;handleEventFromMainThread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;I received&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;from the main thread&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sendEventToMainThread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;forEach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is a lot to unpack here. Once a SharedWorker is created, we’ve to manually start the port using &lt;code class=&quot;highlighter-rouge&quot;&gt;mySharedWorker.port.start()&lt;/code&gt; to establish a connection between the script running on the main thread and the worker thread. Post that, messages can be passed via the worker’s &lt;code class=&quot;highlighter-rouge&quot;&gt;postMessage&lt;/code&gt; method. On the worker side, there is an &lt;code class=&quot;highlighter-rouge&quot;&gt;onconnect&lt;/code&gt; callback which helps in setting up listeners for connections from each browser context.&lt;/p&gt;

&lt;p&gt;Under the hood, SharedWorker spawns a single OS thread per worker script per domain. For instance, if the script name is &lt;code class=&quot;highlighter-rouge&quot;&gt;worker.js&lt;/code&gt; running in the domain &lt;code class=&quot;highlighter-rouge&quot;&gt;https://ce.grab.com&lt;/code&gt;. The logic inside &lt;code class=&quot;highlighter-rouge&quot;&gt;worker.js&lt;/code&gt; runs &lt;em&gt;exactly once&lt;/em&gt; in this domain. The advantage of this approach is that we can run multiple worker scripts in the same-origin each managing a different part of the functionality. This was one of the key reasons why we picked SharedWorker over other solutions.&lt;/p&gt;

&lt;h3 id=&quot;what-are-broadcast-channels&quot;&gt;What are Broadcast channels&lt;/h3&gt;

&lt;p&gt;In a multi-tab environment, our users may send messages from any of the tabs and switch to another for the next message. For a seamless experience, we need to ensure that the state is in sync across all the browser contexts.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image1.png&quot; alt=&quot;Message passing across tabs&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Message passing across tabs&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;BroadcastChannel&lt;/code&gt; API creates a message bus that allows us to pass messages between multiple browser contexts within the same origin. This helps us sync the message that’s being sent on the client to all the open tabs.&lt;/p&gt;

&lt;p&gt;Let’s explore the API with a code example:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BroadcastChannel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chat_messages&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Sets up an event listener to receive messages from other browser contexts&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onmessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Received &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sendMessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;new_message&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Publish event to all browser contexts listening on the chat\_messages channel&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;off&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// clear event listeners&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One thing to note here is that communication is restricted to listeners from the same origin.&lt;/p&gt;

&lt;h2 id=&quot;how-are-our-chat-rooms-powered&quot;&gt;How are our chat rooms powered&lt;/h2&gt;

&lt;p&gt;Now that we have a basic understanding of how SharedWorker and Broadcast channels work, let’s take a peek into how Grab is using it.&lt;/p&gt;

&lt;p&gt;Our Chat SDK abstracts the calls to the worker and the underlying transport mechanism. On the surface, the interface just exposes two methods: one for sending a message and another for listening to incoming events from the server.&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IChatSDK&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;sendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ChatMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;sendReadReceipt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;receiptAck&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;MessageReceiptACK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICallBack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SDKTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The SDK does all the heavy lifting to manage the connection with our TCP service, and keeping the information in-sync across tabs.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image5.png&quot; alt=&quot;SDK flow&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;SDK flow&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In our worker, we additionally maintain all the connections from browser contexts. When an incoming event arrives from the socket, we publish it to the first active connection. Our SDK listens to this event, processes it, sends out an acknowledgment to the server, and publishes it in the BroadcastChannel. Let’s look at how we’ve achieved this via a code example.&lt;/p&gt;

&lt;p&gt;Managing connections in the worker:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;instances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;URI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Called when a  new worker is connected.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Worker is created at&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;onconnect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

 &lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
 &lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onmessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;handleEventFromMainThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;nx&quot;&gt;instances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Publish ONLY to the first connection.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Let the caller decide on how to sync this with other tabs&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;handleEventFromMainThread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;CONNECT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
       &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;c1&quot;&gt;// Establishes a WebSocket connection with the server&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;socket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketManager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({...})&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;CONNECTED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;CLOSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;indexOf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;instances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;splice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;instances&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Forward everything else to the server&lt;/span&gt;
      &lt;span class=&quot;nl&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;sendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And in the ChatSDK:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Implements IChatSDK&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Rough outline of our GrabChat implementation&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;GrabChatSDK&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;constructor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;BroadcastChannel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incoming_events'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onmessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// Handle events from other tabs&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// .....&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SharedWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'./worker'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'module'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appEnv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'include'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Publish a connected event, so the worker manager can register this connection&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;CONNECT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Incoming event from the shared worker&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;onmessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;_handleIncomingMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Disconnect this port before tab closes&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;addEventListener&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'beforeunload'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;_disconnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;sendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Attempt a delivery of the message&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;NEW_MESSAGE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;getPayload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Send the message to all tabs to keep things in sync&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getPayload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Hit if this connection is the leader of the SharedWorker connection&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;_handleIncomingMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Send an ACK to our servers confirming receipt of the message&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SocketTopics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ACK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;shouldBroadcast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;_disconnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;postMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;removeEventListener&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'beforeunload'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;_disconnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This ensures that there is only one connection between our application and the TCP service irrespective of the number of tabs the page is open in.&lt;/p&gt;

&lt;h2 id=&quot;some-caveats&quot;&gt;Some caveats&lt;/h2&gt;

&lt;p&gt;While SharedWorker is a great way to enforce singleton objects across browser contexts, the developer experience of SharedWorker leaves a lot to be desired. There aren’t many resources on the web, and it could be quite confusing if this is the first time you’re using this feature.&lt;/p&gt;

&lt;p&gt;We faced some trouble integrating SharedWorker with bundling the worker code along. This plugin from &lt;a href=&quot;https://github.com/GoogleChromeLabs/worker-plugin&quot;&gt;GoogleChromeLabs&lt;/a&gt; did a great job of alleviating some pain. Debugging an issue with SharedWorker was not obvious. Chrome has a dedicated page for inspecting SharedWorkers (&lt;code class=&quot;highlighter-rouge&quot;&gt;chrome://inspect/#workers&lt;/code&gt;), and it took some getting used to.&lt;/p&gt;

&lt;p&gt;The browser support for SharedWorker is &lt;a href=&quot;https://caniuse.com/sharedworkers&quot;&gt;far from universal&lt;/a&gt;. While it works great in Chrome, Firefox, and Opera, Safari and most mobile browsers lack support. This was an acceptable trade-off in our use case, as we built this for an internal portal and all our users are on Chrome.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/how-we-built-our-in-house-chat-platform-for-the-web/image4.png&quot; alt=&quot;Shared race&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Shared race&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;SharedWorker enforces uniqueness using a combination of origin and the script name. This could potentially introduce an unintentional race condition during deploy times if we’re not careful. Let’s say the user has a tab open before the latest deployment, and another one after deployment, it’s possible to end up with two different versions of the same script. We built a wrapper over the SharedWorker which cedes control to the latest connection, ensuring that there is only one version of the worker active.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h2&gt;

&lt;p&gt;We’re happy to have shared our learnings from building our in-house chat platform for the web, and we hope you found this post helpful. We’ve built the web solution as a reusable SDK for our internal portals and public-facing websites for quick and easy integration, providing a powerful user experience.&lt;/p&gt;

&lt;p&gt;We hope this post also helped you get a deeper sense of how SharedWorker and BroadcastChannels work in a production application.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored By Vasu on behalf of the Real-Time Communications team at Grab. Special thanks to the working team for their contributions- Sanket Thanvi, Dinh Duong, Kevin Lee, and Matthew Yeow.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Mon, 29 Jun 2020 14:34:40 +0000</pubDate>
        <link>https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web</link>
        <guid isPermaLink="true">https://engineering.grab.com/how-we-built-our-in-house-chat-platform-for-the-web</guid>
        
        <category>Chat</category>
        
        <category>Web</category>
        
        <category>Customer Support</category>
        
        <category>Engineering</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Go Modules- A guide for monorepos (Part 1)</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://github.com/golang/go/wiki/Modules%23quick-start&quot;&gt;Go modules&lt;/a&gt; are a new feature in Go for versioning packages and managing dependencies. It has been almost 2 years in the making, and it’s finally production-ready in the Go 1.14 release early this year. Go recommends using single-module repositories by default, and warns that multi-module repositories require great care.&lt;/p&gt;

&lt;p&gt;At Grab, we have a large monorepo and changing from our existing monorepo structure has been an interesting and humbling adventure. We faced serious obstacles to fully adopting Go modules. This series of articles describes Grab’s experience working with Go modules in a multi-module monorepo, the challenges we faced along the way, and the solutions we came up with.&lt;/p&gt;

&lt;p&gt;To fully appreciate Grab’s journey in using Go Modules, it’s important to learn about the beginning of our vendoring process.&lt;/p&gt;

&lt;h2 id=&quot;native-support-for-vendoring-using-the-vendor-folder&quot;&gt;Native support for vendoring using the vendor folder&lt;/h2&gt;

&lt;p&gt;With Go 1.5 came the concept of the &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder, a new package discovery method, providing native support for vendoring in Go for the first time.&lt;/p&gt;

&lt;p&gt;With the &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder, projects influenced the lookup path simply by copying packages into a &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder nested at the project root. Go uses these packages before traversing the &lt;code class=&quot;highlighter-rouge&quot;&gt;GOPATH&lt;/code&gt; root, which allows a monorepo structure to vendor packages within the same repo as if they were 3rd-party libraries. This enabled &lt;code class=&quot;highlighter-rouge&quot;&gt;go build&lt;/code&gt; to work consistently without any need for extra scripts or env var modifications.&lt;/p&gt;

&lt;h3 id=&quot;initial-obstacles&quot;&gt;Initial obstacles&lt;/h3&gt;

&lt;p&gt;There was no official command for managing the &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder, and even copying the files in the &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder manually was common.&lt;/p&gt;

&lt;p&gt;At Grab, different teams took different approaches. This meant that we had multiple version manifests and lock files for our monorepo’s vendor folder. It worked fine as long as there were no conflicts. At this time very few 3rd-party libraries were using proper tagging and semantic versioning, so it was worse because the lock files were largely a jumble of commit hashes and timestamps.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/go-module-a-guide-for-monorepos-part-1/image2.png&quot; alt=&quot;Jumbled commit hashes and timestamps&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Jumbled commit hashes and timestamps&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;As a result of the multiple versions and lock files, the vendor directory was not reproducible, and we couldn’t be sure what versions we had in there.&lt;/p&gt;

&lt;h3 id=&quot;temporary-relief&quot;&gt;Temporary relief&lt;/h3&gt;

&lt;p&gt;We eventually settled on using &lt;a href=&quot;https://github.com/Masterminds/glide&quot;&gt;Glide&lt;/a&gt;, and standardized our vendoring process. Glide gave us a reproducible, verifiable &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder for our dependencies, which worked up until we switched to Go modules.&lt;/p&gt;

&lt;h2 id=&quot;vendoring-using-go-modules&quot;&gt;Vendoring using Go modules&lt;/h2&gt;

&lt;p&gt;I first heard about Go modules from Russ Cox’s talk at &lt;a href=&quot;https://2018.gophercon.sg&quot;&gt;GopherCon Singapore&lt;/a&gt; in 2018, and soon after started working on adopting modules at Grab, which was to manage our existing &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt; folder.&lt;/p&gt;

&lt;p&gt;This allowed us to align with the official Go toolchain and familiarise ourselves with Go modules while the feature matured.&lt;/p&gt;

&lt;h3 id=&quot;switching-to-go-mod&quot;&gt;Switching to go mod&lt;/h3&gt;

&lt;p&gt;Go modules introduced a &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod vendor&lt;/code&gt; command for exporting all dependencies from &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; into &lt;code class=&quot;highlighter-rouge&quot;&gt;vendor&lt;/code&gt;. We didn’t plan to enable Go modules for builds at this point, so our builds continued to run exactly as before, indifferent to the fact that the vendor directory was created using &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The initial task to switch to &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod vendor&lt;/code&gt; was relatively straightforward as listed here:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Generated a &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file from our &lt;code class=&quot;highlighter-rouge&quot;&gt;glide.yaml&lt;/code&gt; dependencies. This was scripted so it could be kept up to date without manual effort.&lt;/li&gt;
  &lt;li&gt;Replaced the vendor directory.&lt;/li&gt;
  &lt;li&gt;Committed the changes.&lt;/li&gt;
  &lt;li&gt;Used &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod&lt;/code&gt; instead of glide to manage the vendor folder.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The change was extremely large (due to differences in how glide and &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod&lt;/code&gt; handled the pruning of unused code), but equivalent in terms of Go code. However, there were some additional changes needed besides porting the version file.&lt;/p&gt;

&lt;h3 id=&quot;addressing-incompatible-dependencies&quot;&gt;Addressing incompatible dependencies&lt;/h3&gt;

&lt;p&gt;Some of our dependencies were not yet compatible with Go modules, so we had to use Go module’s replace directive to substitute them with a working version.&lt;/p&gt;

&lt;p&gt;A more complex issue was that parts of our codebase relied on nested vendor directories, and had dependencies that were incompatible with the top level. The &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod vendor&lt;/code&gt; command attempts to include all code nested under the root path, whether or not they have used a sub-vendor directory, so this led to conflicts.&lt;/p&gt;

&lt;h4 id=&quot;problematic-paths&quot;&gt;Problematic paths&lt;/h4&gt;

&lt;p&gt;Rather than resolving all the incompatibilities, which would’ve been a major undertaking in the monorepo, we decided to exclude these paths from Go modules instead. This was accomplished by &lt;a href=&quot;https://github.com/golang/go/wiki/Modules%23can-an-additional-gomod-exclude-unnecessary-content-do-modules-have-the-equivalent-of-a-gitignore-file&quot;&gt;placing an empty go.mod file&lt;/a&gt; in the problematic paths.&lt;/p&gt;

&lt;h4 id=&quot;nested-modules&quot;&gt;Nested modules&lt;/h4&gt;

&lt;p&gt;The empty &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file worked. This brought us to an important rule of Go modules, which is central to understanding many of the issues we encountered:&lt;/p&gt;

&lt;div&gt;
 &lt;p align=&quot;middle&quot;&gt;&lt;b&gt;&lt;i&gt;A module cannot contain other modules&lt;/i&gt;&lt;/b&gt;
&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;This means that although the modules are within the same repository, Go modules treat them as though they are completely independent. When running &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod&lt;/code&gt; commands in the root of the monorepo, Go doesn’t even ‘see’ the other modules nested within.&lt;/p&gt;

&lt;h3 id=&quot;tackling-maintenance-issues&quot;&gt;Tackling maintenance issues&lt;/h3&gt;

&lt;p&gt;After completing the initial migration of our vendor directory to go mod vendor however, it opened up a different set of problems related to maintenance.&lt;/p&gt;

&lt;p&gt;With Glide, we could guarantee that the Glide files and vendor directory would not change unless we deliberately changed them. This was not the case after switching to Go modules; we found that the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file frequently required unexpected changes to keep our vendor directory reproducible.&lt;/p&gt;

&lt;p&gt;There are two frequent cases that cause the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file to need updates: &lt;em&gt;dependency inheritance&lt;/em&gt; and &lt;em&gt;implicit updates&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;dependency-inheritance&quot;&gt;Dependency inheritance&lt;/h4&gt;

&lt;p&gt;Dependency inheritance is a consequence of Go modules &lt;a href=&quot;https://github.com/golang/go/wiki/Modules%23is-gosum-a-lock-file-why-does-gosum-include-information-for-module-versions-i-am-no-longer-using&quot;&gt;version selection&lt;/a&gt;. If one of the monorepo’s dependencies uses Go modules, then the monorepo inherits those version requirements as well.&lt;/p&gt;

&lt;p&gt;When starting a new module, the default is to use the latest version of dependencies. This was an issue for us as some of our monorepo dependencies had not been updated for some time. As engineers wanted to import their module from the monorepo, it caused &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod vendor&lt;/code&gt; to pull in a huge amount of updates.&lt;/p&gt;

&lt;p&gt;To solve this issue, we wrote a quick script to copy the dependency versions from one module to another.&lt;/p&gt;

&lt;p&gt;One key learning here is to have other modules use the monorepo’s versions, and if any updates are needed then the monorepo should be updated first.&lt;/p&gt;

&lt;h4 id=&quot;implicit-updates&quot;&gt;Implicit updates&lt;/h4&gt;

&lt;p&gt;Implicit updates are a more subtle problem. The typical Go modules &lt;a href=&quot;https://github.com/golang/go/wiki/Modules%23daily-workflow&quot;&gt;workflow&lt;/a&gt; is to use standard Go commands: &lt;code class=&quot;highlighter-rouge&quot;&gt;go build&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;go test&lt;/code&gt;, and so on, and they will automatically update the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file as needed. However, this was sometimes surprising, and it wasn’t always clear why the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file was being updated. Some of the reasons we found were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A new import was added by mistake, causing the dependency to be added to the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file&lt;/li&gt;
  &lt;li&gt;There is a &lt;a href=&quot;https://github.com/golang/go/wiki/Modules%23when-should-i-use-the-replace-directive&quot;&gt;local replace&lt;/a&gt; for some module B, and B changes its own &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt;. When there’s a local replace, it bypasses versioning, so the changes to B’s go.mod are immediately inherited.&lt;/li&gt;
  &lt;li&gt;The build imports a package from a dependency that can’t be satisfied with the current version, so Go attempts to update it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This means that simply &lt;em&gt;creating&lt;/em&gt; a tag in an external repository is sometimes enough to affect the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file, if you already have a broken import in the codebase.&lt;/p&gt;

&lt;h3 id=&quot;resolving-unexpected-dependencies-using-graphs&quot;&gt;Resolving unexpected dependencies using graphs&lt;/h3&gt;

&lt;p&gt;To investigate the unexpected dependencies, the command &lt;code class=&quot;highlighter-rouge&quot;&gt;go mod graph&lt;/code&gt; proved the most useful.&lt;/p&gt;

&lt;p&gt;Running &lt;code class=&quot;highlighter-rouge&quot;&gt;graph&lt;/code&gt; with good old grep was good enough, but its output is also compatible with the &lt;a href=&quot;https://godoc.org/golang.org/x/tools/cmd/digraph&quot;&gt;digraph tool&lt;/a&gt; for more sophisticated queries. For example, we could use the following command to trace the source of a dependency on &lt;code class=&quot;highlighter-rouge&quot;&gt;cloud.google.com/go&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ go mod graph | digraph somepath grab.com/example cloud.google.com/go@v0.26.0

github.com/hashicorp/vault/api@v1.0.4 github.com/hashicorp/vault/sdk@v0.1.13

github.com/hashicorp/vault/sdk@v0.1.13 google.golang.org/genproto@v0.0.0-20190404172233-64821d5d2107

google.golang.org/genproto@v0.0.0-20190404172233-64821d5d2107 google.golang.org/grpc@v1.19.0

google.golang.org/grpc@v1.19.0 cloud.google.com/go@v0.26.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/go-module-a-guide-for-monorepos-part-1/image1.png&quot; alt=&quot;Diagram generated using modgraphviz&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Diagram generated using modgraphviz&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;stay-tuned-for-more&quot;&gt;Stay tuned for more&lt;/h2&gt;
&lt;p&gt;I hope you have enjoyed this article. In our next post, we’ll cover the other solutions we have for catching unexpected changes to the &lt;code class=&quot;highlighter-rouge&quot;&gt;go.mod&lt;/code&gt; file and addressing dependency issues.&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;

&lt;h4 id=&quot;credits&quot;&gt;Credits&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The cute Go gopher logo for this blog’s cover image was inspired by Renee French’s original work.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 29 May 2020 11:34:40 +0000</pubDate>
        <link>https://engineering.grab.com/go-module-a-guide-for-monorepos-part-1</link>
        <guid isPermaLink="true">https://engineering.grab.com/go-module-a-guide-for-monorepos-part-1</guid>
        
        <category>Go</category>
        
        <category>Monorepo</category>
        
        <category>Vendoring</category>
        
        <category>Vendors</category>
        
        <category>Libraries</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Does Southeast Asia run on coffee?</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This article was originally published in the Grab Medium account on December 4, 2019. Reposting it here for your reading pleasure.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;There is no surprise as to why coffee is a go-to drink in the region. For one, almost a third of coffee is produced in &lt;a href=&quot;https://utzcertified.org/en/aboututzcertified/136-general-stories-coffee/asia8/2155-coffee-asia&quot;&gt;Asia&lt;/a&gt;, giving us easy access to beans. Coupled with the plethora of local cafes and stores at every corner in Southeast Asia, coffee has become an accessible and affordable drink — and one that enjoys a huge following.&lt;/p&gt;

&lt;p&gt;For many, a morning cuppa is fuel to kick start their day. For some it’s the secret weapon to a food coma, for others, it’s fuel to keep them going throughout the day.&lt;/p&gt;

&lt;p&gt;To get a glimpse of how our fellow Southeast Asians refuel with coffee on a daily basis, we took a look (along with our ‘kopi’) at GrabFood data, and here is what we found.&lt;/p&gt;

&lt;h2 id=&quot;did-you-know-coffee-orders-have-grown-1400-on-grabfood&quot;&gt;Did you know: Coffee orders have grown 1,400% on GrabFood?&lt;/h2&gt;

&lt;p&gt;How much do we actually love our coffee? It seems like we do, a lot.&lt;/p&gt;

&lt;p&gt;Coffee orders on GrabFood has been growing pervasively throughout the major cities, and a timelapse visualisation based on data from GrabFood orders show us the growth of orders across major cities over a 9-month period:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image1.gif&quot; alt=&quot;Timelapse visualisation&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;time-for-coffee&quot;&gt;Time for coffee?&lt;/h2&gt;

&lt;p&gt;But how reliant are we on caffeine? We analysed the coffee consumption behaviour of GrabFood users from major SEA countries across a typical week.&lt;/p&gt;

&lt;h3 id=&quot;coffee-orders-by-day-of-the-week-singapore-coffee-orders-peak-on-the-weekends&quot;&gt;Coffee Orders by Day of the Week: Singapore coffee orders peak on the weekends&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image2.png&quot; alt=&quot;Coffee Orders by Day of the Week - Chart&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Turns out most coffee orders are placed on Wednesdays — clearly a much needed shot to overcome the dreaded hump day. And as we head into the weekend, orders begin to decline as Southeast Asians wind down from the work week.&lt;/p&gt;

&lt;p&gt;However, the complete opposite happens for our friends in Singapore and the Philippines! Coffee orders actually spike on the weekends, and especially so on Sundays. It can only mean that Singaporeans and Filipinos surely enjoy their coffee catch-ups with friends and family.&lt;/p&gt;

&lt;h3 id=&quot;am--coffee-pm--still-coffee&quot;&gt;AM- Coffee… PM- Still coffee&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;The question begets&lt;/em&gt; — when exactly do SEA coffee drinkers summon that life saving cup from our delivery heroes in green?&lt;/p&gt;

&lt;p&gt;Check out this trippy visualisation that resembles jumping coffee beans:&lt;/p&gt;

&lt;h3 id=&quot;coffee-orders-by-hour-of-day--orders-peak-at-10am-for-thailand-and-2pm-in-indonesia&quot;&gt;Coffee Orders by Hour of Day — Orders peak at 10am for Thailand and 2pm in Indonesia&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image3.gif&quot; alt=&quot;Coffee Orders by Day of the Week&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;While other cities generally reach for the Grab app at noon for that extra boost to fight that food coma through the rest of the day, our friends in Thailand gets their caffeine fix early, with most orders coming in at 10.00am, just before the lunch hour.&lt;/p&gt;

&lt;p&gt;Interestingly, coffee orders for Singapore peak at about 4pm in the afternoon… are they working hard, or are they hardly working?&lt;/p&gt;

&lt;h2 id=&quot;grabfoods-love-is-in-the-air-and-it-smells-like-coffee&quot;&gt;GrabFood’s love is in the air, and it smells like coffee&lt;/h2&gt;

&lt;p&gt;Curious as to what coffee flavours our SEA neighbours prefer? We spill the (coffee) beans!&lt;/p&gt;

&lt;h3 id=&quot;top-3-coffee-flavours-in-each-country&quot;&gt;Top 3 Coffee Flavours in each Country&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image4.png&quot; alt=&quot;Top 3 Coffee Flavours in each Country&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-is-a-non-coffee-drinker-to-do&quot;&gt;What is a non-coffee drinker to do?&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image5.png&quot; alt=&quot;What non-coffee drinker drinks&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Also known as Matcha Latte, Green Tea Latte seems to be the next big beverage fad in the region , serving as a perfect coffee alternative for non-coffee drinkers.&lt;/p&gt;

&lt;p&gt;Matcha latte, made with concentrated shots of green tea and topped with frothy, steamed milk, is gaining popularity. While it offers the same quantity of caffeine as a cup of brewed coffee, the drink is perceived to be as more energising , because of the slower release of caffeine.&lt;/p&gt;

&lt;p&gt;It has consistently been one of the top 10 beverage items ordered on GrabFood, and we’ve delivered over 25 million cups of these green, frothy and creamy ‘heaven in a cup’ over the last nine months!&lt;/p&gt;

&lt;p&gt;Southeast Asian’s love of tea-based latte (other than green tea) is apparent in Grab’s data! Some of the unique flavours that are being ordered on GrabFood include the following flavours:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image6.png&quot; alt=&quot;Unique flavours&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;grabfood-coffee-is-a-hug-in-a-mug&quot;&gt;GrabFood Coffee is a hug in a mug&lt;/h2&gt;

&lt;p&gt;Is your blood type coffee? Whether you feel like caramelly and chocolatey Macchiato, or fruity and floral aroma of freshly brewed Americano, or intense and bitter double-shot Long Black — GrabFood has got you covered! May your coffee get delivered (and kick in) before reality does!&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Mar 2020 08:34:00 +0000</pubDate>
        <link>https://engineering.grab.com/does-southeast-asia-run-on-coffee</link>
        <guid isPermaLink="true">https://engineering.grab.com/does-southeast-asia-run-on-coffee</guid>
        
        <category>Data</category>
        
        <category>Data Analytics</category>
        
        <category>Data Visualisation</category>
        
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>GrabChat Much? Talk Data to me!</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This article was originally published in the Grab Medium account on November 20, 2019. Reposting it here for your reading pleasure.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;In September 2016 GrabChat was born, a platform designed to allow seamless communication between passenger and driver-partner. Since then, Grab has continuously improved the GrabChat experience by introducing features such as instant translation, images, and audio chats, and as a result — reduced cancellation rates by up to 50%! We’ve even &lt;a href=&quot;https://engineering.grab.com/experiment-chat-booking-cancellations&quot;&gt;experimented with various features&lt;/a&gt; to deliver hyper-localised experiences in each country! So with all these features, how have our users responded? Let’s take a deeper look into this to uncover some interesting insights from our data in Singapore, Malaysia and Indonesia.&lt;/p&gt;

&lt;h2 id=&quot;the-chattiest-country&quot;&gt;The Chattiest Country&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image1.png&quot; alt=&quot;Number of Chats by Country&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Number of Chats by Country&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In a previous &lt;a href=&quot;https://www.grab.com/sg/blog/grabchat-feature/&quot;&gt;blog post&lt;/a&gt; several years ago, we revealed that Indonesia was the chattiest nation in South-east Asia. Our latest data is no different. &lt;strong&gt;Indonesia is still the chattiest country out of the three, having an average of 5.5 chats per bookings, while Singapore is the least chatty!&lt;/strong&gt; Furthermore, passengers in Singapore tend to be chattier than driver-partners, while the reverse relationship is true for the other two countries.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But what do people talk about?&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image2.png&quot; alt=&quot;Common words in Indonesia&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image3.png&quot; alt=&quot;Common words in Singapore&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Singapore&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image4.png&quot; alt=&quot;Common words in Malaysia&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Malaysia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;As expected, most of the chats revolve around pick-up points. There are &lt;strong&gt;many similarities between the three countries, such as typing courtesies such as ‘Hi’ and ‘Thank you’, and that the driver-partner/passenger is coming.&lt;/strong&gt; However, there are slight differences between the countries. Can you spot them all?&lt;/p&gt;

&lt;p&gt;In Indonesia, chats are usually in Bahasa Indonesia, and tend to be mostly driver-partners thanking passengers for using Grab.&lt;/p&gt;

&lt;p&gt;Chats in Singapore on the other hand, tend to be in English, and contain mostly pick-up locations, such as a car park. There are quite a few unique words in the Singapore context, such as ‘rubbish chute’ and ‘block’ that reflect features of the ubiquitous HDB’s (public housing) found everywhere in Singapore that serve as popular residential pickup points.&lt;/p&gt;

&lt;p&gt;Malaysia seems to be a blend of the other two countries, with chats in a mix of English and Bahasa Malaysia. Many of the chats highlight pickup locations, such as a guard house, as well as the phrase all Malaysians know: being stuck in traffic.&lt;/p&gt;

&lt;h2 id=&quot;time-trends&quot;&gt;Time Trends&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image5.png&quot; alt=&quot;Time Trend&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Time Trend&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Analysis in chat trends across the three countries revealed an unexpected insight: &lt;strong&gt;a trend of talking more from midnight until around 4am&lt;/strong&gt;. Perplexed but intrigued, we dug further to discover what prompted our users to talk more in such odd hours.&lt;/p&gt;

&lt;p&gt;From midnight to 4am shops and malls are usually closed during these hours, and pickup locations become more obscure as people wander around town late at night. Driver-partners and passengers thus tend to have more conversations to determine the pickup point. This also explains why the &lt;strong&gt;proportion of&lt;/strong&gt; &lt;strong&gt;pick-up location based messages out of all messages is highest between 12 and 6am&lt;/strong&gt;. On the other hand, these messages are less common in the mornings (6am-12pm) as people tend to be picked up from standard residential locations.&lt;/p&gt;

&lt;h2 id=&quot;image-trends&quot;&gt;Image Trends&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6a.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 1&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 1&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6b.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019)  - Image 2&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 2&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6c.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 3&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 3&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The ability to send images on GrabChat was introduced in September 2018, with the aim of helping driver-partners identify the exact pickup location of passengers. Within the first few weeks of release, 22,000 images were sent in Singapore alone. The increase in uptake of the image feature for the cities of Jakarta, Singapore and Kuala Lumpur can be seen in the images above.&lt;/p&gt;

&lt;p&gt;From analysis, we found that &lt;strong&gt;areas that were more remote such as Tengah in Singapore tended to have the highest percentage of images sent&lt;/strong&gt;, indicating that images are useful for users in unfamiliar places.&lt;/p&gt;

&lt;h2 id=&quot;safety-first&quot;&gt;Safety First&lt;/h2&gt;

&lt;p&gt;Aside from images, Grab also introduced two other features: templates and audio chats, to &lt;strong&gt;avoid driver-partners from texting while driving&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image7.png&quot; alt=&quot;Templates and audio features used by driver-partners, and a reduced number of typed texts by driver-partners per booking&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Templates and audio features used by driver-partners, and a reduced number of typed texts by driver-partners per bookin&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;“Templates” (pre-populated phrases) allowed driver-partners to send templated messages with just a quick tap. In our recent data analysis, we discovered that almost 50% of driver-partner texts comprised of templates.&lt;/p&gt;

&lt;p&gt;“Audio chat” alongside “images chat” were introduced in September 2018, and the use of this feature has been steadily increasing, with audio comprising an increasing percentage of driver-partner texts.&lt;/p&gt;

&lt;p&gt;With both features being picked up by driver-partners across all three countries, Grab has successfully seen a decrease in the overall number of driver-partner texts (non-templates) per booking within a 3 month period.&lt;/p&gt;

&lt;h2 id=&quot;a-brief-pick-up-guide&quot;&gt;A Brief Pick-up Guide&lt;/h2&gt;

&lt;p&gt;No one likes a cancelled ride, right? Well, after analysing millions of data points, we’ve unearthed some neat tips and tricks to help you complete your ride, and we’re sharing them with you!&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image8.png&quot; alt=&quot;Completed Rides&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Completed Rides&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;This first tip might be a no-brainer, but replying your driver-partner would result in a higher completion rate. No one likes to be blue-ticked do they?&lt;/p&gt;

&lt;p&gt;Next, we discovered various things you could say that would result in higher completion rates, explained below in the graphic.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image9.png&quot; alt=&quot;Tips for a Better Pickup Experience&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Tips for a Better Pickup Experience&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Informing the driver-partner that you’re coming, giving them directions, and telling them how to identify you results in almost double the chances of completing the ride!&lt;/p&gt;

&lt;p&gt;Last but not least, &lt;strong&gt;let’s not forget our manners&lt;/strong&gt;. Grab’s data analysis revealed that saying ‘thank you’ correlated with an increase in completion rates! Also, be at the pickup point on time — remember, time is money for our driver-partners!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Just like in Shakespeare’s &lt;em&gt;Much Ado about Nothing&lt;/em&gt;, ample information can be gathered from the mere whim of a message. Grab is constantly aspiring to achieve the best experience for both passengers and driver-partners, and data plays a huge role in helping us achieve this.&lt;/p&gt;

&lt;p&gt;This is just the first page of the book. The amount of information lurking between every page is endless. So stay tuned for more interesting insights about our GrabChat platform!&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Mar 2020 05:02:55 +0000</pubDate>
        <link>https://engineering.grab.com/grabchat-much-talk-data-to-me</link>
        <guid isPermaLink="true">https://engineering.grab.com/grabchat-much-talk-data-to-me</guid>
        
        <category>Data</category>
        
        <category>Data Analytics</category>
        
        <category>Data Visualisation</category>
        
        
        <category>Data Science</category>
        
      </item>
    
  </channel>
</rss>
