<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 26 Mar 2020 13:44:36 +0000</pubDate>
    <lastBuildDate>Thu, 26 Mar 2020 13:44:36 +0000</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>Does Southeast Asia run on coffee?</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This article was originally published in the Grab Medium account on December 4, 2019. Reposting it here for your reading pleasure.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;There is no surprise as to why coffee is a go-to drink in the region. For one, almost a third of coffee is produced in &lt;a href=&quot;https://utzcertified.org/en/aboututzcertified/136-general-stories-coffee/asia8/2155-coffee-asia&quot;&gt;Asia&lt;/a&gt;, giving us easy access to beans. Coupled with the plethora of local cafes and stores at every corner in Southeast Asia, coffee has become an accessible and affordable drink — and one that enjoys a huge following.&lt;/p&gt;

&lt;p&gt;For many, a morning cuppa is fuel to kick start their day. For some it’s the secret weapon to a food coma, for others, it’s fuel to keep them going throughout the day.&lt;/p&gt;

&lt;p&gt;To get a glimpse of how our fellow Southeast Asians refuel with coffee on a daily basis, we took a look (along with our ‘kopi’) at GrabFood data, and here is what we found.&lt;/p&gt;

&lt;h2 id=&quot;did-you-know-coffee-orders-have-grown-1400-on-grabfood&quot;&gt;Did you know: Coffee orders have grown 1,400% on GrabFood?&lt;/h2&gt;

&lt;p&gt;How much do we actually love our coffee? It seems like we do, a lot.&lt;/p&gt;

&lt;p&gt;Coffee orders on GrabFood has been growing pervasively throughout the major cities, and a timelapse visualisation based on data from GrabFood orders show us the growth of orders across major cities over a 9-month period:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image1.gif&quot; alt=&quot;Timelapse visualisation&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;time-for-coffee&quot;&gt;Time for coffee?&lt;/h2&gt;

&lt;p&gt;But how reliant are we on caffeine? We analysed the coffee consumption behaviour of GrabFood users from major SEA countries across a typical week.&lt;/p&gt;

&lt;h3 id=&quot;coffee-orders-by-day-of-the-week-singapore-coffee-orders-peak-on-the-weekends&quot;&gt;Coffee Orders by Day of the Week: Singapore coffee orders peak on the weekends&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image2.png&quot; alt=&quot;Coffee Orders by Day of the Week - Chart&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Turns out most coffee orders are placed on Wednesdays — clearly a much needed shot to overcome the dreaded hump day. And as we head into the weekend, orders begin to decline as Southeast Asians wind down from the work week.&lt;/p&gt;

&lt;p&gt;However, the complete opposite happens for our friends in Singapore and the Philippines! Coffee orders actually spike on the weekends, and especially so on Sundays. It can only mean that Singaporeans and Filipinos surely enjoy their coffee catch-ups with friends and family.&lt;/p&gt;

&lt;h3 id=&quot;am--coffee-pm--still-coffee&quot;&gt;AM- Coffee… PM- Still coffee&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;The question begets&lt;/em&gt; — when exactly do SEA coffee drinkers summon that life saving cup from our delivery heroes in green?&lt;/p&gt;

&lt;p&gt;Check out this trippy visualisation that resembles jumping coffee beans:&lt;/p&gt;

&lt;h3 id=&quot;coffee-orders-by-hour-of-day--orders-peak-at-10am-for-thailand-and-2pm-in-indonesia&quot;&gt;Coffee Orders by Hour of Day — Orders peak at 10am for Thailand and 2pm in Indonesia&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image3.gif&quot; alt=&quot;Coffee Orders by Day of the Week&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;While other cities generally reach for the Grab app at noon for that extra boost to fight that food coma through the rest of the day, our friends in Thailand gets their caffeine fix early, with most orders coming in at 10.00am, just before the lunch hour.&lt;/p&gt;

&lt;p&gt;Interestingly, coffee orders for Singapore peak at about 4pm in the afternoon… are they working hard, or are they hardly working?&lt;/p&gt;

&lt;h2 id=&quot;grabfoods-love-is-in-the-air-and-it-smells-like-coffee&quot;&gt;GrabFood’s love is in the air, and it smells like coffee&lt;/h2&gt;

&lt;p&gt;Curious as to what coffee flavours our SEA neighbours prefer? We spill the (coffee) beans!&lt;/p&gt;

&lt;h3 id=&quot;top-3-coffee-flavours-in-each-country&quot;&gt;Top 3 Coffee Flavours in each Country&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image4.png&quot; alt=&quot;Top 3 Coffee Flavours in each Country&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-is-a-non-coffee-drinker-to-do&quot;&gt;What is a non-coffee drinker to do?&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image5.png&quot; alt=&quot;What non-coffee drinker drinks&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Also known as Matcha Latte, Green Tea Latte seems to be the next big beverage fad in the region , serving as a perfect coffee alternative for non-coffee drinkers.&lt;/p&gt;

&lt;p&gt;Matcha latte, made with concentrated shots of green tea and topped with frothy, steamed milk, is gaining popularity. While it offers the same quantity of caffeine as a cup of brewed coffee, the drink is perceived to be as more energising , because of the slower release of caffeine.&lt;/p&gt;

&lt;p&gt;It has consistently been one of the top 10 beverage items ordered on GrabFood, and we’ve delivered over 25 million cups of these green, frothy and creamy ‘heaven in a cup’ over the last nine months!&lt;/p&gt;

&lt;p&gt;Southeast Asian’s love of tea-based latte (other than green tea) is apparent in Grab’s data! Some of the unique flavours that are being ordered on GrabFood include the following flavours:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/does-southeast-asia-run-on-coffee/image6.png&quot; alt=&quot;Unique flavours&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;grabfood-coffee-is-a-hug-in-a-mug&quot;&gt;GrabFood Coffee is a hug in a mug&lt;/h2&gt;

&lt;p&gt;Is your blood type coffee? Whether you feel like caramelly and chocolatey Macchiato, or fruity and floral aroma of freshly brewed Americano, or intense and bitter double-shot Long Black — GrabFood has got you covered! May your coffee get delivered (and kick in) before reality does!&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Mar 2020 08:34:00 +0000</pubDate>
        <link>https://engineering.grab.com/does-southeast-asia-run-on-coffee</link>
        <guid isPermaLink="true">https://engineering.grab.com/does-southeast-asia-run-on-coffee</guid>
        
        <category>Data</category>
        
        <category>Data Analytics</category>
        
        <category>Data Visualisation</category>
        
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>GrabChat Much? Talk Data to me!</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This article was originally published in the Grab Medium account on November 20, 2019. Reposting it here for your reading pleasure.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;In September 2016 GrabChat was born, a platform designed to allow seamless communication between passenger and driver-partner. Since then, Grab has continuously improved the GrabChat experience by introducing features such as instant translation, images, and audio chats, and as a result — reduced cancellation rates by up to 50%! We’ve even &lt;a href=&quot;https://engineering.grab.com/experiment-chat-booking-cancellations&quot;&gt;experimented with various features&lt;/a&gt; to deliver hyper-localised experiences in each country! So with all these features, how have our users responded? Let’s take a deeper look into this to uncover some interesting insights from our data in Singapore, Malaysia and Indonesia.&lt;/p&gt;

&lt;h2 id=&quot;the-chattiest-country&quot;&gt;The Chattiest Country&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image1.png&quot; alt=&quot;Number of Chats by Country&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Number of Chats by Country&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;In a previous &lt;a href=&quot;https://www.grab.com/sg/blog/grabchat-feature/&quot;&gt;blog post&lt;/a&gt; several years ago, we revealed that Indonesia was the chattiest nation in South-east Asia. Our latest data is no different. &lt;strong&gt;Indonesia is still the chattiest country out of the three, having an average of 5.5 chats per bookings, while Singapore is the least chatty!&lt;/strong&gt; Furthermore, passengers in Singapore tend to be chattier than driver-partners, while the reverse relationship is true for the other two countries.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But what do people talk about?&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image2.png&quot; alt=&quot;Common words in Indonesia&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Indonesia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image3.png&quot; alt=&quot;Common words in Singapore&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Singapore&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image4.png&quot; alt=&quot;Common words in Malaysia&quot; /&gt;  
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Common words in Malaysia&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;As expected, most of the chats revolve around pick-up points. There are &lt;strong&gt;many similarities between the three countries, such as typing courtesies such as ‘Hi’ and ‘Thank you’, and that the driver-partner/passenger is coming.&lt;/strong&gt; However, there are slight differences between the countries. Can you spot them all?&lt;/p&gt;

&lt;p&gt;In Indonesia, chats are usually in Bahasa Indonesia, and tend to be mostly driver-partners thanking passengers for using Grab.&lt;/p&gt;

&lt;p&gt;Chats in Singapore on the other hand, tend to be in English, and contain mostly pick-up locations, such as a car park. There are quite a few unique words in the Singapore context, such as ‘rubbish chute’ and ‘block’ that reflect features of the ubiquitous HDB’s (public housing) found everywhere in Singapore that serve as popular residential pickup points.&lt;/p&gt;

&lt;p&gt;Malaysia seems to be a blend of the other two countries, with chats in a mix of English and Bahasa Malaysia. Many of the chats highlight pickup locations, such as a guard house, as well as the phrase all Malaysians know: being stuck in traffic.&lt;/p&gt;

&lt;h2 id=&quot;time-trends&quot;&gt;Time Trends&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image5.png&quot; alt=&quot;Time Trend&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Time Trend&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Analysis in chat trends across the three countries revealed an unexpected insight: &lt;strong&gt;a trend of talking more from midnight until around 4am&lt;/strong&gt;. Perplexed but intrigued, we dug further to discover what prompted our users to talk more in such odd hours.&lt;/p&gt;

&lt;p&gt;From midnight to 4am shops and malls are usually closed during these hours, and pickup locations become more obscure as people wander around town late at night. Driver-partners and passengers thus tend to have more conversations to determine the pickup point. This also explains why the &lt;strong&gt;proportion of&lt;/strong&gt; &lt;strong&gt;pick-up location based messages out of all messages is highest between 12 and 6am&lt;/strong&gt;. On the other hand, these messages are less common in the mornings (6am-12pm) as people tend to be picked up from standard residential locations.&lt;/p&gt;

&lt;h2 id=&quot;image-trends&quot;&gt;Image Trends&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6a.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 1&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 1&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6b.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019)  - Image 2&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 2&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image6c.png&quot; alt=&quot;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 3&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;GrabChat’s Image-function uptake in Jakarta, Singapore, and Kuala Lumpur (Nov 2018 — March 2019) - Image 3&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The ability to send images on GrabChat was introduced in September 2018, with the aim of helping driver-partners identify the exact pickup location of passengers. Within the first few weeks of release, 22,000 images were sent in Singapore alone. The increase in uptake of the image feature for the cities of Jakarta, Singapore and Kuala Lumpur can be seen in the images above.&lt;/p&gt;

&lt;p&gt;From analysis, we found that &lt;strong&gt;areas that were more remote such as Tengah in Singapore tended to have the highest percentage of images sent&lt;/strong&gt;, indicating that images are useful for users in unfamiliar places.&lt;/p&gt;

&lt;h2 id=&quot;safety-first&quot;&gt;Safety First&lt;/h2&gt;

&lt;p&gt;Aside from images, Grab also introduced two other features: templates and audio chats, to &lt;strong&gt;avoid driver-partners from texting while driving&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image7.png&quot; alt=&quot;Templates and audio features used by driver-partners, and a reduced number of typed texts by driver-partners per booking&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Templates and audio features used by driver-partners, and a reduced number of typed texts by driver-partners per bookin&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;“Templates” (pre-populated phrases) allowed driver-partners to send templated messages with just a quick tap. In our recent data analysis, we discovered that almost 50% of driver-partner texts comprised of templates.&lt;/p&gt;

&lt;p&gt;“Audio chat” alongside “images chat” were introduced in September 2018, and the use of this feature has been steadily increasing, with audio comprising an increasing percentage of driver-partner texts.&lt;/p&gt;

&lt;p&gt;With both features being picked up by driver-partners across all three countries, Grab has successfully seen a decrease in the overall number of driver-partner texts (non-templates) per booking within a 3 month period.&lt;/p&gt;

&lt;h2 id=&quot;a-brief-pick-up-guide&quot;&gt;A Brief Pick-up Guide&lt;/h2&gt;

&lt;p&gt;No one likes a cancelled ride, right? Well, after analysing millions of data points, we’ve unearthed some neat tips and tricks to help you complete your ride, and we’re sharing them with you!&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image8.png&quot; alt=&quot;Completed Rides&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Completed Rides&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;This first tip might be a no-brainer, but replying your driver-partner would result in a higher completion rate. No one likes to be blue-ticked do they?&lt;/p&gt;

&lt;p&gt;Next, we discovered various things you could say that would result in higher completion rates, explained below in the graphic.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grabchat-much-talk-data-to-me/image9.png&quot; alt=&quot;Tips for a Better Pickup Experience&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Tips for a Better Pickup Experience&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Informing the driver-partner that you’re coming, giving them directions, and telling them how to identify you results in almost double the chances of completing the ride!&lt;/p&gt;

&lt;p&gt;Last but not least, &lt;strong&gt;let’s not forget our manners&lt;/strong&gt;. Grab’s data analysis revealed that saying ‘thank you’ correlated with an increase in completion rates! Also, be at the pickup point on time — remember, time is money for our driver-partners!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Just like in Shakespeare’s &lt;em&gt;Much Ado about Nothing&lt;/em&gt;, ample information can be gathered from the mere whim of a message. Grab is constantly aspiring to achieve the best experience for both passengers and driver-partners, and data plays a huge role in helping us achieve this.&lt;/p&gt;

&lt;p&gt;This is just the first page of the book. The amount of information lurking between every page is endless. So stay tuned for more interesting insights about our GrabChat platform!&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Mar 2020 05:02:55 +0000</pubDate>
        <link>https://engineering.grab.com/grabchat-much-talk-data-to-me</link>
        <guid isPermaLink="true">https://engineering.grab.com/grabchat-much-talk-data-to-me</guid>
        
        <category>Data</category>
        
        <category>Data Analytics</category>
        
        <category>Data Visualisation</category>
        
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>7 Fun Facts about Grab’s Driver-Partners in Singapore</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This article was originally published in the Grab Medium account on June 17, 2019. Reposting it here for your reading pleasure.&lt;/i&gt;&lt;/p&gt;

&lt;h2 id=&quot;grabs-big-data-story&quot;&gt;Grab’s Big Data Story&lt;/h2&gt;

&lt;p&gt;Grab is on an incredible mission to empower our driver-partners in 336 cities in 8 countries.&lt;/p&gt;

&lt;p&gt;Curious about what Grab’s data tells us about driver-partners on the platform?&lt;/p&gt;

&lt;p&gt;Let us share with you the most interesting data points we found among our driver-partners in Singapore!&lt;/p&gt;

&lt;h3 id=&quot;1-its-a-small-world&quot;&gt;1. It’s a Small World&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image1.png&quot; alt=&quot;It's a Small World&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Lim Chu Kang may feel like a world away from Katong, but Singapore is a small world for our driver-partners — a driver-partner has a 1 in 400 chance of having a repeat passenger amongst the 5.4 million population!&lt;/p&gt;

&lt;h3 id=&quot;2-saturday-night-fever&quot;&gt;2. Saturday Night Fever&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image2.png&quot; alt=&quot;Saturday Night Fever&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;The annual average number of rides that a Grab driver-partner complete on Saturday nights is 110. But there was one special driver-partner who did 1,131 Saturday night trips in the year of 2018! Weekend parties just wouldn’t be the same without you. Rock on!&lt;/p&gt;

&lt;h3 id=&quot;3-share-the-love&quot;&gt;3. Share the Love&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image3.png&quot; alt=&quot;Share the Lover&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Did you know that having more passengers in a car can yield more 5-star ratings? Our GrabShare passengers share more than just rides — they share their appreciation too! GrabShare rides have an average trip rating of 4.8!&lt;/p&gt;

&lt;h3 id=&quot;4-the-road-more-travelled&quot;&gt;4. The Road More Travelled&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image4.png&quot; alt=&quot;The Road More Travelled&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Which neighbourhoods are painting the town green? Our driver partners picked up the most passengers from Tampines, while Orchard &amp;amp; Marina Bay areas were the most popular destination in 2018!&lt;/p&gt;

&lt;h3 id=&quot;5-tricks-of-the-trade&quot;&gt;5. Tricks of the Trade&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image5.png&quot; alt=&quot;Tricks of the Trad&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Ever wondered if seasoned driver-partners who have been with us for more than 2 years, have different driving preferences and habits? They tend to start their day 1 hour earlier around 6–7am, and are on auto-accept most of the time. Did you know that drivers on auto-accept spend less time idle waiting for new jobs?&lt;/p&gt;

&lt;h3 id=&quot;6-busy-bee&quot;&gt;6. Busy Bee&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image6.png&quot; alt=&quot;Busy Bee&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Did you know? Drivers are twice as likely to get back-to-back allocations during evening peak hours! Drivers with frequent back-to-back jobs earn about 50% more per hour.&lt;/p&gt;

&lt;h2 id=&quot;7-road-runner&quot;&gt;7. Road Runner&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/seven-facts-about-grab-partner-drivers-in-sg/image7.png&quot; alt=&quot;Road Runner&quot; /&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;One of our most active driver-partners covered 57,000km ferrying passengers in 2018 — that’s like driving every road, street, jalan, lorong and tanjong in Singapore for more than 57 times!&lt;/p&gt;

&lt;p&gt;How our driver-partners utilize the Grab platform to make a living (and break a few records along the way) never ceases to amaze us.&lt;/p&gt;

&lt;p&gt;Interested to know more about the winning strategies among our driver-partners? Look out for the next data story!&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Fri, 20 Mar 2020 12:13:20 +0000</pubDate>
        <link>https://engineering.grab.com/seven-facts-about-grab-driver-partners-in-sg</link>
        <guid isPermaLink="true">https://engineering.grab.com/seven-facts-about-grab-driver-partners-in-sg</guid>
        
        <category>Data</category>
        
        <category>Data Analytics</category>
        
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Tackling UI test execution time imbalance for Xcode parallel testing</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Testing is a common practice to ensure that code logic is not easily broken during development and refactoring. Having tests running as part of Continuous Integration (CI) infrastructure is essential, especially with a large codebase contributed by many engineers. However, the more tests we add, the longer it takes to execute. In the context of iOS development, the execution time of the whole test suite might be significantly affected by the increasing number of tests written. Running &lt;a href=&quot;https://about.gitlab.com/blog/2019/07/12/guide-to-ci-cd-pipelines/&quot;&gt;CI pre-merge pipelines&lt;/a&gt; against a change, would cost us more time. Therefore, reducing test execution time is a long term epic we have to tackle in order to build a good CI infrastructure.&lt;/p&gt;

&lt;p&gt;Apart from splitting tests into subsets and running each of them in a CI job, we can also make use of the &lt;a href=&quot;https://www.zachsim.one/blog/2018/6/15/parallel-testing-in-xcode-10&quot;&gt;Xcode parallel testing&lt;/a&gt; feature to achieve parallelism within one single CI job. However, due to platform-specific implementations, there are some constraints that prevent parallel testing from working efficiently. One constraint we found is that tests of the same &lt;a href=&quot;https://swift.org/about/&quot;&gt;Swift&lt;/a&gt; class run on the same simulator. In this post, we will discuss this constraint in detail and introduce a tip to overcome it.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;h3 id=&quot;xcode-parallel-testing&quot;&gt;Xcode parallel testing&lt;/h3&gt;

&lt;p&gt;The parallel testing feature was shipped as part of the &lt;a href=&quot;https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes&quot;&gt;Xcode 10 release&lt;/a&gt;. This support enables us to easily configure test setup:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There is no need to care about how to split a given test suite.&lt;/li&gt;
  &lt;li&gt;The number of workers (i.e. parallel runners/instances) is configurable. We can pass this value in the &lt;code class=&quot;highlighter-rouge&quot;&gt;xcodebuild&lt;/code&gt; CLI via the &lt;code class=&quot;highlighter-rouge&quot;&gt;-parallel-testing-worker-count&lt;/code&gt; option.&lt;/li&gt;
  &lt;li&gt;Xcode takes care of cloning and starts simulators accordingly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, &lt;em&gt;the distribution logic under the hood is a black-box&lt;/em&gt;. We do not really know how &lt;em&gt;tests are assigned to each worker or simulator, and in which order&lt;/em&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image6.png&quot; alt=&quot;Three simulators running tests in parallel&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Three simulators running tests in parallel&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;It is worth mentioning that even without the Xcode parallel testing support, we can still achieve similar improvements by running subsets of tests in different child processes. But it takes more effort to dispatch tests to each child process in an efficient way, and to handle the output from each test process appropriately.&lt;/p&gt;

&lt;h3 id=&quot;test-time-imbalance&quot;&gt;Test time imbalance&lt;/h3&gt;

&lt;p&gt;Generally, a &lt;em&gt;parallel execution system&lt;/em&gt; is at its best efficiency if each parallel task executes in roughly the same duration and ends at roughly the same time.&lt;/p&gt;

&lt;p&gt;If the time spent on each parallel task is significantly different, it will take more time than expected to execute all tasks. For example, in the following image, it takes the system on the left 13 mins to finish 3 tasks. Whereas, the one on the right takes only 10.5 mins to finish those 3 tasks.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image3.png&quot; alt=&quot;Bad parallelism vs. good parallelism&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Bad parallelism vs. good parallelism&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Assume there are N workers. The i&lt;sup&gt;th&lt;/sup&gt; worker executes its tasks in t&lt;sub&gt;i&lt;/sub&gt; seconds/minutes. In the left plot, t&lt;sub&gt;1&lt;/sub&gt; = 10 mins, t&lt;sub&gt;2&lt;/sub&gt; = 7 mins, t&lt;sub&gt;3&lt;/sub&gt; = 13 mins.&lt;/p&gt;

&lt;p&gt;We define the test time imbalance metric as the difference between the min and max end time:&lt;/p&gt;

&lt;p&gt;max(t&lt;sub&gt;i&lt;/sub&gt;) - min(t&lt;sub&gt;i&lt;/sub&gt;)&lt;/p&gt;

&lt;p&gt;For the example above, the test time imbalance is 13 mins - 7 mins = 6 mins.&lt;/p&gt;

&lt;h3 id=&quot;contributing-factors-in-test-time-imbalance&quot;&gt;Contributing factors in test time imbalance&lt;/h3&gt;

&lt;p&gt;There are several factors causing test time imbalance. The top two prominent factors are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tests vary in execution time.&lt;/li&gt;
  &lt;li&gt;Tests of the same class run on the same simulator.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An example of the first factor is that in our project, around 50% of tests execute in a range of 20-40 secs. Some tests take under 15 secs to run while several take up to 2 minutes. Sometimes tests taking longer execution time is inevitable since those tests usually touch many flows, which cannot be split. If such tests run last, the test time imbalance may increase.&lt;/p&gt;

&lt;p&gt;However, this issue, in general, does not matter that much because long-time-execution tests do not always run last.&lt;/p&gt;

&lt;p&gt;Regarding the second factor, there is no official Apple documentation that explicitly states this constraint. When &lt;a href=&quot;https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes&quot;&gt;Apple first introduced parallel testing support in Xcode 10&lt;/a&gt;, they only mentioned that test classes are distributed across runner processes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Test parallelization occurs by &lt;strong&gt;distributing the test classes in a target across multiple runner processes&lt;/strong&gt;. Use the test log to see how your test classes were parallelized. You will see an entry in the log for each runner process that was launched, and below each runner you will see the list of classes that it executed.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, we have a test class &lt;code class=&quot;highlighter-rouge&quot;&gt;JobFlowTests&lt;/code&gt; that includes five tests and another test class &lt;code class=&quot;highlighter-rouge&quot;&gt;TutorialTests&lt;/code&gt; that has only one single test.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JobFlowTests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BaseXCTestCase&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testHappyFlow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testRecoverFlow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testJobIgnoreByDax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testJobIgnoreByTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testForceClearBooking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TutorialTests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BaseXCTestCase&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testOnboardingFlow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When executing the two tests with two simulators running in parallel, the actual run is like the one shown on the left side of the following image, but ideally it should work like the one on the right side.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image1.png&quot; alt=&quot;Tests of the same class are supposed to run on the same simulator but they should be able to run on different simulators.&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Tests of the same class are supposed to run on the same simulator but they should be able to run on different simulators.&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;diving-deep-into-xcode-parallel-testing&quot;&gt;Diving deep into Xcode parallel testing&lt;/h2&gt;

&lt;h3 id=&quot;demystifying-xcode-scheduling-log&quot;&gt;Demystifying Xcode scheduling log&lt;/h3&gt;

&lt;p&gt;As mentioned above, Xcode distributes tests to simulators/workers in a black-box manner. However, by looking at the scheduling log generated when running tests, we can understand how Xcode parallel testing works.&lt;/p&gt;

&lt;p&gt;When running UI tests via the &lt;code class=&quot;highlighter-rouge&quot;&gt;xcodebuild&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;xcodebuild &lt;span class=&quot;nt&quot;&gt;-workspace&lt;/span&gt; Driver/Driver.xcworkspace &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-scheme&lt;/span&gt; Driver &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-configuration&lt;/span&gt; Debug &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-sdk&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'iphonesimulator'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-destination&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'platform=iOS Simulator,id=EEE06943-7D7B-4E76-A3E0-B9A5C1470DBE'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-derivedDataPath&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'./DerivedData'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-parallel-testing-enabled&lt;/span&gt; YES &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-parallel-testing-worker-count&lt;/span&gt; 2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 👈👈👈👈👈&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/TutorialTests &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    test-without-building
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The log can be found inside the &lt;code class=&quot;highlighter-rouge&quot;&gt;*.xcresult&lt;/code&gt; folder under &lt;code class=&quot;highlighter-rouge&quot;&gt;DerivedData/Logs/Test&lt;/code&gt;. For example: &lt;code class=&quot;highlighter-rouge&quot;&gt;DerivedData/Logs/Test/Test-Driver-2019.11.04\_23-31-34-+0800.xcresult/1\_Test/Diagnostics/DriverUITests-144D9549-FD53-437B-BE97-8A288855E259/scheduling.log&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image5.png&quot; alt=&quot;Scheduling log under xcresult folder.&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Scheduling log under xcresult folder&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-11-05 03:55:00 +0000: Received worker from worker provider: 0x7fe6a684c4e0 [0: Clone 1 of DaxIOS-XC10-1-iP7-1 (3D082B53-3159-4004-A798-EA5553C873C4)]
2019-11-05 03:55:13 +0000: Worker 0x7fe6a684c4e0 [4985: Clone 1 of DaxIOS-XC10-1-iP7-1 (3D082B53-3159-4004-A798-EA5553C873C4)] finished bootstrapping
2019-11-05 03:55:13 +0000: Parallelization enabled; test execution driven by the IDE
2019-11-05 03:55:13 +0000: Skipping test class discovery
2019-11-05 03:55:13 +0000: Executing tests {(	# 👈👈👈👈👈
    DriverUITests/JobFlowTests,
    DriverUITests/TutorialTests
)}; skipping tests {(
)}
2019-11-05 03:55:13 +0000: Load balancer requested an additional worker
2019-11-05 03:55:13 +0000: Dispatching tests {(  # 👈👈👈👈👈
    DriverUITests/JobFlowTests
)} to worker: 0x7fe6a684c4e0 [4985: Clone 1 of DaxIOS-XC10-1-iP7-1 (3D082B53-3159-4004-A798-EA5553C873C4)]
2019-11-05 03:55:13 +0000: Received worker from worker provider: 0x7fe6a1582e40 [0: Clone 2 of DaxIOS-XC10-1-iP7-1 (F640C2F1-59A7-4448-B700-7381949B5D00)]
2019-11-05 03:55:39 +0000: Dispatching tests {(  # 👈👈👈👈👈
    DriverUITests/TutorialTests
)} to worker: 0x7fe6a684c4e0 [4985: Clone 1 of DaxIOS-XC10-1-iP7-1 (3D082B53-3159-4004-A798-EA5553C873C4)]
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Looking at the log below, we know that once a test class is dispatched or distributed to a worker/simulator, all tests of that class will be executed in that simulator.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-11-05 03:55:39 +0000: Dispatching tests {(
    DriverUITests/TutorialTests
)} to worker: 0x7fe6a684c4e0 [4985: Clone 1 of DaxIOS-XC10-1-iP7-1 (3D082B53-3159-4004-A798-EA5553C873C4)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Even when we customize a test suite (by swizzling some &lt;code class=&quot;highlighter-rouge&quot;&gt;XCTestSuite&lt;/code&gt; class methods or variables), to split a test suite into multiple suites, it does not work because the made-up test suite is only initialized after tests are dispatched to a given worker.&lt;/p&gt;

&lt;p&gt;Therefore, &lt;strong&gt;&lt;em&gt;any hook to bypass this constraint must be done early on&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;passing-the--only-testing-argument-to-xcodebuild-command&quot;&gt;Passing the -only-testing argument to xcodebuild command&lt;/h3&gt;

&lt;p&gt;Now we pass tests (instead of test classes) to the &lt;code class=&quot;highlighter-rouge&quot;&gt;-only-testing&lt;/code&gt; argument.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ xcodebuild -workspace Driver/Driver.xcworkspace \
    # ...
    -only-testing:DriverUITests/JobFlowTests/testJobIgnoreByTimer \
    -only-testing:DriverUITests/JobFlowTests/testRecoverFlow \
    -only-testing:DriverUITests/JobFlowTests/testJobIgnoreByDax \
    -only-testing:DriverUITests/JobFlowTests/testHappyFlow \
    -only-testing:DriverUITests/JobFlowTests/testForceClearBooking \
    -only-testing:DriverUITests/TutorialTests/testOnboardingFlow \
    test-without-building
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But still, the scheduling log shows that &lt;strong&gt;&lt;em&gt;tests are grouped by test class before being dispatched to workers&lt;/em&gt;&lt;/strong&gt; (see the following log for reference). This grouping is automatically done by Xcode (which it should not).&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-11-05 04:21:42 +0000: Executing tests {(	# 👈
    DriverUITests/JobFlowTests/testJobIgnoreByTimer,
    DriverUITests/JobFlowTests/testRecoverFlow,
    DriverUITests/JobFlowTests/testJobIgnoreByDax,
    DriverUITests/TutorialTests/testOnboardingFlow,
    DriverUITests/JobFlowTests/testHappyFlow,
    DriverUITests/JobFlowTests/testForceClearBooking
)}; skipping tests {(
)}
2019-11-05 04:21:42 +0000: Load balancer requested an additional worker
2019-11-05 04:21:42 +0000: Dispatching tests {(  # 👈 ❌
    DriverUITests/JobFlowTests/testJobIgnoreByTimer,
    DriverUITests/JobFlowTests/testForceClearBooking,
    DriverUITests/JobFlowTests/testJobIgnoreByDax,
    DriverUITests/JobFlowTests/testHappyFlow,
    DriverUITests/JobFlowTests/testRecoverFlow
)} to worker: 0x7fd781261940 [6300: Clone 1 of DaxIOS-XC10-1-iP7-1 (93F0FCB6-C83F-4419-9A75-C11765F4B1CA)]
......
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;overcoming-grouping-logic-in-xcode-parallel-testing&quot;&gt;Overcoming grouping logic in Xcode parallel testing&lt;/h2&gt;

&lt;h3 id=&quot;tweaking-the--only-testing-argument-values&quot;&gt;Tweaking the -only-testing argument values&lt;/h3&gt;

&lt;p&gt;Based on our observation, we can imagine how Xcode runs tests in parallel. See below.&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Step&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;tests&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detect_tests_to_run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# parse -only-testing arguments
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Step&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;groups_of_tests&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_tests_by_test_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Step&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;groups_of_tests&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Step&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; 	&lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_free_worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Step&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;dispatch_tests_to_workers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groups_of_tests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the pseudo-code above, we do not have much control to change step 2 since that grouping logic is implemented by Xcode. But we have a good guess that Xcode groups tests, by the first two components (class name) only (For example,  &lt;code class=&quot;highlighter-rouge&quot;&gt;DriverUITests/JobFlowTests&lt;/code&gt;). In other words, tests having the same class name run together on one simulator.&lt;/p&gt;

&lt;p&gt;The trick to break this constraint is simple. We can tweak the input (test names) so that each group contains only one test. By inserting a random token in the class name, all class names in the tests that are passed via &lt;code class=&quot;highlighter-rouge&quot;&gt;-only-testing&lt;/code&gt; argument are different.&lt;/p&gt;

&lt;p&gt;For example, instead of passing:&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests/testJobIgnoreByTimer &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests/testRecoverFlow &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We rather use:&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests_AxY132z8/testJobIgnoreByTimer &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests_By8MTk7l/testRecoverFlow &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or we can use the test name itself as the token:&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests_testJobIgnoreByTimer/testJobIgnoreByTimer &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-only-testing&lt;/span&gt;:DriverUITests/JobFlowTests_testRecoverFlow/testRecoverFlow &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After that, looking at the scheduling log, we will see that the trick can bypass the grouping logic. Now, only one test is dispatched to a worker once ready.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-11-05 06:06:56 +0000: Dispatching tests {(	# 👈 ✅
    DriverUITests/JobFlowTests_testJobIgnoreByDax/testJobIgnoreByDax
)} to worker: 0x7fef7952d0e0 [13857: Clone 2 of DaxIOS-XC10-1-iP7-1 (9BA030CD-C90F-4B7A-B9A7-D12F368A5A64)]
2019-11-05 06:06:58 +0000: Dispatching tests {(	# 👈 ✅
    DriverUITests/TutorialTests_testOnboardingFlow/testOnboardingFlow
)} to worker: 0x7fef7e85fd70 [13719: Clone 1 of DaxIOS-XC10-1-iP7-1 (584F99FE-49C2-4536-B6AC-90B8A10F361B)]
2019-11-05 06:07:07 +0000: Dispatching tests {(	# 👈 ✅
    DriverUITests/JobFlowTests_testRecoverFlow/testRecoverFlow
)} to worker: 0x7fef7952d0e0 [13857: Clone 2 of DaxIOS-XC10-1-iP7-1 (9BA030CD-C90F-4B7A-B9A7-D12F368A5A64)]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;handling-tweaked-test-names&quot;&gt;Handling tweaked test names&lt;/h3&gt;

&lt;p&gt;When a worker/simulator receives a request to run a test, the app (could be the runner app or the hosting app) initializes an &lt;code class=&quot;highlighter-rouge&quot;&gt;XCTestSuite&lt;/code&gt; corresponding to the test name. In order for the test suite to be properly made up, we need to remove the inserted token.&lt;/p&gt;

&lt;p&gt;This could be done easily by swizzling the &lt;a href=&quot;https://developer.apple.com/documentation/xctest/xctestsuite/1500897-init&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;XCTestSuite.init(forTestCaseWithName:)&lt;/code&gt;&lt;/a&gt;. Inside that swizzled function, we remove the token and then call the original init function.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;extension&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;XCTestSuite&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;/// For 'Selected tests' suite&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;@objc&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;dynamic&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swizzled_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forTestCaseWithName&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;maskedName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;XCTestSuite&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;/// Recover the original test name&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;/// - masked: UITestCaseA_testA1/testA1      	--&amp;gt; recovered: UITestCaseA/testA1&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;/// - masked: Driver/UITestCaseA_testA1/testA1   --&amp;gt; recovered: Driver/UITestCaseA/testA1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;guard&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;testBaseName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maskedName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;separator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swizzled_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forTestCaseWithName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maskedName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;recoveredName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maskedName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replacingOccurrences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;_&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testBaseName&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;👈&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swizzled_init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forTestCaseWithName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recoveredName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;👈&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;init&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image2.png&quot; alt=&quot;Swizzle function to run tests properly&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Swizzle function to run tests properly&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;test-class-discovery&quot;&gt;Test class discovery&lt;/h3&gt;

&lt;p&gt;In order to adopt this tip, we need to know which test classes we need to run in advance. Although Apple does not provide an API to obtain the list before running tests, this can be done in several ways. One approach we can use is to generate test classes using &lt;a href=&quot;https://github.com/krzysztofzablocki/Sourcery&quot;&gt;Sourcery&lt;/a&gt;. Another alternative is to parse the binaries inside &lt;code class=&quot;highlighter-rouge&quot;&gt;.xctest&lt;/code&gt; bundles (in build products) to look for symbols related to tests.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we identified some factors causing test execution time imbalance in Xcode parallel testing (particularly for UI tests).&lt;/p&gt;

&lt;p&gt;We also looked into how Xcode distributes tests in parallel testing. We also try to mitigate a constraint in which tests within the same class run on the same simulator. The trick not only reduces the imbalance but also gives us more confidence in adding more tests to a class without caring about whether it affects our CI infrastructure.&lt;/p&gt;

&lt;p&gt;Below is the metric about test time imbalance recorded when running UI tests. After adopting the trick, we saw a decrease in the metric (which is a good sign). As of now, the metric stabilizes at around 0.4 mins.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing/image4.png&quot; alt=&quot;Tracking data of UI test time imbalance (in minutes) in our project, collected by multiple runs&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Tracking data of UI test time imbalance (in minutes) in our project, collected by multiple runs&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;
&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Mon, 16 Mar 2020 08:13:20 +0000</pubDate>
        <link>https://engineering.grab.com/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing</link>
        <guid isPermaLink="true">https://engineering.grab.com/tackling-ui-test-execution-time-imbalance-for-xcode-parallel-testing</guid>
        
        <category>xcode</category>
        
        <category>testing</category>
        
        <category>mobile</category>
        
        <category>parallelism</category>
        
        <category>UI tests</category>
        
        <category>CI</category>
        
        <category>iOS</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Returning 575 Terabytes of storage space back to our users</title>
        <description>&lt;p&gt;Have you ever run out of storage on your phone? Mobile phones come with limited storage and with the multiplication of apps and large video files, many of you are running out of space.&lt;/p&gt;

&lt;p&gt;In this article, we explain how we measure and reduce the storage footprint of the Grab App on a user’s device to help you overcome this issue.&lt;/p&gt;

&lt;h2 id=&quot;the-wakeup-call&quot;&gt;The wakeup call&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.android.com/topic/performance/vitals&quot;&gt;Android vitals&lt;/a&gt; (information provided by Google play Console about our app performance) gives us two main pieces of information about storage footprint.&lt;/p&gt;

&lt;p&gt;15.7% of users have less than 1GB of free storage and they tend to uninstall more than other users (1.2x).&lt;/p&gt;

&lt;p&gt;The proportion of 30 day active devices which reported less than 1GB free storage. Calculated as a 30 days rolling average.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/returning-storage-space-back-to-our-users/image2.png&quot; alt=&quot;Active devices with &amp;lt;1GB free space&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Active devices with &amp;lt;1GB free space&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;This is the ratio of uninstalls on active devices with less than 1GB free storage to uninstalls on all active devices. Calculated as a 30 days rolling average.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/returning-storage-space-back-to-our-users/image5.png&quot; alt=&quot;Ratio of uninstalls on active devices with less than 1GB&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Ratio of uninstalls on active devices with less than 1GB&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;instrumentation-to-know-where-we-stand&quot;&gt;Instrumentation to know where we stand&lt;/h2&gt;

&lt;p&gt;First things first, we needed to know how much space the Grab App occupies on user device. So we started using our personal devices. We can find this information by opening the phone settings and selecting Grab App.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/returning-storage-space-back-to-our-users/image3.jpg&quot; alt=&quot;App Settings&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;App Settings&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;For this device (screenshot), the application itself (Installed binary) was 186 MB and the total footprint was 322 MB. Since this information varies a lot based on the usage of the app, we needed this information directly from our users in production.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: We are only measuring files that are inside the internal Grab app folder (Cache/Database). We do NOT measure any file that is not inside the private Grab folder.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We decided to leverage on our current implementation using &lt;a href=&quot;https://developer.android.com/reference/android/os/storage/StorageManager&quot;&gt;StorageManager&lt;/a&gt; API to gather the following information during each session launch:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Application Size (Installed binary size)&lt;/li&gt;
  &lt;li&gt;Cache folder size&lt;/li&gt;
  &lt;li&gt;Total footprint&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/returning-storage-space-back-to-our-users/image1.png&quot; alt=&quot;Sample code to retrieve storage information on Android&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Sample code to retrieve storage information on Android&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;data-analysis&quot;&gt;Data analysis&lt;/h3&gt;

&lt;p&gt;We began analysing this data one month after our users’ updated their app and found that the cache size was anomaly huge (&amp;gt; 1GB) for a lot of users. Intrigued, we dug deeper.&lt;/p&gt;

&lt;p&gt;We added code to log the top largest files inside the cache folder, and we found that most of the files were inside a sub cache folder that was no longer in use. This was due to a usage of a 3rd party library that was removed from our app. We added a specific metric to track the size of this folder.&lt;/p&gt;

&lt;p&gt;In the end, a lot of users still had this old cache data and for some users the amount of data can be up to 1GB.&lt;/p&gt;

&lt;h3 id=&quot;root-cause-analysis&quot;&gt;Root cause analysis&lt;/h3&gt;

&lt;p&gt;The Grab app relies a lot on 3rd party libraries. For example, &lt;a href=&quot;https://github.com/square/picasso&quot;&gt;Picasso&lt;/a&gt; was a library we used in the past for image display which is now replaced by &lt;a href=&quot;https://developer.android.com/topic/performance/graphics/load-bitmap&quot;&gt;Glide&lt;/a&gt;. Picasso uses a cache to store images and avoid making network calls again and again. After removing Picasso from the app, we didn’t delete this cache folder on the user device. We knew there would likely be more third-party libraries that had been discontinued so we expanded our analysis to look at how other 3rd party libraries cached their data.&lt;/p&gt;

&lt;h2 id=&quot;freeing-up-space-on-users-phone&quot;&gt;Freeing up space on user’s phone&lt;/h2&gt;

&lt;p&gt;Here comes the fun part. We implemented a cleanup mechanism to remove old cache folders. When users update the GrabApp, any old cache folders which were there before would automatically be removed. Through this, we released up to 1GB of data in a second back to our users. In total, we removed 575 terabytes of old cache data across more than 13 million devices (approximately 40MB per user on average).&lt;/p&gt;

&lt;h2 id=&quot;data-summary&quot;&gt;Data summary&lt;/h2&gt;

&lt;p&gt;The following graph shows the total size of junk data (in Terabytes) that we can potentially remove each day, calculated by summing up the maximum size of cache when a user opens the Grab app each day.&lt;/p&gt;

&lt;p&gt;The first half of the graph reflects the amount of junk data in relation to the latest app version before auto-clean up was activated. The second half of the graph shows a dramatic dip in junk data after auto-clean up was activated. We were deleting up to 33 Terabytes of data per day on the user’s device when we first started!&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/returning-storage-space-back-to-our-users/image4.png&quot; alt=&quot;Sum of all junk data on user’s device reported per day in Terabytes&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Sum of all junk data on user’s device reported per day in Terabytes&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&quot;next-step&quot;&gt;Next step&lt;/h2&gt;

&lt;p&gt;This is the first phase of our journey in reducing the storage footprint of our app on Android devices. We specifically focused on making improvements at scale i.e. deliver huge storage gains to the most number of users in the shortest time. In the next phase, we will look at more targeted improvements for specific groups of users that still have a high storage footprint. In addition, we are also reviewing iOS data to see if a round of clean up is necessary.&lt;/p&gt;

&lt;p&gt;Concurrently, we are also reducing the maximum size of cache created by some libraries. For example, Glide by default creates a cache of 250MB but this can be configured and optimised.&lt;/p&gt;

&lt;p&gt;We hope you found this piece insightful and please remember to update your app regularly to benefit from the improvements we’re making every day. If you find that your app is still taking a lot of space on your phone, be assured that we’re looking into it.&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Tue, 25 Feb 2020 20:13:00 +0000</pubDate>
        <link>https://engineering.grab.com/returning-storage-space-back-to-our-users</link>
        <guid isPermaLink="true">https://engineering.grab.com/returning-storage-space-back-to-our-users</guid>
        
        <category>Mobile</category>
        
        <category>Android</category>
        
        <category>Performance</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Grab-Posisi - Southeast Asia’s first comprehensive GPS trajectory dataset</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction        &lt;/h2&gt;

&lt;p&gt;At Grab, thousands of bookings happen daily via the Grab app. The driver phones and GPS devices enable us to collect large-scale GPS trajectories.&lt;/p&gt;

&lt;p&gt;Apart from the time and location of the object, GPS trajectories are also characterised by other parameters such as speed, the headed direction, the area and distance covered during its travel, and the travelled time. Thus, the trajectory patterns from users GPS data are a valuable source of information for a wide range of urban applications, such as solving transportation problems, traffic prediction, and developing reasonable urban planning.&lt;/p&gt;

&lt;p&gt;Currently, it’s a herculean task to create and maintain the GPS datasets since it’s costly and laborious. As a result, most of the GPS datasets available today in the market have poor coverage or contain outdated information. They cover only a small area of a city, have low sampling rates and contain less contextual information of the GPS pings such as no accuracy level, bearing, and speed. Despite over a dozen mapping communities engaged in collecting GPS trajectory datasets, a significant amount of effort would be required for data cleaning and data pre-processing in order to utilize them.&lt;/p&gt;

&lt;p&gt;To overcome the shortfalls in the existing datasets, we built Grab-Posisi, the first GPS trajectory dataset of Southeast Asia. The term Posisi refers to a position in Bahasa. The data was collected from Grab drivers’ phones while in transit. By tackling the addition of major arterial roads in regions where existing maps have poor coverage, and the incremental improvement of coverage in regions where major roads are already mapped, Posisi substantially improves mapping productivity.&lt;/p&gt;

&lt;h2 id=&quot;whats-inside-the-dataset&quot;&gt;What’s inside the dataset&lt;/h2&gt;

&lt;p&gt;The whole Grab-Posisi dataset contains in total 84K trajectories that consist of more than 80 million GPS pings and cover over 1 million km. The average trajectory length is 11.94 km and the average duration per trip is 21.50 minutes.&lt;/p&gt;

&lt;p&gt;The data were collected very recently in April 2019 with a 1 second sampling rate, which is the highest amongst all the publicly available datasets. It also has richer contextual information, including the accuracy level, bearing and speed. The accuracy level is important because GPS measurements are noisy and the true location can be anywhere inside a circle centred at the reported location with a radius equal to the accuracy level. The bearing is the horizontal direction of travel, measured in degrees relative to true north. Finally, the speed is reported in meters/second over ground.&lt;/p&gt;

&lt;p&gt;As the GPS trajectories were collected from Grab drivers’ phones while in transit, we labelled each trajectory by phone device type being either Android or iOS. This is the first dataset which differentiates such device information. Furthermore, we also label the trajectories by driving mode (Car or Motorcycle).&lt;/p&gt;

&lt;p&gt;All drivers’ personal information is encrypted and the real start/end locations are removed within the dataset.&lt;/p&gt;

&lt;h3 id=&quot;data-format&quot;&gt;Data format&lt;/h3&gt;

&lt;p&gt;Each trajectory is serialised in a file in Apache Parquet format. The whole dataset size is around 2 GB. Each GPS ping is associated with values for a trajectory ID, latitude, longitude, timestamp (UTC), accuracy level, bearing and speed. The GPS sampling rate is 1 second, which is the highest among all the existing open source datasets. Table 1 shows a sample of the dataset.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grab-posisi/image6.png&quot; alt=&quot;Table 1: Sample dataset&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Table 1: Sample dataset&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h3 id=&quot;coverage&quot;&gt;Coverage&lt;/h3&gt;

&lt;p&gt;Figure 1a shows the spatial coverage of the dataset in Singapore. Compared with the GPS datasets available in the market that only cover a specific area of a city, the Grab-Posisi dataset encompasses almost the whole island of Singapore. Figure 1b depicts the GPS density in Singapore. Red represents high density while green represents low density. Expressways in Singapore are clearly visible because of their dense GPS pings.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grab-posisi/image7.png&quot; alt=&quot;Figure 1a. Spatial coverage (Singapore)&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 1a. Spatial coverage (Singapore)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grab-posisi/image5.png&quot; alt=&quot;Figure 1b. GPS density (highways have more GPS)&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 1b. GPS density (highways have more GPS)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;p&gt;Figure 2a illustrates that the Grab-Posisi dataset encloses not only central Jakarta but also extends to external highways. Figure 2b depicts the GPS density of cars in Jakarta. Compared with Singapore, trips in Jakarta are spread out in all different areas, not just concentrated on highways.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grab-posisi/image2.png&quot; alt=&quot;Figure 2a. Spatial coverage (Jakarta)&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 2a. Spatial coverage (Jakarta)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/grab-posisi/image1.png&quot; alt=&quot;Figure 2b. GPS density (Car)&quot; /&gt;
  &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 2b. GPS density (Car)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/div&gt;

&lt;h4 id=&quot;applications-of-grab-posisi&quot;&gt;Applications of Grab-Posisi&lt;/h4&gt;

&lt;p&gt;The following are some of the applications of Grab-Posisi dataset.&lt;/p&gt;

&lt;h5 id=&quot;on-map-inference&quot;&gt;On Map Inference&lt;/h5&gt;

&lt;p&gt;The traditional method used in updating road networks in maps is time-consuming and labour-intensive. That’s why maps might have important roads missing and real-time traffic conditions might be unavailable. To address this problem, we can use GPS trajectories in reconstructing road networks automatically.&lt;/p&gt;

&lt;p&gt;A bunch of map generation algorithms can be applied to infer both map topology and road attributes. Figure 3b shows a snippet of the inferred map from our GPS trajectories (Figure 3a) using one of the algorithms. As you can see from the blue dots, the skeleton of the underlining map inferred is correct, although some section of the inferred road is disconnected, and at the roundabout in the bottom right corner it’s not a smooth curve.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;column&quot;&gt;
    &lt;img src=&quot;/img/grab-posisi/image3.jpg&quot; alt=&quot;Figure 3a. Raw GPS trajectories&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 3a. Raw GPS trajectories  &lt;/i&gt;&lt;/figcaption&gt;
  &lt;/div&gt;
  &lt;div class=&quot;column&quot;&gt;
    &lt;img src=&quot;/img/grab-posisi/image4.jpg&quot; alt=&quot;Figure 3b. Inferred Map&quot; /&gt;
    &lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Figure 3b. Inferred Map&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h5 id=&quot;on-map-matching-&quot;&gt;On Map Matching                                         &lt;/h5&gt;

&lt;p&gt;The map matching refers to the task of automatically determining the correct route where the driver has travelled on a digital map, given a sequence of raw and noisy GPS points. The correction of the raw GPS data has been important for many location-based applications such as navigation, tracking, and road attribute detection as aforementioned. The accuracy levels provided in the Grab-Posisi dataset can be of great use to address this issue.&lt;/p&gt;

&lt;h5 id=&quot;on-traffic-detection-and-forecast-&quot;&gt;On Traffic Detection and Forecast                         &lt;/h5&gt;

&lt;p&gt;In addition to the inference of a static digital map, the Grab-Posisi GPS dataset can also be used to perform real-time traffic forecasting, which is very important for congestion detection, flow control, route planning, and navigation. Some examples of the fundamental indicators that are mostly used to monitor the current status of traffic conditions include the average speed, volume, and density in each road segment. These variables can be computed based on drivers’ GPS trajectories and can be used to predict the future traffic conditions.&lt;/p&gt;

&lt;h5 id=&quot;on-mode-detection-&quot;&gt;On Mode Detection                         &lt;/h5&gt;

&lt;p&gt;Transportation mode detection refers to the task of identifying the travel mode of a user (some examples of transportation mode include walk, bike, car, bus, etc.). The GPS trajectories in our dataset are associated with rich attributes including GPS accuracy, bearing, and speed in addition to the latitude and longitude of geo-coordinates, which can be used to develop mode detection models. Our dataset also provides labels for each trajectory to be collected from a car or motorcycle, which can be used to verify performance of those models.&lt;/p&gt;

&lt;h5 id=&quot;economics-perspective-&quot;&gt;Economics Perspective                                         &lt;/h5&gt;

&lt;p&gt;The real-world GPS trajectories of people reveal realistic travel patterns and demands, which can be of great help for city planning. As there are some realistic constraints faced by governments such as budget limitations and construction inconvenience, it is important to incorporate both the planning authorities’ requirements and the realistic travel demands mined from trajectories for intelligent city planning. For example, the trajectories of cars can provide suggestions on how to schedule highway constructions. The trajectories of motorcycles can help the government to choose the optimal locations to construct motorcycle lanes for safety concerns.&lt;/p&gt;

&lt;h2 id=&quot;want-to-access-our-dataset&quot;&gt;Want to access our dataset?&lt;/h2&gt;

&lt;p&gt;Grab-Posisi dataset offers a great value and is a significant resource to the community for benchmarking and revisiting existing technologies.         &lt;/p&gt;

&lt;p&gt;If you want to access our dataset for research purposes, email &lt;a href=&quot;mailto:grab.posisi@grabtaxi.com&quot;&gt;grab.posisi@grabtaxi.com&lt;/a&gt; with the following details:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Your Name and contact details&lt;/li&gt;
  &lt;li&gt;Your institution&lt;/li&gt;
  &lt;li&gt;Your potential usage of the dataset&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When using Grab-Posisi dataset, please cite the following paper:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Huang, X., Yin, Y., Lim, S., Wang, G., Hu, B., Varadarajan, J., … &amp;amp; Zimmermann, R. (2019, November). Grab-Posisi: An Extensive Real-Life GPS Trajectory Dataset in Southeast Asia. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Prediction of Human Mobility (pp. 1-10). DOI: &lt;a href=&quot;https://doi.org/10.1145/3356995.3364536&quot;&gt;https://doi.org/10.1145/3356995.3364536&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;div&gt;Click &lt;a href=&quot;/files/Grab-Posisi_An_Extensive_Real-Life_GPS_Trajectory_Dataset_in_Southeast_Asia.pdf&quot; download=&quot;&quot;&gt;here&lt;/a&gt; to download the published paper.&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

&lt;div&gt;Click &lt;a href=&quot;/files/grab-posisi-dataset.bib&quot; download=&quot;&quot;&gt;here&lt;/a&gt; to download the BibTex file.&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Note: You cannot use Grab-Posisi dataset for commercial purposes.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Feb 2020 18:43:40 +0000</pubDate>
        <link>https://engineering.grab.com/grab-posisi</link>
        <guid isPermaLink="true">https://engineering.grab.com/grab-posisi</guid>
        
        <category>gps</category>
        
        <category>datasets</category>
        
        <category>map</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How We Prevented App Performance Degradation From Sudden Ride Demand Spikes</title>
        <description>&lt;p&gt;In Southeast Asia, when it rains, it pours. It’s a major mood dampener especially if you are stuck outside when the rain starts, you are about to have an awful day.&lt;/p&gt;

&lt;p&gt;In the early days of Grab, if the rains came at the wrong time, like during morning rush hour, then we engineers were also in for a terrible day.&lt;/p&gt;

&lt;p&gt;In those days, demand for Grab’s ride services grew much faster than our ability to scale our tech system and this often meant clocking late nights just to ensure our system could handle the ever-growing demand. When there’s a massive, sudden spike in ride bookings, our system often struggled to manage the load.&lt;/p&gt;

&lt;p&gt;There were also other contributors to demand spikes, for example when public transport services broke down or when a major event such as an international concert ends and event-goers all need a ride at the same time.&lt;/p&gt;

&lt;p&gt;Upon reflection, we realized there were two integral aspects to these incidents.&lt;/p&gt;

&lt;p&gt;Firstly, they were localized events. The increase in demand came from a particular geographical location; in some cases a very small area. These localized events had the potential to cause so much load on our system that it impacted the experience of other users outside the geolocation.&lt;/p&gt;

&lt;p&gt;Secondly, the underlying problem was a lack of drivers (supply) in that particular geographical area.&lt;/p&gt;

&lt;p&gt;At Grab, our goal has always been to get everyone a ride when and where they needed it, but in this situation, it was just not possible. We needed to find a way to ensure this localized demand spike did not affect our ability to meet the needs of other users.&lt;/p&gt;

&lt;h2 id=&quot;enter-the-spampede-filter&quot;&gt;Enter the Spampede Filter&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Spampede&lt;/strong&gt; (a play of the words spam and stampede) filter was inspired by another concept you may have read on this blog, &lt;a href=&quot;https://engineering.grab.com/designing-resilient-systems-part-1&quot;&gt;circuit breakers&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In software, as in electronics, circuit breakers are designed to protect a system by short-circuiting in the face of adverse conditions.&lt;/p&gt;

&lt;p&gt;Let’s break this down.&lt;/p&gt;

&lt;p&gt;There are two key concepts here: &lt;em&gt;short-circuiting&lt;/em&gt; and &lt;em&gt;adverse conditions&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Firstly, &lt;em&gt;short-circuiting&lt;/em&gt;, in this context means performing minimal processing on a particular booking, and by doing so, reducing the overall load on the system. Secondly, &lt;em&gt;adverse conditions&lt;/em&gt;, in this, we refer to a large number of unfulfilled requests for a particular service, from a small geographical area, within a short time window. With these two concepts in mind, we devised the following process.&lt;/p&gt;

&lt;h2 id=&quot;spampede-design&quot;&gt;Spampede Design&lt;/h2&gt;

&lt;p&gt;First, we needed to track unallocated requests in a location-aware manner. To do this, we convert the requested pickup location of an unallocated request using the &lt;a href=&quot;https://github.com/corsc/go-geohash&quot;&gt;Geohash Integer&lt;/a&gt; algorithm.  &lt;/p&gt;

&lt;p&gt;After the conversion, the resulting value is an exact location. We can convert this location into a “bucket” or area by reducing the precision.&lt;/p&gt;

&lt;p&gt;This method is by no means smart or aware of the local geography, but it is incredibly CPU efficient and requires no external resources like network API calls.&lt;/p&gt;

&lt;p&gt;Now that we can track unallocated requests, we needed a way for the tracking to be time-aware. After all, traffic conditions, driver locations, and passenger demand are continually changing. We could have implemented something precise like a sliding window sum, but that would have introduced a lot of complexity and a significantly higher CPU and memory cost.&lt;/p&gt;

&lt;p&gt;By using the Unix timestamp, we converted the current time to a “bucket” of time by using the straightforward formula:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Event Sourcing&quot; src=&quot;/img/preventing-app-performance-degradation-due-to-sudden-ride-demand-spikes/image1.png&quot; /&gt;
      &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;where &lt;em&gt;bs&lt;/em&gt; is the size of the time buckets in seconds&lt;/p&gt;

&lt;p&gt;With location and time buckets calculated, we can track the unallocated bookings using Redis. We could have used any data store, but Redis was familiar and battle-proven to us.&lt;/p&gt;

&lt;p&gt;To do this, we first constructed the Redis key by combining the service type, the geographic location, and the time bucket. With this key, we call the &lt;a href=&quot;https://redis.io/commands/incr&quot;&gt;INCR&lt;/a&gt; command, which increments the value stored in that location and returns the new value.&lt;/p&gt;

&lt;p&gt;If the value returned is 1, this indicates that this is the first value stored for this bucket combination, and we would then make a second call, this time to &lt;a href=&quot;https://redis.io/commands/expire&quot;&gt;EXPIRE&lt;/a&gt;. With this second call, we would set a time to live (TTL) on the Redis item, allowing the data to be self-cleaning.&lt;/p&gt;

&lt;p&gt;You will notice that we are blindly calling increment and only making a second call if needed. This pattern is more efficient and resource-friendly than using a more traditional, load-check-store pattern.&lt;/p&gt;

&lt;p&gt;The next step was the configuration. Specifically, setting how many unallocated bookings could happen in a particular location and time bucket before the circuit opened. For this, we decided on Redis again. Again, we could have used anything, but we were already using Redis and, as mentioned previously, quite familiar with it.&lt;/p&gt;

&lt;p&gt;Finally, the last piece. We introduced code at the beginning of our booking processing, most importantly, before any calls to any other services and before any significant processing was done. This code compared the location, time, and requested service to the currently configured Spampede setting, along with the previously unallocated bookings. If the maximum had already been reached, then we immediately stopped processing the booking.&lt;/p&gt;

&lt;p&gt;This might sound harsh- to immediately refuse a booking request without even trying to fulfill it. But the goal of the Spampede filter is to prevent excessive, localized demand from impacting all of the users of the system.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Reading about this as a programmer, it probably feels strange, intentionally dropping bookings and impacting the business this way.&lt;/p&gt;

&lt;p&gt;After all, we want nothing more than to help people get to where they need to be. This process is a system safety mechanism to ensure that the system stays alive and able to do just that.&lt;/p&gt;

&lt;p&gt;I would be remiss if I didn’t highlight the critical software-engineering takeaway here is a combination of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Observer_effect_(physics)&quot;&gt;Observer effect&lt;/a&gt; and the underlying goals of the &lt;a href=&quot;https://en.wikipedia.org/wiki/CAP_theorem&quot;&gt;CAP theorem&lt;/a&gt;. Observing a system will influence the system due to the cost of instrumentation and monitoring.&lt;/p&gt;

&lt;p&gt;Generally, the higher the accuracy or consistency of the monitoring and limits, the higher the resource cost.&lt;/p&gt;

&lt;p&gt;In this case, we have intentionally chosen the most resource-efficient options and traded accuracy for more throughput.&lt;/p&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Jan 2020 15:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/preventing-app-performance-degradation-due-to-sudden-ride-demand-spikes</link>
        <guid isPermaLink="true">https://engineering.grab.com/preventing-app-performance-degradation-due-to-sudden-ride-demand-spikes</guid>
        
        <category>Resiliency</category>
        
        <category>Circuit Breakers</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Plumbing At Scale</title>
        <description>&lt;p&gt;When you open the Grab app and hit book, a series of events are generated that define your personalised experience with us: booking state machines kick into motion, driver partners are notified, reward points are computed, your feed is generated, etc. While it is important for you to know that a request has been received, a lot happens asynchronously in our back-end services.&lt;/p&gt;

&lt;p&gt;As custodians and builders of the streaming platform at Grab operating at massive scale (think terabytes of data ingress each hour), the Coban team’s mission is to provide a NoOps, managed platform for seamless, secure access to event streams in real-time, for every team at Grab.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Coban Sewu Waterfall In Indonesia&quot; height=&quot;65%&quot; width=&quot;65%&quot; src=&quot;/img/plumbing-at-scale/coban-waterfall.jpg&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Coban Sewu Waterfall In Indonesia. (Streams, get it?)&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Streaming systems are often at the heart of event-driven architectures, and what starts as a need for a simple message bus for asynchronous processing of events quickly evolves into one that requires a more sophisticated stream processing paradigms.
Earlier this year, we saw common patterns of event processing emerge across our Go backend ecosystem, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Filtering and mapping stream events of one type to another&lt;/li&gt;
  &lt;li&gt;Aggregating events into time windows and materializing them back to the event log or to various types of transactional and analytics databases&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generally, a class of problems surfaced which could be elegantly solved through an event sourcing&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; platform with a stream processing framework built over it, similar to the Keystone platform at Netflix&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;This article details our journey building and deploying an event sourcing platform in Go, building a stream processing framework over it, and then scaling it (reliably and efficiently) to service over 300 billion events a week.&lt;/p&gt;

&lt;h2 id=&quot;event-sourcing&quot;&gt;Event Sourcing&lt;/h2&gt;
&lt;p&gt;Event sourcing is an architectural pattern where changes to an application state are stored as a sequence of events, which can be replayed, recomputed, and queried for state at any time. An implementation of the event sourcing pattern typically has three parts to it:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An event log&lt;/li&gt;
  &lt;li&gt;Processor selection logic: The logic that selects which chunk of domain logic to run based on an incoming event&lt;/li&gt;
  &lt;li&gt;Processor domain logic: The domain logic that mutates an application’s state&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Event Sourcing&quot; src=&quot;/img/plumbing-at-scale/event-sourcing.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Event Sourcing&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Event sourcing is a building block on which architectural patterns such as Command Query Responsibility Segregation&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, serverless systems, and stream processing pipelines are built.&lt;/p&gt;

&lt;h2 id=&quot;the-case-for-stream-processing&quot;&gt;The Case For Stream Processing&lt;/h2&gt;
&lt;p&gt;Below are some use cases serviced by stream processing, built on event sourcing.&lt;/p&gt;

&lt;h4 id=&quot;asynchronous-state-management&quot;&gt;Asynchronous State Management&lt;/h4&gt;
&lt;p&gt;A pub-sub system allows for change events from one service to be fanned out to multiple interested subscribers without letting any one subscriber block the progress of others. Abstracting the event log and centralising it democratises access to this log to all back-end services. It enables the back-end services to apply changes from this centralised log to their own state, independent of downstream services, and/or publish their state changes to it.&lt;/p&gt;

&lt;h4 id=&quot;time-windowed-aggregations&quot;&gt;Time Windowed Aggregations&lt;/h4&gt;
&lt;p&gt;Time-windowed aggregates are a common requirement for machine learning models (as features) as well as analytics. For example, personalising the Grab app landing page requires counting your interaction with various widget elements in recent history, not any one event in particular. Similarly, an analyst may not be interested in the details of a singular booking in real-time, but in building demand heatmaps segmented by geohashes. For latency-sensitive lookups, especially for the personalisation example, pre-aggregations are preferred instead of post-aggregations.&lt;/p&gt;

&lt;h4 id=&quot;stream-joins-filtering-mapping&quot;&gt;Stream Joins, Filtering, Mapping&lt;/h4&gt;
&lt;p&gt;Event logs are typically sharded by some notion of topics to logically divide events of interest around a theme (booking events, profile updates, etc.). Building bigger topics out of smaller ones, as well as smaller ones from bigger ones are common ways to compose “substreams”  of the log of interest directed towards specific services. For example, a promo service may only be interested in listening to booking events for promotional bookings.&lt;/p&gt;

&lt;h4 id=&quot;realtime-business-intelligence&quot;&gt;Realtime Business Intelligence&lt;/h4&gt;
&lt;p&gt;Outputs of stream processing workloads are also plugged into realtime Business Intelligence (BI) and stream analytics solutions upstream, as raw data for visualizations on operations dashboards.&lt;/p&gt;

&lt;h4 id=&quot;archival&quot;&gt;Archival&lt;/h4&gt;
&lt;p&gt;For offline analytics, as well as reconciliation and disaster recovery, having an archive in a cold store helps for certain mission critical streams.&lt;/p&gt;

&lt;h2 id=&quot;platform-requirements&quot;&gt;Platform Requirements&lt;/h2&gt;
&lt;p&gt;Any processing platform for event sourcing and stream processing has certain expectations around its functionality.&lt;/p&gt;

&lt;h4 id=&quot;scaling-and-elasticity&quot;&gt;Scaling and Elasticity&lt;/h4&gt;
&lt;p&gt;Stream/Event Processing pipelines need to be elastic and responsive to changes in traffic patterns, especially considering that user activity (rides, food, deliveries, payments) varies dramatically during the course of a day or week. A spike in food orders on rainy days shouldn’t cause indefinite order processing latencies.&lt;/p&gt;

&lt;h4 id=&quot;noops&quot;&gt;NoOps&lt;/h4&gt;
&lt;p&gt;For a platform team, it’s important that users can easily onboard and manage their pipeline lifecycles, at their preferred cadence. To scale effectively, the process of scaffolding, configuring, and deploying pipelines needs to be standardised, and infrastructure managed. Both the platform and users are able to leverage common standards of telemetry, configuration, and deployment strategies, and users benefit from a lack of infrastructure management overhead.&lt;/p&gt;

&lt;h4 id=&quot;multi-tenancy&quot;&gt;Multi-Tenancy&lt;/h4&gt;
&lt;p&gt;Our platform has quickly scaled to support hundreds of pipelines. Workload isolation, independent processing uptime guarantees, and resource allocation and cost audit are important requirements necessitating multi-tenancy, which help amortize platform overhead costs.&lt;/p&gt;

&lt;h4 id=&quot;resiliency&quot;&gt;Resiliency&lt;/h4&gt;
&lt;p&gt;Whether latency sensitive or latency tolerant, all workloads have certain expectations on processing uptime. From a user’s perspective, there must be guarantees on pipeline uptimes and data completeness, upper bounds on processing delays, instrumentation for alerting, and self-healing properties of the platform for remediation.&lt;/p&gt;

&lt;h4 id=&quot;tunable-tradeoffs&quot;&gt;Tunable Tradeoffs&lt;/h4&gt;
&lt;p&gt;Some pipelines are latency sensitive, and rely on processing completeness seconds after event ingress. Other pipelines are latency tolerant, and can tolerate disruption to processing lasting in tens of minutes. A one size fits all solution is likely to be either cost inefficient or unreliable. Having a way for users to make these tradeoffs consciously becomes important for ensuring efficient processing guarantees at a reasonable cost. Similarly, in the case of upstream failures or unavailability, being able to tune failure modes (like wait, continue, or retry) comes in handy.&lt;/p&gt;

&lt;h2 id=&quot;stream-processing-framework&quot;&gt;Stream Processing Framework&lt;/h2&gt;
&lt;p&gt;While basic event sourcing covers simple use cases like archival, more complicated ones benefit from a common framework that shifts the mental model for processing from per event processing to stream pipeline orchestration.
Given that Go is a “paved road” for back-end development at Grab, and we have service code and bindings for streaming data in a mono-repository, we built a Go framework with a subset of capabilities provided by other streaming frameworks like Flink&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Logic Blocks In A Stream Processing Pipeline&quot; src=&quot;/img/plumbing-at-scale/pipeline-life-cycle.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Logic Blocks In A Stream Processing Pipeline&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;capabilities&quot;&gt;Capabilities&lt;/h4&gt;
&lt;p&gt;Some capabilities built into the framework include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Deduplication:&lt;/strong&gt;  Enables pipelines to idempotently reprocess data in case of rewinds/replays, and provides some processing guarantees within a time window for certain use cases including sinking to datastores.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Filtering and Mapping:&lt;/strong&gt; An ability to filter a source stream data and map them onto target streams.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Aggregation:&lt;/strong&gt; An ability to generate and execute aggregation logic such as sum, avg, max, and min in a window.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Windowing:&lt;/strong&gt; An ability to window processing into tumbling, sliding, and session windows.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Join:&lt;/strong&gt; An ability to combine two streams together with certain join keys in a window.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Processor Chaining:&lt;/strong&gt; Various functionalities can be chained to build more complicated pipelines from simpler ones. For example: filter a large stream into a smaller one, aggregate it over a time window, and then map it to a new stream.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rewind:&lt;/strong&gt; The ability to rewind the processing logic by a few hours through configuration.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Replay:&lt;/strong&gt; The ability to replay archived data into the same or a separate pipeline via configuration.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sinks:&lt;/strong&gt; A number of connectors to standard Grab stores are provided, with concerns of auth, telemetry, etc. managed in the runtime.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Error Handling:&lt;/strong&gt; Providing an easy way to indicate whether to wait, skip, and/or retry in case of upstream failures is an important tuning parameter that users need for making sensible tradeoffs in dimensions of backpressure, latency, correctness, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;
&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Coban Platform&quot; src=&quot;/img/plumbing-at-scale/coban-platform.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Coban Platform&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Our event log is primarily a bunch of critical Kafka clusters, which are being polled by various pipelines deployed by service teams on the platform for incoming events. Each pipeline is an isolated deployment, has an identity, and the ability to connect to various upstream sinks to materialise results into, including the event log itself.
There is also a metastore available as an intermediate store for processing pipelines, so the pipelines themselves are stateless with their lifecycle completely beholden to the whims of their owners.&lt;/p&gt;

&lt;h3 id=&quot;anatomy-of-a-processing-pipeline&quot;&gt;Anatomy of a Processing Pipeline&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Anatomy Of A Stream Processing Pod&quot; src=&quot;/img/plumbing-at-scale/anatomy-of-a-stream-processing-pod.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;Anatomy Of A Stream Processing Pod&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Anatomy of a Stream Processing Pod
Each stream processing pod (the smallest unit of a pipeline’s deployment) has three top level components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Triggers:&lt;/strong&gt; An interface that connects directly to the source of the data and converts it into an event channel.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Runtime:&lt;/strong&gt; This is the app’s entrypoint and the orchestrator of the pod. It manages the worker pools, triggers, event channels, and lifecycle events.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Pipeline plugin:&lt;/strong&gt; The plugin is provided by the user, and conforms to a contract that the platform team publishes. It contains the domain logic for the pipeline and houses the pipeline orchestration defined by a user based on our Stream Processing Framework.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deployment-infrastructure&quot;&gt;Deployment Infrastructure&lt;/h3&gt;
&lt;p&gt;Our deployment infrastructure heavily leverages Kubernetes on AWS. After a (pretty high) initial cost for infrastructure set up, we’ve found scaling to hundreds of pipelines a breeze with the Kubernetes provided controls. We package our stateless pipeline workloads into Kubernetes deployments, with each pod containing a unit of a stream pipeline, with sidecars that integrate them with our monitoring systems. Other cluster wide tooling deployed (usually as DaemonSets) deal with metric collection, log ingestion, and autoscaling. We currently use the Horizontal Pod Autoscaler&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; to manage traffic elasticity, and the Cluster Autoscaler&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; to manage worker node scaling.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;figure&gt;
    &lt;img alt=&quot;Kubernetes&quot; src=&quot;/img/plumbing-at-scale/kubernetes.png&quot; /&gt;
    &lt;figcaption&gt;&lt;em&gt;A Typical Kubernetes Set Up On AWS&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;metastore&quot;&gt;Metastore&lt;/h4&gt;
&lt;p&gt;Some pipelines require storage for use cases ranging from deduplication to stores for materialised results of time windowed aggregations. All our pipelines have access to clusters of ScyllaDB instances (which we use as our internal store), made available to pipeline authors via interfaces in the Stream Processing Framework. Results of these aggregations are then made available to backend services via our GrabStats service, which is a thin query layer over the latest pipeline results.&lt;/p&gt;

&lt;h4 id=&quot;compute-isolation&quot;&gt;Compute Isolation&lt;/h4&gt;
&lt;p&gt;A nice property of packaging pipelines as Kubernetes deployments is a good degree of compute workload isolation for pipelines. While node resources of pipeline pods are still shared (and there are potential noisy neighbour issues on matters like logging throughput), the pipeline pods of various pods can be scheduled and rescheduled across a wide range of nodes safely and swiftly, with minimal impact to pods of other pipelines.&lt;/p&gt;

&lt;h4 id=&quot;redundancy&quot;&gt;Redundancy&lt;/h4&gt;
&lt;p&gt;Stateless processing pods mean we can set up backup or redundant Kubernetes clusters in hot-hot, hot-warm, or hot-cold modes. We use this to ensure high processing availability despite limited control plane guarantees from any single cluster. (Since EKS SLAs for the Kubernetes control plane guarantee only 99.9% uptime today&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;.) Transparent to our users, we make the deployment systems aware of multiple available targets for scheduling.&lt;/p&gt;

&lt;h4 id=&quot;availability-vs-cost&quot;&gt;Availability vs Cost&lt;/h4&gt;
&lt;p&gt;As alluded to in the “Platform Requirements” section, having a way of trading off availability for cost becomes important where the requirements and criticality of each processing pipeline are very different. Given that AWS spot instances are a lot cheaper&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; than on-demand ones, we use user annotated Kubernetes priority classes to determine deployment targets for pipelines. For latency tolerant pipelines, we schedule them on Spot instances which are routinely between 40-90% cheaper than on demand instances on which latency sensitive pipelines run. The caveat is that Spot instances occasionally disappear, and these workloads are disrupted until a replacement node for their scheduling can be found.&lt;/p&gt;

&lt;h1 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Expand the ecosystem of triggers to support custom sources of data i.e. the “event log”, as well as push based (RPC driven) versus just pull based triggers&lt;/li&gt;
  &lt;li&gt;Build a control plane for API integration with pipeline lifecycle management&lt;/li&gt;
  &lt;li&gt;Move some workloads to use the Vertical Pod Autoscaler&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; in Kubernetes instead of horizontal scaling, as most of our workloads have a limit on parallelism (which is their partition count in Kafka topics)&lt;/li&gt;
  &lt;li&gt;Move from Go plugins for pipelines to plugins over RPC, like what HashiCorp does&lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;, to enable processing logic in non-Go languages.&lt;/li&gt;
  &lt;li&gt;Use either pod gossip or a service mesh with a control plane to set up quotas for shared infrastructure usage per pipeline. This is to protect upstream dependencies and the metastore from surges in event backlogs.&lt;/li&gt;
  &lt;li&gt;Improve availability guarantees for pipeline pods by occasionally redistributing/rescheduling pods across nodes in our Kubernetes cluster to prevent entire workloads being served out of a few large nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Authored By Karan Kamath on behalf of the Coban team at Grab-
Zezhou Yu, Ryan Ooi, Hui Yang, Yuguang Xiao, Ling Zhang, Roy Kim, Matt Hino, Jump Char, Lincoln Lee, Jason Cusick, Shrinand Thakkar, Dean Barlan, Shivam Dixit, Shubham Badkur, Fahad Pervaiz, Andy Nguyen, Ravi Tandon, Ken Fishkin, and Jim Caputo.&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;join-us&quot;&gt;Join us&lt;/h2&gt;

&lt;p&gt;Grab is more than just the leading ride-hailing and mobile payments platform in Southeast Asia. We use data and technology to improve everything from transportation to payments and financial services across a region of more than 620 million people. We aspire to unlock the true potential of Southeast Asia and look for like-minded individuals to join us on this ride.&lt;/p&gt;

&lt;p&gt;If you share our vision of driving South East Asia forward, &lt;a href=&quot;https://grab.careers/jobs/&quot;&gt;apply&lt;/a&gt; to join our team today.&lt;/p&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Coban Sewu Waterfall Photo by Dwinanda Nurhanif Mujito on Unsplash&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Cover Photo by tian kuan on Unsplash&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;https://martinfowler.com/eaaDev/EventSourcing.html &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;https://martinfowler.com/bliki/CQRS.html &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;https://flink.apache.org &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;https://aws.amazon.com/eks/sla/ &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;https://aws.amazon.com/ec2/pricing/ &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;https://github.com/hashicorp/go-plugin &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 06 Jan 2020 19:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/plumbing-at-scale</link>
        <guid isPermaLink="true">https://engineering.grab.com/plumbing-at-scale</guid>
        
        <category>Event Sourcing</category>
        
        <category>Stream Processing</category>
        
        <category>Kubernetes</category>
        
        <category>Backend</category>
        
        <category>Platform</category>
        
        <category>Go</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Journey to a Faster Everyday Super App Where Every Millisecond Counts</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;At &lt;a href=&quot;https://www.grab.com&quot;&gt;Grab&lt;/a&gt;, we are moving faster than ever. In 2019 alone, we released dozens of new features in the Grab passenger app. With our goal to delight users in Southeast Asia with a powerful everyday super app, the app’s performance became one of the most critical components in delivering that experience to our users.&lt;/p&gt;

&lt;p&gt;This post narrates the journey of our performance improvement efforts on the Grab passenger app. It highlights how we were able to reduce the time spent starting the app by more than 60%, while preventing regressions introduced by new features. We use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Percentile&quot;&gt;p95&lt;/a&gt; scale when referring to these improvements.&lt;/p&gt;

&lt;p&gt;Here’s a quick look at the improvements and timeline:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Improvements Timeline&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image8.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&quot;improving-app-performance&quot;&gt;Improving App Performance&lt;/h2&gt;

&lt;p&gt;While app performance consists of different aspects - such as battery consumption rate, network performance, app responsiveness, etc. - the first thing users notice is the time it takes for an app to start. Apps that take too long to load frustrate users, leading to bad reviews and uninstalls.&lt;/p&gt;

&lt;p&gt;We focused our efforts on the app’s &lt;a href=&quot;https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive&quot;&gt;time to interactive&lt;/a&gt;(TTI), which consists of two main operations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Starting the app&lt;/li&gt;
  &lt;li&gt;Displaying interactive &lt;em&gt;service tiles&lt;/em&gt; (these are the icons for the services offered on the app such as Transport, Food, Delivery, and so on)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many other operations that occur in the background, which we won’t cover in this article.&lt;/p&gt;

&lt;p&gt;We prioritised on optimising the app’s ability to load the service tiles (highlighted in the image below) and render them as interactive upon startup (cold start). This allowed users to use the app as soon as they launch it.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Service Tiles&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image1.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&quot;instrumentation-and-benchmarking&quot;&gt;Instrumentation and Benchmarking&lt;/h2&gt;

&lt;p&gt;Before we could start improving the app’s performance, we needed to know where we stood and set measurable goals.&lt;/p&gt;

&lt;p&gt;We couldn’t get a baseline from local performance testing as it did not simulate the real environment condition, where network variability and device performance are contributing factors. Thus, we needed to use real production data to get an accurate reflection of our current performance at a scale. In production, we measured the performance of &lt;em&gt;~8-9 millions users per day&lt;/em&gt; - a small subset of our overall active user base.&lt;/p&gt;

&lt;p&gt;As a start, we measured the different components contributing to TTI, such as binary loading, library initialisations, and tiles loading. For example, if we had to measure the time taken by function A, this is how it looked like in the code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;functionA (){
// start the timer
....
....
...
//Stop the timer, calculate the time difference and send it as an analytic event
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With all the numbers from the contributing components, we took the sum to calculate the full TTI (as shown in the following image).&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Full TTI&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image9.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;When the numbers started rolling in from production, we needed specific measurements to interpret those numbers, so we started looking at TTI’s  50th, 90th, and 95th percentile. A 90th percentile (p90) of x seconds means that 90% of the users have an interactive screen in at most x seconds.&lt;/p&gt;

&lt;p&gt;We chose to only focus on p50 and p95 as these cover the majority of our users who deal with performance issues. Improving performance for &amp;lt;p50 (who already have high-end devices) would not bring too much of a value, and improving for &amp;gt;p95 would be very difficult as the app performance improvements will be limited by device performance.&lt;/p&gt;

&lt;p&gt;By the end of January, we got the p50, p90, and p95 numbers for the contributing components that summed up to TTI numbers for tiles, which allowed us to start identifying areas with potential improvements.&lt;/p&gt;

&lt;h2 id=&quot;caching-and-animation-removal&quot;&gt;Caching and Animation Removal&lt;/h2&gt;

&lt;p&gt;While reviewing the TTI numbers, we were drawn to contributors with high time consumption rates such as tile loading and app start animation. Other evident improvement we worked on was caching data between app launches instead of waiting for a network response for loading tiles at every single app launch.&lt;/p&gt;

&lt;h3 id=&quot;tile-caching&quot;&gt;Tile Caching&lt;/h3&gt;

&lt;p&gt;Based on the gathered data, the service tiles only change when a user travels between cities. This is because the available services vary in each city. Since users do not frequently change cities, the service tiles do not change very frequently either, and so caching the tiles made sense. However, we also needed to sync the fresh tiles, in case of any change. So, we updated the logic based on these findings. as illustrated in the following image:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Tile Caching Logic&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image6.jpg&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Caching tiles brought us a huge improvement of &lt;em&gt;~3s&lt;/em&gt; on each platform.&lt;/p&gt;

&lt;h3 id=&quot;animation-removal&quot;&gt;Animation Removal&lt;/h3&gt;

&lt;p&gt;We came across a beautifully created animation at appstart that didn’t provide any additional value in terms of information or practicality.&lt;/p&gt;

&lt;p&gt;With detailed discussions and trade-offs with designers, we removed the animation and improved our TTI further by &lt;em&gt;1s&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In conclusion, with the caching and animation removal alone, we improved the TTI by &lt;em&gt;4s&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;welcome-static-linking-and-coroutines&quot;&gt;Welcome Static Linking and Coroutines&lt;/h2&gt;

&lt;p&gt;At this point, our users gained 4 seconds of their time back, but we didn’t want to stop with that number. So, we dug through the data to see what further enhancements we could do. When we could not find anything else that was similar to caching and animation removal, we shifted to architecture fundamentals.&lt;/p&gt;

&lt;p&gt;We knew that this was not an easy route to take and that it would come with a cost; if we decided to choose a component related to architecture fundamentals, all the other teams working on the Grab app would be impacted. We had to evaluate our options and make decisions with trade-offs for overall improvements. And this eventually led to static linking on iOS and &lt;a href=&quot;https://developer.android.com/kotlin/coroutines&quot;&gt;coroutines&lt;/a&gt; on Android.&lt;/p&gt;

&lt;h3 id=&quot;binaryloading&quot;&gt;Binary Loading&lt;/h3&gt;

&lt;p&gt;Binary loading is one of the first steps in both mobile platforms when an app is launched. It primarily contributes to pre-main and dex-loading, on iOS and Android respectively.&lt;/p&gt;

&lt;p&gt;The pre-main time on iOS was about 7.9s. It is known in the iOS development world that each framework (binary) can either be &lt;a href=&quot;https://www.runtastic.com/blog/en/frameworks-ios/&quot;&gt;dynamically or statically&lt;/a&gt; linked. While &lt;em&gt;static&lt;/em&gt; helps in a faster app start, it brings complexity in building frameworks that are elaborate or contain resources bundles.Building a lot of libraries statically also impact build times negatively.With proper evaluations, we decided to take the route to enable more static linking due to the trade-offs.&lt;/p&gt;

&lt;p&gt;Apple recommends&lt;a href=&quot;https://developer.apple.com/videos/play/wwdc2016/406/?time%3D78&quot;&gt; a maximum of half a dozen dynamic frameworks&lt;/a&gt; for an optimal performance. Guess what? Our passenger app had 107 dynamically linked frameworks, a lot of them were internal.&lt;/p&gt;

&lt;p&gt;The task looked daunting at first, since it affected all parts of the app, but we were ready to tackle the challenge head on. Deciding to take this on was the easy part, the actual work entailed lots of tricky coordination and collaboration with multiple teams.&lt;/p&gt;

&lt;p&gt;We created an &lt;a href=&quot;https://en.wikipedia.org/wiki/Request_for_Comments&quot;&gt;RFC (Request For Comments)&lt;/a&gt; doc to propose the static linking of frameworks, wherever applicable, and co-ordinated with teams with the agreed timelines to execute this change.&lt;/p&gt;

&lt;p&gt;While collaborating with teams, we learned that we could remove 12 frameworks entirely that were no longer required. This exercise highlighted the importance of regular cleanup and deprecation in our codebase, and was added into our standard process.&lt;/p&gt;

&lt;p&gt;And so, we were left with 95 frameworks; 75 of which were statically linked successfully, resulting in our &lt;em&gt;p90&lt;/em&gt; pre-main dropping by &lt;em&gt;41%&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;As Grabbers, it’s in our DNA to push ourselves a little more. With the remaining 20 frameworks, our pre-main was still considerably high. Out of the 20 frameworks, 10 could not be statically linked without issues. As a workaround, we merged multiple dynamic frameworks into one. One of our outstanding engineers even created a plug-in for this, which is called the Cocoapod Merge. With this plug-in, we were able to merge 10 dynamically linked frameworks into 2. &lt;em&gt;We’ve made this plug-in open source: &lt;a href=&quot;https://github.com/grab/cocoapods-pod-merge&quot;&gt;https://github.com/grab/cocoapods-pod-merge&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;With all of the above steps, we were finally left with 12 dynamic frameworks - a huge &lt;em&gt;88%&lt;/em&gt; reduction.&lt;/p&gt;

&lt;p&gt;The following image illustrates the complex numbers mentioned above:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Static Linking&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image5.jpg&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Using cocoapod merge further helped us with &lt;em&gt;~0.8s&lt;/em&gt; of improvement.&lt;/p&gt;

&lt;h3 id=&quot;coroutines&quot;&gt;Coroutines&lt;/h3&gt;

&lt;p&gt;While we were executing the static linking initiative on iOS, we also started refactoring the application initialisation for a modular and clean code on Android. This resulted in creating an &lt;em&gt;ApplicationInitialiser&lt;/em&gt; class, which handles the entire application initialisation process with maximum parallelism using coroutines.&lt;/p&gt;

&lt;p&gt;Now all the libraries are being initialised in parallel via coroutines and thus enabling better utilisations of computing resources and a faster TTI.&lt;/p&gt;

&lt;p&gt;This refactoring and background initialisation for libraries on Android helped in gaining &lt;em&gt;~0.4s&lt;/em&gt; of improvements.&lt;/p&gt;

&lt;h2 id=&quot;changing-the-basics---visualisation-setup&quot;&gt;Changing the Basics - Visualisation Setup&lt;/h2&gt;

&lt;p&gt;By the end of H1 2019, we observed a 50% improvement in TTI, and now it was time to set new goals for H2 2019. Until this point, we would query our database for all metric numbers, copy the numbers into a spreadsheet, and compare them against weeks and app versions.&lt;/p&gt;

&lt;p&gt;Despite the high loads of manual work and other challenges, this method still worked at the beginning due to the improvements we had to focus on.&lt;/p&gt;

&lt;p&gt;However, in H2 2019 it became apparent that we had to reassess our methodology of reading numbers. So, we started thinking about other ways to present and visualise these numbers better. With help from our Product Analyst, we took advantage of &lt;a href=&quot;https://www.metabase.com&quot;&gt;metabase’s&lt;/a&gt; advanced capabilities and presented our goals and metrics in a clear and easy to understand format.&lt;/p&gt;

&lt;p&gt;For example, here is a graph that shows the top contributing metrics for Android:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Android Metrics&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image4.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Looking at it, we could clearly tell which metric needed to be prioritised for improvements.&lt;/p&gt;

&lt;p&gt;We did this not only for our metrics, but also for our main goals, which allowed us to easily see our progress and track our improvements on a daily basis.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Visualisation&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image3.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The color bars in the above image depicts the status of our numbers against our goals and also shows the actual numbers at p50, p90, and p95.&lt;/p&gt;

&lt;p&gt;As our tracking progressed, we started including more granular and precise measurements, to help guide the team and achieve more impactful improvements of around &lt;em&gt;~0.3-0.4s&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Fortunately, we were deprecating a third-party library for analytics and experimentation, which happened to be one of the highest contributing metrics for both platforms due to a high number of operations on the main thread. We started using our own in-house experimentation platform where we had better control over performance. We removed this third-party dependency, and it helped us with huge improvements of &lt;em&gt;~2.5s&lt;/em&gt; on Android and &lt;em&gt;~0.5-0.7s&lt;/em&gt; on iOS.&lt;/p&gt;

&lt;p&gt;You might be wondering as to why there is such a big difference on the iOS and Android improvement numbers for this dependency. This was due to the setting user attributes operations that ran only in the Android codebase, which was performed on the main thread and took a huge amount of time. These were the times that made us realise that we should focus more on the consistency for both platforms, as well as to identify the third-party library APIs that are used, and to assess whether they are absolutely necessary.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;*Tip*: So, it is time for you as well to eliminate such inconsistencies, if there are any.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Ok, there goes our third quarter with &lt;em&gt;~3s&lt;/em&gt; of improvement on Android and &lt;em&gt;~1.3s&lt;/em&gt; on iOS.&lt;/p&gt;

&lt;h2 id=&quot;performance-regression-detection&quot;&gt;Performance Regression Detection&lt;/h2&gt;

&lt;p&gt;Entering into Q4 brought us many challenges as we were running out of improvements to make. Even finding an improvement worth &lt;em&gt;~0.05s&lt;/em&gt; was really difficult! We were also strongly challenged by regressions (increase in TTI numbers) because of continuous feature releases and code additions to the app start process.&lt;/p&gt;

&lt;p&gt;So, maintaining the TTI numbers became our primary task for this period. We started looking into setting up processes to block regressions from being merged to the master, or at least get notified before they hit production.&lt;/p&gt;

&lt;p&gt;To begin with, we identified the main sources of regressions: static linking breakage on iOS and library initialisation in the app startup process on Android.&lt;/p&gt;

&lt;p&gt;We took the following measures to cover these cases:&lt;/p&gt;

&lt;h3 id=&quot;linters&quot;&gt;Linters&lt;/h3&gt;

&lt;p&gt;We built &lt;a href=&quot;https://en.wikipedia.org/wiki/Lint_(software)&quot;&gt;linters&lt;/a&gt; on the Continuous Integration (CI) pipeline to detect potential changes in &lt;em&gt;static linking&lt;/em&gt; on iOS and the &lt;em&gt;ApplicationInitialiser&lt;/em&gt; class on Android. The linters block the changelist and enforce a special review process for such changes.&lt;/p&gt;

&lt;h3 id=&quot;library-integration-process&quot;&gt;Library Integration Process&lt;/h3&gt;

&lt;p&gt;The team also focused on setting up a process for library integrations, where each library (internal or third party) will first be evaluated for performance impact before it is integrated into the codebase.&lt;/p&gt;

&lt;p&gt;While regression guarding was in process, we were simultaneously trying to bring in more improvements for TTI. We enabled the &lt;a href=&quot;https://llvm.org/docs/LinkTimeOptimization.html&quot;&gt;Link Time Optimisations&lt;/a&gt; (LTO) flag on iOS to improve the overall app performance. We also experimented on &lt;a href=&quot;https://medium.com/@michael.eisel/improving-app-performance-with-order-files-c7fff549907f&quot;&gt;order files&lt;/a&gt; on iOS and &lt;a href=&quot;https://github.com/Kotlin/anko&quot;&gt;anko layout&lt;/a&gt; on Android, but  were ruled out due to known issues.&lt;/p&gt;

&lt;p&gt;On Android, we hit the bottom hard as there were minimal improvements. Fortunately, it was a different story for iOS. We managed to get improvements worth &lt;em&gt;~0.6s&lt;/em&gt; by opting for lazy loading, optimising I/O operations, and deferring more operations to post app start (if applicable).&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;We will be looking at the different aspects of performance such as network, battery, and storage, while maintaining our current numbers for TTI.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Network performance - Track the turnaround time for network requests then move on to optimisations.&lt;/li&gt;
  &lt;li&gt;Battery performance - Focus on profiling the app for CPU and energy intensive operations, which drains the battery, and then move to optimisations.&lt;/li&gt;
  &lt;li&gt;Storage performance - Review our caching and storage mechanisms, and then look for ways to optimise them.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to these, we are also focusing on bringing performance initiatives for all the teams at Grab. We believe that performance is a collaborative approach, and we would like to improve the app performance in all aspects.&lt;/p&gt;

&lt;p&gt;We defined different metrics to track performance e.g. Time to Interactive, Time to feedback (the time taken to get the feedback for a user action), UI smoothness indicators, storage, and network metrics.&lt;/p&gt;

&lt;p&gt;We are enabling all teams to benchmark their performance numbers based on defined metrics and move on to a path of improvement.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Overall, we improved by 60%, and this calls for a big celebration! &lt;em&gt;Woohoo!&lt;/em&gt; The bigger celebration came from knowing that we’ve improved our customers’ experience in using our app.&lt;/p&gt;

&lt;p&gt;This graph represents our performance improvement journey for the entire 2019, in terms of TTI.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Performance Graph&quot; src=&quot;/img/journey-to-a-faster-everyday-super-app/image2.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Based on the graph, looking at our p95 improvements and converting them to number of hours saved per day gives us &lt;em&gt;~21,388 hours on iOS and ~38,194 hours saved per day on Android&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Hey, did you know that it takes approximately &lt;em&gt;80-85&lt;/em&gt; hours to watch all the episodes of &lt;em&gt;Friends&lt;/em&gt;? Just saying. :)&lt;/p&gt;

&lt;p&gt;We will continue to serve our customers for a better and faster experience in the upcoming years.&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Dec 2019 22:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/journey-to-a-faster-everyday-super-app</link>
        <guid isPermaLink="true">https://engineering.grab.com/journey-to-a-faster-everyday-super-app</guid>
        
        <category>Superapp</category>
        
        <category>Mobile</category>
        
        <category>Performance</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Marionette - Enabling E2E user-scenario simulation</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;A plethora of interconnected microservices is what powers the Grab’s app. The microservices work behind the scenes to delight millions of our customers in Southeast Asia. It is a no-brainer that we emphasize on strong testing tools, so our app performs flawlessly to continuously meet our customers’ needs.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;We have a microservices-based architecture, in which microservices are interconnected to numerous other microservices. Each passing day sees teams within Grab updating their microservices, which in turn enhances the overall app. If any of the microservices fail after changes are rolled out, it may lead to the whole app getting into an unstable state or worse. This is a major risk and that’s why we stress on conducting “end-to-end (E2E) testing” as an integral part of our software test life-cycle.&lt;/p&gt;

&lt;p&gt;E2E tests are done for all crucial workflows in the app, but not for every detail. For that we have conventional tests such as unit tests, component tests, functional tests, etc. Consider E2E testing as the final approval in the quality assurance of the app.&lt;/p&gt;

&lt;p&gt;Writing E2E tests in the microservices world is not a trivial task. We are not testing just a single monolithic application. To test a workflow on the app from a user’s perspective, we need to traverse multiple microservices, which communicate through different protocols such as HTTP/HTTPS and TCP. E2E testing gets even more challenging with the continuous addition of microservices. Over the years, we have grown tremendously with hundreds of microservices working in the background to power our app.&lt;/p&gt;

&lt;p&gt;Some major challenges in writing E2E tests for the microservices-based apps are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Getting all microservices together for E2E testing is tough. Each development team works independently and is responsible only for its microservices. Teams use different programming languages, data stores, etc for each microservice. It’s hard to construct all pieces in a common test environment as a complete app for E2E testing each time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data or resource set up&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;E2E testing requires comprehensive data set up. Otherwise, testing results are affected because of data constraints, and not due to any recent changes to underlying microservices. For example, we need to create real-life equivalent driver accounts, passenger accounts, etc and to have those, there are a few dependencies on other internal systems which manage user accounts. Further, data and booking generation should be robust enough to replicate real-world scenarios as far as possible.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Access and authentication&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Usually, the test cases require sequential execution in E2E testing. In a microservices architecture, it is difficult to test a workflow which requires access and permissions to several resources or data that should remain available throughout the test execution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Resource and time intensive&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;It is expensive and time consuming to run E2E tests; significant time is involved in deploying new changes, configuring all the necessary test data, etc.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Though there are several challenges, we had to find a way to overcome them and test workflows from the beginning to the end in our app.&lt;/p&gt;

&lt;h2 id=&quot;our-approach-to-overcome-challenges&quot;&gt;Our approach to overcome challenges&lt;/h2&gt;

&lt;p&gt;We knew what our challenges were and what we wanted to achieve from E2E testing, so we started thinking about how to develop a platform for E2E tests. To begin with, we determined that the scope of E2E testing that we’re going to primarily focus on is Grab’s transport domain — the microservices powering the driver and passenger apps.&lt;/p&gt;

&lt;p&gt;One approach is to &lt;em&gt;“simulate”&lt;/em&gt; user scenarios through a single platform before any new versions of these microservices are released. Ideally, the platform should also have the capabilities to set up the data required for these simulations. For example, ride booking requires data set up such as driver accounts, passenger accounts, location coordinates, geofencing, etc.&lt;/p&gt;

&lt;p&gt;We wanted to create a single platform that multiple teams could use to set up their test data and run E2E user-scenario simulations easily. We put ourselves to work on that idea, which resulted in the creation of an internal platform called “Marionette”. It simulates actions performed by Grab’s passenger and driver apps as they are expected to behave in the real world. The objective is to ensure that all standard user workflows are tested before deploying new app versions.&lt;/p&gt;

&lt;h2 id=&quot;introducing-marionette&quot;&gt;Introducing Marionette&lt;/h2&gt;

&lt;p&gt;Marionette enables Grabbers (developers and QAs) to run E2E user-scenario simulations without depending on the actual passenger and driver apps. Grabbers can set up data as well as configure data such as drivers, passengers, taxi types, etc to mimic the real-world behavior.&lt;/p&gt;

&lt;p&gt;Let’s look at the overall architecture to understand Marionette better:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Overall Architecture&quot; src=&quot;/img/marionette-enabling-e2e-user-scenario-simulation/architecture.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Grabbers can interact with Marionette through three channels: UI, SDK, and through RESTful API endpoints in their test scripts. All requests are routed through a load balancer to the Marionette platform. The Marionette platform in turn talks to the required microservices to create test data and to run the simulations.&lt;/p&gt;

&lt;h2 id=&quot;the-benefits&quot;&gt;The benefits&lt;/h2&gt;

&lt;p&gt;With Marionette, Grabbers now have the ability to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Simulate the whole booking flow including customer and driver behavior as well as transition through the booking life cycle including pick-up, drop-off, cancellation, etc. For example, developers can make passenger booking from the UI and configure pick-up points, drop-off points, taxi types, and other parameters easily. They can define passenger behaviour such as “make bookings after a specified time interval”, “cancel each booking”, etc. They can also set driver locations, define driver behaviour such as “always accept booking manually”, “decline received bookings”, etc.&lt;/li&gt;
  &lt;li&gt;Simulate bookings in all cities where Grab operates. Further, developers can run simulations for multiple Grab taxi types such as JustGrab, GrabShare, etc.&lt;/li&gt;
  &lt;li&gt;Visualize passengers, drivers, and ride transitions on the UI, which lets them easily test their workflows.&lt;/li&gt;
  &lt;li&gt;Save efforts and time spent on installing third-party android or iOS emulators, troubleshooting or debugging &lt;code class=&quot;highlighter-rouge&quot;&gt;.apk&lt;/code&gt; installation files, etc before testing workflows.&lt;/li&gt;
  &lt;li&gt;Conduct E2E testing without real mobile devices and installed apps.&lt;/li&gt;
  &lt;li&gt;Run automatic simulations, in which a particular set of scenarios are run continuously, thus helping developers with exploratory testing.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-we-isolated-simulations-among-users&quot;&gt;How we isolated simulations among users&lt;/h2&gt;

&lt;p&gt;It is important to have independent simulations for each user. Otherwise, simulations don’t yield correct results. This was one of the challenges we faced when we first started running simulations on Marionette.&lt;/p&gt;

&lt;p&gt;To resolve this issue, we came up with the idea of “cohorts”. A cohort is a logical group of passengers and drivers who are located in a particular city. Each simulation on Marionette is run using a “cohort” containing the number of drivers and passengers required for that simulation. When a passenger/driver needs to interact with other passengers/drivers (such as for ride bookings), Marionette ensures that the interaction is constrained to resources within the cohort. This ensures that drivers and passengers are not shared in different test cases/simulations, resulting in more consistent test runs.&lt;/p&gt;

&lt;h2 id=&quot;how-to-interact-with-marionette&quot;&gt;How to interact with Marionette&lt;/h2&gt;

&lt;p&gt;Let’s take a look at how to interact with Marionette starting with its user interface first.&lt;/p&gt;

&lt;h3 id=&quot;user-interface&quot;&gt;User Interface&lt;/h3&gt;

&lt;p&gt;The Marionette UI is designed to provide the same level of granularity as available on the real passenger and driver apps.&lt;/p&gt;

&lt;p&gt;Generally, the UI is used in the following scenarios:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To test common user scenarios/workflows after deploying a change on staging.&lt;/li&gt;
  &lt;li&gt;To test the end-to-end booking flow right from the point where a passenger makes a booking till drop-off at the destination.&lt;/li&gt;
  &lt;li&gt;To simulate functionality of other teams within Grab - the passenger app developers can simulate the driver app for their testing and vice versa. Usually, teams work independently and the ability to simulate the dependent app for testing allows developers to work independently.&lt;/li&gt;
  &lt;li&gt;To perform E2E testing (such as by QA teams) without writing any test scripts.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Marionette UI also allows Grabbers to create and set up data. All that needs to be done is to specify the necessary resources such as number of drivers, number of passengers, city to run the simulation, etc. Running E2E simulations involves just the click of a button after data set up. Reports generated at the end of running simulations provide a graphical visualization of the results. Visual reports save developers’ time, which otherwise is spent on browsing through logs to ascertain errors.&lt;/p&gt;

&lt;h3 id=&quot;sdk&quot;&gt;SDK&lt;/h3&gt;

&lt;p&gt;Marionette also provides an SDK, written in the Go programming language.&lt;/p&gt;

&lt;p&gt;It lets developers:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create resources such as passengers, drivers, and cohorts for simulating booking flows.&lt;/li&gt;
  &lt;li&gt;Create booking simulations in both staging and production.&lt;/li&gt;
  &lt;li&gt;Set bookings to specific states as needed for simulation through customizable driver and passenger behaviour.&lt;/li&gt;
  &lt;li&gt;Make HTTP requests and receive responses that matter in tests.&lt;/li&gt;
  &lt;li&gt;Run load tests by scaling up booking requests to match the required workload (QPS).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s look at a high-level booking test case example to understand the simulation workflow.&lt;/p&gt;

&lt;p&gt;Assume we want to run an E2E booking test with this driver behavior type — “accepts passenger bookings and transits between booking states according to defined behavior parameters”. This is just one of the driver behavior types in Marionette; other behavior types are also supported. Similarly, passengers also have behaviour types.&lt;/p&gt;

&lt;p&gt;To write the E2E test for this example case, we first define the driver behavior in a function like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Overall Architecture&quot; src=&quot;/img/marionette-enabling-e2e-user-scenario-simulation/code1.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Then, we handle the booking request for the driver like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Overall Architecture&quot; src=&quot;/img/marionette-enabling-e2e-user-scenario-simulation/code2.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The SDK client makes the handling of passengers, drivers, and bookings very easy as developers don’t need to worry about hitting multiple services and multiple APIs to set up their required driver and passenger actions. Instead, teams can focus on testing their use cases.&lt;/p&gt;

&lt;p&gt;To ensure that passengers and drivers are isolated in our test, we need to group them together in a cohort before running the E2E test.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Overall Architecture&quot; src=&quot;/img/marionette-enabling-e2e-user-scenario-simulation/code3.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;In summary, we have defined the driver’s behavior, created the booking request, created the SDK client and associated the driver and passenger to a cohort. Now, we just have to trigger the E2E test from our IDE. It’s just that simple and easy!&lt;/p&gt;

&lt;p&gt;Previously, developers had to write boilerplate code to make HTTP requests and parse returned HTTP responses. With the Marionette SDK in place, developers don’t have to write any boilerplate code saving significant time and effort in E2E testing.&lt;/p&gt;

&lt;h3 id=&quot;restful-apis-in-test-scripts&quot;&gt;RESTful APIs in test scripts&lt;/h3&gt;

&lt;p&gt;Marionette provides several RESTful API endpoints that cover different simulation areas such as resource or data creation APIs, driver APIs, passenger APIs, etc. APIs are particularly suitable for scripted testing. Developers can directly call these APIs in their test scripts to facilitate their own tests such as load tests, integration tests, E2E tests, etc.&lt;/p&gt;

&lt;p&gt;Developers use these APIs with their preferred programming languages to run simulations. They don’t need to worry about any underlying complexities when using the APIs. For example, developers in Grab have created custom libraries using Marionette APIs in Python, Java, and Bash to run simulations.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next&lt;/h2&gt;

&lt;p&gt;Currently, we cover E2E tests for our transport domain (microservices for the passenger and driver apps) through Marionette. The next phase is to expand into a full-fledged platform that can test microservices in other Grab domains such as Food, Payments, and so on. Going forward, we are also looking to further simplify the writing of E2E tests and running them as a part of the CD pipeline for seamless testing before deployment.&lt;/p&gt;

&lt;h2 id=&quot;in-conclusion&quot;&gt;In conclusion&lt;/h2&gt;

&lt;p&gt;We had an idea of creating a simulation platform that can run and facilitate E2E testing of microservices. With Marionette, we have achieved this objective. Marionette has helped us understand how end users use our apps, allowing us to make improvements to our services. Further, Marionette ensures there are no breaking changes and provides additional visibility into potential bugs that might be introduced as a result of any changes to microservices.&lt;/p&gt;

&lt;p&gt;If you have any comments or questions about Marionette, please leave a comment below.&lt;/p&gt;
</description>
        <pubDate>Mon, 23 Dec 2019 21:00:00 +0000</pubDate>
        <link>https://engineering.grab.com/marionette-enabling-e2e-user-scenario-simulation</link>
        <guid isPermaLink="true">https://engineering.grab.com/marionette-enabling-e2e-user-scenario-simulation</guid>
        
        <category>Backend</category>
        
        <category>Testing</category>
        
        <category>Microservice</category>
        
        
        <category>Engineering</category>
        
      </item>
    
  </channel>
</rss>
