<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab&#39;s Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>http://engineering.grab.com/</link>
    <atom:link href="http://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 17 Jun 2017 05:42:58 +0000</pubDate>
    <lastBuildDate>Sat, 17 Jun 2017 05:42:58 +0000</lastBuildDate>
    <generator>Jekyll v3.0.3</generator>
    
      <item>
        <title>Grab&#39;s Front End Study Guide</title>
        <description>&lt;div class=&quot;text-center&quot;&gt;
  &lt;iframe src=&quot;https://ghbtns.com/github-btn.html?user=grab&amp;amp;repo=front-end-guide&amp;amp;type=star&amp;amp;count=true&amp;amp;size=large&quot; frameborder=&quot;0&quot; scrolling=&quot;0&quot; width=&quot;142px&quot; height=&quot;30px&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img alr=&quot;Front End at Grab&quot; src=&quot;/img/grabs-front-end-study-guide/front-end-at-grab-banner.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The original post can be found on &lt;a href=&quot;https://github.com/grab/front-end-guide&quot;&gt;Github&lt;/a&gt;. Future updates to the study guide will be made there. If you like what you are reading, give the repository a &lt;a href=&quot;https://github.com/grab/front-end-guide&quot;&gt;star&lt;/a&gt;! üåü&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.grab.com&quot;&gt;Grab&lt;/a&gt; is Southeast Asia (SEA)‚Äôs leading transportation platform and our mission is to drive SEA forward, leveraging on the latest technology and the talented people we have in the company. As of May 2017, we handle &lt;a href=&quot;https://www.bloomberg.com/news/videos/2017-05-11/tans-says-company-has-more-than-850-000-drivers-video&quot;&gt;2.3 million rides daily&lt;/a&gt; and we are growing and hiring at a rapid scale.&lt;/p&gt;

&lt;p&gt;To keep up with Grab‚Äôs phenomenal growth, our web team and web platforms have to grow as well. Fortunately, or unfortunately, at Grab, the web team has been &lt;a href=&quot;https://blog.daftcode.pl/hype-driven-development-3469fc2e9b22&quot;&gt;keeping up&lt;/a&gt; with the latest best practices and has incorporated the modern JavaScript ecosystem in our web apps.&lt;/p&gt;

&lt;p&gt;The result of this is that our new hires or back end engineers, who are not necessarily well-acquainted with the modern JavaScript ecosystem, may feel overwhelmed by the barrage of new things that they have to learn just to complete their feature or bug fix in a web app. Front end development has never been so complex and exciting as it is today. New tools, libraries, frameworks and plugins emerge every other day and there is so much to learn. It is imperative that newcomers to the web team are guided to embrace this evolution of the front end, learn to navigate the ecosystem with ease, and get productive in shipping code to our users as fast as possible. We have come up with a study guide to introduce why we do what we do, and how we handle front end at scale.&lt;/p&gt;

&lt;p&gt;This study guide is inspired by &lt;a href=&quot;https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.g9egaapps&quot;&gt;‚ÄúA Study Plan to Cure JavaScript Fatigue‚Äù&lt;/a&gt; and is mildly opinionated in the sense that we recommend certain libraries/frameworks to learn for each aspect of front end development, based on what is currently deemed most suitable at Grab. We explain why a certain library/framework/tool is chosen and provide links to learning resources to enable the reader to pick it up on their own. Alternative choices that may be better for other use cases are provided as well for reference and further self-exploration.&lt;/p&gt;

&lt;p&gt;If your company is exploring a modern JavaScript stack as well, you may find this study guide useful to your company too! Feel free to adapt it to your needs. We will update this study guide periodically, according to our latest work and choices.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;- Grab Web Team&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-requisites&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Good understanding of core programming concepts.&lt;/li&gt;
  &lt;li&gt;Comfortable with basic command line actions and familiarity with source code version control systems such as Git.&lt;/li&gt;
  &lt;li&gt;Experience in web development. Have built server-side rendered web apps using frameworks like Ruby on Rails, Django, Express, etc.&lt;/li&gt;
  &lt;li&gt;Understanding of how the web works. Familiarity with web protocols and conventions like HTTP and RESTful APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#single-page-apps-spas&quot;&gt;Single-page Apps (SPAs)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-age-javascript&quot;&gt;New-age JavaScript&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#user-interface---react&quot;&gt;User Interface&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#state-management---fluxredux&quot;&gt;State Management&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#coding-with-style---css-modules&quot;&gt;Coding with Style&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#maintainability&quot;&gt;Maintainability&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#testing---jest--enzyme&quot;&gt;Testing&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#linting-javascript---eslint&quot;&gt;Linting JavaScript&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#linting-css---stylelint&quot;&gt;Linting CSS&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#types---flow&quot;&gt;Types&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#build-system---webpack&quot;&gt;Build System&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#package-management---yarn&quot;&gt;Package Management&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Certain topics can be skipped if you have prior experience in them.&lt;/p&gt;

&lt;h3 id=&quot;single-page-apps-spas&quot;&gt;Single-page Apps (SPAs)&lt;/h3&gt;

&lt;p&gt;Web developers these days refer to the products they build as web apps, rather than websites. While there is no strict difference between the two terms, web apps tend to be highly interactive and dynamic, allowing the user to perform actions and receive a response for their action. Traditionally, the browser receives HTML from the server and renders it. When the user navigates to another URL, a full-page refresh is required and the server sends fresh new HTML for the new page. This is called server-side rendering.&lt;/p&gt;

&lt;p&gt;However in modern SPAs, client-side rendering is used instead. The browser loads the initial page from the server, along with the scripts (frameworks, libraries, app code) and stylesheets required for the whole app. When the user navigates to other pages, a page refresh is not triggered. The URL of the page is updated via the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/History_API&quot;&gt;HTML5 History API&lt;/a&gt;. New data required for the new page, usually in JSON format, is retrieved by the browser via &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/AJAX/Getting_Started&quot;&gt;AJAX&lt;/a&gt; requests to the server. The SPA then dynamically updates the page with the data via JavaScript, which it has already downloaded in the initial page load. This model is similar to how native mobile apps work.&lt;/p&gt;

&lt;p&gt;The benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The app feels more responsive and users do not see the flash between page navigations due to full-page refreshes.&lt;/li&gt;
  &lt;li&gt;Fewer HTTP requests are needed to the server, as the same assets do not have to be downloaded again for each page load.&lt;/li&gt;
  &lt;li&gt;Clear separation of the concerns between the client and the server; you can easily build new clients for different platforms (e.g. mobile, chatbots, smart watches) without having to modify the server code. You can also modify the technology stack on the client and server independently, as long as the API contract is not broken.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The downsides:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Heavier initial page load due to loading of framework, app code, and assets required for multiple pages &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
  &lt;li&gt;There‚Äôs an additional step to be done on your server which is to configure it to route all requests to a single entry point and allow client-side routing to take over from there.&lt;/li&gt;
  &lt;li&gt;SPAs are reliant on JavaScript to render content, but not all search engines execute JavaScript during crawling, and they may see empty content on your page. This inadvertently hurts the SEO of your app &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While traditional server-side rendered apps are still a viable option, a clear client-server separation scales better for larger engineering teams, as the client and server code can be developed and released independently. This is especially so at Grab when we have multiple client apps hitting the same API server.&lt;/p&gt;

&lt;p&gt;As web developers are now building apps rather than pages, organization of client-side JavaScript has become increasingly important. In server-side rendered pages, it is common to use snippets of jQuery to add user interactivity to each page. However, when building large apps, jQuery is not sufficient. After all, jQuery is primarily a library for DOM manipulation and it‚Äôs not a framework, it does not define a clear structure and organization for your app.&lt;/p&gt;

&lt;p&gt;JavaScript frameworks have been created to provide higher-level abstractions over the DOM, allowing you to keep state in memory, out of the DOM. Using frameworks also brings the benefits of reusing recommended concepts and best practices for building apps. A new engineer on the team who has experience with a framework but not the app will find it easier to understand the code because it is organized in a structure that he is familiar with. Popular frameworks have a lot of tutorials and guides, and tapping on the knowledge and experience from colleagues and the community will help new engineers get up to speed.&lt;/p&gt;

&lt;h4 id=&quot;study-links&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/21862054/single-page-app-advantages-and-disadvantages&quot;&gt;Single Page App: advantages and disadvantages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.isquaredsoftware.com/presentations/2016-10-revolution-of-web-dev/&quot;&gt;The (R)Evolution of Web Development&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;new-age-javascript&quot;&gt;New-age JavaScript&lt;/h3&gt;

&lt;p&gt;Before you dive into the various aspects of building a JavaScript web app, it is important to get familiar with the language of the web - JavaScript, or ECMAScript. JavaScript is an incredibly versatile language which you can also use to build &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;web servers&lt;/a&gt;, &lt;a href=&quot;https://facebook.github.io/react-native/&quot;&gt;native mobile apps&lt;/a&gt; and &lt;a href=&quot;https://electron.atom.io/&quot;&gt;desktop apps&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Prior to 2015, the last major update was ECMAScript 5.1, in 2011. However, in the recent years, JavaScript has suddenly seen a huge burst of improvements within a short span of time. In 2015, ECMAScript 2015 (previously called ECMAScript 6) was released and a ton of syntactic constructs were introduced to make writing code less unwieldy. Auth0 has written a &lt;a href=&quot;https://auth0.com/blog/a-brief-history-of-javascript/&quot;&gt;nice history of JavaScript&lt;/a&gt;. Till this day, not all browsers have fully implemented the ES2015 specification. Tools such as &lt;a href=&quot;https://babeljs.io/&quot;&gt;Babel&lt;/a&gt; enable developers to write ES2015 in their apps and Babel transpiles them down to ES5 to be compatible for browsers.&lt;/p&gt;

&lt;p&gt;Being familiar with both ES5 and ES2015 is crucial. ES2015 is still relatively new and a lot of open source code and Node.js apps are still written in ES5. If you are doing debugging in your browser console, you might not be able to use ES2015 syntax. On the other hand, documentation and example code for many modern libraries that we will introduce later below are written in ES2015. At Grab, we use ES2015 (with &lt;a href=&quot;https://babeljs.io/docs/plugins/preset-stage-0/&quot;&gt;Babel Stage-0 preset&lt;/a&gt;) to embrace the syntactic improvements the future of JavaScript provides and we have been loving it so far.&lt;/p&gt;

&lt;p&gt;Spend a day or two revising ES5 and exploring ES2015. The more heavily used features in ES2015 include ‚ÄúArrows and Lexical This‚Äù, ‚ÄúClasses‚Äù, ‚ÄúTemplate Strings‚Äù, ‚ÄúDestructuring‚Äù, ‚ÄúDefault/Rest/Spread operators‚Äù, and ‚ÄúImporting and Exporting modules‚Äù.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 3-4 days.&lt;/strong&gt; You can learn/lookup the syntax as you learn the other libraries and try building your own app.&lt;/p&gt;

&lt;h4 id=&quot;study-links-1&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.codecademy.com/learn/learn-javascript&quot;&gt;Learn ES5 on Codecademy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://babeljs.io/learn-es2015/&quot;&gt;Learn ES2015 on Babel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.freecodecamp.com/&quot;&gt;Free Code Camp&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://es6katas.org/&quot;&gt;ES6 Katas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/getify/You-Dont-Know-JS&quot;&gt;You Don‚Äôt Know JS&lt;/a&gt; (Advanced content, optional for beginners)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;user-interface---react&quot;&gt;User Interface - React&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;React Logo&quot; src=&quot;/img/grabs-front-end-study-guide/react-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;If any JavaScript project has taken the front end ecosystem by storm in recent years, that would be &lt;a href=&quot;https://facebook.github.io/react/&quot;&gt;React&lt;/a&gt;. React is a library built and open-sourced by the smart people at Facebook. In React, developers write components for their web interface and compose them together.&lt;/p&gt;

&lt;p&gt;React brings about many radical ideas and encourages developers to &lt;a href=&quot;https://www.youtube.com/watch?v=DgVS-zXgMTk&quot;&gt;rethink best practices&lt;/a&gt;. For many years, web developers were taught that it was a good practice to write HTML, JavaScript and CSS separately. React does the exact opposite, and encourages that you write your HTML and &lt;a href=&quot;https://speakerdeck.com/vjeux/react-css-in-js&quot;&gt;CSS in your JavaScript&lt;/a&gt; instead. This sounds like a crazy idea at first, but after trying it out, it actually isn‚Äôt as weird as it sounds initially. Reason being the front end development scene is shifting towards a paradigm of component-based development. The features of React:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Declarative&lt;/strong&gt; - You describe what you want to see in your view and not how to achieve it. In the jQuery days, developers would have to come up with a series of steps to manipulate the DOM to get from one app state to the next. In React, you simply change the state within the component and the view will update itself according to the state. It is also easy to determine how the component will look like just by looking at the markup in the &lt;code class=&quot;highlighter-rouge&quot;&gt;render()&lt;/code&gt; method.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Functional&lt;/strong&gt; - The view is a pure function of &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt;. In most cases, a React component is defined by &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; (external parameters) and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; (internal data). For the same &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt;, the same view is produced. Pure functions are easy to test, and the same goes for functional components. Testing in React is made easy because a component‚Äôs interfaces are well-defined and you can test the component by supplying different &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; to it and comparing the rendered output.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Maintainable&lt;/strong&gt; - Writing your view in a component-based fashion encourages reusability. We find that defining a component‚Äôs &lt;code class=&quot;highlighter-rouge&quot;&gt;propTypes&lt;/code&gt; make React code self-documenting as the reader can know clearly what is needed to use that component. Lastly, your view and logic is self-contained within the component, and should not be affected nor affect other components. That makes it easy to shift components around during large-scale refactoring, as long as the same &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; are supplied to the component.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;High Performance&lt;/strong&gt; - You might have heard that React uses a virtual DOM (not to be confused with &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/Web_Components/Shadow_DOM&quot;&gt;shadow DOM&lt;/a&gt;) and it re-renders everything when there is a change in state. Why is there a need for a virtual DOM? While modern JavaScript engines are fast, reading from and writing to the DOM is slow. React keeps a lightweight virtual representation of the DOM in memory. Re-rendering everything is a misleading term. In React it actually refers to re-rendering the in-memory representation of the DOM, not the actual DOM itself. When there‚Äôs a change in the underlying data of the component, a new virtual representation is created, and compared against the previous representation. The difference (minimal set of changes required) is then patched to the real browser DOM.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ease of Learning&lt;/strong&gt; - Learning React is pretty simple. The React API surface is relatively small compared to &lt;a href=&quot;https://angular.io/docs/ts/latest/api/&quot;&gt;this&lt;/a&gt;; there are only a few APIs to learn and they do not change often. The React community is one of the largest, and along with that comes a vibrant ecosystem of tools, open-sourced UI components, and a ton of great resources online to get you started on learning React.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Developer Experience&lt;/strong&gt; - There are a number of tools that improves the development experience with React. &lt;a href=&quot;https://github.com/facebook/react-devtools&quot;&gt;React Devtools&lt;/a&gt; is a browser extension that allows you to inspect your component, view and manipulate its &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt;. &lt;a href=&quot;https://github.com/gaearon/react-hot-loader&quot;&gt;Hot reloading&lt;/a&gt; with webpack allows you to view changes to your code in your browser, without you having to refresh the browser. Front end development involves a lot of tweaking code, saving and then refreshing the browser. Hot reloading helps you by eliminating the last step. When there are library updates, Facebook provides &lt;a href=&quot;https://github.com/reactjs/react-codemod&quot;&gt;codemod scripts&lt;/a&gt; to help you migrate your code to the new APIs. This makes the upgrading process relatively pain-free. Kudos to the Facebook team for their dedication in making the development experience with React great.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Over the years, new view libraries that are even more performant than React have emerged. React may not be the fastest library out there, but in terms of the ecosystem, overall usage experience and benefits, it is still one of the greatest. Facebook is also channeling efforts into making React even faster with a &lt;a href=&quot;https://github.com/acdlite/react-fiber-architecture&quot;&gt;rewrite of the underlying reconciliation algorithm&lt;/a&gt;. The concepts that React introduced has taught us how to write better code, more maintainable web apps and made us better engineers. We like that.&lt;/p&gt;

&lt;p&gt;We recommend going through the &lt;a href=&quot;https://facebook.github.io/react/tutorial/tutorial.html&quot;&gt;tutorial&lt;/a&gt; on building a tic-tac-toe game on the React homepage to get a feel of what React is and what it does. For more in-depth learning, check out the highly-rated free course, &lt;a href=&quot;https://reacttraining.com/online/react-fundamentals&quot;&gt;React Fundamentals&lt;/a&gt; by the creators of &lt;a href=&quot;https://github.com/ReactTraining/react-router/&quot;&gt;React Router&lt;/a&gt;, who are experts from the React community. It also covers more advanced concepts that are not covered by the React documentation. &lt;a href=&quot;https://github.com/facebookincubator/create-react-app&quot;&gt;Create React App&lt;/a&gt; by Facebook is a tool to scaffold a React project with minimal configuration and is highly recommended to use for starting new React projects.&lt;/p&gt;

&lt;p&gt;React is a library, not a framework, and does not deal with the layers below the view - the app state. More on that later.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 3-4 days.&lt;/strong&gt; Try building simple projects like a to-do list, Hacker News clone with pure React. You will slowly gain an appreciation for it and perhaps face some problems along the way that isn‚Äôt solved by React, which brings us to the next topic‚Ä¶&lt;/p&gt;

&lt;h4 id=&quot;study-links-2&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://facebook.github.io/react/tutorial/tutorial.html&quot;&gt;React Official Tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://reacttraining.com/online/react-fundamentals&quot;&gt;React Fundamentals&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/simple-react-development-in-2017-113bd563691f&quot;&gt;Simple React Development in 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0#.5iexphyg5&quot;&gt;Presentational and Container Components&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://angular.io/&quot;&gt;Angular&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.emberjs.com/&quot;&gt;Ember&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://vuejs.org/&quot;&gt;Vue&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cycle.js.org/&quot;&gt;Cycle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;state-management---fluxredux&quot;&gt;State Management - Flux/Redux&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Redux Logo&quot; src=&quot;/img/grabs-front-end-study-guide/redux-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;As your app grows bigger, you may find that the app structure becomes a little messy. Components throughout the app may have to share and display common data but there is no elegant way to handle that in React. After all, React is just the view layer, it does not dictate how you structure the other layers of your app, such as the model and the controller, in traditional MVC paradigms. In an effort to solve this, Facebook invented Flux, an app architecture that complements React‚Äôs composable view components by utilizing a unidirectional data flow. Read more about how Flux works &lt;a href=&quot;https://facebook.github.io/flux/docs/in-depth-overview.html&quot;&gt;here&lt;/a&gt;. In summary, the Flux pattern has the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Unidirectional data flow&lt;/strong&gt; - Makes the app more predictable as updates can be tracked easily.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Separation of concerns&lt;/strong&gt; - Each part in the Flux architecture has clear responsibilities and are highly decoupled.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Works well with declarative programming&lt;/strong&gt; - The store can send updates to the view without specifying how to transition views between states.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As Flux is not a framework per se, developers have tried to come up with many implementations of the Flux pattern. Eventually, a clear winner emerged, which was &lt;a href=&quot;http://redux.js.org/&quot;&gt;Redux&lt;/a&gt;. Redux combines the ideas from Flux, &lt;a href=&quot;https://www.wikiwand.com/en/Command_pattern&quot;&gt;Command pattern&lt;/a&gt; and &lt;a href=&quot;https://guide.elm-lang.org/architecture/&quot;&gt;Elm architecture&lt;/a&gt; and is the de facto state management library developers use with React these days. Its core concepts are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;App &lt;strong&gt;state&lt;/strong&gt; is described by a single plain old JavaScript object (POJO).&lt;/li&gt;
  &lt;li&gt;Dispatch an &lt;strong&gt;action&lt;/strong&gt; (also a POJO) to modify the state.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reducer&lt;/strong&gt; is a pure function that takes in current state and action to produce a new state.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The concepts sound simple, but they are really powerful as they enable apps to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Have their state rendered on the server, booted up on the client.&lt;/li&gt;
  &lt;li&gt;Trace, log and backtrack changes in the whole app.&lt;/li&gt;
  &lt;li&gt;Implement undo/redo functionality easily.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The creator of Redux, &lt;a href=&quot;https://github.com/gaearon&quot;&gt;Dan Abramov&lt;/a&gt;, has taken great care in writing up detailed documentation for Redux, along with creating comprehensive video tutorials for learning &lt;a href=&quot;https://egghead.io/courses/getting-started-with-redux&quot;&gt;basic&lt;/a&gt; and &lt;a href=&quot;https://egghead.io/courses/building-react-applications-with-idiomatic-redux&quot;&gt;advanced&lt;/a&gt; Redux. They are extremely helpful resources for learning Redux.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Combining View and State&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While Redux does not necessarily have to be used with React, it is highly recommended as they play very well with each other. React and Redux have a lot of ideas and traits in common:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Functional composition paradigm&lt;/strong&gt; - React composes views (pure functions) while Redux composes pure reducers (also pure functions). Output is predictable given the same set of input.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easy To Reason About&lt;/strong&gt; - You may have heard this term many times but what does it actually mean? Through our experience, React and Redux makes debugging simpler. As the data flow is unidirectional, tracing the flow of data (server responses, user input events) is easier and it is straightforward to determine which layer the problem occurs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layered Structure&lt;/strong&gt; - Each layer in the app / Flux architecture is a pure function, and has clear responsibilities. It is pretty easy to write tests for them.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Development Experience&lt;/strong&gt; - A lot of effort has gone into creating tools to help in debugging and inspecting the app while development, such as &lt;a href=&quot;https://github.com/gaearon/redux-devtools&quot;&gt;Redux DevTools&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your app will likely have to deal with async calls like making remote API requests. &lt;a href=&quot;https://github.com/gaearon/redux-thunk&quot;&gt;redux-thunk&lt;/a&gt; and &lt;a href=&quot;https://github.com/redux-saga/redux-saga&quot;&gt;redux-saga&lt;/a&gt; were created to solve those problems. They may take some time to understand as they require understanding of functional programming and generators. Our advice is to deal with it only when you need it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/reactjs/react-redux&quot;&gt;react-redux&lt;/a&gt; is an official React binding for Redux and is very simple to learn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 4 days.&lt;/strong&gt; The egghead courses can be a little time consuming but they are worth spending time on. After learning Redux, you can try incorporating it into the React projects you have built. Does Redux solve some of the state management issues you were struggling with in pure React?&lt;/p&gt;

&lt;h4 id=&quot;study-links-3&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://facebook.github.io/flux&quot;&gt;Flux Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://redux.js.org/&quot;&gt;Redux Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://egghead.io/courses/getting-started-with-redux&quot;&gt;Egghead Course - Getting Started with Redux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://egghead.io/courses/building-react-apps-with-idiomatic-redux&quot;&gt;Egghead Course - Build React Apps with Idiomatic Redux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/markerikson/react-redux-links&quot;&gt;React Redux Links&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@dan_abramov/you-might-not-need-redux-be46360cf367&quot;&gt;You Might Not Need Redux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-1&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/mobxjs/mobx&quot;&gt;MobX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;coding-with-style---css-modules&quot;&gt;Coding with Style - CSS Modules&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;CSS Modules Logo&quot; src=&quot;/img/grabs-front-end-study-guide/css-modules-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Writing good CSS is hard. It takes many years of experience and frustration of shooting yourself in the foot before one is able to write maintainable and scalable CSS. CSS, having a global namespace, is fundamentally designed for web documents, and not really for web apps that favor a components architecture. Hence, experienced front end developers have designed methodologies to guide people on how to write organized CSS for complex projects, such as using &lt;a href=&quot;https://smacss.com/&quot;&gt;SMACSS&lt;/a&gt;, &lt;a href=&quot;http://getbem.com/&quot;&gt;BEM&lt;/a&gt;, &lt;a href=&quot;http://suitcss.github.io/&quot;&gt;SUIT CSS&lt;/a&gt;, etc. However, the encapsulation of styles that these methodologies bring about are artificially enforced by conventions and guidelines. They break the moment developers do not follow them.&lt;/p&gt;

&lt;p&gt;Fortunately, the front end ecosystem is saturated with tools, and unsurprisingly, tools have been invented to &lt;a href=&quot;https://speakerdeck.com/vjeux/react-css-in-js&quot;&gt;partially solve some of the problems&lt;/a&gt; with writing CSS at scale. ‚ÄúAt scale‚Äù means that many developers are working on the same project and touching the same stylesheets. There is no community-agreed approach on writing &lt;a href=&quot;https://github.com/MicheleBertoli/css-in-js&quot;&gt;CSS in JS&lt;/a&gt; at the moment, and we are hoping that one day a winner would emerge, just like Redux did, among all the Flux implementations. For now, we are banking on &lt;a href=&quot;https://github.com/css-modules/css-modules&quot;&gt;CSS Modules&lt;/a&gt;. CSS modules is an improvement over existing CSS that aims to fix the problem of global namespace in CSS; it enables you to write styles that are local by default and encapsulated to your component. This feature is achieved via tooling. With CSS modules, large teams can write modular and reusable CSS without fear of conflict or overriding other parts of the app. However, at the end of the day, CSS modules are still being compiled into normal globally-namespaced CSS that browsers recognize, and it is still important to learn raw CSS.&lt;/p&gt;

&lt;p&gt;If you are a total beginner to CSS, Codecademy‚Äôs &lt;a href=&quot;https://www.codecademy.com/learn/learn-html-css&quot;&gt;HTML &amp;amp; CSS course&lt;/a&gt; will be a good introduction to you. Next, read up on the &lt;a href=&quot;http://sass-lang.com/&quot;&gt;Sass preprocessor&lt;/a&gt;, an extension of the CSS language which adds syntactic improvements and encourages style reusability. Study the CSS methodologies mentioned above, and lastly, CSS modules.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 3-4 days.&lt;/strong&gt; Try styling up your app using the SMACSS/BEM approach and/or CSS modules.&lt;/p&gt;

&lt;h4 id=&quot;study-links-4&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.codecademy.com/learn/learn-html-css&quot;&gt;Learn HTML &amp;amp; CSS course on Codecademy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khanacademy.org/computing/computer-programming/html-css&quot;&gt;Intro to HTML/CSS on Khan Academy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://smacss.com/&quot;&gt;SMACSS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://getbem.com/introduction/&quot;&gt;BEM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://suitcss.github.io/&quot;&gt;SUIT CSS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/css-modules/css-modules&quot;&gt;CSS Modules Specification&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://sass-lang.com/&quot;&gt;Sass Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.intelligiblebabble.com/a-pattern-for-writing-css-to-scale&quot;&gt;A pattern for writing CSS to scale&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-2&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/cssinjs/jss&quot;&gt;JSS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/styled-components/styled-components&quot;&gt;Styled Components&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;maintainability&quot;&gt;Maintainability&lt;/h3&gt;

&lt;p&gt;Code is read more frequently than it is written. This is especially true at Grab, where the team size is large and we have multiple engineers working across multiple projects. We highly value readability, maintainability and stability of the code and there are a few ways to achieve that: ‚ÄúExtensive testing‚Äù, ‚ÄúConsistent coding style‚Äù and ‚ÄúTypechecking‚Äù.&lt;/p&gt;

&lt;h3 id=&quot;testing---jest--enzyme&quot;&gt;Testing - Jest + Enzyme&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Jest Logo&quot; src=&quot;/img/grabs-front-end-study-guide/jest-logo.svg&quot; width=&quot;164px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://facebook.github.io/jest/&quot;&gt;Jest&lt;/a&gt; is a testing library by Facebook that aims to make the process of testing pain-free. As with Facebook projects, it provides a great development experience out of the box. Tests can be run in parallel for faster speed and during watch mode, only the tests for the changed files are run. One particular feature we like is ‚ÄúSnapshot Testing‚Äù. Jest can save the generated output of your React component and Redux state and save it as serialized files, so you wouldn‚Äôt have to manually come up with the expected output yourself. Jest also comes with built-in mocking, assertion and test coverage. One library to rule them all!&lt;/p&gt;

&lt;p&gt;React comes with some testing utilities, but &lt;a href=&quot;http://airbnb.io/enzyme/&quot;&gt;Enzyme&lt;/a&gt; by Airbnb makes it easier to generate, assert, manipulate and traverse your React components‚Äô output with a jQuery-like API. It is recommended that Enzyme be used to test React components.&lt;/p&gt;

&lt;p&gt;Jest and Enzyme makes writing front end tests fun and easy. It also helps that React components and Redux actions/reducers are relatively easy to test because of clearly defined responsibilities and interfaces. For React components, we can test that given some &lt;code class=&quot;highlighter-rouge&quot;&gt;props&lt;/code&gt;, the desired DOM is rendered, and that callbacks are fired upon certain simulated user interactions. For Redux reducers, we can test that given a prior state and an action, a resulting state is produced.&lt;/p&gt;

&lt;p&gt;The documentation for Jest and Enzyme are pretty concise, and it should be sufficient to learn them by reading it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 2-3 days.&lt;/strong&gt; Try writing Jest + Enzyme tests for your React + Redux app!&lt;/p&gt;

&lt;h4 id=&quot;study-links-5&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://facebook.github.io/jest/&quot;&gt;Jest Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://auth0.com/blog/testing-react-apps-with-jest/&quot;&gt;Testing React Apps with Jest&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://airbnb.io/enzyme/&quot;&gt;Enzyme Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/airbnb-engineering/enzyme-javascript-testing-utilities-for-react-a417e5e5090f&quot;&gt;Enzyme: JavaScript Testing utilities for React&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-3&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/avajs/ava&quot;&gt;AVA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://karma-runner.github.io/&quot;&gt;Karma&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;linting-javascript---eslint&quot;&gt;Linting JavaScript - ESLint&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;ESLint Logo&quot; src=&quot;/img/grabs-front-end-study-guide/eslint-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;A linter is a tool to statically analyze code and finds problems with them, potentially preventing bugs/runtime errors and at the same time, enforcing a coding style. Time is saved during pull request reviews when reviewers do not have to leave nitpicky comments on coding style. &lt;a href=&quot;http://eslint.org/&quot;&gt;ESLint&lt;/a&gt; is a tool for linting JavaScript code that is highly extensible and customizable. Teams can write their own lint rules to enforce their custom styles. At Grab, we use Airbnb‚Äôs &lt;a href=&quot;https://www.npmjs.com/package/eslint-config-airbnb&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;eslint-config-airbnb&lt;/code&gt;&lt;/a&gt; preset, that has already been configured with the common good coding style in the &lt;a href=&quot;https://github.com/airbnb/javascript&quot;&gt;Airbnb JavaScript style guide&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For the most part, using ESLint is as simple as tweaking a configuration file in your project folder. There‚Äôs nothing much to learn about ESLint if you‚Äôre not writing new rules for it. Just be aware of the errors when they surface and Google it to find out the recommended style.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 1/2 day.&lt;/strong&gt; Nothing much to learn here. Add ESLint to your project and fix the linting errors!&lt;/p&gt;

&lt;h4 id=&quot;study-links-6&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://eslint.org/&quot;&gt;ESLint Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/airbnb/javascript&quot;&gt;Airbnb JavaScript Style Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-4&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/feross/standard&quot;&gt;Standard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jshint.com/&quot;&gt;JSHint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;linting-css---stylelint&quot;&gt;Linting CSS - stylelint&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;stylelint Logo&quot; src=&quot;/img/grabs-front-end-study-guide/stylelint-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;As mentioned earlier, good CSS is notoriously hard to write. Usage of static analysis tools on CSS can help to maintain our CSS code quality and coding style. For linting CSS, we use stylelint. Like ESLint, stylelint is designed in a very modular fashion, allowing developers to turn rules on/off and write custom plugins for it. Besides CSS, stylelint is able to parse SCSS and has experimental support for Less, which lowers the barrier for most existing code bases to adopt it.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;stylelint Demo&quot; src=&quot;/img/grabs-front-end-study-guide/stylelint-demo.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Once you have learnt ESLint, learning stylelint would be effortless considering their similarities. stylelint is currently being used by big companies like &lt;a href=&quot;https://code.facebook.com/posts/879890885467584/improving-css-quality-at-facebook-and-beyond/&quot;&gt;Facebook&lt;/a&gt;, &lt;a href=&quot;https://github.com/primer/stylelint-config-primer&quot;&gt;Github&lt;/a&gt; and &lt;a href=&quot;https://github.com/WordPress-Coding-Standards/stylelint-config-wordpress&quot;&gt;Wordpress&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One downside of stylelint is that the autofix feature is not fully mature yet, and is only able to fix for a limited number of rules. However, this issue should improve with time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 1/2 day.&lt;/strong&gt; Nothing much to learn here. Add stylelint to your project and fix the linting errors!&lt;/p&gt;

&lt;h4 id=&quot;study-links-7&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://stylelint.io/&quot;&gt;stylelint Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://css-tricks.com/stylelint/&quot;&gt;Lint your CSS with stylelint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-5&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/sasstools/sass-lint&quot;&gt;Sass Lint&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://csslint.net/&quot;&gt;CSS Lint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;types---flow&quot;&gt;Types - Flow&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Flow Logo&quot; src=&quot;/img/grabs-front-end-study-guide/flow-logo.png&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Static typing brings about many benefits when writing apps. They can catch common bugs and errors in your code early. Types also serve as a form of documentation for your code and improves the readability of your code. As a code base grows larger, we see the importance of types as they gives us greater confidence when we do refactoring. It is also easier to onboard new members of the team to the project when it is clear what kind of values each object holds and what each function expects.&lt;/p&gt;

&lt;p&gt;Adding types to your code comes with the trade-off of increased verbosity and a learning curve of the syntax. But this learning cost is paid upfront and amortized over time. In complex projects where the maintainability of the code matters and the people working on it change over time, adding types to the code brings about more benefits than disadvantages.&lt;/p&gt;

&lt;p&gt;The two biggest contenders in adding static types to JavaScript are &lt;a href=&quot;https://flow.org/&quot;&gt;Flow&lt;/a&gt; (by Facebook) and &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt; (by Microsoft). As of date, there is no clear winner in the battle. For now, we have made the choice of using Flow. We find that Flow has a lower learning curve as compared to TypeScript and it requires relatively less effort to migrate an existing code base to Flow. Being built by Facebook, Flow has better integration with the React ecosystem out of the box. Anyway, it is not extremely difficult to move from Flow to TypeScript as the syntax and semantics are quite similar, and we will re-evaluate the situation in time to come. After all, using one is better than not using any at all.&lt;/p&gt;

&lt;p&gt;Flow recently revamped their documentation site and it‚Äôs pretty neat now!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 1 day.&lt;/strong&gt; Flow is pretty simple to learn as the type annotations feel like a natural extension of the JavaScript language. Add Flow annotations to your project and embrace the power of type systems.&lt;/p&gt;

&lt;h4 id=&quot;study-links-8&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://flow.org/&quot;&gt;Flow Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/niieani/typescript-vs-flowtype&quot;&gt;TypeScript vs Flow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-6&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;build-system---webpack&quot;&gt;Build System - webpack&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;webpack Logo&quot; src=&quot;/img/grabs-front-end-study-guide/webpack-logo.svg&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;This part will be kept short as setting up webpack can be a tedious process and might be a turn-off to developers who are already overwhelmed by the barrage of new things they have to learn for front end development. In a nutshell, &lt;a href=&quot;https://webpack.js.org/&quot;&gt;webpack&lt;/a&gt; is a module bundler that compiles a front end project and its dependencies into a final bundle to be served to users. Usually, projects will already have the webpack configuration set up and developers rarely have to change it. Having an understanding of webpack is still a good to have in the long run. It is due to webpack that features like hot reloading and CSS modules are made possible.&lt;/p&gt;

&lt;p&gt;We have found the &lt;a href=&quot;https://survivejs.com/webpack/foreword/&quot;&gt;webpack walkthrough&lt;/a&gt; by SurviveJS to be the best resource on learning webpack. It is a good complement to the official documentation and we recommend following the walkthrough first and referring to the documentation later when the need for further customization arises.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 2 days (Optional).&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;study-links-9&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://webpack.js.org/&quot;&gt;webpack Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://survivejs.com/webpack/foreword/&quot;&gt;SurviveJS - Webpack: From apprentice to master&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-7&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://rollupjs.org/&quot;&gt;Rollup&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://browserify.org/&quot;&gt;Browserify&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;package-management---yarn&quot;&gt;Package Management - Yarn&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Yarn Logo&quot; src=&quot;/img/grabs-front-end-study-guide/yarn-logo.png&quot; width=&quot;256px&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;If you take a peek into your &lt;code class=&quot;highlighter-rouge&quot;&gt;node_modules&lt;/code&gt; directory, you will be appalled by the number of directories that are contained in it. Each babel plugin, lodash function, is a package on its own. When you have multiple projects, these packages are duplicated across each project and they are largely similar. Each time you run &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install&lt;/code&gt; in a new project, these packages are downloaded over and over again even though they already exist in some other project in your computer.&lt;/p&gt;

&lt;p&gt;There was also the problem of non-determinism in the installed packages via &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install&lt;/code&gt;. Some of our CI builds fail because at the point of time when the CI server installs the dependencies, it pulled in minor updates to some packages that contained breaking changes. This would not have happened if library authors respected &lt;a href=&quot;http://semver.org/&quot;&gt;semver&lt;/a&gt; and engineers assumed that API contracts are respected all the time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://yarnpkg.com/&quot;&gt;Yarn&lt;/a&gt; solves these problems. The issue of non-determinism of installed packages via a &lt;code class=&quot;highlighter-rouge&quot;&gt;yarn.lock&lt;/code&gt; file and it ensures that every install results in the exact same file structure in &lt;code class=&quot;highlighter-rouge&quot;&gt;node_modules&lt;/code&gt; across all machines. Yarn utilizes a global cache directory within your machine, and packages that have been downloaded before do not have to be downloaded again. This also enables offline installation of dependencies!&lt;/p&gt;

&lt;p&gt;The most common Yarn commands can be found &lt;a href=&quot;https://yarnpkg.com/en/docs/usage&quot;&gt;here&lt;/a&gt;. Most other yarn commands are similar to the &lt;code class=&quot;highlighter-rouge&quot;&gt;npm&lt;/code&gt; equivalents and it is fine to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;npm&lt;/code&gt; versions instead. One of our favorite commands is &lt;code class=&quot;highlighter-rouge&quot;&gt;yarn upgrade-interactive&lt;/code&gt; which makes updating dependencies a breeze especially when the modern JavaScript project requires so many dependencies these days. Do check it out!&lt;/p&gt;

&lt;p&gt;npm@5.0.0 was &lt;a href=&quot;https://github.com/npm/npm/releases/tag/v5.0.0&quot;&gt;released in May 2017&lt;/a&gt; and it seems to address many of the issues that Yarn aims to solve. Do keep an eye on it!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Estimated Duration: 2 hours.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;study-links-10&quot;&gt;Study Links&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://yarnpkg.com/&quot;&gt;Yarn Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://code.facebook.com/posts/1840075619545360&quot;&gt;Yarn: A new package manager for JavaScript&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;alternatives-8&quot;&gt;Alternatives&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/npm/npm/releases/tag/v5.0.0&quot;&gt;Good old npm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-journey-has-just-begun&quot;&gt;The Journey has Just Begun&lt;/h3&gt;

&lt;p&gt;Congratulations on making it this far! Front end development today is &lt;a href=&quot;https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f&quot;&gt;hard&lt;/a&gt;, but it is also more interesting than before. What we have covered so far will help any new engineer to Grab‚Äôs web team to get up to speed with our technologies pretty quickly. There are many more things to be learnt, but building up a solid foundation in the essentials will aid in learning the rest of the technologies. This helpful &lt;a href=&quot;https://github.com/kamranahmedse/developer-roadmap#-front-end-roadmap&quot;&gt;front end web developer roadmap&lt;/a&gt; shows the alternative technologies available for each aspect.&lt;/p&gt;

&lt;p&gt;We made our technical decisions based on what was important to a rapidly growing Grab Engineering team - maintainability and stability of the front end code base. These decisions may or may not apply to smaller teams and projects. Do evaluate what works best for you and your company.&lt;/p&gt;

&lt;p&gt;As the front end ecosystem grows, we are actively exploring, experimenting and evaluating how new technologies can make us a more efficient team and improve our productivity. We hope that this post has given you insights into the front end technologies we use at Grab. If what we are doing interests you, &lt;a href=&quot;https://grab.careers&quot;&gt;we are hiring&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Many thanks to &lt;a href=&quot;https://github.com/lowjoel&quot;&gt;Joel Low&lt;/a&gt;, &lt;a href=&quot;https://github.com/li-kai&quot;&gt;Li Kai&lt;/a&gt; and &lt;a href=&quot;https://github.com/xming13&quot;&gt;Tan Wei Seng&lt;/a&gt; who reviewed drafts of this article.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The original post can be found on &lt;a href=&quot;https://github.com/grab/front-end-guide&quot;&gt;Github&lt;/a&gt;. Future updates to the study guide will be made there. If you like what you are reading, give the repository a &lt;a href=&quot;https://github.com/grab/front-end-guide&quot;&gt;star&lt;/a&gt;! üåü&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;text-center&quot;&gt;
  &lt;iframe src=&quot;https://ghbtns.com/github-btn.html?user=grab&amp;amp;repo=front-end-guide&amp;amp;type=star&amp;amp;count=true&amp;amp;size=large&quot; frameborder=&quot;0&quot; scrolling=&quot;0&quot; width=&quot;130px&quot; height=&quot;30px&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&quot;more-reading&quot;&gt;More Reading&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;General&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/articles/state-of-javascript-2016&quot;&gt;State of the JavaScript Landscape: A Map for Newcomers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://marcobotto.com/the-hitchhikers-guide-to-the-modern-front-end-development-workflow/&quot;&gt;The Hitchhiker‚Äôs guide to the modern front end development workflow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.tmy8gzgvp&quot;&gt;How it feels to learn JavaScript in 2016&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kamranahmedse/developer-roadmap#-frontend-roadmap&quot;&gt;Roadmap to becoming a web developer in 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://trackchanges.postlight.com/modern-javascript-for-ancient-web-developers-58e7cae050f9&quot;&gt;Modern JavaScript for Ancient Web Developers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Other Study Guides&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.c0wnrrcwd&quot;&gt;A Study Plan To Cure JavaScript Fatigue&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/verekia/js-stack-from-scratch&quot;&gt;JS Stack from Scratch&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.com/a-beginners-javascript-study-plan-27f1d698ea5e#.bgf49xno2&quot;&gt;A Beginner‚Äôs JavaScript Study Plan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;This can be solved via &lt;a href=&quot;https://webpack.js.org/guides/code-splitting/&quot;&gt;webpack code splitting&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://medium.com/@mjackson/universal-javascript-4761051b7ae9&quot;&gt;Universal JS&lt;/a&gt; to the rescue! &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 03 Jun 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/grabs-front-end-study-guide</link>
        <guid isPermaLink="true">http://engineering.grab.com/grabs-front-end-study-guide</guid>
        
        <category>Front End</category>
        
        <category>JavaScript</category>
        
        <category>Web</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>DNS Resolution in Go and Cgo</title>
        <description>&lt;p&gt;&lt;em&gt;This article is part two of a two-part series (&lt;a href=&quot;/troubleshooting-unusual-aws-elb-5xx-error&quot;&gt;part one&lt;/a&gt;). In this article, we will talk about RFC 6724 (3484), how DNS resolution works in Go and Cgo, and finally explaining why disabling IPv6 also disables the sorting of IP Addresses.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As a quick recap of our journey so far, we walked you through our investigative process of a load balancing issue on our AWS Elastic Load Balancer (ELB) nodes and how we temporarily fixed it by using Cgo and disabling IPv6. In this part of the series, we will be diving deeper into RFC 6724 (3484), exploring DNS Resolution in Go and Cgo, explaining why disabling IPv6 ‚Äúfixes‚Äù the IP addresses sorting and how the permanent fix requires modifying the Go source code. If you already understand RFC 6274 (3484), please feel free to jump to the section titled ‚ÄúFurther Investigation‚Äù and if you are short on time, the ‚ÄúSummary‚Äù is also provided at the end of the article.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;h4 id=&quot;rfc-6724-3484&quot;&gt;RFC 6724 (3484)&lt;/h4&gt;

&lt;p&gt;RFC 6724 and its earlier revision ‚Äì RFC 3484, defines how connections between two systems over the internet should be established when there is more than one possible IP address on the source and destination systems. And because of the way the internet works, if you connect to a website by entering a domain name instead of a IP address, it is almost guaranteed that you will execute an implementation of the RFC. When you enter a domain name in your browser, behind the scenes, your browser will send a DNS A (for IPv4) or AAAA (for IPv6) query to a DNS server to get a list of IP addresses that it should connect to. Because nowadays, almost all websites have two or more servers behind them, it‚Äôs very likely for you to get at least two IP addresses back from the DNS. The question is then, what happens when you get two IP addresses? Which one should you choose? This is exactly the question that the RFC is attempting to address. (For more detailed information, please refer to the &lt;a href=&quot;https://www.ietf.org/rfc/rfc6724.txt&quot;&gt;RFC&lt;/a&gt; itself. The sorting rules for the source and destination address are located on page 9 and 13 respectively)&lt;/p&gt;

&lt;h4 id=&quot;go-and-cgo&quot;&gt;Go and Cgo&lt;/h4&gt;

&lt;p&gt;During the early days of Go, Cgo was introduced as a way for Go programs to embed C code inside of Go. Cgo allows Go to tap into the vast amount of C libraries, an ability that is especially useful in situations where you want to execute some low level operation that you know works really well in C and is non-trivial to rewrite in Go. However, with Go maturing, the Go maintainers have decided to move away from C implementations to native Go implementations. When Go executes C code, it will actually run the C code on an OS thread instead of goroutines that are orders of magnitude cheaper.&lt;/p&gt;

&lt;h3 id=&quot;further-investigation&quot;&gt;Further Investigation&lt;/h3&gt;

&lt;p&gt;Now that we have fixed the problem on our production systems by forcing the use of the Cgo DNS resolver and disabling IPv6, we are able to comfortably explore the problem and figure out why the unintuitive solution of using Cgo and disabling IPv6 works. Seeing how the Go source code in general has decent documentation, we decide to investigate that first. From the section titled ‚ÄúName Resolution‚Äù of the &lt;a href=&quot;https://golang.org/pkg/net/&quot;&gt;documentation of the net package&lt;/a&gt;, we can see that by default, Go uses the Go DNS Resolver. In cases where it is not supported, it falls back to Cgo or some other implementation that is the default on the OS. In our case, our production servers run on Ubuntu so the default DNS resolver is the native Go DNS Resolver and if we were to enable Cgo, we will be either using the &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;getnameinfo&lt;/code&gt; functions in glibc.&lt;/p&gt;

&lt;p&gt;Being armed with that knowledge, we write up a small Go program that calls the &lt;code class=&quot;highlighter-rouge&quot;&gt;net.LookupHost&lt;/code&gt; function and a simple C program that calls &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt; to make sure that our understanding is accurate and to test out the behaviour of both these programs in different situations.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;log&quot;&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;net&quot;&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;net/http&quot;&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astrolabe&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;astrolabe.ap-southeast-1.elb.amazonaws.com&quot;&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;x&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LookupHost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astrolabe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;# Modified from http://www.binarytides.com/hostname-to-ip-address-c-sockets-linux/
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include&amp;lt;stdio.h&amp;gt; //printf
#include&amp;lt;string.h&amp;gt; //memset
#include&amp;lt;stdlib.h&amp;gt; //for exit(0);
#include&amp;lt;sys/socket.h&amp;gt;
#include&amp;lt;errno.h&amp;gt; //For errno - the error number
#include&amp;lt;netdb.h&amp;gt; //hostent
#include&amp;lt;arpa/inet.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostname_to_ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;astrolabe.ap-southeast-1.elb.amazonaws.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;hostname_to_ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;astrolabe elb resolved to %s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
    Get ip from domain name
*/&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hostname_to_ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sockfd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;addrinfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;servinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sockaddr_in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;memset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ai_family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AF_UNSPEC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// use AF_INET6 to force IPv6
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ai_socktype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SOCK_STREAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getaddrinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hints&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;servinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fprintf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stderr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;getaddrinfo: %s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gai_strerror&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// loop through all the results and connect to the first we can
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;servinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ai_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sockaddr_in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ai_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;strcat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;strcat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inet_ntoa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin_addr&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;strcat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;freeaddrinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;servinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// all done with this structure
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;First of all, to see the default state of the source system, we run the &lt;code class=&quot;highlighter-rouge&quot;&gt;ip address show&lt;/code&gt; command to show the list of network interfaces available on the source system.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;ip address show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 02:b4:d4:24:bb:ad brd ff:ff:ff:ff:ff:ff
    inet 172.21.2.90/24 brd 172.21.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::b4:d4ff:fe24:bbad/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And because we are only interested in the outgoing network interface, we will be using the command &lt;code class=&quot;highlighter-rouge&quot;&gt;ip address show dev eth0&lt;/code&gt; from this point onwards.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;ip address show dev eth0
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 02:b4:d4:24:bb:ad brd ff:ff:ff:ff:ff:ff
    inet 172.21.2.90/24 brd 172.21.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::b4:d4ff:fe24:bbad/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now to run the Go, Cgo and C DNS resolvers.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;go run gocode/dnslookup.go
2017/01/18 02:07:31 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.2.108 172.21.2.144 172.21.1.152 172.21.1.97] &amp;lt;nil&amp;gt;


&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GODEBUG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;netdns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Cgo+2 go run gocode/dnslookup.go
go package net: using Cgo DNS resolver
go package net: hostLookupOrder&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;astrolabe.ap-southeast-1.elb.amazonaws.com&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Cgo
2017/01/18 02:08:08 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.2.108 172.21.2.144 172.21.1.97 172.21.1.152] &amp;lt;nil&amp;gt;

&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;./ccode/dnslookup.out
astrolabe elb resolved to 172.21.2.108  172.21.2.144  172.21.1.97  172.21.1.152
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, they all have the exact same sorting order with 172.21.2.108 being the first and 172.21.1.152 being the last, which is exactly as defined in Rule 9 of the RFC‚Äôs destination address sorting algorithm ‚Äì addresses are sorted based on the longest matching prefix first.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Source
172.21.2.90:  10101100.00010101.00000010.01011010


Destination
172.21.2.108: 10101100.00010101.00000010.01101100
172.21.2.144: 10101100.00010101.00000010.10010000
172.21.1.97:  10101100.00010101.00000001.01100001
172.21.1.152: 10101100.00010101.00000001.10011000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To make it clearer, we have converted the IP addresses to their binary form for easier comparison. We can see that 172.21.2.108 has the longest matching prefix with our source interface of 172.21.2.90 and because the IP addresses in the 172.21.1.* subnet has the same matching prefix length, they can actually show up in a different order in which either 172.21.1.97 or 172.21.1.152 comes first.
Now let‚Äôs see what happens when we disable IPv6. This can be done with the following commands:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# We can either disable IPv6 completely&lt;/span&gt;
sh -c &lt;span class=&quot;s1&quot;&gt;&#39;echo 1 &amp;gt; /proc/sys/net/ipv6/conf/eth0/disable_ipv6&#39;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# or we can just remove IPv6 from the outgoing interfaces&lt;/span&gt;
ip -6 addr del fe80::b4:d4ff:fe24:bbad/64 dev eth0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After disabling IPv6, we run the &lt;code class=&quot;highlighter-rouge&quot;&gt;ip address show dev eth0&lt;/code&gt; command again to verify that the IPv6 address is no longer attached to the source interface.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;ip address show dev eth0
2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 02:b4:d4:24:bb:ad brd ff:ff:ff:ff:ff:ff
    inet 172.21.2.90/24 brd 172.21.2.255 scope global eth0
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we run the programs again to see what has changed. For the sake of clarity, we are showing 2 runs of each of the programs.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;go run gocode/dnslookup.go
2017/01/18 02:14:39 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.2.108 172.21.2.144 172.21.1.97 172.21.1.152] &amp;lt;nil&amp;gt;
&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;go run gocode/dnslookup.go
2017/01/18 02:14:40 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.2.108 172.21.2.144 172.21.1.97 172.21.1.152] &amp;lt;nil&amp;gt;


&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GODEBUG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;netdns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Cgo+2 go run gocode/dnslookup.go
go package net: using Cgo DNS resolver
go package net: hostLookupOrder&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;astrolabe.ap-southeast-1.elb.amazonaws.com&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Cgo
2017/01/18 02:15:41 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.1.97 172.21.1.152 172.21.2.108 172.21.2.144] &amp;lt;nil&amp;gt;
&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GODEBUG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;netdns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Cgo+2 go run gocode/dnslookup.go
go package net: using Cgo DNS resolver
go package net: hostLookupOrder&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;astrolabe.elb.amazonaws.com&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Cgo
2017/01/18 02:15:43 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;172.21.2.144 172.21.1.97 172.21.1.152 172.21.2.108] &amp;lt;nil&amp;gt;

&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;./ccode/dnslookup.out
astrolabe elb resolved to 172.21.1.152  172.21.2.108  172.21.2.144  172.21.1.97
&lt;span class=&quot;gp&quot;&gt;root@ip-172-21-2-90:~# &lt;/span&gt;./ccode/dnslookup.out
astrolabe elb resolved to 172.21.1.97  172.21.1.152  172.21.2.108  172.21.2.144
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And from the results, you can see that it has no impact on the native Go DNS resolver but both the Cgo and C DNS resolvers are starting to return the IP addresses in a random order, as expected from our learnings in &lt;a href=&quot;/troubleshooting-unusual-aws-elb-5xx-error&quot;&gt;part one&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;ok-disabling-ipv6-and-using-cgoc-works-now-what&quot;&gt;Ok, disabling IPv6 and using Cgo/C works, now what?&lt;/h4&gt;

&lt;p&gt;Now that we have established that disabling IPv6 does indeed solve the problem for us in Cgo and C (both use the same underlying &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt; function in glibc), it is time for us to explore the Go source code to see if there is anything that stands out in its implementation of a DNS resolver.&lt;/p&gt;

&lt;p&gt;Being Go programmers, we can quickly navigate around the Go source code to reach the native Go DNS resolver (&lt;a href=&quot;https://github.com/golang/go/blob/db07c9ecb617117a86364e9e03acd6f7937e1732/src/net/addrselect.go&quot;&gt;net/addrselect.go&lt;/a&gt;) and from the source code, we can see that it only implements part of the rules in the RFC. It does not provide a way to override the rules and, most importantly, it does not do any form of source address selection but instead relies on processing the Rule 9 sorting based on a couple of selected and reserved CIDR blocks (&lt;a href=&quot;https://github.com/golang/go/blob/db07c9ecb617117a86364e9e03acd6f7937e1732/src/net/addrselect.go#L411&quot;&gt;Reserved CIDR Blocks&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Knowing what we have done so far, we had strong reasons to believe that it is the lack of source address selection that is causing the Go DNS resolver to behave differently from the DNS resolver in glibc.&lt;/p&gt;

&lt;h3 id=&quot;source-address-selection&quot;&gt;Source Address Selection&lt;/h3&gt;

&lt;p&gt;Referring back to the RFC, the part on source address selection states that the source address selection should be configurable by the system administrators. A quick google search shows us that for Ubuntu systems, the file is &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gai.conf&lt;/code&gt;. To isolate the changes that we are making, we re-enable IPV6 before proceeding further. First, we try to move IPv4 addresses to the top of the list. We suspect that for some weird reason, the IPv6 source address is somehow being used to make the outgoing connection, otherwise why would disabling IPv6 do anything at all? Surprisingly, all of our different attempts at modifying &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gai.conf&lt;/code&gt; do not do anything (Well, one of the attempts does, by adding a &lt;code class=&quot;highlighter-rouge&quot;&gt;172.21.2.90/26&lt;/code&gt; prefix. It works because the common prefix for the addresses in the 172.21.2.* subnet would now be the same). Welp, we are now back at square one.&lt;/p&gt;

&lt;p&gt;After hours and hours of research by talking to people with networking experience and going through pages and pages of Google search results that touch on this topic (Microsoft‚Äôs blog posts on Vista, Debian mailing list, etc.), we finally come across a series of article on Linux Hacks (&lt;a href=&quot;http://linux-hacks.blogspot.com/2008/04/default-address-selection-part-1.html&quot;&gt;Part 1&lt;/a&gt;, &lt;a href=&quot;http://linux-hacks.blogspot.com/2008/07/default-address-selection-part-2.html&quot;&gt;Part 2&lt;/a&gt;). Guess what? The article actually tells us that source address selection is not configured through &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gai.conf&lt;/code&gt; but is done through the kernel instead! &lt;strong&gt;Aha!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Off we go, once again making a bunch of different configuration changes to the network interface that bring us nowhere. Also, because the Go DNS resolver does not actually do any sort of source address selection, spending more time on this avenue does not really help us in finding the problem.&lt;/p&gt;

&lt;h3 id=&quot;the-source-code-we-go&quot;&gt;The Source Code We Go&lt;/h3&gt;

&lt;p&gt;If you have ever gotten stuck on trying to figure out how something works and all the googling is not giving you the right answers, you know that going through the source code is the next thing to try. It is almost never the first thing that any programmer wants to do though. Navigating someone else‚Äôs code is hard and it‚Äôs even harder when it‚Äôs not a language you‚Äôre very familiar with. Ultimately, we decide to bite the bullet and dive deep into the code in glibc to see how source address selection is done specifically and get an understanding of how it affects the sorting of the IP addresses.&lt;/p&gt;

&lt;p&gt;Funnily enough, even finding the source code of glibc is not as straightforward as we expect. Nowadays, when you want to find a piece of code, you will probably just google it and find it on github. This isn‚Äôt the case for glibc as the main source code is hosted at &lt;a href=&quot;https://sourceware.org/git/?p=glibc.git&quot;&gt;sourceware&lt;/a&gt; and is unfortunately not easy to navigate. Luckily, we found a mirror on &lt;a href=&quot;https://github.molgen.mpg.de/git-mirror/glibc/blob/glibc-2.19/sysdeps/posix/getaddrinfo.c#L2310&quot;&gt;Github&lt;/a&gt; that provided us with a familiar interface. Again, finding the source code for &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt; itself also isn‚Äôt easy. At first, we end up in the &lt;a href=&quot;https://github.molgen.mpg.de/git-mirror/glibc/tree/master/inet&quot;&gt;inet directory&lt;/a&gt; and we get completely confused as all the files only have macro definitions and no code at all. Only after some googling and stumbling around, we find that the source code for &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt; is at &lt;a href=&quot;https://github.molgen.mpg.de/git-mirror/glibc/blob/glibc-2.19/sysdeps/posix/getaddrinfo.c#L2310&quot;&gt;sysdeps/posix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Being mostly Go or Ruby programmers, it takes a little bit of time to understand how the C-based code works. After getting a basic understanding, we decide to whip out good old gdb to start debugging the code step by step. Eventually, we find the issue. The way the prefix attributes of the source addresses are set disables the sorting of the IP addresses, since they are the only values that are different when we enable/disable IPv6. With some more research, we identify a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;check_pf.c&lt;/code&gt; where the source address selection is actually being done. In the end, we narrow it down to a block of code in &lt;a href=&quot;https://github.molgen.mpg.de/git-mirror/glibc/blob/master/sysdeps/unix/sysv/linux/check_pf.c#L266&quot;&gt;check_pf.c&lt;/a&gt; that is the root cause of this whole thing. The block of code basically states that if there are no IPv6 source addresses on the outgoing interface, it will just return that there are no possible source addresses at all that in turn causes Rule 9 sorting of the RFC to be completely bypassed and give us back the default DNS ordering (round robin in most scenarios).&lt;/p&gt;

&lt;p&gt;Finally understanding how it works in glibc, we modify the Go source code and to add in the same behaviour. With the same weird logic in &lt;code class=&quot;highlighter-rouge&quot;&gt;check_pf.c&lt;/code&gt;, the Go DNS resolver now works the same as the glibc DNS resolver. However, we‚Äôre not interested in maintaining a separate fork of Go and instead opened a ticket with the Go maintainers. Within a very short timeframe, the Go maintainers decided to skip RFC 6274 completely for IPv4 addresses and merge this patch into the current upstream with release in Go 1.9. Eventually, the fix is also backported to Go 1.8.1 a release on April 7, 2017. The image below shows the effects of this change on one of our systems running on Go 1.8.1&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;ELB Requests per AZ&quot; src=&quot;/img/dns-resolution-in-go-and-cgo/elb-requests-per-az.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;To summarize, in the first part of the series, we walked through our process investigating why we were receiving ELB HTTP 5xx alerts on Astrolabe (our driver location processing service) and how we fixed it by forcing Go to use the Cgo DNS resolver while IPv6 was disabled. In the second part of the series, we dived deeper into the problem to figure out why our solution in part 1 worked. In the end, it turns out that it was because of some undocumented behaviour in glibc that allowed the internet to continue working as it did.&lt;/p&gt;

&lt;p&gt;A couple of takeaways that we had from this investigation:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It is never easy to reimplement something that is already working, as in the case of Go‚Äôs reimplementation of glibc‚Äôs &lt;code class=&quot;highlighter-rouge&quot;&gt;getaddrinfo&lt;/code&gt;. Because of a couple of lines of undocumented code in glibc, the Go maintainers did not manage to replicate glibc exactly and that caused strange and hard to understand problems.&lt;/li&gt;
  &lt;li&gt;Software is something that we can always reason with. With enough time, you will almost always be able to find the root cause and fix it.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That‚Äôs it, we hope that you enjoyed reading our journey as much as we enjoyed going through it!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: All the sensitive information in this article has been modified and does not reflect the true state of our systems.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 24 May 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/dns-resolution-in-go-and-cgo</link>
        <guid isPermaLink="true">http://engineering.grab.com/dns-resolution-in-go-and-cgo</guid>
        
        <category>Golang</category>
        
        <category>Networking</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Driving Southeast Asia Forward with AWS</title>
        <description>&lt;div class=&quot;video-container&quot;&gt;
  &lt;iframe class=&quot;video-frame&quot; src=&quot;https://www.youtube.com/embed/qMOpFrzalJE&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;My name is Arul Kumaravel, VP of Engineering at Grab. Grab‚Äôs mission is to drive Southeast Asia (SEA) forwards. Today I would like to share with you how Amazon Web Services (AWS) is helping us with this mission. Grab was started in 2012 by our founders Anthony Tan and Tan Hooi Ling when they were in Harvard Business School. Both are from Malaysia. They started Grab, known as MyTeksi then, with a simple idea: to make Grab simple and easy to use for the people. We‚Äôve come a long way since our humble beginnings.&lt;/p&gt;

&lt;p&gt;Today, we offer the most comprehensive suite of transport services in SEA, including taxis, cars and bikes. We have services that cater to every transport need, preferences and price points of our customers. The numbers tell a story. We‚Äôre currently in 40 cities in 7 countries, the largest land fleet of 780,000 drivers in the region. Our app is installed in 38 million devices. We‚Äôre no longer just a taxi app, we‚Äôre much more than that. We‚Äôve built a market-leading transportation platform. So whether you need a car, limo or a bike, whether you want to pay with cash, with credit, you just have to go to one place.&lt;/p&gt;

&lt;p&gt;Our journey doesn‚Äôt stop here. We continue to outserve our customers by launching new products and services, such as social sharing, which is GrabHitch, parcel delivery, GrabExpress, and GrabFood. We are able to build the best and most widely-used app because of our talented pool of developers spread across all our six development centres. Our largest center is here in Singapore. We also have centres in Bangalore, Beijing, Ho Chi Minh, Jakarta and Seattle. Our engineers love that they are making an impact on the lives of SEA. A lot of these have been made possible thanks to our work with AWS.&lt;/p&gt;

&lt;p&gt;Grab started using Amazon Web Services since its inception in 2012. Our initial application was built using Ruby on Rails, which we ran on Amazon EC2. We used Amazon RDS MySQL for our storage. Of course we used VPC and other networking infrastructure for running our application. We have since evolved our app architecture from a single monolithic application to microservices-based architecture. We have grown quickly over the years and our usage of AWS increased tremendously. We used a number of AWS services that helps Grab team save time and resources up to 40%. There are so many services that we use today and you might be wondering why. Each of the services has its own use case. Let me give you a concrete example of how we used AWS. AWS has enabled us to build strong capabilities to review real-time data. We use this capability to make matching drivers to passengers efficiently. For example, we pro-actively push information, telling drivers where the demand is high during certain time of the day. What you‚Äôre seeing is a demand heat map created on a Monday morning for Singapore at around 8.45am. This is the time that most people leave for work. As you can see, the red dot here in the map represents that the demand is high. As you can see, the demand is high in the center part of Singapore. For those who are familiar with Singpore, you‚Äôll know that‚Äôs where most of the housing estates are. We monitor changing custom demands in real-time, and send drivers notifications to go to areas with higher booking demand. For example, there‚Äôs another heat map on a Friday evening after work. We can clearly see the difference between Friday night and Monday morning. Friday night hot spots are in the central business district. Monday morning when people go to work, high demand is mostly in the residential areas. this seems obvious, but demand is not always where we expect it to be. We have to track in real-time, so that we can respond quickly when there are unforeseen like weather and public transportation breakdowns. What this means is our drivers get to get increased revenue or they can reduce the numbers they are driving. For consumers, this means that they can book the fastest ride, without having to stand at the side of the road trying to hail a taxi.&lt;/p&gt;

&lt;p&gt;By using big data, we have been able to increase our allocation rate, which is the matching of drivers to passengers by up to 30%. beyond using data to make Grab bookings more efficient, we want to solve bigger problems of traffic congestion, and also help with urban planning. What do we do with the 100 of millions of GPS data points we get from our drivers fleet? Here‚Äôs a screenshot of our open traffic platform, a collaboration between grab and World Bank. In this image, the red means the traffic moves less than 10 km per hour while the dark blue means the traffic moves more than 70-80 km per hour. This screenshot is taken on a peak hour on Tuesday in Singapore‚Äôs Central Business Distract. It‚Äôs easy to see which roads are smooth flowing and which roads to avoid. City governments have free access to open traffic. They can get real-time traffic condition in the city at one glance. open traffic helps government save costs and manpower on manual monitoring and focus  on issues that matter. It can identify roads to help manage traffice beside areas that need more infrastructure and identify roads with high action rates. AWS has enabled us to manage this multi-petabyte flow of data and leverage it to improve our customer experience.&lt;/p&gt;

&lt;p&gt;We‚Äôve been using AWS since our inception and there are many benefits to using AWS but I want to pick three that I would like to call out here. The first one being lean operation scheme. We have fewer than 10 engineers full-time maintaining all the services mentioned before. as a startup, the speed of innovation and growth is key. AWS has allowed us to focus on our users and customers and not spend time on infrastructure. That‚Äôs where AWS enterprise support came in. Even though our user count increased multiple fold, we didn‚Äôt have to increase our headcount.&lt;/p&gt;

&lt;p&gt;Second benefit is awesome scalability. We started small but have grown tremendously over the last 4 years. Our usage of AWS has increased 200 times over the last 4 years but it was never an artificial limitation for us to scale our business. With a couple of button touches, our infrastructure grew with us.&lt;/p&gt;

&lt;p&gt;Lastly, continuous innovation. We have been using AWS for our analytics platform. it has evolved over the years and gone through several iterations. we started with MySQL, later on we moved to Redshift, now our analytics platform runs on data lake on S3 with EMR and presto. All these was done in AWS without any need to look for another platform. Now we look forward to using Athena as well, this is something that we have been waiting for, looks like it‚Äôs coming to Singapore soon, so we‚Äôll be using that as well.&lt;/p&gt;

&lt;p&gt;Using AWS has enabled Grab Engineering team to focus on customers, innovating on new ideas, iterating on new features and rolling them out quickly into the hands of the customers. This has given Grab a competitive advantage in transforming the customer experience. SEA is growing at a tremendous pace. We have an unprecedented opportunity to build a platform that caters to the mobile-first environment and infrastructure needs. We are working on two main areas: making the baby travel easier, and we‚Äôre building a multi-modal transport system that offers the most affordable and convenient option across the mobility spectrum, making the way we pay easier. A payments platform, that is the most affordable and convenient platform to pay for services. Momentous challenges, but with AWS on our side, that‚Äôs a singular focus. We believe we are only scratching the surface of what‚Äôs possible with Grab.&lt;/p&gt;

&lt;p&gt;Grab is SEA‚Äôs largest homegrown technology company and we want to continue growing and provide better service to our customers. We‚Äôre the number one transport app in the region, but more importantly, how does tomorrow look like? Grab is part of the first wave of the technology startups from SEA, for SEA. And we belong to the first group focused on building the tech ethos ecosystem and using innovation to improve peoples‚Äô lives. We expect most startups to be creative and built in SEA. AWS platforms make barrier to entry low for startups, and to scale when the business scales. We believe to our very core, but we then we are in this journey together to build SEA‚Äôs Baidu, Alibaba, and Tencent. If China and India can do it, why cant we? I look forward to hearing success stories of aspiring entrepreneurs among you in the future for work like this. Good luck and thank you.&lt;/p&gt;
</description>
        <pubDate>Sun, 21 May 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/driving-southeast-asia-forward-with-aws</link>
        <guid isPermaLink="true">http://engineering.grab.com/driving-southeast-asia-forward-with-aws</guid>
        
        <category>AWS</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How to Go from a Quick Idea to an Essential Feature in Four Steps</title>
        <description>&lt;p&gt;How do you work within a startup team and build a quick idea into a key feature for an app that impacts millions of people? It‚Äôs one of those things that is hard to understand when you just graduate as an engineer.&lt;/p&gt;

&lt;p&gt;Software engineer Huang Da and data scientist Tan Sien Yi can explain just that. Huang Da and his team first came up with the idea for a chat function in the Grab app in early 2016 and since the official roll out of GrabChat, the first messaging tool in a ride-hailing app, more than 78 million messages have been exchanged across the region. Here‚Äôs their story on how this feature evolved from a quick idea to an essential feature.&lt;/p&gt;

&lt;h3 id=&quot;identify-the-problem&quot;&gt;1. Identify the problem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Huang Da:&lt;/strong&gt; Southeast Asia is a pretty challenging place for an app. We have countries with vastly different internet conditions and infrastructural capabilities. You don‚Äôt always have access to Wi-Fi. A lot of people are still using 2G, which has limited bandwidth, slow speeds and the high probability of data packets dropping due to congestion or interference affecting the Wi-Fi signal.&lt;/p&gt;

&lt;p&gt;With that context in mind, in January 2016, we first started thinking of a new, safe and automated way for drivers and passengers to communicate better. Cities in Southeast Asia change so fast, so being able to communicate makes a big difference if you‚Äôre trying to find your driver or passenger.&lt;/p&gt;

&lt;p&gt;In discussing the problem with my team, one idea jumped out: why don‚Äôt we build an in-app chat solution? It‚Äôs the safest and most anonymized way to allow passengers and drivers to communicate. Also, if there‚Äôs one thing we know, it‚Äôs that people in Southeast Asia love to chat, with applications such as WhatsApp, Facebook Messenger and Line being ubiquitous.&lt;/p&gt;

&lt;h3 id=&quot;build-an-mvp-solution&quot;&gt;2. Build an MVP solution&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Huang Da:&lt;/strong&gt; Once we decided to build GrabChat, we started with a prototype. We could have integrated it with third parties, but building it yourself allows more flexibility and options, as well as the opportunity to scale up down the line.&lt;/p&gt;

&lt;p&gt;We started with a very simple TCP server, without making use of our architecture or entire back end, because we were expecting challenges to arise in any case. While the basic communication protocol is easy, making sure messages get delivered in the real world, is a different ordeal. The messages going through a TCP connection might get lost; we might have to get up with an ad-layer and that‚Äôs just two examples.&lt;/p&gt;

&lt;p&gt;As a next step, we built an architecture, which made use of the whole Grab infrastructure, extracting out the TCP layer and making it a stand-alone layer.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;GrabChat System Architecture&quot; src=&quot;/img/how-to-go-from-a-quick-idea-to-an-essential-feature-in-four-steps/grabchat-system-architecture.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We decided to design GrabChat as a service: it opens interfaces for other services to create and manage the chat room. After a chat room is created, clients in the same chat room could send messages to each other through TCP messages. Services interacts with GrabChat through internal HTTPS requests, and clients interact with GrabChat through Message Exchange service via Gundam and Hermes, our TCP gateway and message dispatcher.&lt;/p&gt;

&lt;p&gt;The core component of a GrabChat conversation is the message exchange service, which oversees the delivery of messages to all the recipients. It implements a protocol that involves sufficient handshake acknowledgement to make sure the message arrives. There are multiple ways to design the protocol, but finally we agreed on implementing around the concept of ‚Äúserver only push once‚Äù.&lt;/p&gt;

&lt;p&gt;The difficult part of coming up with the protocol is to decide which part of the system, the client or the server, should handle the message loss. It essentially becomes a push or pull problem: If we handle it on the server, the server needs to keep pushing (spamming) the message until the client acknowledges it; on the other hand, if we handle it on the client‚Äôs side, the client needs to poll the server for the latest status and message.&lt;/p&gt;

&lt;p&gt;We chose not to do with the server push method because a message could remain unacknowledged for many reasons, key reason among them being network issues, but if a server pushes regardless, it might drop into a resend loop and never come out, resulting in a severe loss of resources.&lt;/p&gt;

&lt;p&gt;On the other hand, if we do it on the client side, we don‚Äôt need to worry too much about the extra resource consumption: we only process the requests that reach the backend. From the perspective of a client, it keeps trying to send a message until it receives a response from the server before it times out, or fails to maintain a keep-alive heartbeat with the server. When that happens, it terminates the connection and reconnects. In other words, clients only send requests when needed, which is more friendly to server.&lt;/p&gt;

&lt;h3 id=&quot;evaluate&quot;&gt;3. Evaluate&lt;/h3&gt;

&lt;p&gt;After building the initial architecture is when the most time-intensive part comes in. There‚Äôs a lot of discussions across different teams, including product manager, team leads, front-end and design around the feature‚Äôs impact and ways to mature the design.&lt;/p&gt;

&lt;p&gt;Data scientist Sien Yi evaluated the impact of GrabChat to give the engineering team the analysis it needed to further improve the product. One hypothesis was that the use of GrabChat would lower the cancellation rates in the Grab app. Sien Yi tested this thesis.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sien Yi:&lt;/strong&gt; Measuring the effect of GrabChat isn‚Äôt just about comparing the cancellations ratios on the Grab app, before and after implementation of the GrabChat feature. For all we know, those who use GrabChat could be the more engaged customers who are less likely to cancel anyway ‚Äî even without GrabChat.&lt;/p&gt;

&lt;p&gt;We approached testing the hypothesis from two sides.&lt;/p&gt;

&lt;h4 id=&quot;comparing-non-chat-vs-chat-bookings-of-individual-passengers&quot;&gt;Comparing non-chat vs chat bookings of individual passengers&lt;/h4&gt;

&lt;p&gt;As a first line of enquiry, we looked at a sample size of 20,000 passengers who had done a significant number of bookings before GrabChat and continued making a significant number of bookings after GrabChat was introduced.&lt;/p&gt;

&lt;p&gt;Our research showed that 8 out of 10 passengers cancelled less on bookings where GrabChat was used.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;GrabChat CR minus Non-GrabChat CR&quot; src=&quot;/img/how-to-go-from-a-quick-idea-to-an-essential-feature-in-four-steps/cancellation-likelihood-prediction.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;There were still some remaining issues with this analysis though:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One could say that even for the same passenger, they might already be more engaged at a booking level when they use GrabChat.&lt;/li&gt;
  &lt;li&gt;There might be a selection bias in that we necessarily sample passengers with more experience on the Grab platform in order to measure meaningful differences between their Chat and non-Chat bookings.&lt;/li&gt;
  &lt;li&gt;We haven‚Äôt accounted for driver cancels.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;using-the-cancellation-prediction-model&quot;&gt;Using the cancellation prediction model&lt;/h4&gt;

&lt;p&gt;This is where the cancellation prediction model came in. With the data science team, we‚Äôve been building a model that predicts how likely an allocated booking will be cancelled. We trained the model on GrabCar data for September in Singapore (before GrabChat was ever used), and then ran the model on October data (after GrabChat was adopted).&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Match cancel likelihood predicted by GrabChat-unaware model&quot; src=&quot;/img/how-to-go-from-a-quick-idea-to-an-essential-feature-in-four-steps/grabchat-cancellation-rate-graph.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We developed a calibration plot (see above), which put actual cancellation proportions against predicted cancellation figures. The plot above suggests the model predicted that many allocated bookings would have been cancelled had GrabChat not been used. In other words, the data implied the use of GrabChat correlated with a decrease in the likelihood of cancellations.&lt;/p&gt;

&lt;p&gt;Sien Yi and the data science team confirmed that the use of GrabChat is correlated with lower cancellation rates, meaning that the experience of passengers and drivers has been improved by the introduction of GrabChat.&lt;/p&gt;

&lt;h3 id=&quot;iterate&quot;&gt;4. Iterate&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Huang Da:&lt;/strong&gt; While the first protocol was built in March 2016, we‚Äôve had many evaluation and iteration sessions before and after GrabChat was made available to all users in September/October. Together with the product manager, we built a roadmap with updates far beyond the first set of protocols.&lt;/p&gt;

&lt;p&gt;For example, one of our insights from the first tests with the communications protocol was that the driver needs to be able to continue driving and not get distracted by the messages. To make it easier for our drivers to deal with the messages, we built template messages such as ‚ÄúI‚Äôm here‚Äù or ‚ÄúI‚Äôll be there in 2 minutes‚Äù, which created a serious uptick in the volume of messages.&lt;/p&gt;

&lt;p&gt;Building a product which is essential to our business is a never-ending project. We‚Äôre never ‚Äúdone‚Äù. Instead, we continue to look for iterations and solutions which serve our passengers and drivers in the best way possible.&lt;/p&gt;
</description>
        <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
        <link>http://engineering.grab.com/how-to-go-from-a-quick-idea-to-an-essential-feature-in-four-steps</link>
        <guid isPermaLink="true">http://engineering.grab.com/how-to-go-from-a-quick-idea-to-an-essential-feature-in-four-steps</guid>
        
        <category>Data Science</category>
        
        <category>Product Management</category>
        
        
        <category>Data Science</category>
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>Troubleshooting Unusual AWS ELB 5XX Error</title>
        <description>&lt;p&gt;&lt;em&gt;This article is part one of a two-part series (&lt;a href=&quot;/dns-resolution-in-go-and-cgo&quot;&gt;part two&lt;/a&gt;). In this article we explain the ELB 5XX errors which we experience without an apparent reason. We walk you through our investigative process and show you our immediate solution to this production issue. In the second article, we will explain why the non-intuitive immediate solution works and how we eventually found a more permanent solution.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Triggered: [Gothena] Astrolabe failed (Warning)&lt;/strong&gt;, an alert from Datadog that we have been seeing very often in our &lt;code class=&quot;highlighter-rouge&quot;&gt;#tech-operations&lt;/code&gt; slack channel. This alert basically tells us that Gothena &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; is receiving ELB &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; HTTP 5xx &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; errors when calling Astrolabe &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. Because of how frequently we update our driver location data, losing one or two updates of a single driver has never really been an issue for us at Grab. It was only when this started creating a lot of noise for our on call engineers, we decided that it was time to dig into it and fix it once and for all.&lt;/p&gt;

&lt;p&gt;Here is a high level walkthrough of the systems involved. The Driver app would connect to the Gothena Service ELB. Requests are routed to Gothena service. Gothena sends location update related requests to Astrolabe.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Driver Location Update Flow&quot; src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/driver-location-update-flow.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Hopefully the above gives you a better understanding of the background before we dive into the problem.&lt;/p&gt;

&lt;h3 id=&quot;clues-from-aws&quot;&gt;Clues from AWS&lt;/h3&gt;

&lt;p&gt;If you have ever taken a look at the AWS ELB dashboards, you will know that it shows a number of interesting metrics such as SurgeQueue &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, SpillOver &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, RequestCount, HealthyInstances, UnhealthyInstances and a bunch of other backend metrics. As you see below, every time we receive one of the Astrolabe failed alerts, the AWS monitors would show that the SurgeQueue is filling up, SpillOver of requests is happening and that the average latency &lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; of the requests increase. Interestingly, this situation would only persist for 1-2 minutes during our peak hours and only in one of the two AWS Availability Zones (AZ) that our ELBs are located in.&lt;/p&gt;

&lt;h3 id=&quot;cloudwatch-metrics&quot;&gt;Cloudwatch Metrics&lt;/h3&gt;

&lt;div id=&quot;carousel-example-generic&quot; class=&quot;carousel slide&quot; data-ride=&quot;carousel&quot; data-interval=&quot;false&quot;&gt;
  &lt;div class=&quot;carousel-inner&quot; role=&quot;listbox&quot;&gt;
    &lt;div class=&quot;item active&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-1.png&quot; alt=&quot;Cloudwatch Latency&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-2.png&quot; alt=&quot;Cloudwatch SurgeQueueLength&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-3.png&quot; alt=&quot;Cloudwatch SpilloverCount&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-4.png&quot; alt=&quot;Cloudwatch HTTPCode_ELB_5XX&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-5.png&quot; alt=&quot;Cloudwatch HTTPCode_Backend_5XX&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-6.png&quot; alt=&quot;Cloudwatch Healthy/Unhealty HostCount&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-7.png&quot; alt=&quot;Cloudwatch HTTPCode_Backend_2XX&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-8.png&quot; alt=&quot;Cloudwatch RequestCount&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-9.png&quot; alt=&quot;Cloudwatch HTTPCode_Backend_4XX&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;item&quot;&gt;
      &lt;img src=&quot;/img/troubleshooting-unusual-aws-elb-5xx-errors/cloudwatch-10.png&quot; alt=&quot;Cloudwatch RequestCount&quot; /&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;a class=&quot;left carousel-control&quot; href=&quot;#carousel-example-generic&quot; role=&quot;button&quot; data-slide=&quot;prev&quot;&gt;
    &lt;span class=&quot;glyphicon glyphicon-chevron-left&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt;
    &lt;span class=&quot;sr-only&quot;&gt;Previous&lt;/span&gt;
  &lt;/a&gt;
  &lt;a class=&quot;right carousel-control&quot; href=&quot;#carousel-example-generic&quot; role=&quot;button&quot; data-slide=&quot;next&quot;&gt;
    &lt;span class=&quot;glyphicon glyphicon-chevron-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt;
    &lt;span class=&quot;sr-only&quot;&gt;Next&lt;/span&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Few interesting points worth noting in above metrics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are no errors from backend i.e. no 5XX or 4XX errors.&lt;/li&gt;
  &lt;li&gt;Healthy and unhealthy instance count do not change i.e. all backend instances are healthy and serving the ELB.&lt;/li&gt;
  &lt;li&gt;Backend 2XX count drops significantly i.e requests are not reaching backend instances.&lt;/li&gt;
  &lt;li&gt;RequestCount drops significantly. It adds further proof of the above point that requests are not reaching the backend instances.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By jumping into the more detailed CloudWatch metrics, we are able to further confirm from our side that there is an uneven distribution of requests across the two different AZs. When we reach out to AWS‚Äô tech support, they confirm that one of the many ELB nodes is somehow preferred and is causing a load imbalance across ELB nodes that in turn causes a single ELB node to occasionally fail and results in the ELB 5xx errors that we are seeing.&lt;/p&gt;

&lt;h3 id=&quot;what-is-happening&quot;&gt;What is happening?&lt;/h3&gt;

&lt;p&gt;Having confirmation of the issue from AWS is a start. Now we can confidently say that our monitoring systems are working correctly ‚Äì something that is always good to know. After some internal discussions, we then came up with some probable causes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ELB is not load balancing correctly (Astrolabe ELB)&lt;/li&gt;
  &lt;li&gt;ELB is misconfigured (Astrolabe ELB)&lt;/li&gt;
  &lt;li&gt;DNS/IP caching is happening on the client side (Gothena)&lt;/li&gt;
  &lt;li&gt;DNS is misconfigured and is not returning IP(s) in a round-robin manner (AWS DNS Server)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We once again reach out to AWS tech support to see if there are any underlying issues with ELB when running at high loads (we are serving upwards for 20k request per second on Astrolabe). In case you‚Äôre wondering, AWS ELB is just like any other web service, it can occasionally not work as expected . However, in this instance, they confirm that there are no such issues at this point.&lt;/p&gt;

&lt;p&gt;Moving on to the second item on the list ‚Äì ELB configurations. When configuring ELBs, there are a couple of things that you would want to look out for: make sure that you are connecting to the right backend ports, your Route 53 &lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; configuration for the ELB is correct and the same goes for the timeout settings. At one point, we suspected that our Route 53 configuration was not using CNAME records when pointing to the ELB but it turns out that for the case of ELBs, AWS actually provides an Alias Record Set that is essentially the same as a CNAME but with the added advantages of being able to reflect IP changes on the DNS server more quickly and not incurring additional ingress/egress charges for resolving Alias Record Set. Please refer to &lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html&quot;&gt;this to learn more about CNAME vs Alias record set&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Having eliminated the possibility of a misconfiguration on the ELB, we move on to see if Gothena itself is doing some sort of IP caching or if there is some sort DNS resolution misconfiguration that is happening on the service itself. While doing this investigation, we notice the same pattern in all other services that are calling Astrolabe (we record all outgoing connections from our services on Datadog). It just so happens that because Gothena is responsible for the bulk of the requests to Astrolabe that the problem is more prominent here than on other services. Knowing this, allows us to narrow the scope down to either a library that is used by all these services or some sort of server configuration that we were applying across the board. This is where things start to get a lot more interesting.&lt;/p&gt;

&lt;h3 id=&quot;a-misconfigured-server-is-it-ubuntu-is-it-go&quot;&gt;A misconfigured server? Is it Ubuntu? Is it Go?&lt;/h3&gt;

&lt;p&gt;Here at Grab, all of our servers are running on AWS with Ubuntu installed on them and almost all our services are written in Go, which means that we have a lot of common setup and code between services.&lt;/p&gt;

&lt;p&gt;The first thing that we check is the number of connections created from one single Gothena instance to each individual ELB node. To do this, we first use the dig command to get the list of IP addresses to look for:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;dig +short astrolabe.grab.com
172.18.2.38
172.18.2.209
172.18.1.10
172.18.1.37
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then we proceed with running the netstat command to get connection counts from the Gothena instance to each of the ELB IPs retrieved above.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;netstat | grep 172.18.2.38 | wc -l; netstat | grep 172.18.2.209 | wc -l; netstat | grep 172.18.1.10 | wc -l; netstat | grep 172.18.1.37 | wc -l;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And of course, the output of the command above shows that 1 of the 4 ELB nodes is preferred and the numbers are heavily skewed towards that one single node.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.1.9 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
0
0
58
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.1.34 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
0
0
9
25
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.2.137 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
0
100
0
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.1.18 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
0
0
59
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.1.96 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
0
0
49
5
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.2.22 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
100
0
0
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.2.66 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
100
0
0
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0;32m172.18.2.50 | SUCCESS | &lt;span class=&quot;nv&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &amp;gt;&amp;gt;
100
0
0
0
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0m
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is the sum of total connections to each ELB node from all Gothena instances. This also explains an uneven distribution of requests across the two different AZs with 1b serving more requests than 1a.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;172.18.2.38 -&amp;gt; 84
172.18.2.209 -&amp;gt; 66
172.18.1.10 -&amp;gt; 138
172.18.1.37 -&amp;gt; 87
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And just to make sure that we did not just end up with a random outcome, we ran the same &lt;code class=&quot;highlighter-rouge&quot;&gt;netstat&lt;/code&gt; command across a number of different services that are running on different servers and codebases. Surely enough, the same thing is observed on all of them. This narrows down the potential problem to either something in the Go code, in Ubuntu or in the configurations. With this newfound knowledge, the first thing that we look into is whether Ubuntu is somehow caching the DNS results. This quickly turned into a dead end as DNS results are never cached on Linux by default, it would only be cached if we are running a local DNS server like dnsmasq.d or have a modified host file which we do not have.&lt;/p&gt;

&lt;p&gt;The next thing to do now is to dive into the code itself. And to do that, we spin up a new EC2 instance in a &lt;strong&gt;different subnet&lt;/strong&gt; (this is important later on) but with the same configuration as the other servers to run some tests.&lt;/p&gt;

&lt;p&gt;To help narrow down the problem points, we do some tests using cURL and a program in Go, Python and Ruby to try out the different scenarios and check consistency. While running the programs, we also capture the DNS TCP packets (by using the &lt;code class=&quot;highlighter-rouge&quot;&gt;tcpdump&lt;/code&gt; command below) to understand how many DNS queries are being made by each of the program. This helps us to understand if any DNS caching is happening.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;tcpdump -l -n port 53
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Curiously, when running the 5 requests to a health check URL from Go, Ruby, and Python, we see that cURL, Ruby and Python make 5 different DNS queries while Go only makes 1 DNS query. It turned out that cURL, Ruby and Python create new connections for each request by default while Go uses the same connection for multiple requests by default. The tests show that the DNS is correctly returning the IP addresses list in a round robin manner as cURL, Ruby, Python and Go programs were all making connections to both the IPs in an even manner. Note: Because we are running the tests on a &lt;strong&gt;different isolated environment&lt;/strong&gt;, there are only 2 Astrolabe ELB nodes instead of the earlier 4.&lt;/p&gt;

&lt;p&gt;For simplicity the &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tcpdump&lt;/code&gt; output is shown here:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-12-187:~$ &lt;/span&gt;dig +short astrolabe.grab.com
172.21.2.115
172.21.1.107
&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-12-187:~$ &lt;/span&gt;curl -v http://astrolabe.grab.com/health_check
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Hostname was NOT found &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;DNS cache
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;   Trying 172.21.1.107...
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connected to astrolabe.grab.com &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;172.21.1.107&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; port 80 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#0)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;GET /health_check HTTP/1.1
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;User-Agent: curl/7.35.0
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Host: astrolabe.grab.com
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Accept: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Access-Control-Allow-Headers: Authorization
&amp;lt; Access-Control-Allow-Methods: GET,POST,OPTIONS
&amp;lt; Access-Control-Allow-Origin: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;lt; Content-Type: application/json; &lt;span class=&quot;nv&quot;&gt;charset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;utf-8
&amp;lt; Date: Mon, 09 Jan 2017 11:19:00 GMT
&amp;lt; Content-Length: 0
&amp;lt; Connection: keep-alive
&amp;lt;
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connection &lt;span class=&quot;c&quot;&gt;#0 to host astrolabe.grab.com left intact&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-12-187:~$ &lt;/span&gt;curl -v http://astrolabe.grab.com/health_check
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Hostname was NOT found &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;DNS cache
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;   Trying 172.21.2.115...
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connected to astrolabe.grab.com &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;172.21.2.115&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; port 80 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#0)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;GET /health_check HTTP/1.1
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;User-Agent: curl/7.35.0
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Host: astrolabe.grab.com
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Accept: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Access-Control-Allow-Headers: Authorization
&amp;lt; Access-Control-Allow-Methods: GET,POST,OPTIONS
&amp;lt; Access-Control-Allow-Origin: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;lt; Content-Type: application/json; &lt;span class=&quot;nv&quot;&gt;charset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;utf-8
&amp;lt; Date: Mon, 09 Jan 2017 11:19:01 GMT
&amp;lt; Content-Length: 0
&amp;lt; Connection: keep-alive
&amp;lt;
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connection &lt;span class=&quot;c&quot;&gt;#0 to host astrolabe.grab.com left intact&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-12-187:~$ &lt;/span&gt;sudo tcpdump -l -n port 53
tcpdump: verbose output suppressed, use -v or -vv &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;full protocol decode
listening on eth0, link-type EN10MB &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ethernet&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, capture size 65535 bytes
09:29:37.906017 IP 172.21.12.187.37107 &amp;gt; 172.21.0.2.53: 19598+ A? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:37.906030 IP 172.21.12.187.37107 &amp;gt; 172.21.0.2.53: 41742+ AAAA? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:37.907518 IP 172.21.0.2.53 &amp;gt; 172.21.12.187.37107: 41742 0/1/0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;121&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:37.909391 IP 172.21.0.2.53 &amp;gt; 172.21.12.187.37107: 19598 2/0/0 A 172.21.1.107, A 172.21.2.115 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:43.109745 IP 172.21.12.187.59043 &amp;gt; 172.21.0.2.53: 13434+ A? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:43.109761 IP 172.21.12.187.59043 &amp;gt; 172.21.0.2.53: 63973+ AAAA? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:43.110508 IP 172.21.0.2.53 &amp;gt; 172.21.12.187.59043: 13434 2/0/0 A 172.21.2.115, A 172.21.1.107 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
09:29:43.110575 IP 172.21.0.2.53 &amp;gt; 172.21.12.187.59043: 63973 0/1/0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;121&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The above tests make things even more interesting. We carefully kept the testing environment close to production in hopes of reproducing the issue yet everything seems to be working correctly. We run tests from the same OS image, same version of Golang, with the same HTTP client code and the same server configuration, but the issue of preferring a particular IP never happens.&lt;/p&gt;

&lt;p&gt;How about running the tests on one of the staging Gothena instance? For simplicity, we‚Äôll show &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tcpdump&lt;/code&gt; output which is indicative of the issue faced by our Go service.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-2-17:~$ &lt;/span&gt;dig +short astrolabe.grab.com
172.21.2.115
172.21.1.107
&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-2-17:~$ &lt;/span&gt;curl -v http://astrolabe.grab.com/health_check
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Hostname was NOT found &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;DNS cache
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;   Trying 172.21.2.115...
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connected to astrolabe.grab.com &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;172.21.2.115&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; port 80 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#0)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;GET /health_check HTTP/1.1
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;User-Agent: curl/7.35.0
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Host: astrolabe.grab.com
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Accept: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Access-Control-Allow-Headers: Authorization
&amp;lt; Access-Control-Allow-Methods: GET,POST,OPTIONS
&amp;lt; Access-Control-Allow-Origin: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;lt; Content-Type: application/json; &lt;span class=&quot;nv&quot;&gt;charset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;utf-8
&amp;lt; Date: Fri, 06 Jan 2017 11:07:16 GMT
&amp;lt; Content-Length: 0
&amp;lt; Connection: keep-alive
&amp;lt;
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connection &lt;span class=&quot;c&quot;&gt;#0 to host astrolabe.grab.com left intact&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-2-17:~$ &lt;/span&gt;curl -v http://astrolabe.grab.com/health_check
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Hostname was NOT found &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;DNS cache
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;   Trying 172.21.2.115...
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connected to astrolabe.grab.com &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;172.21.2.115&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; port 80 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#0)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;GET /health_check HTTP/1.1
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;User-Agent: curl/7.35.0
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Host: astrolabe.stg-myteksi.com
&lt;span class=&quot;gp&quot;&gt;&amp;gt; &lt;/span&gt;Accept: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;gt;
&amp;lt; HTTP/1.1 200 OK
&amp;lt; Access-Control-Allow-Headers: Authorization
&amp;lt; Access-Control-Allow-Methods: GET,POST,OPTIONS
&amp;lt; Access-Control-Allow-Origin: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&amp;lt; Content-Type: application/json; &lt;span class=&quot;nv&quot;&gt;charset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;utf-8
&amp;lt; Date: Fri, 06 Jan 2017 11:07:19 GMT
&amp;lt; Content-Length: 0
&amp;lt; Connection: keep-alive
&amp;lt;
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Connection &lt;span class=&quot;c&quot;&gt;#0 to host astrolabe.grab.com left intact&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;dharmarth@ip-172-21-2-17:~# &lt;/span&gt;tcpdump -l -n port 53 | grep -A4 -B1 astrolabe
tcpdump: verbose output suppressed, use -v or -vv &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;full protocol decode
listening on eth0, link-type EN10MB &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ethernet&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, capture size 65535 bytes
11:10:00.072042 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.51937: 25522 2/0/0 A 172.21.3.78, A 172.21.0.172 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:01.893912 IP 172.21.2.17.28047 &amp;gt; 172.21.0.2.53: 11695+ A? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:01.893922 IP 172.21.2.17.28047 &amp;gt; 172.21.0.2.53: 13413+ AAAA? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:01.895053 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.28047: 13413 0/1/0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;121&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:02.012936 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.28047: 11695 2/0/0 A 172.21.1.107, A 172.21.2.115 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:04.242975 IP 172.21.2.17.51776 &amp;gt; 172.21.0.2.53: 54031+ A? kinesis.ap-southeast-1.amazonaws.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;54&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:04.242984 IP 172.21.2.17.51776 &amp;gt; 172.21.0.2.53: 49840+ AAAA? kinesis.ap-southeast-1.amazonaws.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;54&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
--
11:10:07.397387 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.18405: 1772 0/1/0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;119&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.644113 IP 172.21.2.17.12129 &amp;gt; 172.21.0.2.53: 27050+ A? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.644124 IP 172.21.2.17.12129 &amp;gt; 172.21.0.2.53: 3418+ AAAA? astrolabe.grab.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;43&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.644378 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.12129: 3418 0/1/0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;121&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.644378 IP 172.21.0.2.53 &amp;gt; 172.21.2.17.12129: 27050 2/0/0 A 172.21.2.115, A 172.21.1.107 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.999919 IP 172.21.2.17.12365 &amp;gt; 172.21.0.2.53: 55314+ A? kinesis.ap-southeast-1.amazonaws.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;54&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
11:10:08.999928 IP 172.21.2.17.12365 &amp;gt; 172.21.0.2.53: 14140+ AAAA? kinesis.ap-southeast-1.amazonaws.com. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;54&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
^C132 packets captured
136 packets received by filter
0 packets dropped by kernel
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It didn‚Äôt work as expected in cURL. There is no IP caching, cURL is making DNS queries. We can see DNS is returning output correctly as per round robin. But somehow it‚Äôs still choosing the same one IP to connect to.&lt;/p&gt;

&lt;p&gt;With all that, we have indirectly confirmed that the DNS round robin behaviour is working as expected and thus leaving us with nothing else left on the list. Everybody that participated in the discussion up to this point was equally dumbfounded.&lt;/p&gt;

&lt;p&gt;After that long fruitless investigation, one question comes to mind. Which IP address will get the priority when the DNS results contain more than one IP address? A quick search on Google gives the following StackOverflow &lt;a href=&quot;http://serverfault.com/questions/102879/how-do-dns-clients-choose-an-ip-address-when-they-get-multiple-answers&quot;&gt;result&lt;/a&gt; with the following snippet:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A DNS server resolving a query, may prioritize the order in which it uses the listed servers based on historical response time data (RFC1035 section 7.2). It may also prioritize by closer sub-net (I have seen this in RFC but don‚Äôt recall which). If no history or sub-net priority is available, it may choose by random, or simply pick the first one. I have seen DNS server implementations doing various combinations of above.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Well, that is disappointing, no new insights to preen from that. Having spent the whole day looking at the same issue, we were ready to call it a night while having the gut feeling that something must be misconfigured on the servers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you are interested in finding the answers from the clues above, please hold off reading the next section and see if you can figure it out by yourself.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;breakthrough&quot;&gt;Breakthrough&lt;/h3&gt;

&lt;p&gt;Coming in fresh from having a good night‚Äôs sleep, the issue managed to get the attention of even more Grab engineers that happily jumped in to help investigate the issue together. Then the magical clue happened, someone with an eye for networking spotted that the requests were always going to the ELB node that has the same subnet as the client that was initiating the request. Another engineer then quickly found RFC 3484 that talked about sorting of source and destination IP addresses. That was it! The IP addresses were always being sorted and that resulted in one ELB node getting more traffic than the rest.&lt;/p&gt;

&lt;p&gt;Then an article surfaced that suggests disabling IPv6 for C-based applications. We quickly try that with our Go program which does not work. But when we then try running the same code with Cgo &lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; enabled as the DNS resolver it leads to success! The request count to the different ELB nodes is now properly balanced. Hooray!&lt;/p&gt;

&lt;p&gt;If you have been following this post, you would have figured that the issue is impacting all of our internal services. But as stated earlier, the load on the other ELBs is not high as Astrolabe. So we do not see any issues with the other services, The traffic to Astrolabe has been steadily increasing over the past few months, which might have hit some ELB limits and causing 5XX errors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Alternatives Considered&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Move Gothena instances into a different subnet&lt;/li&gt;
  &lt;li&gt;Move all ELBs into a different subnet&lt;/li&gt;
  &lt;li&gt;Use service discovery to connect internal services and bypass ELB&lt;/li&gt;
  &lt;li&gt;Use weighted DNS + bunch of other config to balance the load&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the 4 solutions could solve our problem too but seeing how disabling IPv6 and using Cgo for DNS resolution required the least effort, we went with that.&lt;/p&gt;

&lt;p&gt;Stay tuned for part 2 which will go into detail about the RFC, why disabling IPv6 and using Cgo works as well as what our plans are for the future.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: All the sensitive information in this article has been modified and does not reflect the true state of our systems.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Gothena ‚Äì An internal service that is in-charge of all driver communications logic. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/elasticloadbalancing/&quot;&gt;AWS ELB&lt;/a&gt; ‚Äì AWS Elastic Load Balancer, a load balancing service that is offered by AWS. There can be more than one instance representing an AWS ELB. DNS RoundRobin is used to distribute connections among AWS ELB instances. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ts-elb-error-message.html#ts-elb-errorcodes-http504&quot;&gt;ELB HTTP 5xx errors&lt;/a&gt; ‚Äì An HTTP 5xx error that is returned by the ELB instead of the backend service. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Astrolabe ‚Äì An internal service that is in charge of storing and processing all driver location data. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html&quot;&gt;ELB SurgeQueue&lt;/a&gt; - The number of requests that are pending routing. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;ELB SpillOver - The total number of requests that were rejected because the surge queue is full. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;ELB Latency - The time elapsed, in seconds, after the request leaves the load balancer until the headers of the response are received. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/route53&quot;&gt;AWS Route 53&lt;/a&gt; - A managed cloud DNS solution provided by AWS. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://golang.org/cmd/cgo/&quot;&gt;Cgo&lt;/a&gt; - Cgo enables the creation of Go packages that call C code. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 10 May 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/troubleshooting-unusual-aws-elb-5xx-error</link>
        <guid isPermaLink="true">http://engineering.grab.com/troubleshooting-unusual-aws-elb-5xx-error</guid>
        
        <category>AWS</category>
        
        <category>Networking</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Scaling Like a Boss with Presto</title>
        <description>&lt;p&gt;A year ago, the data volumes at Grab were much lower than the volume we currently use for data-driven analytics. We had a simple and robust infrastructure in place to gather, process and store data to be consumed by numerous downstream applications, while supporting the requirements for data science and analytics.&lt;/p&gt;

&lt;p&gt;Our analytics data store, Amazon Redshift, was the primary storage machine for all historical data, and was in a comfortable space to handle the expected growth. Data was collected from disparate sources and processed in a daily batch window; and was available to the users before the start of the day. The data stores were well-designed to benefit from the distributed columnar architecture of Redshift, and could handle strenuous SQL workloads required to arrive at insights to support out business requirements.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Redshift Architecture&quot; src=&quot;/img/scaling-like-a-boss-with-presto/redshift-architecture.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;While we were confident in handling the growth in data, what really got challenging was to cater to the growing number of users, reports, dashboards and applications that accessed the datastore. Over time, the workloads grew in significant numbers, and it was getting harder to keep up with the expectations of returning results within required timelines. The workloads are peaky with Mondays being the most demanding of all. Our Redshift cluster would struggle to handle the workloads, often leading to really long wait times, occasional failures and connection timeouts. The limited workload management capabilities of Redshift also added to the woes.&lt;/p&gt;

&lt;p&gt;In response to these issues, we started conceptualizing an alternate architecture for analytics, which could meet our main requirements:
- The ability to scale and to meet the demands of our peaky workload patterns
- Provide capabilities to isolate different types of workloads
- To support future requirements of increasing data processing velocity and reducing time to insight&lt;/p&gt;

&lt;h3 id=&quot;so-we-built-the-data-lake&quot;&gt;So we built the data lake&lt;/h3&gt;

&lt;p&gt;We began our efforts to overcome the challenges in our analytics infrastructure by building out our Data Lake. It presented an opportunity to decouple our data storage from our computational modules while providing reliability, robustness, scalability and data consistency. To this effect, we started replicating our existing data stores to Amazon‚Äôs Simple Storage Service (S3), a platform proven for its high reliability, and widely used by data-driven companies as part of their analytics infrastructure.&lt;/p&gt;

&lt;p&gt;The data lake design was primarily driven by understanding the expected usage patterns, and the considerations around the tools and technologies allowing the users to effectively explore the datasets in the data lake. The design decisions were also based on the data pipelines that would collect the data and the common data transformations to shape and prepare the data for analysis.&lt;/p&gt;

&lt;p&gt;The outcome of all those considerations were:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;All large datasets were sharded/partitioned based on the timestamps, as most of the data analysis involved a specific time range and it gave an almost even distribution of data over a length of time. The granularity was at an hour, since we designed the data pipelines to perform hourly incremental processing. We followed the prescribed technique to build the S3 keys for the partitions, which is using the year, month, day and hour prefixes that are known to work well with big data tools such as Hive and Spark.&lt;/li&gt;
  &lt;li&gt;Data was stored as AVRO and compressed for storage optimizations. We considered several of the available storage formats - ORC, Parquet, RC File, but AVRO emerged as the elected winner mainly due to its compatibility with Redshift. One of the focus points during the design was to offload some of the heavy workloads run on Redshift to the data lake and have the processed data copied to Redshift.&lt;/li&gt;
  &lt;li&gt;We relied on Spark to power our data pipelines and handle the important transformations. We implemented a generic framework to handle different data collection methodologies from our primary data sources - MySQL and Amazon Kinesis. The existing workloads in Redshift written in SQL were easy enough to be replicated on Spark SQL with minimal syntax changes. For everything else we relied on the Spark data frame API.&lt;/li&gt;
  &lt;li&gt;The data pipelines were designed to perform, what we started to term as RDP, Recursive Data Processing. While majority of the data sets handled were immutable such as driver states, availability and location, payment transactions, fare requests and more, we still had to deal with the mutable nature of our most important datasets - bookings and candidates. The life cycle of a passenger booking request goes through several states from the starting point of when the booking request was made, through the assignment of the driver, to the length of the ride until completion. Since we collected data at hourly intervals we had to reprocess the bookings previously collected and update the records in the data lake. We performed this recursively until the final state of the data was captured. Updating data stored as files in the data lake is an expensive affair and our strategy to partition, format and compress the data made it achievable using Spark jobs.&lt;/li&gt;
  &lt;li&gt;RDP posed another interesting challenge. Most of the data transformation workloads, for example - denormalizing the data from multiple sources, required the availability of the individual hourly datasets before the workloads were executed. Managing the workloads to orchestrate complex dependencies at hourly frequencies required a suitable scheduling tool. We were faced with the classic question - to adapt, or to build our own? We chose to build a scheduler that fit the bill.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once we had the foundational blocks defined and the core components in place, the actual effort in building the data lake was relatively low and the important datasets were available to the users for exploration and analytics in a matter of few days to weeks. Also, we were able to offload some of the workload from Redshift to the data lake with EMR + Spark as the platform and computational engine respectively. However, retrospectively speaking, what we didn‚Äôt take into account was the adaptability of the data lake and the fact that majority of our data consumers had become more comfortable in using a SQL-based data platform such as Redshift for their day-to-day use of the data stores. Working with the data using tools such as Spark and Zeppelin involved a larger learning curve and was limited to the skill sets of the data science teams.&lt;/p&gt;

&lt;p&gt;And more importantly, we were yet to tackle our most burning challenge, which was to handle the high workload volumes and data requests that was one of our primary goals when we started. We aimed to resolve some of those issues by offloading the heavy workloads from Redshift to the data lake, but the impact was minimal and it was time to take the next steps. It was time to presto.&lt;/p&gt;

&lt;h3 id=&quot;gusto-with-presto&quot;&gt;Gusto with Presto&lt;/h3&gt;

&lt;p&gt;SQL on Hadoop has been an evolving domain, and is advancing at a fast pace matching that of other big data frameworks. A lot of commercial distributions of the Hadoop platform have taken keen interest in providing SQL capabilities as part of their ecosystem offerings. Impala, Stinger, Drill appear to be the frontrunners, but being on the AWS EMR stack, we looked at Presto as our SQL engine over the data lake in S3.&lt;/p&gt;

&lt;p&gt;The very first thing we learnt was the lack of support for the AVRO format in Presto. However, that seemed to be the only setback as it was fairly straightforward to adapt Parquet as the data storage format instead of AVRO. Presto had excellent support for Hive metastore, and our data lake design principles were a perfect fit for that. AWS EMR had a fairly recent version of Presto when we started (they have upgraded to more recent versions since). Presto supports ANSI SQL. While the syntax was slightly different to Redshift, we had no problems to adapt and work with that. Most importantly, our performance benchmarks showed results that were much better than anticipated. A lot of online blogs and articles about Presto always tend to benchmark its performance against Hive which frankly doesn‚Äôt provide any insights on how well Presto can perform. What we were more interested in was to compare the performance of Presto over Redshift, since we were aiming to offload the Redshift workloads to Presto. Again, this might not be a fair enough comparison since Redshift can be blazingly fast with the right distribution and sort keys in place, and well written SQL queries. But we still aimed to hit at-least 50-60% of the performance numbers with Presto as compared to Redshift, and were able to achieve it in a lot of scenarios. Use cases where the SQL only required a few days of data (which was mostly what the canned reports needed), due to the partitions in the data, Presto performed as well as (if not better than) Redshift. Full table scans involving distribution and sort keys in Redshift were a lot faster than Presto for sure, but that was only needed as part of ad-hoc queries that were relatively rare.&lt;/p&gt;

&lt;p&gt;We compared the query performance for different types of workloads:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A. Aggregation of data on the entire table (2 Billion records)
    &lt;ul&gt;
      &lt;li&gt;Sort key column used in Redshift&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B. Aggregation of data with a specific data range (1 week)
    &lt;ul&gt;
      &lt;li&gt;Partitioning fields used in Presto&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;C. Single record fetch&lt;/li&gt;
  &lt;li&gt;D. Complex SQL query with join between a large table (with date range) and multiple small tables&lt;/li&gt;
  &lt;li&gt;E. Complex SQL query with join between two large tables (with date range) and multiple small tables&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Presto vs Redshift Performance Comparison&quot; src=&quot;/img/scaling-like-a-boss-with-presto/presto-vs-redshift.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Notes on the performance comparison:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The Presto and Redshift clusters had similar configurations&lt;/li&gt;
  &lt;li&gt;No other workloads were being executed when the performance tests were run.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Although Presto could not exceed the query performance of Redshift in all scenarios, we could divide the workloads across different Presto clusters while maintaining a single underlying storage layer. We wanted to move away from a monolithic multi-tenant to a completely different approach of shared-data multi-cluster architecture, with each cluster catering to a specific application or a type of usage or a set of users. Hosting Presto on EMR provided us with the flexibility to spin up new clusters in a matter of minutes, or scale existing clusters during peak loads.&lt;/p&gt;

&lt;p&gt;With the introduction of Presto to our analytics stack, the architecture now stands as depicted:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Redshift Architecture&quot; src=&quot;/img/scaling-like-a-boss-with-presto/presto-architecture.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;From an implementation point of view, each Presto cluster would connect to a common Hive metastore built on RDS. The Hive metastore provided the abstraction over the Parquet datasets stored in the data lake. Parquet is the next best known storage format suited for Presto after ORC, both of which are columnar stores with similar capabilities. A common metastore meant that we only had to create a Hive external table on the datasets in S3 and register the partitions once, and all the individual presto clusters would have the data available for querying. This was both convenient and provided an excellent level of availability and recovery. If any of the cluster went down, we would failover to a standby Presto cluster in a jiffy, and scale it for production use. That way we could ensure business continuity and minimal downtime and impact on the performance of the applications dependant on Presto.&lt;/p&gt;

&lt;p&gt;The migration of workloads and canned SQL queries from Redshift to Presto was time consuming, but all in all, fairly straightforward. We built custom UDFs for Presto to simplify the process of migration, and extended the support on SQL functions available to the users. We learnt extensively about writing optimized queries for Presto along the way. There were a few basic rules of thumb listed below, which helped us achieve the performance targets we were hoping for.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Always rely on the time-based partition columns whenever querying large datasets. Using the partition columns restricts the amount of data being read from S3 by Presto.&lt;/li&gt;
  &lt;li&gt;When joining multiple tables, ordering the join sequences based on the size of the table (from largest to the smallest) provided significant performance benefits and also helped avoid skewness in the data that usually leads to ‚Äúexceeds memory limit‚Äù exceptions on Presto.&lt;/li&gt;
  &lt;li&gt;Anything other than equijoin conditions would cause the queries to be extremely slow. We recommend avoiding non equijoin conditions as part of the ON clause, and instead apply them as a filter within the WHERE clause wherever possible.&lt;/li&gt;
  &lt;li&gt;Sorting of data using &lt;code class=&quot;highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clauses must be avoided, especially when the resulting dataset is large.&lt;/li&gt;
  &lt;li&gt;If a query is being filtered to retrieve specific partitions, use of SQL functions on the partitioning columns as part of the filtering condition leads to a really long PLANNING phase, during which Presto is trying to figure out the partitions that need to be read from the source tables. The partition column must be used directly to avoid this effect.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;back-on-the-highway&quot;&gt;Back on the Highway&lt;/h3&gt;

&lt;p&gt;It has been a few months since we have adopted Presto as an integral part of our analytics infrastructure, and we have seen excellent results so far. On an average we cater to 1500 - 2000 canned report requests a day at Grab, and support ad-hoc/interactive query requirements which would most likely double those numbers. We have been tracking the performance of our analytics infrastructure since last year (during the early signs of the troubles). We hit the peak just before we deployed Presto into our production systems, and the migration has since helped us achieve a 400% improvement in our 90th percentile numbers. The average execution times of queries have also improved significantly, and we have successfully eliminated the high wait times that were associated with the Redshift workload manager during periods with large numbers of concurrent requests.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Adding Presto to our stack has give us the boost we needed to scale and meet the growing requirements for analytics. We have future-proofed our infrastructure by building the data lake, and made it easier to evaluate and adapt new technologies in the big data space. We hope this article has given you insights in Grab‚Äôs analytics infrastructure. We would love to hear your thoughts or your experience, so please do leave a note in the comments below.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Many thanks to Edwin Law who reviewed drafts and waited patiently for it to be published.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 01 May 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/scaling-like-a-boss-with-presto</link>
        <guid isPermaLink="true">http://engineering.grab.com/scaling-like-a-boss-with-presto</guid>
        
        <category>Analytics</category>
        
        <category>AWS</category>
        
        <category>Data</category>
        
        <category>Storage</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Deep Dive Into iOS Automation At Grab - Continuous Delivery</title>
        <description>&lt;p&gt;This is the second part of our series ‚ÄúDeep Dive into iOS Automation at Grab‚Äù, where we will cover how we manage continuous delivery. The first article is available &lt;a href=&quot;/deep-dive-into-ios-automation-at-grab-integration-testing&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a common solution to the limitations of an Apple developer account‚Äôs device whitelist, we use an enterprise account to distribute beta apps internally. There are 4 build configurations per target:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adhoc QA -&lt;/strong&gt; Most frequently distributed builds for mobile devs and QAs whose devices present in the ad hoc provisioning profile.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hot Dogfood -&lt;/strong&gt; Similar to Adhoc QA (both have debug options to connect to a staging environment) but signed under an enterprise account. This build is meant for backend devs to test out their APIs on staging.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dogfood -&lt;/strong&gt; Company-wide beta testing that includes both the online and offline team. This is often released when new features are ready or accepted by QA. It can also be a release candidate before we submit to the App Store.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Testflight -&lt;/strong&gt; Production regression testing for QA team. The accepted build will be submitted to the App Store for release.&lt;/p&gt;

&lt;p&gt;The first 3 are distributed through &lt;a href=&quot;https://get.fabric.io/&quot;&gt;Fabric&lt;/a&gt;. The last one is, of course, distributed through iTunes Connect. Archiving is done simply through bash scripts. Why did we move away from Fastlane? First of all, our primary need is archiving. We don‚Äôt really need a bunch of other powerful features. The scripts simply perform clean build and archive actions using &lt;code class=&quot;highlighter-rouge&quot;&gt;xcodebuild&lt;/code&gt;. Each of them is less than 100 lines. Secondly, it‚Äôs so much easier and flexible for us to customize our own script. E.g. final modifications to the code before archiving. Lastly, we have one less dependency. That means one less step to provision a new server.&lt;/p&gt;

&lt;h3 id=&quot;server-side-swift&quot;&gt;Server-side Swift&lt;/h3&gt;

&lt;p&gt;Now whenever we need a new build we simply execute a script. But the question is, who should do it? It‚Äôs clearly not an option to login to the build machine and do it manually. So again, as a whole bunch of in-house enthusiasts, we wrote a simple app using server-side Swift. The first version was implemented by our teammate &lt;a href=&quot;https://github.com/mno2&quot;&gt;Paul Meng&lt;/a&gt;. It has gone through a few iterations over time.&lt;/p&gt;

&lt;p&gt;The app integrates with &lt;a href=&quot;https://github.com/pvzig/SlackKit.git&quot;&gt;SlackKit&lt;/a&gt; using Swift Package Manager and listens to the command from a Slackbot &lt;strong&gt;@iris&lt;/strong&gt;. (In case you were wondering, Iris is not someone on the team. Iris is the reverse of Siri üôä. We love Iris.)&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Goddess Iris&quot; src=&quot;/img/ios-automation/goddess-iris.png&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Iris Slack&quot; src=&quot;/img/ios-automation/iris-slack.png&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Irisbot&lt;/code&gt; is a Swift class that conforms to &lt;code class=&quot;highlighter-rouge&quot;&gt;messageEventsDelegate&lt;/code&gt; protocol offered by SlackKit. When it receives a message, we parse the message and enqueue a job into a customized serialized &lt;code class=&quot;highlighter-rouge&quot;&gt;DispatchQueue&lt;/code&gt;. Here are a few lines of the main logic.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;received&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Interpret message to get the command and sanitize user inputs...&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// Schedule a job.&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;archiveQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ync&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Execute scripts based on command.&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;shell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Scripts/&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executableFileName&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;branch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Notify Slack channel when job is done.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;webAPI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;job &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobID&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; completed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// Send ACK to the channel.&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;webAPI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sendMessage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;building... your job ID is &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobID&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now if anyone needs a build they can trigger it themselves. üéâ&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Corgi Macbook&quot; src=&quot;/img/ios-automation/corgi-macbook-meme.jpg&quot; width=&quot;80%&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Literally anyone&lt;/small&gt;
&lt;/div&gt;

&lt;h3 id=&quot;deployments&quot;&gt;Deployments&lt;/h3&gt;

&lt;p&gt;We sometimes add new features to &lt;strong&gt;@iris&lt;/strong&gt; or modify build scripts. How to deploy those changes? We did it with a little help of Capistrano. Here is how:&lt;/p&gt;

&lt;p&gt;The plain Iris project looks like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;‚îú‚îÄ‚îÄ Package.swift
‚îú‚îÄ‚îÄ Package.pins
‚îú‚îÄ‚îÄ Packages
‚îú‚îÄ‚îÄ Sources
‚îÇ   ‚îî‚îÄ‚îÄ main.swift
‚îî‚îÄ‚îÄ Scripts
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Additional files after Capistrano look like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;‚îú‚îÄ‚îÄ Gemfile
‚îú‚îÄ‚îÄ Gemfile.lock
‚îú‚îÄ‚îÄ Capfile
‚îú‚îÄ‚îÄ config
‚îÇ   ‚îú‚îÄ‚îÄ deploy
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ production.rb
‚îÇ   ‚îî‚îÄ‚îÄ deploy.rb
‚îî‚îÄ‚îÄ lib
    ‚îî‚îÄ‚îÄ capistrano
            ‚îî‚îÄ‚îÄ tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Iris doesn‚Äôt have a staging environment. So simply config the server IPs in &lt;code class=&quot;highlighter-rouge&quot;&gt;production.rb&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;x.x.x.x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;user: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;XCode Server User Name&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And then a set of variables in &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy.rb&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:application&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;osx-server&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:repo_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;git@github.com:xxx/xxxxx.git&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:deploy_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/path/to/wherever&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:keep_releases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ask&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:branch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`git rev-parse --abbrev-ref HEAD`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;chomp&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:linked_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;config.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;linked_files&lt;/code&gt; will symlink any file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;shared/&lt;/code&gt; folder on the server into the current project directory. Here we linked a &lt;code class=&quot;highlighter-rouge&quot;&gt;config.json&lt;/code&gt; which consists of the path to the iOS passenger app repo on the server and where to put the generated &lt;code class=&quot;highlighter-rouge&quot;&gt;.xcarchive&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;.ipa&lt;/code&gt; files. So that people can pass in a different value in their local machine when they want to test out their changes.&lt;/p&gt;

&lt;p&gt;We are all set. How simple is that! To deploy üöÄ, simply execute &lt;code class=&quot;highlighter-rouge&quot;&gt;cap production deploy&lt;/code&gt;.
Screwed up? &lt;code class=&quot;highlighter-rouge&quot;&gt;cap production deploy:rollback&lt;/code&gt; will rescue.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;What Grab has now, isn‚Äôt the most mature setup (there is still a lot to consider. e.g. scaling, authorization, better logging etc.), but it serves our needs at the moment. Setting up a basic working environment is not hard at all, it took an engineer slightly over a week. Every team and product has its unique needs and preferences, so do what works for you! We hope this article has given you some insights on some of the decisions made by the iOS team at Grab. We would love to hear about your experience in the comments below.&lt;/p&gt;

&lt;p&gt;Happy automating!&lt;/p&gt;
</description>
        <pubDate>Sun, 23 Apr 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/deep-dive-into-ios-automation-at-grab-continuous-delivery</link>
        <guid isPermaLink="true">http://engineering.grab.com/deep-dive-into-ios-automation-at-grab-continuous-delivery</guid>
        
        <category>Continuous Delivery</category>
        
        <category>iOS</category>
        
        <category>Mobile</category>
        
        <category>Swift</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Deep Dive Into iOS Automation At Grab - Integration Testing</title>
        <description>&lt;p&gt;This is the first part of our series ‚ÄúDeep Dive Into iOS Automation At Grab‚Äù, where we will cover testing automation in the iOS team. The second article is available &lt;a href=&quot;/deep-dive-into-ios-automation-at-grab-continuous-delivery&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Over the past two years at Grab, the iOS passenger app team has grown from 3 engineers in Singapore to 20 globally. Back then, each one of us was busy shipping features and had no time to set up a proper automation process. It was common to hear these frustrations from the team:&lt;/p&gt;

&lt;h4 id=&quot;travis-failed-again-but-it-passes-in-my-local&quot;&gt;Travis failed again but it passes in my local&lt;/h4&gt;

&lt;p&gt;There was a time when iOS 9 came out and Travis failed for us for every single integration. We tried emailing their support but the communication took longer than we would have liked, and ultimately we didn‚Äôt manage to fix the issue in time.&lt;/p&gt;

&lt;h4 id=&quot;fastlane-chose-the-wrong-provisioning-profile-again&quot;&gt;Fastlane chose the wrong provisioning profile again&lt;/h4&gt;

&lt;p&gt;We relied on &lt;a href=&quot;https://fastlane.tools/&quot;&gt;Fastlane&lt;/a&gt; for quite some time and it is a brilliant tool. There was a time, however, that some of us had issues with provisioning profiles constantly. Why and how we moved away from Fastlane will be explained later.&lt;/p&gt;

&lt;h4 id=&quot;argh-if-more-people-tested-in-production-before-the-release-this-crash-might-have-been-caught&quot;&gt;Argh, if more people tested in production before the release, this crash might have been caught&lt;/h4&gt;

&lt;p&gt;Prior to the app release, we do regression testing in a production environment. In the past, this was done almost entirely by our awesome QA team via Testflight distributions exclusively. That meant it was hard to cover all combinations of OSes, device models, locations and passenger account settings. We had prior incidents that only happened to a particular phone model, operating system, etc. Those gave us motivation to install a company-wide dogfooding program.&lt;/p&gt;

&lt;p&gt;If you can relate to any of the above. This article is for you. We set up and developed most of the stuff below in-house, hence if you don‚Äôt have the time or manpower to maintain, it is still better to go with third-party services.&lt;/p&gt;

&lt;p&gt;Testing and distribution are two aspects that we put a lot of effort in automating. Part I will cover how we do integration tests at Grab.&lt;/p&gt;

&lt;h3 id=&quot;testing---xcode-server&quot;&gt;Testing - Xcode Server&lt;/h3&gt;

&lt;p&gt;Besides being a complete Apple fan myself, there are a couple of other reasons why we chose Xcode Server over &lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis&lt;/a&gt; and &lt;a href=&quot;https://www.bitrise.io/&quot;&gt;Bitrise&lt;/a&gt; (which our Android team uses) to run our tests.&lt;/p&gt;

&lt;h4 id=&quot;faster-integration&quot;&gt;Faster integration&lt;/h4&gt;

&lt;p&gt;Unlike most cloud services where every test is run in a random box from a macOS farm, at Grab, we have complete control of what machine we connect to. Provisioning a server (pretty much downloading Xcode, a macOS server, combined with some extremely simple steps) is a one-time affair and does not have to be repeated during each integration. e.g. Installing correct version of Cocoapod and command line libraries.&lt;/p&gt;

&lt;p&gt;Instead of fresh cloning a repository, Xcode Server simply checks out the branch and pulls the latest code. That can save time especially when you have a long commit history.&lt;/p&gt;

&lt;h4 id=&quot;native-native-native&quot;&gt;Native native native&lt;/h4&gt;

&lt;p&gt;It is a lot more predictable. It guarantees that it‚Äôs the same OS, same Xcode version, same Swift version. If the tests passes on your Xcode, and on your teammates‚Äô Xcodes, it will pass on the server‚Äôs Xcode.&lt;/p&gt;

&lt;h4 id=&quot;perfect-ui-testing-process-recording&quot;&gt;Perfect UI Testing Process Recording&lt;/h4&gt;

&lt;p&gt;This is the most important reason and is something Travis / Bitrise didn‚Äôt offer at the time I was doing my research. When a UI test fails, knowing which line number caused it to fail is simply not enough. You would rather know what exactly happened. Xcode Server records every single step of your integration just like Xcode. You can easily skim through the whole process and view the screenshots at each stage. Xcode 8 even allows you to view a live screen on the Xcode Server while an integration is running.&lt;/p&gt;

&lt;p&gt;For those of you who are familiar with UI testing on Xcode, you can view the results from the server in the exact same format. Clicking on the eye icon allows you to view the screenshots.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Xcode UI Tests&quot; src=&quot;/img/ios-automation/xcode-ui-tests.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Sounds good! Let‚Äôs get started. On the day we got our server, we found creative ways to use it.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Mac Pro&quot; src=&quot;/img/ios-automation/mac-pro.jpg&quot; width=&quot;60%&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Our multi-purpose server ‚ôªÔ∏è&lt;/small&gt;
&lt;/div&gt;

&lt;h3 id=&quot;workflow&quot;&gt;Workflow&lt;/h3&gt;

&lt;p&gt;The basic idea is to create a bot when a feature branch is pushed, trigger the bot on each commit and delete the bot after the feature is merged / branch is deleted. Grab uses &lt;a href=&quot;https://www.phacility.com/phabricator/&quot;&gt;Phabricator&lt;/a&gt; as the main code review tool. We wrote scripts to create and delete the bots as &lt;a href=&quot;https://secure.phabricator.com/book/phabricator/article/arcanist/&quot;&gt;Arcanist&lt;/a&gt; post diff (branch is created/updated) and land (branch is merged) hooks.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Surprised Koala&quot; src=&quot;/img/ios-automation/surprised-koala.jpg&quot; width=&quot;60%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Some PHP is still required. This is all of it üòπ:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$botCommand = &quot;ruby bot.rb trigger $remoteBranchName&quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Creating a bot manually is simply a &lt;code class=&quot;highlighter-rouge&quot;&gt;POST&lt;/code&gt; request to your server with the bot specifications in body and authentication in headers. You can totally use &lt;code class=&quot;highlighter-rouge&quot;&gt;cURL&lt;/code&gt;. We wrote it in Ruby:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RestClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;url: &lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XCODE_SERVER_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;method: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;post&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;verify_ssl: &lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;headers: &lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;@headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;payload: &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;201&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Successfully created bot &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;, uuid &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;_id&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Failed to create bot &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, &lt;code class=&quot;highlighter-rouge&quot;&gt;XCODE_SERVER_URL&lt;/code&gt; is configurable. This is how we scale when the team expands.&lt;/p&gt;

&lt;p&gt;Now the only thing left is to figure out the body payload. It is simple, all the bots and their configurations can be viewed as JSON via the following API. Simply create a bot via Xcode UI and it will reveal all the secrets:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -k -u username:password https://your.server.com:20343/api/bots
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Apple doesn‚Äôt have a lot of documentation on this. For a list of Xcode Server APIs you can try out &lt;a href=&quot;http://docs.xcodeserverapidocs.apiary.io/#reference/bots/bots/create-a-new-bot&quot;&gt;this list&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;gotchas&quot;&gt;Gotchas&lt;/h3&gt;

&lt;p&gt;We have been happy with the server most of the time. However, along the way we did discover several downsides:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The simulator that the Xcode Server spins up does not necessarily have customized location enabled. You probably want to mock your locations in code in testing environment.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Installed builds are being updated during each integration and reused. There might be cache issues from previous integrations. Hence, deleting the app in your pre-integration script can be a good idea:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;xcrun simctl uninstall booted your.bundle.id
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Right after upgrading Xcode, you may face some transient issues. An example from what we‚Äôve observed so far is that existing bots often can‚Äôt find the simulators that used to be attached to them. Deleting old simulators and configuring new ones will help. That may also require you to change your bot creation script depending on your configuration. Restarting the server machine sometimes helps too.&lt;/li&gt;
  &lt;li&gt;If you have one machine like us, there will be downtime during the software update. It either introduces inconvenience to your teammates or worse, someone could break master during the downtime.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stay tuned for the second part where we will cover on how we manage continuous delivery.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Many thanks to Dillion Tan and Tay Yang Shun who reviewed drafts and waited patiently for it to be published.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Apr 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/deep-dive-into-ios-automation-at-grab-integration-testing</link>
        <guid isPermaLink="true">http://engineering.grab.com/deep-dive-into-ios-automation-at-grab-integration-testing</guid>
        
        <category>Continuous Integration</category>
        
        <category>iOS</category>
        
        <category>Mobile</category>
        
        <category>Testing</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>A Key Expired In Redis, You Won&#39;t Believe What Happened Next</title>
        <description>&lt;p&gt;One of Grab‚Äôs more popular caching solutions is &lt;a href=&quot;https://redis.io/&quot;&gt;Redis&lt;/a&gt; (often in the flavour of the misleadingly named ElastiCache &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;), and for most cases, it works. Except for that time it didn‚Äôt. Follow our story as we investigate how Redis deals with consistency on key expiration.&lt;/p&gt;

&lt;p&gt;A recent problem we had with our ElastiCache Redis involving our Unicorn API, was that we were serving unusually outdated Unicorns to our clients.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Unicorn&quot; src=&quot;/img/key-expired-in-redis/unicorn.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Unicorns are in popular demand and change infrequently, and as a result, Grab Unicorns are cached at almost every service level. Unfortunately, customers typically like having shiny new unicorns as soon as they are spotted, so we had to make sure we bound our Unicorn change propagation time. In this particular case, we found that apart from the usual minuscule DB replication lag, a region-specific change in Unicorns took up to 60 minutes to reach our customers.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Cacheception&quot; src=&quot;/img/key-expired-in-redis/cacheception.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Considering that our Common Data Service (CDS) server cache (5 minutes), CDS client cache (1 minute), Grab API cache (5 minutes), and mobile cache (varies, but insignificant) together accounted for at most ~11 minutes of Unicorn change propagation time, this was a rather perplexing find. (Also, we should really consider an inter-service cache invalidation strategy for this &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.)&lt;/p&gt;

&lt;h3 id=&quot;how-we-cache-unicorns-at-the-api-level&quot;&gt;How We Cache Unicorns At The API Level&lt;/h3&gt;

&lt;p&gt;Subsequently, we investigated why the Unicorns returned from the API were up to 45 minutes stale, as tested on production. Before we share our findings, let‚Äôs go through a quick overview of what the Unicorn API‚Äôs ElastiCache Redis looks like.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Block Diagram&quot; src=&quot;/img/key-expired-in-redis/block-diagram.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We have a master node used exclusively for writes, and 2 read-only slaves &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. This is also a good time to mention that we use Redis 2.x as ElastiCache support for 3.x was only added in October 2016.&lt;/p&gt;

&lt;p&gt;As Unicorns are region-specific, we were caching Unicorns based on locations, and consequently, have a rather large number of keys in this Redis (~5594518 at the time). This is also why we encountered cases where different parts of the same city inexplicably had different Unicorns.&lt;/p&gt;

&lt;h3 id=&quot;so-what-gives&quot;&gt;So What Gives?&lt;/h3&gt;

&lt;p&gt;As part of our investigation, we tried monitoring the TTLs (Time To Live) on some keys in the Redis.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Steps (on the master node):&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Run TTL for a key, and monitor the countdown to expiry
    &lt;ul&gt;
      &lt;li&gt;Starting from 300 (seconds), it counted down to 0&lt;/li&gt;
      &lt;li&gt;After expiry, it returned -2 (expected behaviour)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Running GET on an expired key returned nothing&lt;/li&gt;
  &lt;li&gt;Running a GET on the expired key in a slave returned nothing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Interestingly, running the same experiment on the slave yielded different behaviour.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Steps (on a slave node):&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Run TTL for a key, and monitor the countdown to expiry
    &lt;ul&gt;
      &lt;li&gt;Starting from 300 (seconds), it counted down to 0&lt;/li&gt;
      &lt;li&gt;After expiry, it returned -2 (expected behaviour)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Running GET on an expired key returned data!&lt;/li&gt;
  &lt;li&gt;Running GET for the key on master returned nothing&lt;/li&gt;
  &lt;li&gt;Subsequent GETs on the slave returned nothing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This finding, together with the fact that we don‚Äôt read from the master branch, explained how we ended up with Unicorn ghosts, but not why.&lt;/p&gt;

&lt;p&gt;To understand this better, we needed to &lt;a href=&quot;https://en.wikipedia.org/wiki/RTFM&quot;&gt;RTFM&lt;/a&gt;. More precisely, we need two key pieces of information.&lt;/p&gt;

&lt;h4 id=&quot;how-expires-are-managed-between-master-and-slave-nodes-on-redis-2x&quot;&gt;How EXPIREs Are Managed Between Master And Slave Nodes On Redis 2.x&lt;/h4&gt;

&lt;p&gt;To ‚Äúmaintain consistency‚Äù, slaves aren‚Äôt allowed to expire keys unless they receive a DEL from the master branch, even if they know the key is expired. The only exception is when a slave becomes master &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. So basically, if the master doesn‚Äôt send a DEL to the slave, the key (which might have been set with a TTL using the Redis API contract), is not guaranteed to respect the TTL it was set with. This is when you scale to have read slaves, which, apparently, is a shocking requirement in production systems.&lt;/p&gt;

&lt;h4 id=&quot;how-expires-are-managed-for-keys-that-arent-gotten-from-master&quot;&gt;How EXPIREs Are Managed For Keys That Aren‚Äôt ‚Äúgotten from master‚Äù&lt;/h4&gt;

&lt;p&gt;Since every key needs to be deleted on master first, and some of our keys were expired correctly, there had to be a ‚Äúpassive‚Äù manner in which Redis was deleting expired keys that didn‚Äôt involve an explicit GET command from the client. The manual &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Redis keys are expired in two ways: a passive way, and an active way.&lt;/p&gt;

  &lt;p&gt;A key is passively expired simply when some client tries to access it, and the key is found to be timed out.&lt;/p&gt;

  &lt;p&gt;Of course this is not enough as there are expired keys that will never be accessed again. These keys should be expired anyway, so periodically Redis tests a few keys at random among keys with an expire set. All the keys that are already expired are deleted from the keyspace.&lt;/p&gt;

  &lt;p&gt;Specifically this is what Redis does 10 times per second:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;Test 20 random keys from the set of keys with an associated expire.&lt;/li&gt;
    &lt;li&gt;Delete all the keys found expired.&lt;/li&gt;
    &lt;li&gt;If more than 25% of keys were expired, start again from step 1.&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;This is a trivial probabilistic algorithm, basically the assumption is that our sample is representative of the whole key space, and we continue to expire until the percentage of keys that are likely to be expired is under 25%.&lt;/p&gt;

  &lt;p&gt;This means that at any given moment the maximum amount of keys already expired that are using memory is at max equal to max amount of write operations per second divided by 4.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So that‚Äôs 200 keys tested for expiry each second on the master branch, and about 25% of your keys on the slaves guaranteed to be serving dead Unicorns, because they didn‚Äôt get the memo.&lt;/p&gt;

&lt;p&gt;While 200 keys/s might be enough to make it through a hackathon project blazingly fast, it certainly isn‚Äôt fast enough at our scale, to expire 25% of our 5594518 keys in time for Unicorn updates.&lt;/p&gt;

&lt;h4 id=&quot;doing-the-math&quot;&gt;Doing The Math&lt;/h4&gt;

&lt;p&gt;Number of expired keys (at iteration 0) = &lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Total number of keys = &lt;em&gt;s&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Probability of choosing an expired key (&lt;em&gt;p&lt;/em&gt;) = &lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt; / s&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Assuming Binomial trials, the expected number of expired keys chosen in n trials:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;E&lt;/em&gt; = &lt;em&gt;n * p&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Number of expired keys for next iteration =&lt;/p&gt;

&lt;p&gt;&lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt; - E = e&lt;sub&gt;0&lt;/sub&gt; - n * (e&lt;sub&gt;0&lt;/sub&gt; / s) = e&lt;sub&gt;0&lt;/sub&gt; * (1 - n / s)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Number of expired keys at the end of iteration &lt;em&gt;k&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;e&lt;sub&gt;k&lt;/sub&gt;&lt;/em&gt; = &lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt; * (1 - n / s)&lt;sup&gt;k&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So to have fewer than 1 expired key,&lt;/p&gt;

&lt;p&gt;&lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt; * (1 - n / s)&lt;sup&gt;k&lt;/sup&gt; &amp;lt; 1&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;=&amp;gt; k &amp;lt; ln(1 / e&lt;sub&gt;0&lt;/sub&gt;) / ln(1 - n / s)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Assuming we started with 25% keys expired, we plug in:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;e&lt;sub&gt;0&lt;/sub&gt; = 0.25 * 5594518, n = 20, s = 5594518&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We obtain a value of &lt;em&gt;k&lt;/em&gt; around 3958395. Since this is repeated 10 times a second, it would take roughly 110 hours to achieve this (as &lt;em&gt;e&lt;sub&gt;k&lt;/sub&gt;&lt;/em&gt; is a decreasing function of &lt;em&gt;k&lt;/em&gt;).&lt;/p&gt;

&lt;h3 id=&quot;the-bottom-line&quot;&gt;The Bottom Line&lt;/h3&gt;

&lt;p&gt;At our scale, and assuming &amp;gt;25% expired keys at the beginning of time, it would take at least 110 hours to guarantee no expired keys in our cache.&lt;/p&gt;

&lt;h3 id=&quot;what-we-learnt&quot;&gt;What We Learnt&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The Redis author pointed out and fixed this issue in a later version of Redis &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Upgrade our Redis more often&lt;/li&gt;
  &lt;li&gt;Pay more attention to cache invalidation expectations and strategy during software design&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Many thanks to Althaf Hameez, Ryan Law, Nguyen Qui Hieu, Yu Zezhou and Ivan Poon who reviewed drafts and waited patiently for it to be published.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;ElastiCache is hardly elastic, considering your ‚Äúscale up‚Äù is a deliberate process involving backup, replicate, deploy, and switch, during which time your server is serving peak hour teapots (as reads and writes may be disabled). &lt;a href=&quot;http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Scaling.html&quot;&gt;http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Scaling.html&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Turns out that streaming solutions are rather good at this, when we applied them to some of our non-Unicorn offerings. (Writes are streamed, and readers listen and invalidate their cache as required.) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;This, as it turns out, is a bad idea. In case of failovers, AWS updates the master address to point to the new master, but this is not guaranteed for the slaves. So we could end up with an unused slave and a master with reads + writes in the worst case (unless we add some custom code to manage the failover). Best practice is to have read load distributed on master as well. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://redis.io/commands/expire#how-expires-are-handled-in-the-replication-link-and-aof-file&quot;&gt;https://redis.io/commands/expire#how-expires-are-handled-in-the-replication-link-and-aof-file&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://redis.io/commands/expire#how-redis-expires-keys&quot;&gt;https://redis.io/commands/expire#how-redis-expires-keys&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/antirez/redis/issues/1768&quot;&gt;https://github.com/antirez/redis/issues/1768&lt;/a&gt; (TL;DR: Slaves now use local clock to return null to clients when it thinks keys are expired. The trade-off is the possibility of early expires if a slave‚Äôs clock is faster than the master.) &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 27 Mar 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/a-key-expired-in-redis-you-wont-believe-what-happened-next</link>
        <guid isPermaLink="true">http://engineering.grab.com/a-key-expired-in-redis-you-wont-believe-what-happened-next</guid>
        
        <category>Back End</category>
        
        <category>Redis</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How Grab Hires Engineers In Singapore</title>
        <description>&lt;p&gt;&lt;em&gt;Working at Grab will be the ‚Äúmost challenging yet rewarding opportunity‚Äù any employee will ever encounter.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Grab App Make Booking&quot; src=&quot;/img/how-grab-hires-engineers-in-singapore/grab-app-make-booking.jpg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;When was the last time you met someone who was happy with his or her job?&lt;/p&gt;

&lt;p&gt;Yeah, me too. Complaining about work is probably one of the greatest Singaporean pastimes yet.&lt;/p&gt;

&lt;p&gt;A recent study conducted by &lt;a href=&quot;http://www.jobstreet.com.sg/career-resources/singapores-workforce-ranks-unhappiest-amongst-asian-counterparts-2/#.WKFd8xJ97sk&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;JobStreet&lt;/a&gt; found that Singaporean workers were the most dissatisfied in the region. Out of the 7 Asian countries surveyed, Singaporean workers had the lowest average job satisfaction rating at 5.09 out of 10.&lt;/p&gt;

&lt;p&gt;That‚Äôs close to failing, something we don‚Äôt take kindly to. Here‚Äôs how we measure up:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;JobStreet Regional Job Happiness Index&quot; src=&quot;/img/how-grab-hires-engineers-in-singapore/regional-job-happiness-index.jpg&quot; width=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Simply put, it‚Äôs not easy to find a job that you‚Äôll be happy in. Each stage of the hiring process - from attending interviews to negotiating job offers - reveals a bit more information about your future position, but much of it is cloaked in hearsay and secrecy.&lt;/p&gt;

&lt;p&gt;We, however, are on your side. We want to make the hiring process as transparent as possible so that you, dear reader, will be able to make a more informed choice. After all, this is the job that you‚Äôll spend a good bulk of your time at.&lt;/p&gt;

&lt;p&gt;For this reason, we‚Äôre embarking on a series of articles that will uncover the hiring processes of leading technology companies in Singapore. Let us know how we can improve on this - what other information you‚Äôd like to see, which companies you‚Äôd like to read about here, and so on.&lt;/p&gt;

&lt;p&gt;First up, a ride-hailing company that has &lt;a href=&quot;https://www.techinasia.com/companies/grab&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;raised US$1.4 billion in funding&lt;/a&gt; (that we know of) to date - &lt;strong&gt;Grab&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;interview-process-at-grab&quot;&gt;Interview Process at Grab&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Rachel Lee Cherry Blossoms&quot; src=&quot;/img/how-grab-hires-engineers-in-singapore/rachel-lee-cherry-blossoms.jpg&quot; width=&quot;75%&quot; /&gt;
  &lt;small class=&quot;post-image-caption&quot;&gt;Rachel Lee, Grab‚Äôs Talent Acquisition Business Partner, Regional Tech&lt;/small&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Not surprisingly, they experience a high volume of inbound candidates for some of their more popular roles, but few make it to the final stage. ‚ÄúOn average, it could be as low as 3 to 5 per cent of candidates who start the interview process to reach to offer stage, as our bar for engineering talent is set really high ‚Äì for good reason!‚Äù Rachel explains.&lt;/p&gt;

&lt;p&gt;From start to end, the number of interview rounds highly depends on the role in question, and how senior the position is. A 100offer user who recently joined Grab tells us that his journey took between three to four weeks , during which he went through the following interview rounds: one phone screen interview with a Human Resources representative, one online coding round, and two rounds of technical tests.&lt;/p&gt;

&lt;p&gt;The final technical round was conducted with three Grab software engineers in quick succession.&lt;/p&gt;

&lt;p&gt;In the first cut, Rachel takes a look at a variety of factors to assess if an engineering candidate is suitable or not.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚Äú[First], we take a look at their demonstrated ability in previous projects as listed on GitHub. The complexity of the projects is of interest to us,‚Äù she says. ‚ÄúI will seek out their blogs, slideshow presentations, as well as review peer recommendations to ensure I am able to create a more holistic profile of the individual.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On the subject of qualifications, she deems them to be secondary, as ‚Äúmany qualified and suitable candidates for us would not have passed a typical CV screen otherwise.‚Äù&lt;/p&gt;

&lt;h3 id=&quot;technical-vs-cultural-fit&quot;&gt;Technical vs. Cultural Fit&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;
  &lt;img alt=&quot;Happy Grab Employees&quot; src=&quot;/img/how-grab-hires-engineers-in-singapore/happy-grab-employees.jpg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Beyond technical proficiency and competency, however, they also take special care to evaluate if candidates fit Grab‚Äôs culture and values:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúTo succeed and thrive in a growing company, we want adaptable people, equally balanced with soft and hard skills, who are driven and eager to make a difference to solving and improving transportation in Southeast Asia.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sounds like a tall order? Bear in mind that only 3 to 5% of candidates actually get an offer.&lt;/p&gt;

&lt;p&gt;To be part of this select group, Rachel explains that there are some hard and soft skills that she tends to look out for:&lt;/p&gt;

&lt;h4 id=&quot;hard-skills&quot;&gt;Hard Skills&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Experience developing software that is highly scalable, distributed service geared for low latency read requests&lt;/li&gt;
  &lt;li&gt;Experience building complex distributed systems - helping our systems to be faster, more scalable, more reliable, better!&lt;/li&gt;
  &lt;li&gt;Mobile experience - Different than other engineering roles but share a lot of the same attributes, show some interest and knowledge in these areas: applications, data, and mobile UI/UX&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;soft-skills&quot;&gt;Soft Skills&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Willingness to collaborate&lt;/li&gt;
  &lt;li&gt;Thoughtful communication style with clearly thought through, logical solutions&lt;/li&gt;
  &lt;li&gt;Entrepreneurial spirit and a track record of doing whatever it takes to succeed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Between cultural and technical fit, which weighs more heavily in Grab‚Äôs hiring process? To Rachel, both are equally important, though cultural fit is critical in sealing the deal.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúNo matter how technically capable a candidate is, we will not proceed with a job offer if the team will not enjoy working with the person,‚Äù she says. ‚ÄúWe are really focused on creating and maintaining a great working culture at Grab!‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Rachel uses the example of one of Grab‚Äôs principles, ‚ÄúYour problem is my problem.‚Äù&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúWe want people who will take the initiative to offer help to their fellow colleagues.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;grabs-interview-questions&quot;&gt;Grab‚Äôs Interview Questions&lt;/h4&gt;

&lt;p&gt;For Rachel, she‚Äôs ‚Äúlaser focused on strategic recruitment for mid- to senior- level hires in engineering, and she ‚Äúexpects all our future Grabbers to come with a high level of technical ability.‚Äù The questions she asks candidates in the technical rounds follow accordingly:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúFor senior leaders, we ask them about the last, or the best technical decisions they have made recently, that had impact on scalability and high availability performant systems; as well as their thought processes around design for solutions for backend microservices, if not, in areas of their pursuant domain.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In addition, our 100offer user recalls that he was fielded more algorithm questions than other interviews that he attended previously.&lt;/p&gt;

&lt;p&gt;Beyond that, Rachel and her colleagues tend to quiz candidates on their career ambitions, as well as find out whether they have ‚Äúa good aptitude for learning and collaboration with colleagues from all around the world.‚Äù This is necessary as Grab currently has more than 30 nationalities in their ranks.&lt;/p&gt;

&lt;p&gt;For senior candidates, Rachel will ‚Äúoften ask them their views on their hiring philosophy - how they would hire a good engineer, as well as how they would build a strong, cohesive and high-performing team.‚Äù&lt;/p&gt;

&lt;p&gt;‚ÄúIt is critical that we understand a senior candidate‚Äôs management style,‚Äù she emphasizes.&lt;/p&gt;

&lt;p&gt;For junior candidates, she would ask questions that help give a sense of their sense of responsibility and interest in being a team owner and manager, as well as their commitment to building a long and successful career with Grab.&lt;/p&gt;

&lt;p&gt;‚ÄúQuestions we ask are focused on assessing future aptitude for leadership roles, and their analytical skills and thought processes when it comes to solving problems.‚Äù&lt;/p&gt;

&lt;h4 id=&quot;insider-tips&quot;&gt;Insider Tips&lt;/h4&gt;

&lt;p&gt;According to Rachel, there are many opportunities to relocate and work at Grab‚Äôs Research &amp;amp; Development Centres in Beijing, Seattle, and Singapore. When relocating candidates, though, she is careful to assess their ability to adapt to a new environment.&lt;/p&gt;

&lt;p&gt;‚ÄúI recognize that their entire life can change!‚Äù she explains. ‚ÄúFor those keen to explore an overseas work opportunity with Grab, do take time to consider and research about living in Singapore. Singapore is a great place for tech talent, as it comes with plenty of opportunities in the tech industry.‚Äù&lt;/p&gt;

&lt;p&gt;Indeed, she‚Äôs extremely optimistic about the prospects of those keen on moving to Singapore, where Grab chose to &lt;a href=&quot;http://www.channelnewsasia.com/news/business/singapore/grabtaxi-opens-s-136m-r-d/1772932.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;open its US$100 million R&amp;amp;D centre&lt;/a&gt; - right in the heart of the Central Business District.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúThe city-state hosts a mature tech ecosystem and the abundance of local, regional and global companies is beneficial to tech professionals. What‚Äôs more it has been consistently ranked as the top city in the world for technology readiness, transportation, infrastructure, tax and the ease of doing business by PwC‚Äôs Cities of Opportunity report.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Furthermore, she believes that working at Grab will be the ‚Äúmost challenging yet rewarding opportunity‚Äù any employee will ever encounter. This is due to the scale and speed at which they operate.&lt;/p&gt;

&lt;p&gt;‚ÄúI personally wouldn‚Äôt trade this experience for anything else right now, and it makes it all the most critical to to have teammates who believe in the same - that we are all fighting a battle to bring lasting benefits and improvements to millions in Southeast Asia!‚Äù&lt;/p&gt;

&lt;p&gt;Grab is one of several leading technology companies hiring technical talent on 100offer‚Äôs marketplace. Sign up for 100offer to see what opportunities there are in the market right now.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This article was first published on the &lt;a href=&quot;https://www.100offer.com/blog/posts/grab-hiring-singapore/?utm_source=grab-engineering&amp;amp;utm_medium=essay&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;100offer blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 16 Feb 2017 18:43:40 +0000</pubDate>
        <link>http://engineering.grab.com/how-grab-hires-engineers-in-singapore</link>
        <guid isPermaLink="true">http://engineering.grab.com/how-grab-hires-engineers-in-singapore</guid>
        
        <category>Hiring</category>
        
        
        <category>Engineering</category>
        
      </item>
    
  </channel>
</rss>
